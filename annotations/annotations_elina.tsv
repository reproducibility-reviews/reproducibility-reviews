		For scoring a given reviewer	Put 1 if the reviewer has commented on at least one of  the items falling into this category	Put 1 if the reviewer has commented on at least one of  the items falling into this category	Put 1 if the reviewer has commented on at least one of  the items falling into this category	Put 1 if the reviewer has commented on at least one of  the items falling into this category	Put 1 if the reviewer has commented on at least one of these two aspects	Choose the category of statement	Choose the category of comments	For scoring a given reviewer								For scoring a given reviewer								Meta-categories			Aggregate over 3 reviews						Put 1 if all reviewers agree. Put 0 if at least two disagree, or if at least one review is too vague to tell if they agree
Paper ID	Paper title	Review 1	Models and algorithms	Datasets	Code	Experimental results	Error bars or statistical significance	Statement	Comments	Review 2	Models and algorithms	Datasets	Code	Experimental results	Error bars or statistical significance	Statement	Comments	Review 3	Models and algorithms	Datasets	Code	Experimental results	Error bars or statistical significance	Statement	Comments	Review 1	Review 2	Review 3	Models and algorithms	Datasets	Code	Experimental results	Error bars or statistical significance	meta-category	Agreement
001-Paper0829	3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images	Within supplementary material authors provide information about preprocessing steps and network architecture.	1	0	0	0	0	1. (none) statement	3. (+) comments	This study suggests that the reproducibility of performance can be ensured when the following two accurate annotations are secured:    Depth information: Even in spectral CT, decomposing contrast material in contrast-enhanced CT is a challenging task, and the intensity of the contrast becomes blurred and faint over time. Therefore, it is expected that many voxels with similar intensity to the contrast material will be encountered in noisy contrast-enhanced CT images depending on the image, and substantial manual work will be required to remove them, which may significantly impair reproducibility.    2D annotations: While this study obtained 2D annotations by performing forward-projection from 3D annotations, securing the quality of 2D annotations in this study might not be easy if 2D annotations were performed from the beginning. For instance, as shown in Fig. 2 (g), directly performing 2D annotation would make it difficult to accurately segment small, separated contrast voxels. If the 2D annotations are noisy, the reproducibility is likely to be compromised as well.	1	0	0	0	0	1. (none) statement	4. (-/+) comments	Didn't see the code or link contained in the submission, not sure how to comment on reproducibility.	0	0	1	0	0	1. (none) statement	2. (-) comments	Reproducible	Irreproducible	Irreproducible	2	0	1	0	0	1	Disagreement
002-Paper1655	3D Dental Mesh Segmentation Using Semantics-Based Feature Learning with Graph-Transformer	the reproducibility of the paper is very good	0	0	0	0	0	3. (+) statement	1. (none) comments	There are only mean errors/IOU etc provided, without standard deviation, error distribution nor statistical tests. There is no code provided and no data. Hyperparameters for reproduction are provided. It is unclear how easy the additions to the TSGCNet can be re-implemented. Ablation study to examine the effect of different components is provided.	1	1	1	1	1	1. (none) statement	2. (-) comments	Firstly, the article will make the code publicly available after publication, but there is no mention of publicly available datasets. According to the article description, readers can easily implement the overall framework, and each module has reference articles. The author provides an introduction to the TSGCNet method for extracting C-domain and N-domain from input images, as well as how to fuse the information of these two domains, how to fuse features of different scale features, and the process of generating pseudo labels. The author also mentioned the loss function, GPU configuration, training epochs and other relevant information in the implementation details. But for some hyperparameter and details in the network, the author has not explained in the article (maybe it can be directly obtained from the code), such as the l, the way to maximize different cells, encoder parameters, etc.	1	1	1	1	0	1. (none) statement	2. (-) comments	Reproducible	Irreproducible	Irreproducible	2	2	2	2	1	1	Disagreement
003-Paper1307	3D Medical Image Segmentation with Sparse Annotation via Cross-Teaching between 3D and 2D Networks	Methods are clearly presented. No concerns.	1	0	0	0	0	3. (+) statement	3. (+) comments	No code provided	0	0	1	0	0	1. (none) statement	2. (-) comments	Through Implementation Details.	0	0	0	0	0	1. (none) statement	1. (none) comments	Reproducible	Irreproducible	Unusable	1	0	1	0	0	1	Disagreement
004-Paper2386	3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers	seems ok	0	0	0	0	0	3. (+) statement	1. (none) comments	This paper is reproducible	0	0	0	0	0	3. (+) statement	1. (none) comments	The authors have used publicly available benchmark datasets for their experiments, which is a positive aspect for the reproducibility of the paper.	0	1	0	0	0	1. (none) statement	3. (+) comments	Reproducible	Reproducible	Reproducible	0	1	0	0	0	3	Agreement
005-Paper2035	3D Teeth Reconstruction from Panoramic Radiographs using Neural Implicit Functions	The code is not provided.	0	0	1	0	0	1. (none) statement	2. (-) comments	Dataset is not available which limits the reproducibility of the paper.	0	1	0	0	0	1. (none) statement	2. (-) comments	I think the work could be reproduced given the dataset. Well it would better to release the segmentation model.	0	1	1	0	0	3. (+) statement	2. (-) comments	Irreproducible	Irreproducible	Reproducible	0	2	2	0	0	1	Disagreement
006-Paper1808	A Closed-form Solution to Electromagnetic Sensor Based Intraoperative Limb Length Measurement in Total Hip Arthroplasty	I don't think the results could be reproduced easily. The supplementary video makes things clearer but from the paper there is insufficient information on the data collection to be confident that an attempt to repeat the experiment would yield similar results. The key point is on page 6, para 2 "the surgeon slightly rotated the femur". This is an insufficient description and could not be replicated.   The authors haven't included any data or software implementation.	0	1	1	0	0	2. (-) statement 	2. (-) comments	The description of the method is enough to reproduce the results.	1	0	0	0	0	3. (+) statement	3. (+) comments	Despite code or data will not be shared, authors did report sufficient information to support the reproducibility of the paper.	0	1	1	0	0	3. (+) statement	2. (-) comments	Irreproducible	Reproducible	Reproducible	1	2	2	0	0	2	Disagreement
007-Paper0976	A Conditional Flow Variational Autoencoder for Controllable Synthesis of Virtual Populations of Anatomy	Information about model architecture and training procedures is provided.	1	0	0	1	0	1. (none) statement	3. (+) comments	The reproducibility criteria is well satisfied	0	0	0	0	0	3. (+) statement	1. (none) comments	Clear description of the data processing and training strategy.   Overall good reproducibility	1	0	0	1	0	3. (+) statement	3. (+) comments	Reproducible	Reproducible	Reproducible	2	0	0	2	0	3	Agreement
008-Paper3288	A coupled-mechanisms modelling framework for neurodegeneration	The data used in the study comes from a widely known public domain source (ADNI), which is good for reproducibility.  As mentioned above though, many critical details of the evaluation are unclear, thus reducing the ability to reproduce results from these descriptions alone.	0	1	0	1	0	1. (none) statement	4. (-/+) comments	Authors provided details of data processing and how the models were trained. I would assume, one could repeat the experiments by following the steps explained in the paper.	1	0	0	1	0	3. (+) statement	3. (+) comments	The description of the model and implementation is clear for reproducibility purposes.	1	0	0	0	0	1. (none) statement	3. (+) comments	Irreproducible	Reproducible	Reproducible	2	1	0	2	0	2	Disagreement
009-Paper1168	A denoised Mean Teacher for domain adaptive point cloud registration	This paper clearly presented technical details of the method and experiments. The code is made public, the dataset used in experiment is public available. The reproducibility is excellent.	1	1	1	1	0	3. (+) statement	3. (+) comments	The datasets used for evaluation are publicly available.  The authors provided the code and models in an anonymous GitHub repo. However, the details given in the paper regarding the use of the different datasets are confusing to me and I do not feel able to exactly reproduce the training phase.  For the evaluation, the authors provided a clear description of metrics and tendency. Statistical significance was stated when needed.  The average runtime in the testing phase was provided. However, it is important to know the runtime in the training phase and the memory footprint. These magnitudes are not provided.  The clinical significance of the method can be inferred from the introduction. However, the proposed method needs further validation in more different datasets for considering moving to clinical application.	0	1	1	1	1	2. (-) statement 	4. (-/+) comments	Reproducibility is feasible.	0	0	0	0	0	3. (+) statement	1. (none) comments	Reproducible	Irreproducible	Reproducible	1	2	2	2	1	2	Disagreement
010-Paper1779	A flexible framework for simulating and evaluating biases in deep learning-based medical image analysis	Reproducibility appears to be fair.	0	0	0	0	0	3. (+) statement	1. (none) comments	The data set, template, and software (version missing though) used to estimate the deformation fields are clearly stated.	1	1	0	0	0	1. (none) statement	4. (-/+) comments	The authors will share the code if accepted. The experiments seem reproducible based on seeding information.	0	0	1	0	0	3. (+) statement	4. (-/+) comments	Reproducible	Irreproducible	Reproducible	1	1	1	0	0	2	Disagreement
011-Paper0286	A General Stitching Solution for Whole-Brain 3D Nuclei Instance Segmentation from Microscopy Images	looks ok, everything made available	0	0	0	0	0	3. (+) statement	1. (none) comments	This work is reproducible.	0	0	0	0	0	3. (+) statement	1. (none) comments	The paper is reproducible.	0	0	0	0	0	3. (+) statement	1. (none) comments	Reproducible	Reproducible	Reproducible	0	0	0	0	0	3	Agreement
012-Paper1873	A Model-Agnostic Framework for Universal Anomaly Detection of Multi-Organ and Multi-Modal Images	Enough detail seem to be provided to replicate the experiments. The models are based on existing baselines with simple enough modifications. The only missing parts are hyperparameters and types of optimizer are missing in the main paper.	1	0	0	1	0	3. (+) statement	4. (-/+) comments	I consider the paper is reproducible as the authors declare the code will be released after the anonymous review.	0	0	1	0	0	3. (+) statement	1. (none) comments	The description is clear and the method seems reproducible.	0	0	0	0	0	3. (+) statement	1. (none) comments	Reproducible	Reproducible	Reproducible	1	0	1	1	0	3	Agreement
013-Paper1912	A Modulatory Elongated Model for Delineating Retinal Microvasculature in OCTA Images	The work might not be reproducible. ROSE-1 is a public dataset and the modulatory function is well-defined, but the complete algorithm for turning a OCTA image into a vessel segmented image is not specified.	1	1	0	0	0	2. (-) statement 	4. (-/+) comments	The proposed model is clearly presented and thus it is feasible to reproduce the results.	1	0	0	0	0	3. (+) statement	3. (+) comments	The authors describe their method in extensive detail and use a publicly available dataset, making the research highly reproducible.	1	1	0	0	0	3. (+) statement	3. (+) comments	Irreproducible	Reproducible	Reproducible	3	2	0	0	0	2	Disagreement
014-Paper0643	A Motion Transformer for Single Particle Tracking in Fluorescence Microscopy Images	Except for the training data the training strategy is described and reproducible.	0	0	0	1	0	1. (none) statement	4. (-/+) comments	They did not provide the source code, which is the main weakness. However, the provided avi give me the confident that the results are reproducible at some extend.	0	0	1	0	0	3. (+) statement	2. (-) comments	Good	0	0	0	0	0	3. (+) statement	1. (none) comments	Irreproducible	Reproducible	Reproducible	0	0	1	1	0	2	Disagreement
015-Paper2184	A Multimodal Disease Progression Model for Genetic Associations with Disease Dynamics	Fine	0	0	0	0	0	3. (+) statement	1. (none) comments	The simulated and real data are from well-described sources, which should help with reproducibility.  Several aspects of the proposed algorithm are described vaguely or not at all, especially in the optimization part. So I believe true reproduction would be difficult.	1	1	0	0	0	2. (-) statement 	4. (-/+) comments	Not applicable	0	0	0	0	0	0. Unusable (statement)	0. Unusable (comments)	Reproducible	Irreproducible	Unusable	1	1	0	0	0	1	Disagreement
016-Paper1115	A Multi-Task Method for Immunofixation Electrophoresis Image Classification	The link of the source code is given in the the Implementation details (Section 3).	0	0	1	0	0	1. (none) statement	3. (+) comments	Although data and code are not provided, the method description is clear. I expect the method to be reproducible.	1	1	1	0	0	3. (+) statement	4. (-/+) comments	The authors provide a fair amount of details about the training setup and the architecture being used. With the dataset being private, the dataset statistics are available in the supplementary material.	1	1	0	1	0	1. (none) statement	4. (-/+) comments	Reproducible	Reproducible	Irreproducible	2	2	2	1	0	2	Disagreement
017-Paper2273	A Multi-Task Network for Anatomy Identification in Endoscopic Pituitary Surgery	The data is collected in the representative institute and is not publicly available. The codes will be publically available.	0	1	1	0	0	1. (none) statement	4. (-/+) comments	Reproducibility:   The authors provide a lot of information on how to reproduce this model (model architecture and hyperparameters).   However, There is no mention of providing the trained model or the codebase through an open repository. I would recommend considering this.	1	0	1	1	0	1. (none) statement	4. (-/+) comments	I'm not sure, the dataset is not public, the code is not publically available. My decision is not made upon the reproducibility.	0	1	1	0	0	1. (none) statement	2. (-) comments	Irreproducible	Irreproducible	Irreproducible	1	2	3	1	0	0	Agreement
018-Paper1457	A Novel Multi-Task Model Imitating Dermatologists for Accurate Differential Diagnosis of Skin Diseases in Clinical Images	Although the paper provides some details that can aid reproducibility, it would be beneficial to release the code and dataset to make the research more reproducible.	0	1	1	0	0	1. (none) statement	4. (-/+) comments	The paper has good reproducibility for it has a clear model discussion, sufficient formula derivation and implementation details.	1	0	0	0	0	3. (+) statement	3. (+) comments	This paper can be reproduced.	0	0	0	0	0	3. (+) statement	1. (none) comments	Irreproducible	Reproducible	Reproducible	1	1	1	0	0	2	Disagreement
019-Paper0813	A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation	The manuscript does not mention the publication of the code/dataset if paper is accepted.	0	1	1	0	0	1. (none) statement	2. (-) comments	Good	0	0	0	0	0	3. (+) statement	1. (none) comments	The reproducibility of the paper is satisfactory, although the code is not open accessed.	0	0	1	0	0	3. (+) statement	2. (-) comments	Irreproducible	Reproducible	Reproducible	0	1	2	0	0	2	Disagreement
020-Paper2659	A One-class Variational Autoencoder (OCVAE) cascade for classifying atypical bone marrow cell sub-types	Based on what was reported by the authors of the article and based on the Reproducibility Checklist, I believe that the reproducibility details are adequate. However, if it were possible to focus my concerns on the experimental part described above, the reproducibility of the paper would also benefit.	0	0	0	0	0	3. (+) statement	2. (-) comments	The method description is clear enough, and authors are publishing the code. Dataset is publicly available.	1	1	1	0	0	3. (+) statement	3. (+) comments	Reproducibility should be possible, as training and evaluation code is provided (based on the checklist).	0	0	1	0	0	3. (+) statement	3. (+) comments	Reproducible	Reproducible	Reproducible	1	1	2	0	0	3	Agreement
021-Paper2349	A Patient-Specific Self-supervised Model for Automatic X-ray/CT Registration	The reproducibility is ok since most of the details are included in this paper. The code and data will not be released.	0	1	1	0	0	3. (+) statement	4. (-/+) comments	Sufficient information is provided to reproduce the experiments, for instance using a public CT dataset.	0	0	0	0	0	3. (+) statement	1. (none) comments	Clear pipeline introduction, while the introduction of the proposed refinment model is a bit simplified to follow its performance;  Clear delination of experiments including DRR and X-rays cases.	1	0	0	1	0	1. (none) statement	3. (+) comments	Reproducible	Reproducible	Reproducible	1	1	1	1	0	3	Agreement
022-Paper3224	A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications	Reproducibility reported by the authors is accurate	0	0	0	0	0	1. (none) statement	3. (+) comments	The information that the authors provide is satisfactory, however thecode is not provided.	0	0	1	0	0	1. (none) statement	4. (-/+) comments	The datasets used are publicly available. The hyperparameters and training details are described in the paper. They promise to release the code.	0	1	1	1	0	1. (none) statement	3. (+) comments	Reproducible	Irreproducible	Reproducible	0	1	2	1	0	2	Disagreement
023-Paper0753	A Reliable and Interpretable Framework of Multi-view Learning for Liver Fibrosis Staging	The data provided about the networks structure and hyperparameters are enough to reproduce the code.	1	0	0	1	0	3. (+) statement	3. (+) comments	Open-source is encouraged.	0	0	1	0	0	1. (none) statement	1. (none) comments	I think the proposed method is reproducible.	0	0	0	0	0	3. (+) statement	1. (none) comments	Reproducible	Unusable	Reproducible	1	0	1	1	0	2	Agreement
024-Paper1104	A Semantic-guided and Knowledge-based Generative Framework for Orthodontic Visual Outcome Preview	Fine, however, the dataset or link to the dataset needed to run the code is not available.	0	1	0	0	0	3. (+) statement	2. (-) comments	The dataset is private and the code is not open source.	0	1	1	0	0	1. (none) statement	2. (-) comments	The labeling process of the data to obtain ground truth is not clearly explained.	0	1	0	0	0	1. (none) statement	2. (-) comments	Reproducible	Irreproducible	Irreproducible	0	3	1	0	0	1	Disagreement
025-Paper1008	A Sheaf Theoretic Perspective for Robust Prostate Segmentation	The authors provide some details.	0	0	0	0	0	1. (none) statement	0. Unusable (comments)	Equations are clear and thanks to Figure 2, all the details seem to be given for reproducibility, nothing to say.	1	0	0	0	0	3. (+) statement	3. (+) comments	The presented results should be easily reproducible since the source code will be made publicly available and one of the experiments is based solely on public data.	0	1	1	0	0	3. (+) statement	3. (+) comments	Unusable	Reproducible	Reproducible	1	1	1	0	0	2	Agreement
026-Paper2327	A Small-Sample Method with EEG Signals Based on Abductive Learning for Motor Imagery Decoding	Good. The authors will release the code.	0	0	1	0	0	3. (+) statement	3. (+) comments	It would be easy to reproduce if they make their code public.	0	0	1	0	0	1. (none) statement	1. (none) comments	The code could have been already released at the submission stage.	0	0	1	0	0	1. (none) statement	2. (-) comments	Reproducible	Unusable	Irreproducible	0	0	3	0	0	1	Disagreement
027-Paper1755	A Spatial-Temporal Deformable Attention based Framework for Breast Lesion Detection in Videos	The authors used a public dataset and claimed they would publish their code upon acceptance.	0	1	1	0	0	1. (none) statement	3. (+) comments	The proposed model architecture and the implementation details are well provided .	1	0	0	0	0	1. (none) statement	3. (+) comments	In the paper a lot of details that allow the reproducibility of the method are given. However, it is not clear the distribution of data in training/validation sets.	0	0	0	1	0	1. (none) statement	2. (-) comments	Reproducible	Reproducible	Irreproducible	1	1	1	1	0	2	Disagreement
028-Paper2027	A Spatial-Temporally Adaptive PINN Framework for 3D Bi-Ventricular Electrophysiological Simulations and Parameter Inference	I have a few minor comments.    I recommend the authors to better describe the time-stepping strategy and to further justify this choice in relation to the existing adaptation strategies.    I can't find the temporal discretization strategy. For several schemes (eg BDF-2), the use of a variable time step will affect the coefficients multiplying the different approximations. The authors should clarify this point.    Typo on page 5, paragraph 2 "is acehived".	0	0	0	0	0	0. Unusable (statement)	0. Unusable (comments)	The method proposed in the paper looks reproducible.	0	0	0	0	0	3. (+) statement	1. (none) comments	The method is overall clearly explained. Some additional details would be needed for a practical implementation: in particular, what are the requirements for the numerical simulation (what kind of geometry representation / computational grid, temporal and spatial resolution).	1	0	0	0	0	1. (none) statement	4. (-/+) comments	Unusable	Reproducible	Irreproducible	1	0	0	0	0	1	Disagreement
029-Paper0501	A Style Transfer-based Augmentation Framework for Improving Segmentation and Classification Performance across Different Sources in Ultrasound Images	The followings are the detailed comments to the authors.    In Fig. 2, there are no inputs or outputs specified. Data augmentation generally produces variation in the training data. Fig. 2, on the other hand, contains a training source and a testing source. What do they indicate?    Does $A$ in Eq. (1) denote the feature map obtained after global average pooling? Also, in Eq. (1), is the same dynamic range noise given to the mean and variance?    Experiments to evaluate accuracy should be conducted using not only private datasets, but also public datasets.    Each dataset is divided into training and test. In general, we divide each dataset into training, validation, and test. What is the reason for not setting validation?    In addition to evaluation within the dataset, experiments should also be conducted on cross DB to demonstrate the generality of the data augmentation. Cross-validation should also be performed to reduce data bias.    Table II is referenced, but there is no Table II.    Since AutoAug is cited in the paper, a comparison with AutoAug would be helpful.    In the results of Table 1, why are LD1 and TD1 results for the training data?	0	0	0	0	0	0. Unusable (statement)	0. Unusable (comments)	The authors have not provided an adequate description of the dataset utilized in the study, which may hinder the reader's understanding of the context and the applicability of the proposed method. Furthermore, the lack of information regarding the preprocessing steps implemented in the research could adversely affect the reproducibility of the method, thereby limiting its potential adoption by other researchers	1	1	0	0	0	1. (none) statement	2. (-) comments	The network architecture and training is explained but dataset is not available online	1	1	0	1	0	1. (none) statement	4. (-/+) comments	Unusable	Irreproducible	Irreproducible	2	2	0	1	0	0	Agreement
030-Paper3722	A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging	The results are based on the analysis of a local dataset using the proposed method, which is not public. No information was provided in the reproducibility checklist. it is difficult to access the reproducibility of this work.	0	1	0	0	0	1. (none) statement	2. (-) comments	The authors have not properly filled out the reproducibility form (all NA)	0	0	0	0	0	1. (none) statement	2. (-) comments	No code or data was provided along with the paper.	0	1	1	0	0	1. (none) statement	2. (-) comments	Irreproducible	Irreproducible	Irreproducible	0	2	1	0	0	0	Agreement
031-Paper1001	A Transfer Learning Approach to Localise a Deep Brain Stimulation Target	The work should be reproducible with reasonable efforts, especially as the authors indicated that multiple key items including the code would be made public.	0	0	1	0	0	3. (+) statement	3. (+) comments	The authors relied on some public datasets and transfer knowledge to a different domain, so as far as I can judge, it might be reproducible for other group's data.	0	1	0	0	0	3. (+) statement	3. (+) comments	The model is difficult to be reproduced.The model setup and training details are not decribed, which can make the work less reproducible.	1	0	0	1	0	2. (-) statement 	2. (-) comments	Reproducible	Reproducible	Irreproducible	1	1	1	1	0	2	Disagreement
032-Paper1827	A Unified Deep-Learning-Based Framework for Cochlear Implant Electrode Array Localization	No dataset, no code. It might be difficult to reproduce	0	1	1	0	0	2. (-) statement 	2. (-) comments	will be ok	0	0	0	0	0	3. (+) statement	1. (none) comments	While none of the datasets is accessible, the reproducibility of the methods is possible thanks to the clear explanation of the implementation details for the presented algorithms.	1	1	0	0	0	3. (+) statement	4. (-/+) comments	Irreproducible	Reproducible	Reproducible	1	2	1	0	0	2	Disagreement
033-Paper2320	A Video-based End-to-end Pipeline for Non-nutritive Sucking Action Recognition and Segmentation in Young Infants	training dataset is hidden.  code will be made public.  small portion of data will be made public.	0	1	1	0	0	1. (none) statement	4. (-/+) comments	From what I undestand the main dataset they created will not be public. SInce it inlucdes that faces of babies, recorded by the research team, it is understandable it will not be made public. Yet this will make it harder to compete with the results presented by this study.	0	1	0	0	0	1. (none) statement	2. (-) comments	The authors mentioned they would release their code and a part of the datasets. I do not have further worries on the reproducibility.	0	1	1	0	0	1. (none) statement	3. (+) comments	Irreproducible	Irreproducible	Reproducible	0	3	2	0	0	1	Disagreement
034-Paper2791	A2FSeg: Adaptive Multi-Modal Fusion Network for Medical Image Segmentation	Reproducibility is OK.	0	0	0	0	0	3. (+) statement	1. (none) comments	authors claim source code is provided but no link is provided in the text.	0	0	1	0	0	1. (none) statement	2. (-) comments	Largely reproducible.	0	0	0	0	0	3. (+) statement	1. (none) comments	Reproducible	Irreproducible	Reproducible	0	0	1	0	0	2	Disagreement
035-Paper2655	ACC-UNet: A Completely Convolutional UNet model for the 2020s	The results are based on public dataset. Code is also provided.	0	1	1	0	0	1. (none) statement	3. (+) comments	The 5 dataset used in this paper provide a solid basis of the evaluation. But, no access to the dataset will limit the reproducibility of the paper.	0	1	0	0	0	1. (none) statement	4. (-/+) comments	Given the fact that the authors have anonymously published their source code together with the training/evaluation pipelines, there are no issues related to the paper's reproducibility. The readers can therefore follow into detail how the architecture works.  Additionally, all the details of the architecture, training procedures, experiments have been clearly described in the article.	1	0	1	1		3. (+) statement	3. (+) comments	Reproducible	Irreproducible	Reproducible	1	2	2	1	0	2	Disagreement
036-Paper2373	Accurate and Robust Patient Height and Weight Estimation in Clinical Imaging using a Depth Camera	Not clear if the code or the large dataset will be public avaialble.	0	1	1	0	0	1. (none) statement	2. (-) comments	The large dataset the authors present is not publicly available. Also, as mentioned above, the pre-processing steps are not explained in a way that can be reproduced. Additionally, the pre-training with landmark detection lacks more explanations: which landmarks, how many, how were they annotated...	1	1	0	0	0	1. (none) statement	2. (-) comments	The deep learning architecture was common and reproducible. The data preprocessing was well explained.	1	0	0	0	0	1. (none) statement	3. (+) comments	Irreproducible	Irreproducible	Reproducible	2	2	1	0	0	1	Disagreement
037-Paper1541	Accurate multi-contrast MRI super-resolution via a dual cross-attention transformer network	The paper provides sufficient information for reproducibility.	0	0	0	0	0	3. (+) statement	1. (none) comments	Common MRI datasets are utilized for training and testing. Furthermore, the authors state that "The code for DCAMSR will be available at GitHub after the blind review" - so probably a high level of reproducibility will be ensured if this draft is accepted for publication at the MICCAI.	0	1	1	0	0	3. (+) statement	3. (+) comments	The authors completed the reproducibility checklist without fully committing to its requirements. For instance, they listed "an analysis of statistical significance of reported differences in performance between methods" on the checklist, but the paper does not provide any statistical analysis for performance comparison. This lack of adherence to the reproducibility checklist raises significant concerns about the credibility of the self-claimed reproducibility.	0	0	0	1	1	2. (-) statement 	2. (-) comments	Reproducible	Reproducible	Irreproducible	0	1	1	1	1	2	Disagreement
038-Paper0867	ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast	Authors have provided enough details in the paper. It would be great if they can release the code after publication.	0	0	1	0	0	3. (+) statement	1. (none) comments	I think the paper is reproducible.	0	0	0	0	0	3. (+) statement	1. (none) comments	The reproducibility of the paper is sufficient.	0	0	0	0	0	3. (+) statement	1. (none) comments	Reproducible	Reproducible	Reproducible	0	0	1	0	0	3	Agreement
039-Paper1160	ACT-Net: Anchor-context Action Detection in Surgery Videos	The code and dataset used in this paper will not be provided as indicated. This would not prove that the results are reproducible.	0	1	1	0	0	1. (none) statement	2. (-) comments	At the moment, the paper is not reproducible since the dataset is not public and the code is not available.	0	1	1	0	0	1. (none) statement	2. (-) comments	may not reproducible as the author didn't release code	0	0	1	0	0	1. (none) statement	2. (-) comments	Irreproducible	Irreproducible	Irreproducible	0	2	3	0	0	0	Agreement
040-Paper2061	Acute Ischemic Stroke Onset Time Classification with Dynamic Convolution and Perfusion Maps Fusion	code availability checked, data is not available although I believe similar or larger size of CTP data can be easily found at many institutions to try the proposed method. Some parts of the method lack details, need to see the code to double check.	1	1	1	0	0	1. (none) statement	4. (-/+) comments	The authors have provided a comprehensive description of the model, which includes mathematical formulations of the attention modules, as well as a clear graphical illustration. A clear description of the data and its preprocessing is warranted.	1	1	0	0	0	1. (none) statement	3. (+) comments	The paper contains sufficient details about the methods, but the lack of clarity significantly detracts from the reproducibility. The authors indicate in their reproducibility checklist that they will make source code available, but this is not indicated in the manuscript. The dataset is private.	1	1	1	0	0	1. (none) statement	4. (-/+) comments	Irreproducible	Reproducible	Irreproducible	3	3	2	0	0	1	Disagreement
041-Paper1499	Adapter Learning in Pretrained Feature Extractor for Continual Learning of Diseases	Some details are provided to implement their method, but source code is unavailable for review.								Yes, it is reproducibile.								Good. key resources (e.g., proofs, code, data) are available and sufficient details (e.g., proofs, experimental setup) are described such that an expert should be able to reproduce the main results.											0	0	0	0	0	0	
042-Paper2125	Adaptive Multi-scale Online Likelihood Network for AI-assisted Interactive Segmentation	If the code will be publicly available, there would be no issue with reproducibility.								The reproducibility of the paper is good with code to be released. Expert evaluation is introduced clearly to reproduce.								The reproducibility seems to be good. The authors use publicly available datasets for training/evaluation and have implemented their code with MONAI Label to facilitate reproduction of results and access to the community.											0	0	0	0	0	0	
043-Paper1681	Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation	For all code related to this work that they will release if this work is accepted								Not so good in reproduction due to the code is not release and the performance of the method can vary quite a lot at different random condition referring to the experiment results (which is one drawback in this kind of active learning method).								In the Reproducibility Response, the authors promised to release the codes, and the data they used were from public dataset. Therefore, it is easy to carry out the reproduction of the paper.											0	0	0	0	0	0	
044-Paper1894	Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs	Since all the code and datasets will be made public, there are good chances for being a reproducible paper.								It is reproducible since it is clearly described and code will be public.								The methods seems reproducible. The authors also promise to release the code.											0	0	0	0	0	0	
045-Paper0722	Additional Positive Enables Better Representation Learning for Medical Images	Good, the authors claim the availability of their source codes if accepted.								There are enough implementation details but providing the code would highly improve reproducibility.								It is mentioned that access to code and trained models will be available. I would suggest that anonymous github account with code is published and weights are shared also in anonymous way. These can then be easily pointed to non blind repositories if the manuscript is accepted.											0	0	0	0	0	0	
046-Paper1865	Adjustable Robust Transformer for High Myopia Screening in Optical Coherence Tomography	The authors work on a closed-source dataset.								The code is released.								Good reproducibility. The dataset is not public. The code is online.											0	0	0	0	0	0	
047-Paper0340	Adult-like Phase and Multi-scale Assistance for Isointense Infant Brain Tissue Segmentation	It is reproducible given the code and data								The reproducibility of this paper is good except for the link of the code that is not provided.								Although some technical details are missing in the current version of manuscript, the authors committed in the checklist that will provide codes. The data is public. Work is reproducible.											0	0	0	0	0	0	
048-Paper1475	AirwayFormer: Structure-Aware Boundary-Adaptive Transformers for Airway Anatomical Labeling	The description seems to be very clear and reproducible.								There are several unclear aspects in the authors' methodology description. This prevents the article to be fully understood and thus reproduced.  I recommend that the authors provide the code associated to this article.								The techique details is explained well. With the input from the previous work [21], the results could be reproducible.											0	0	0	0	0	0	
049-Paper0690	Alias-Free Co-Modulated Network for Cross-Modality Synthesis and Super-Resolution of MR Images	It seems to be reproducible.								Implementation details are somewhat provided.								No information is provided in the text. But, the authors state that they will make the code available upon acceptance.											0	0	0	0	0	0	
050-Paper2820	ALL-IN: A Local GLobal Graph-based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment	Reproducibility might be slightly challenging without knowing all parameters (ex: number of super nodes) but this method is reproducible in a reasonable manner.								Sufficiently reproducible if code is provided. Paper likely does not provide sufficient detail on model architecture/training to replicate otherwise.								good											0	0	0	0	0	0	
051-Paper1205	AMAE: Adaptation of Pre-Trained Masked Autoencoder for Dual-Distribution Anomaly Detection in Chest X-Rays	Most concepts should be quite easily reproducible. However, since this work uses a pretrained model, multiple stages and no training code will be made available I feel like this would hinder the reproducibility quite a lot.								It seems reproducible as the authors have provided many details of the proposed methods. If the authors promise the release their codes, I will consider increase my score.								Have no idea.											0	0	0	0	0	0	
052-Paper0989	AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor	Authors provide a link for the release of their code								The authors did not specifically introduce the experimental environment and parameters and did not provide the code, which is not very convenient for other researchers to access.								The paper is reproducible											0	0	0	0	0	0	
053-Paper2596	An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment	No relevant								The dataset does not seem to be available for download.								The paper focuses on dataset that is strictly related to the data, so it is reproducible for someone possessing the base data.											0	0	0	0	0	0	
054-Paper1278	An Anti-Biased TBSRTC-Category Aware Nuclei Segmentation Framework with A Multi-Label Thyroid Cytology Benchmark	The code is provided and the model is explained well, helping with the reproducibility of the method.								Code is available.  Data will be available upon acceptance								The illustration of the method is clear to reproduce the method. And the dataset will be released on GitHub after the review process.											0	0	0	0	0	0	
055-Paper2173	An Auto-Encoder to Reconstruct Structure with Cryo-EM Images via Theoretically Guaranteed Isometric Latent Space, and its Application for Automatically Computing the Conformational Pathway	Reproducibility is fine								The work is reproducible.								code was provided											0	0	0	0	0	0	
056-Paper2970	An automated pipeline for quantitative T2* fetal body MRI and segmentation at low field	The present application-oriented study has poor reproducibility based since:    data is not made available  code of the whole pipeline is not made to , only certain parts like the standard nnUnet  trained models are not made available  computational requirements were not described  due to small number of test cases, reproducing the results on different dataset could be challenging (especially since the test data structure is not fully reported, i.e. sex, gestational age, diagnosis, ethnicity, etc.)								The paper has provided enough details for ensuring general reproducibility.								Information to reproduce the experiments is provided.											0	0	0	0	0	0	
057-Paper0599	An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis	Reproducibility is good. Public datasets in development and evaluation. Publicly available code (up on acceptance). Reported both mean and standard deviation in comparisons.								Limited reproducibility. This is an interesting work. It would be better if the authors could make corresponding codes public to make a better contribution to the community.								okayish but more details need to presented.											0	0	0	0	0	0	
058-Paper3214	An Explainable Geometric-Weighted Graph Attention Network for Identifying Functional Networks Associated with Gait Impairment	No significant concerns, code not released yet during the reviewing phase.								The paper describes they will release the code upon acceptance.								They did well											0	0	0	0	0	0	
059-Paper3355	An Interpretable and Attention-based Method for Gaze Estimation Using Electroencephalography	According to the authors' answers to the checklist as well as the information provided in the article, the reproducibility appears to be possible.   The actual code is not included.								Details clear. Data and code not available, although data may become available via another paper on arxiv								Dataset is publicly available. No information about code release is provided.											0	0	0	0	0	0	
060-Paper1858	An Unsupervised Multispectral Image Registration Network for Skin Diseases	The data used is not publicly available, making it hard both to reproduce and compare in future studies.  The architecture hyperparameters and training details (loss, train/test splits, etc..) are provided.  The code is yet not made available (maybe for anonymisation of the submission).								The authors mark all "Yes" in the reproducibility checklist. Based on the model explanation and loss functions in the paper, reproducing the method should be feasible.								Despite the lack of open-source code, the reproducibility of this paper is acceptable.											0	0	0	0	0	0	
061-Paper2566	Analysis of Suture Force Simulations for Optimal Orientation of Rhomboid Skin Flaps	The Authors' statements about the reproducibility of the paper appear to be correct/true. Including the input files for conducting the simulations may be one possible area for improvement.								The reproducibility can be rated as sufficient.								The given conditions in FEM during a skin flap procedure is quite unknown. So, it is difficult to reproduce the simulation and experiments. For example, the followings information are unknown or insufficient:    The applied forces or given displacements during a skin flap procedure  (In the supplemental movie, the flapped skin moves step by step, and the movement looks depending not on the simple applied forces. The applied forces look changing during skin flap. But, it is unclear how the temporal difference of applied conditions are determined. )  How to match the nodes of different segments in a skin flap											0	0	0	0	0	0	
062-Paper2830	Anatomical Landmark Detection Using a Multiresolution Learning Approach with a Hybrid Transformer-CNN Model	While datasets used in this study for experiments are publicly available, the hybrid transformer-CNN algorithm is not mathematically expressed or made available to the reader/reviewer for checking. This definitely reduces the reproducibility of the paper.								Authors have indicated that the code will be released upon acceptance. This in conjunction with the observation that the model is evaluated on public benchmark would significant help with reproducibility.								n/a											0	0	0	0	0	0	
063-Paper0270	Anatomical-aware Point-Voxel Network for Couinaud Segmentation in Liver CT	Yes								The intra- and inter-user variability between multiple annotators are not reported. This variability is essential to clarify the desired resolution for the output!    The split for the training/validation is not mentioned.    The network is trained for 400 epochs, but how the final weight is chosen? Best on the validation loss?    The training and validation loss of the selected epoch for each method is not mentioned.    The robustness of the Couinaud segmentation with respect to the performance of the liver/vessel segmentation is not reported.								The used hyperparameters were well documented											0	0	0	0	0	0	
064-Paper0383	Anatomy-Driven Pathology Detection on Chest X-rays	Code provided. Links to data provided. So, in general, it is reproducibility is adequate in the way the method has been described in the paper. However, a link to github repository (even if private at this stage) is not provided. And without that the description isnt sufficient for someone to recreate this work easily - but, it is possible.								The authors used 2 public datasets and the approach explained quite well which makes it feasible to reproduce.								The author provides the code and supplementary materials.											0	0	0	0	0	0	
065-Paper1594	Anatomy-informed Data Augmentation for Enhanced Prostate Cancer Detection	This is a 100% reproducible.								Reproducible. Method details described well.								The paper is unlikely to be reproduccible with the current information provided.											0	0	0	0	0	0	
066-Paper2034	Aneurysm Pose Estimation with Deep Learning	Except the evaluation with the private dataset, other aspect of the paper can be reproduced. The network architecture is well described, implementation detail are given, both evaluation metrics and validation schema are detailed.								This paper includes implementation detail section with sufficient information which allows it to be reproducible.								The methods described in the paper seem sufficient to reproduce the results. The reproducibility points given are mostly valid, more so than in any other paper I have reviewed. It was particularly nice that the authors (only in 5 papers reviewed) included a placeholder for a link to the cod.   The following points were checked in the reproducibility response, but I couldn't find them in the paper:   I) Hyperparameter tuning II) Runtime, III) Memory footprint, IV)											0	0	0	0	0	0	
067-Paper0522	AngioMoCo: Learning-based Motion Correction in Cerebral Digital Subtraction Angiography	"We will make the code publicly available."in this paper.								The reproducibility is possible knowing that the authors mention that they will make the code available.								Good reproducibility of the neural networks method. The author state that the data will be released.											0	0	0	0	0	0	
068-Paper2152	Annotator Consensus Prediction for Medical Image Segmentation with Diffusion Models	They used the public datasets. The code will be published.								Database is available, but no code is provided nor mention will be provided.								Yes, the authors provide the implementation details, such as the platform, the main parameters.											0	0	0	0	0	0	
069-Paper2200	Anti-Adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation	The method and experimental setup is well-described in the paper, and the authors intent to make their code publicly available.								Authors have provided enough details in the paper. It would be great if they can release the code after publication.								This method might be easy to reproduce.											0	0	0	0	0	0	
070-Paper2382	AR2T: Advanced Realistic Rendering Technique for Biomedical Volumes	This paper has a Satisfactory reproducibility.  The authors have a clear and detailed description of the algorithm, but but many of the used parameters are not specified. For example, in the reproducibility checklist, the authors mention "camera properties", but throughout the paper, no details are given about this.  About the dataset, the autors mention the CBCT (Cone-Beam Computed Tomography) volumes acquired by Anonymous CT Medical Imaging Platform but no additional information is given about the platform. The exception is the Manix data set from https://docs.set.health/docs/introduction/public-medical-data which the authors refer to use and to which they present references.								The method is the author's own implementation, not released as open source. The data used by the authors is accessible however.								The paper provides a detailed description of the methods and techniques used to implement the AR2T rendering framework, including the transfer functions, phase functions, and voxelization process. Additionally, the paper provides examples of the rendered images, as well as a convergence criterion for the iterative process.  However, the paper does not provide the exact data sets used for the experiments, making it difficult to reproduce the results. Furthermore, while the authors mention evaluating the framework's speed and quality, they do not provide any quantitative measurements or benchmarks for comparison with other approaches. Finally, the availability of the executable to the research community for further evaluation and comparison is currently under evaluation, which may limit reproducibility.  Therefore, while the paper provides a detailed description of the methods used, there are some weaknesses in terms of reproducibility, making it difficult to fully evaluate the framework's effectiveness and compare it with other approaches.											0	0	0	0	0	0	
071-Paper3171	Ariadne's Thread: Using Text Prompts to Improve Segmentation of Infected Areas from Chest X-ray images	The authors evaluate their method on the QaTa-COV19 dataset and mention that they have corrected errors in the text annotations. While this is a positive aspect, sharing the updated dataset and any pre-processing steps taken would be crucial for reproducibility.								reproducibility is good								Reproducible    Training and Evaluation codes available  Model description included											0	0	0	0	0	0	
072-Paper1249	ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models	The method, training setting is well described and the architecture is clear								Based on the details given in the document most of the experiments are reproducible. However, additional information on the hyperparameters/optimisation part would be required (see point #6, i.e. optimiser, lr, etc)								Detailed parameters are shown in the manuscript. I think reproducibility is fine.											0	0	0	0	0	0	
073-Paper0943	Artifact Restoration in Histology Images with Diffusion Probabilistic Models	I recommend the author to add the detailed explanation of the code in README.md.								Codes are provided.								The diffusion method is slow due to the large number of samplings. However, the paper does not provide a direct comparison of ArtiFusion's speed to existing methods. However, the authors do mention that the proposed method is computationally expensive due to the large number of samplings required by the diffusion process.  To address this issue, the authors propose a time token scheme that reduces the number of samplings required during training and inference. Additionally, they use a Swin-Transformer denoising architecture that is designed to capture local-global correlations in regional artifact restoration more efficiently than other architectures.  While there is no direct comparison of ArtiFusion's speed to existing methods, the authors do report that their proposed method achieves superior results compared to state-of-the-art GAN-based methods on a public histological dataset. Therefore, while ArtiFusion may be computationally expensive due to its use of diffusion-based artifact restoration, it is still able to achieve promising results in terms of accuracy and preservation of tissue structures and stain style in artifact-free regions during restoration.											0	0	0	0	0	0	
074-Paper1934	ASC: Appearance and Structure Consistency for Unsupervised Domain Adaptation in Fetal Brain MRI Segmentation	The code will be public. The experiments performed on public datasets.								The reproducibility of this paper is good because 1) the code and data will be available, and 2) the implementation details are clear.								The authors would provide the code, and this paper utilizes the public dataset.											0	0	0	0	0	0	
075-Paper1927	ASCON: Anatomy-aware Supervised Contrastive Learning Framework for Low-dose CT Denoising	This paper is reproducible with the provided implementation details. Making source code publicly accessiable is deseriable.								The proposed method may be reproducible since the implementation details, network architecture in supplemental materials, and pseudo algorithm are provided.								Given the clear description of the algorithm, it should be easy to reproduce.											0	0	0	0	0	0	
076-Paper2274	Assignment Theory-Augmented Neural Network for Dental Arch Labeling	Sounds good.								Author filled out the reproducibility checklist but does not include codes.								Good.											0	0	0	0	0	0	
077-Paper1850	Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation	As long as the author's provide code, reproducibility is not a problem.								this paper is reproducible since the authors claimed they will release the code								The paper would be difficult to reproduce without an official implementation due to the lack of clarity about the exact definition of uncertainty maps, as well as validation metrics. Details about the datasets are provided. Some but not all implementation details are provided.											0	0	0	0	0	0	
078-Paper2614	Attentive Deep Canonical Correlation Analysis for Diagnosing Alzheimer's Disease using Multimodal Imaging Genetics	The authors marked yes to everything. After reading the paper I think this is obviously not correct.								Reproducible								Authors have provided detailed descriptions of the methods used, the data preprocessing steps, and the evaluation metrics used. Additionally, they have made the code for the ADCCA model publicly available, which promotes reproducibility and allows other researchers to build on this work. Overall, the paper appears to have taken reproducibility seriously and has made efforts to ensure that their work can be replicated by others.											0	0	0	0	0	0	
079-Paper1623	atTRACTive: Semi-automatic white matter tract segmentation using active learning	The paper has the source code available for the reproducibility of the results.								The authors have committed themselves to sustain a good reproducibility of the paper, despite a portion of empirical investigation based on trials with human operators. Some of the data used in the analysis belongs to the Human Connectome Project, a public dataset. In the paper, it is indicated that the code used for the paper's analysis is publicly available. Moreover the authors provide the proposed method, atTRACTive, as a prototype freely available.  The major issue with the reproducibility of the paper is the clinical dataset. Both data tractography and annotated bundles are not distributed as open data.								It might be difficult to reproduce because it includes in-house data.											0	0	0	0	0	0	
080-Paper1042	AUA-dE: An adaptive uncertainty guided attention for diffusion MRI models estimation	It is difficult to determine the reproducibility of the paper.								N/A.								OK. Despite not sharing the code/data, the authors described the network architecture clearly with detailed theoretical analysis.											0	0	0	0	0	0	
081-Paper3582	Automated CT Lung Cancer Screening Workflow using 3D Camera	There isn't really much detail at all on the hardware (3D camera) or network hyper parameters and deep learning libraries used. So reproducibility is poor for this work.								It requires large dataset (<60,000 CTs and 2742 pairs of depth and CT images) to train, but it is not easy to collect.  Providing more information on the architecture of the model and the training process could increase reproducbility.								* This work is difficult to reproduce as many key details are not included. For example, the paper does not describe how to set up the 3D camera and how to acquire the depth image. Additionally, the chosen network description is not well-defined.  * The dataset and code are not available											0	0	0	0	0	0	
082-Paper0174	Automatic Bleeding Risk Rating System of Gastric Varices	Hard to reproduce.    The key equations of RCN module is missing.  They didn't mention the data augmentation.								The authors curate a in-house dataset, and experiment only on the closed source data.								The paper is clearly written but, releasing the code will help improve its reproducibility. Also, the paper intends to release the dataset in the future.											0	0	0	0	0	0	
083-Paper0836	Automatic Retrieval of Corresponding US Views in Longitudinal Examinations	The paper is reproducible, mainly because the authors provide a (redacted) URL of their source code.								They will free the code. But they also give enough details in the paper so that the architecture can be reproduce. They give all the necessary information if you want to reproduce the training, like the values of: Epochs, learning rate, batch size, number of images for train/val/test, size of the images, even the framework used.								Besides a lack of justification for some of the architecture and hyperparameter choices, no major issues.											0	0	0	0	0	0	
084-Paper2746	Automatic Segmentation of Internal Tooth Structure from CBCT Images using Hierarchical Deep Learning	The method is tested on a single internal dataset of 3D dental CBCT images collected from a single institution. Neither the data nor the code have been made publicly available and it has not been validated on external or public data, which hinders the reproducibility of the method.								It has strong reproducibility.								The authors mention in the reproducibility checklist that code/pretrained models will be made public.The hyper-parameters,batch size,learning rate, epochs,gpu etc are mentioned in the supplementary material. Hence it is reasonable to expect that the code will be reproducible.											0	0	0	0	0	0	
085-Paper2247	Automatic Surgical Reconstruction for Orbital Blow-out Fracture via Symmetric Prior Anatomical Knowledge-Guided Adversarial Generative Network	The paper's main concept is clear and I have confidence in its ability to be reproduced.								good things about reproducibility  o well described methods  o clear pre and post processing described  o  limiting the ability to reproduce  o a closed dataset is used  o The method for manual annotation of the images could be better described. Little is said about how the segmentations were done than an experienced clinician did them. It is unlikely that another clinician would exactly segment and reconstruct as done in this investigation								The paper contains small amount of implementation details. However, the authors will provide code, which may improve the reproducibility of the paper.											0	0	0	0	0	0	
086-Paper0682	B-Cos Aligned Transformers Learn Human-Interpretable Features	Sufficient information is provided								Not clear to me.								good, if the code will be public											0	0	0	0	0	0	
087-Paper2016	BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation	The method is very clear, with sufficient diagrams and formulas to illustrate the proposed algorithm, so this method is highly reproducible.								The algorithm can be reproduced to some extent.								The code is not provided, but the description of the proposed method is clear enough to re-implement.											0	0	0	0	0	0	
088-Paper1399	Beyond the Snapshot: Brain Tokenized Graph Transformer for Longitudinal Brain Functional Connectome Embedding	The reproducibility of this work is relatively low considering that they provide neither the source code nor the network design and training details.								It needs to provide more details about the network architectures and learning strategies.								The experimental environment and configurations are provided in the supplementary file.											0	0	0	0	0	0	
089-Paper1392	Bidirectional Mapping with Contrastive Learning on Multimodal Neuroimaging Data	Good.								This work is clear in algorithms and datasets description, experiemental result reporting and code release.								The experimental results are based on two public-released datasets. The main settings about the experiments and model parameters are given. However, the specific selected participants of the data, data preprocessing steps, and the cross-validation results are not clear enough. Based on the consideration about these contents, the idea was reasonable, while it is doubtful to be reproducible.											0	0	0	0	0	0	
090-Paper2993	BigFUSE: Global Context-Aware Image Fusion in Dual-View Light-Sheet Fluorescence Microscopy with Image Formation Prior	I cannot judge on the part of code due to lack of information.								This paper is clearly written and is reproducible.								Some parameters used in preparing the data could be specified. Runtime was not reported.											0	0	0	0	0	0	
091-Paper1973	Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation	No code provided.								Open-sourcing the code is highly encouraged.								All datasets used in the work are public, and the source code is not available.											0	0	0	0	0	0	
092-Paper1650	Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers	Ok.								Reasonably reproducible.								Generally, the details on the experimental setup for the compared methods and ablation study are lacking.  Choice of model, training strategy and hyperparameters is not motivated despite saying so in the reproducibility report.  The authors state that "The average runtime for each result, or estimated energy cost." and "An analysis of situations in which the method failed" are not applicable to this study, which I do not agree with.  the authors state that they have included a "Discussion of clinical significance" which I do not agree with.											0	0	0	0	0	0	
093-Paper1247	Boundary Difference Over Union Loss For Medical Image Segmentation	The authors provide links to the two datasets used in their study and mention several hyperparameters used for their model and baselines. However, some important hyperparameters are not explicitly stated, such as the learning rate, batch size, and optimizer. The authors do note that their code will be made publicly available, which will allow interested readers to access this information.								The reproducibility checklist agrees to what can be seen in the paper.								It's easy to reproduce.											0	0	0	0	0	0	
094-Paper2691	Boundary-weighted logit consistency improves calibration of segmentation networks	Good. Datasets are publicly available, and methods are described with acceptable detail.								The reproducibility checklist agrees to what can be seen in the paper.								The reproducibility of the paper can be improved.  Pros    The authors state in their reproducibility report that all code will be release upon acceptance.  The paper uses publicly available data sets to conduct experiments.  The general method is well described, which makes reimplementation of CR possible.  Most parameters of the training procedure are reported.    Cons    As stated above, BWCR is described insufficiently and could not be re-implemented given only the information in the paper.  The parameters of the geometric transformations T_\psi are not given in the paper.											0	0	0	0	0	0	
095-Paper0844	Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI	The code is not made publicly available, yet. Nonetheless, they provide some implementation details on the architecture, hyperparameters, loss function, hardware and software. The data for the pretext task is publicly available, while the data for the prediction task seems private (thus not reproducible).								Method should not be difficult to reproduce. For the data, authors are using 9,544 MRIs from ADNI. However, it is unclear if they plan to release the tissue segmentation maps.								None											0	0	0	0	0	0	
096-Paper1572	BrainUSL: Unsupervised Graph Structure Learning for Functional Brain Network Analysis	The code is available to the reviewer however important experimental details are missing in the manuscript. Data are private for privacy reasons.								It is good. The code for the model is provided.								It is not clear how the learned brain connectivity structure is used for the final diagnosis/classification.											0	0	0	0	0	0	
097-Paper1347	Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network	I suggest the authors share their code and log. Though, The reproducibility is satisfactory because the method is not complicated and is introduced in detail.								As the technical quality of the paper is low and there is no link to public codes, the work would be hardly reproducible.								The proposed method is validated on four public datasets, and the results are provided and can be reproduced. However, it would be beneficial to provide the code for better reproducibility.											0	0	0	0	0	0	
098-Paper2554	Bridging ex-vivo training and intra-operative deployment for surgical margin assessment with Evidential Graph Transformer	It is reproducible. Experimental design and detailed introduction of the datasets for validation is needed.								The reproducibility of this paper seems moderate.								Code was not provided. Unclear for reproducibility.											0	0	0	0	0	0	
099-Paper1146	Building A Bridge: Close The Domain Gap in CT Metal Artifact Reduction	The complete network structure is presented. The data used in this article comes from the public dataset, and the training details and parameter settings are explained in the article. This article is with good reproducibility.								can be reproduced according to the paper.								This paper analyzes the shortcomings of unsupervised and fully supervised methods on the metal artifact reduction (MAR) problem raised. The structure of the article is reasonable, but there is a mismatch between the figure and the text.											0	0	0	0	0	0	
100-Paper2579	Can point cloud networks learn statistical shape models of anatomies?	The paper is using existing methods which allows for easy reproduction.								The reproducibility of the paper is fair. Release of code is recommended.								The authors conduct experiments on several datasets that are not public. The supplementary material gives more details about the datasets. The implementation should be accessible in each method chosen in this paper.											0	0	0	0	0	0	
101-Paper1428	CARL: Cross-aligned Representation Learning for Multi-view Lung Cancer Histology Classification	The authors suggest that they will open the codebase of the proposed work and they have used public dataset, so it seems to be ok.								I think this paper can be reproducible.								The authors agree to publish their training and evaluation code on acceptance, which greatly improves reproducibility. In contrast to the reproducibility form, the manuscript does not include a measure of variation, such as error bars.											0	0	0	0	0	0	
102-Paper3517	Cascade Transformer Encoded Boundary-Aware Multibranch Fusion Networks for Real-Time and Accurate Colonoscopic Lesion Segmentation	This paper would be highly reproducible if the authors do indeed release their dataset. Their method is well defined and the data would be available. As mentioned in some of my feedback, the main hurdle to reproducibility would be the lack of detail provided regarding the handling and preprocessing of the datasets.								The author will release the code of the method and the new colonoscopic lesion image data.								The reproducibility of this paper is fine.											0	0	0	0	0	0	
103-Paper0651	CAS-Net: Cross-view Aligned Segmentation by Graph Representation of Knees	The code is not provided, but the dataset is accessible. The reproducibility of this paper is good.								Assuming that the code is made available, and details of which of the images from the OAI dataset were used, this should be reproducible.								It should be possible to reproduce the results with the given description											0	0	0	0	0	0	
104-Paper0442	Category-independent Visual Explanation for Medical Deep Network Understanding	In my view, the experiments performed in this paper are reproducible.								The hyper parameters are specified but there is no mention of a public repository anywhere. The model for the eye fundus data is not described.								Even though the code is not provided, I consider this paper is reproducible as the model architecture, datasets, parameters, evaluation metrics are clearly listed.											0	0	0	0	0	0	
105-Paper0176	Category-level Regularized Unlabeled-to-labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data	In the reproducibility checklist, the authors promised to release the code and trained weights for their proposed method. It is essential to others reproduce their results.   For the sake of completeness, I would also suggest the authors report the average runtime and the memory footprint for each approach evaluated in their experiments.								No code provided								Good reproducibility											0	0	0	0	0	0	
106-Paper2024	CAT-ViL: Co-Attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery	The paper has provided most of the details.								This research is reproducible based on the checklist.								I believe that this paper has the potential to contribute to the community through its reproducibility, especially if the authors open-source their code and software. This would allow other researchers to easily replicate their results and build upon their findings.											0	0	0	0	0	0	
107-Paper0204	CDiffMR: Can We Replace the Gaussian Noise with K-Space Undersampling for Fast MRI?	The authors have plans to make the code and dataset public, which would benefit the community in recognizing this problem. The evaluation metric is clearly described so that the result would be convincing.								The authors have chosen to share the code, pretrained models and data upon acceptance.								The requirements resulting from the answers to the checklist are met in the manuscript.											0	0	0	0	0	0	
108-Paper0672	CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification	The proposed work is described clearly and logically and has a certain reproducibility.								Mostly reproducible. Sufficient references and details are provided in the paper for the proposed method, but not the implementation details of the compared methods.								The authors did include the sufficient details of the computational infrastructure, however, the hyper-parameters provided might not be enough to reproduce the model training. The authors did not provide sufficient details regarding data preprocessing.											0	0	0	0	0	0	
109-Paper0692	CenterlinePointNet++: A new point cloud based architecture for coronary artery pressure drop and vFFR estimation	Not easy to reproduce. A lot of important implementation details are not given.								The synthetic data cannot be accessed openly, and neither can the parameters used for the simulation.								Methods were clearly described and code will be released. The paper seems to be reproducible.											0	0	0	0	0	0	
110-Paper0619	Centroid-aware feature recalibration for cancer grading in pathology images	Reproducibility is good.								The version and platform of the model implementation should also be given for the reproducibility.  The specific variant of the compared methods should also be made clear. E.g. which variant of Swin is used?								The paper offers implementation details and a description of the datasets used in the study.											0	0	0	0	0	0	
111-Paper2489	Certification of Deep Learning Models for Medical Image Segmentation	The reproducibility of this paper is low. In the reproducibility checklist, the authors have replied "Yes" to all the items, but almost all of them are missing from the paper or the supplementary material.    "A clear declaration of what software framework and version you used." -> missing.  "The range of hyper-parameters considered, method to select the best hyper-parameter configuration, and specification of all hyper-parameters used to generate results." -> missing.  "Information on sensitivity regarding parameter changes." -> missing.  "The exact number of training and evaluation runs." -> missing.  "A description of results with central tendency (e.g. mean) & variation (e.g. error bars)." -> missing.  "An analysis of statistical significance of reported differences in performance between methods." -> missing.  "The average runtime for each result, or estimated energy cost." -> missing.  "A description of the memory footprint." -> missing.  "An analysis of situations in which the method failed." -> missing.  "A description of the computing infrastructure used (hardware and software)." -> missing."								The authors employed public datasets and the paper is easy to follow and understand, so it seems reproducible.								The reproducibility is very good. The authors only use public datasets and they will release their code. It is also possible to follow the descriptions in the paper to reproduce certain parts of their method.											0	0	0	0	0	0	
112-Paper0586	Chest X-ray Image Classification: A Causal Perspective	Seems fine.								The dataset is publically availabel and the codes are provided in the supplementary materials.								yes											0	0	0	0	0	0	
113-Paper2463	CheXstray: A Real-Time Multi-Modal Monitoring Workflow for Medical Imaging AI	code sharing declared upon acceptance  lack of supplementary info								Yes								Reproducible since it is trained on publicly available datasets											0	0	0	0	0	0	
114-Paper0478	CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention	It can be reproducable.								The authors didi not provide their source code, and thus the reproducibility is not guaranteed.								To ensure the reproducibility of the results, I recommend that the authors release the code and any relevant details about the implementation.											0	0	0	0	0	0	
115-Paper2139	CL-ADDA: Contrastive Learning with Amplitude-Driven Data Augmentation for fMRI-Based Individualized Predictions	Code is released and the datasets can be accessed on demand so this work should be reproducible.								It is ok.								Good, the parameters involved in the paper and the details of the method are given.											0	0	0	0	0	0	
116-Paper0966	Class Specific Feature Disentanglement And Text Embeddings For Multi-Label Generalized Zero Shot CXR Classification	The datasets used are open datasets, and we encourage making the code public for reproducibility.								Major details related to the experimental protocol and implementation are missing.								N/O											0	0	0	0	0	0	
117-Paper0956	Class-Aware Feature Alignment for Domain Adaptative Mitochondria Segmentation	This paper is not reproducible as important information about the basic set-up and implementation is missing. See weaknesses for details.  The authors do not provide any code and also do not mention whether they intend to make code public if the paper was to be accepted.								Detailed methodology: The authors provide a comprehensive description of their proposed method, including the formulation of various loss functions and the overall architecture. This information would be helpful for researchers looking to implement the method on their own.  Implementation details: The authors have described the implementation details, including the patch size, optimizer, learning rate, and the number of training iterations. They also provide the balancing weights and thresholds used in their loss functions. This information should be helpful for reproducing the experiments.  Dataset: The authors use publicly available datasets, Lucchi and MitoEM, which can be accessed by other researchers.  Evaluation metrics: The authors use standard evaluation metrics (e.g., Intersection over Union) to assess the performance of their method, which would allow for a fair comparison with other methods and make it easier to reproduce the evaluation.								It is achievable to reproduce the method according to the illustration in the paper.											0	0	0	0	0	0	
118-Paper1871	Client-Level Differential Privacy via Adaptive Intermediary in Federated Medical Imaging	This paper claims to have theoretical and empirical evidence to support its feasibility. It also provides analytical studies to demonstrate the effectiveness and stability of its method. However, the paper's feasibility might be improved by providing more details on how it compares with other methods.								Appears to be reproducible.								The authors state that the code will be made available and they explain the backbone models used + the training regime. The datasets are also in the public domain, so their tests should be reproducible.											0	0	0	0	0	0	
119-Paper2270	Clinical Evaluation of AI-assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma	There is limited reproducibility as the authors acknowledge in their checklist-code is not available and there are no details on model parameters nor hyperparameters, nor training schema.								The evaluation was done with multi-institutional data with two readers. The reproducibility is very high.								The authors should provide more details about how the radiologists viewed the images. For example, did they use any window/level? What kind of monitor was used for viewing? How to make sure the viewing conditions are calibrated across different monitors?											0	0	0	0	0	0	
120-Paper1961	CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction	Since the data is public and the test is performed with only one dataset, tests can be reimplemented and diversified by adding different datasets. Furthermore, this model can be developed and varied using different text attributes. Since information or data sources can be extended and varied by making visual representations from text annotations, similar techniques can be developed to be used in different fields.  However, since the model code is private, this will significantly affect the reproducibility or reusability of the methods. It will be challenging to produce all those identical inferences since they tested the model with too many subsets of the same data and all combinations of different loss functions.								The technologies used in this paper have good reproducibility.								The paper can be reproduced to some extent.											0	0	0	0	0	0	
121-Paper0680	Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans	Not sure since the data and the code are not publicly available.								model parameters are provided. Nevertheless, without the datasets and ground truth labels of the proposed study, neither testing nor training can be reproduced.								probably doable (method is based on cvpr and eccv papers)											0	0	0	0	0	0	
122-Paper2079	Clustering disease trajectories in contrastive feature space for biomarker proposal in age-related macular degeneration	good								The reproducibility of the work is low because the both the code and datasets will not be released. In addition, the qualitative assessment cannot be repeated.								Reproducibility is addressed.											0	0	0	0	0	0	
123-Paper0169	CoactSeg: Learning from Heterogeneous Data for New Multiple Sclerosis Lesion Segmentation	Currently not reproducible before the code and data are made available but all supposed to happen at publication. Details on training is given but limited information (except if present in the repo) of the data used in training / validation / testing								Code and data would be released upon acceptance. Validating reproducibility will be straightforward.								The method is easy to follow and reproduce. Authors will public the code at a later time.											0	0	0	0	0	0	
124-Paper1473	Co-assistant Networks for Label Correction	Three public database are used to validate the proposed approach: BreakHis (breast cancer histopathological images), ISIC (skin images), and NIHCC (frontal-view X-ray images)								This is fine								The author provides sufficient implementation details which helps reproduce the results.											0	0	0	0	0	0	
125-Paper1393	Cochlear Implant Fold Detection in Intra-operative CT using Weakly Supervised Multi-Task Deep Learning	The paper is fairly difficult to reproduce as is. One of the main components (generation of realistic images with metallic artifacts) is not described in sufficient detail),								Partially reproducible - the geometric aspects and constraints used in the process of creating the artificial electrodes are provided at a very high-level detail. This hinders the reproducibility of the datasets. In case this paper is going to be extended to a journal paper, I strongly emphasize on the importance of clarifying this part being the prominent contribution of the work.								The network is simple and hyperparameters are reported to reproduce it. No information on accessibility of the synthetic and/or real dataset.											0	0	0	0	0	0	
126-Paper2305	CoLa-Diff: Conditional Latent Diffusion Model for Multi-Modal MRI Synthesis	The authors are using a public dataset and the hyper-parameters and training settings of the network is shared. These factors have a positive effect on the reproducibility of the paper.								The requirements resulting from the answers to the checklist are met in the manuscript.  Additionally the authors submitted their code.								It is claimed that the code will be released.											0	0	0	0	0	0	
127-Paper0107	Co-Learning Semantic-aware Unsupervised Segmentation for Pathological Image Registration	The method is quite complex but I believe it is reproducible. Some details will have to be taken from the works describing the related methods used.  Not sure if the synthetic data is fully reproducible or will be made available								The description of the method and experiments is not clear enough to replicate it.								The data used in the paper is all freely available data (provided by others, not the authors) which helps to reproduce their results and/or compare alternative methods. Details on network training or data simulation are NOT provided. The code used in the paper does not appear to be made available.											0	0	0	0	0	0	
128-Paper1979	Collaborative modality generation and tissue segmentation for early-developing macaque brain MR images	I think this paper can be reproducible.								The authors claim will release the code in the checklist. The dataset is public. The study is reproducible.								the description of the method part is clear and the used dataset is public.											0	0	0	0	0	0	
129-Paper0594	COLosSAL: A Benchmark for Cold-start Active Learning for 3D Medical Image Segmentation	Excellent levels of reproducibility								The paper states that the code will be publicly available.								The methods and dataset used in this paper are all publicly available. The code is also publicly available. So the reviewer believes that the reproducibility of the paper is great.											0	0	0	0	0	0	
130-Paper0232	Combat Long-tails in Medical Classification with Relation-aware Consistency and Virtual Features Compensation	The authors used two publicly available datasets. The authors haven't released the code, however, the work should be reproducible based on the descriptions. The authors haven't reported the mean and standard deviation despite the claim in the reproducibility form.								Although it is stated that the code for the method and experiments is available, I did not find this information in the paper. The methods described in the paper seem sufficient to reproduce the results. The reproducibility points given are mostly valid and agree with the reported details, with the exception of the code release.  The following items are checked in the reproducibility check and are not found in the paper: I) The hyperparameter selection procedure II) Number of training runs III) Results with central tendency and variation IV) Run time V) Memory usage (reported as not relevant, but would be relevant)								Good. The paper designed a long-tail dataset based on a public dataset. The supplementary material provides more details about the label distributions of various classes. Also, Section 3.2 provides implementation details including setting the parameters. However, the authors didn't mention the plan of releasing the code.											0	0	0	0	0	0	
131-Paper2991	Combating Medical Label Noise via Robust Semi-supervised Contrastive Learning	The method is well-described; some hyperparameters are not part of the ablations (omega, mu). Training hyperparameters are described in supplementary materials, and code will be made available upon acceptance.								While i appreciate the paper consider multiple baselines, I couldn't find sufficient experiment details in both the main paper and supplement for these compared algorithms. For example, did you do a hyperparameter search for each algorithm? did you try to ensure the hyperparameter search is relatively fair for each compared algorithm? Did you use the same backbone or ensure the backbone used is alsor relatively fair for different algorithms?etc.								The experiment should be reproducible											0	0	0	0	0	0	
132-Paper1939	Community-Aware Transformer for Autism Prediction in fMRI Connectome	Some important details about the transformer architecture used in the proposed model are missing which will hinder reproducibility.								No major issues. Don't seem to be able to find the average runtime despite it being mentioned in the checklist, would have been useful to have it mentioned somewhere in the paper or readme.								Good, the source codes are given to ensure the implementation.											0	0	0	0	0	0	
133-Paper1089	Computationally Efficient 3D MRI Reconstruction with Adaptive MLP	The papers results are reproducible.								Proper data statement was provided.								The reproducibility of the paper is good.											0	0	0	0	0	0	
134-Paper3305	Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation	The code will be made public upon acceptance and the method does not seem difficult to implement. The datasets used in the paper is public.								The results presented by the paper could be 100% reproducible by the community if the code is provided, given that all the experiments were done using public medical image segmentation dataset. The computational resources used to train the model and perform inference are fully within the reach of the vast majority of groups conducting research in deep learning applied to medical imaging.								The method is reproducible. A detailed description of the algorithm as well as the experimental configuration is available in the paper.											0	0	0	0	0	0	
135-Paper0259	Conditional Physics-Informed Graph Neural Network For Fractional Flow Reserve Assessment	The manuscript presents most of the details to reproduce the results, but the text is often difficult to follow and leaves room for guessing.								The authors provide a general structure of their model.They do not report hyperparameters nor the exact architecture they use. but the description of the in-vivo is missing (I assume they are private datasets).								The method description is fairly clear and complete. I found it not very clear how the Hq and Hp features are obtained (how does the "element-wise fusion" work?).											0	0	0	0	0	0	
136-Paper1290	Conditional Temporal Attention Networks for Neonatal Cortical Surface Reconstruction	The proposed method seems reproducible.								Although code will be made available upon publication, the clearly described method will help reproduce the work.								Looks great!											0	0	0	0	0	0	
137-Paper0848	Consistency-guided Meta-Learning for Bootstrapping Semi-Supervised Medical Image Segmentation	As the authors provide code for their method, it seems unlikely that reproducibility will be a problem.								The paper has high reproducibility and the dataset and code are publicly available.								The authors have provided code, so the reproducibility should be guaranteed.											0	0	0	0	0	0	
138-Paper1221	Content-Preserving Diffusion Model for Unsupervised AS-OCT image Despeckling	This study is not based on public dataset. The code is not open to public either.								The proposed needs more implementation detail (noise level and iteration number estimation) to reproduce.								Might be difficult due to unavailability of dataset and code.											0	0	0	0	0	0	
139-Paper0770	Context-Aware Pseudo-Label Refinement for Source-Free Domain Adaptive Fundus Image Segmentation	The reproducibility of the paper is not an easy task. Although the method is a little clear, the trainable parts of the method would present several issues to obtain the same obtained results.								The method in the paper is trained on a publicly available dataset and is also relatively well reproducible.								The source code is not open, which may affect the reproducibility.											0	0	0	0	0	0	
140-Paper0621	Continual Learning for Abdominal Multi-Organ and Tumor Segmentation	It can reproduce, the author provide data and code.								The source code is available online.								The approach is reproducible in a lab setting with resources available. On top of that, they have used a couple of publicly available datasets alongside publishing their code. Therefore, it would be a good contribution in the medical science and is relatively easy to incorporate even with clinical applications to identify and segment brain tumors.											0	0	0	0	0	0	
141-Paper3247	ConTrack: Contextual Transformer for Device Tracking in X-ray	Yes, for the algorithm description and relevant hyper parameters of the model.								The study uses an internal dataset so reproducibility is not applicable in this case; the description of the method is feasible, though the ability to implement the method independently is not known because we do not have the underlying hyperparameters.								The reproducibility can be questioned given the huge volume of annotated data to collect.											0	0	0	0	0	0	
142-Paper1275	Contrastive Diffusion Model with Auxiliary Guidance for Coarse-to-Fine PET Reconstruction	The method can be reproduced if the code is provided								It is stated on CMT that the code and model weights will be released. Please confirm.								The general libraries used in the proposed method are mentioned.											0	0	0	0	0	0	
143-Paper1098	Contrastive Feature Decoupling for Weakly-supervised Disease Detection	Datasets are open from other studies  Code is supposed to be in Github and not available due to anonymity								In the abstract, the authors indicate both code and dataset will be made available through Github.																			0	0	0	0	0	0	
144-Paper1768	Contrastive Masked Image-Text Modeling for Medical Visual Representation Learning	The proposed approach, used hyper-parameters, training approach, and hardware configuration are well defined. Experimental datasets are publicly available. Considering these points, the paper should be reproducible.								The authors clearly describe their experimental and hardware setup and the parameter configurations of the model. Further, the authors, upon acceptance, will publish the code, and the model weights. With this information, I'm confident that the results in this paper can be reproduced.								Reproducible    Training and Evaluation codes available  Model description included											0	0	0	0	0	0	
145-Paper2620	ConvFormer: Plug-and-Play CNN-Style Transformers for Improving Medical Image Segmentation	Authors perform experiments on 2 public and 1 private dataset. Authors do not provide the code to reproduce the experiments, nor trained NN weights.								Good								The proposed method was tested on public datasets and the method is easy to implement. Besides, the code will be provided.											0	0	0	0	0	0	
146-Paper3654	Convolving Directed Graph Edges via Hodge Laplacian for Brain Network Analysis	The information and level detail provided is sufficient to reproduce the results.								The paper is not easily reproducible right now. The proposed convolutional operator should be integrated into torch_geometric, and the architecture needs to be described. A clear description of the model training would also be needed for reproducibility.								The paper provides formalism to derive their framework, but no source code. Substantial expertise in GNN concepts and implementation may be required to reproduce it.											0	0	0	0	0	0	
147-Paper0206	cOOpD: Reformulating COPD classification on chest CT scans as anomaly detection using contrastive representations	The paper seems reproducible; the data is opensource and the code will be make public.								The experimental results cannot be replicated solely from the paper's description.								Details regarding the models and algorithms, and datasets used were provided. The code related to this will be made available upon acceptance. Some details related to the reported experimental results were also provided.											0	0	0	0	0	0	
148-Paper0603	Correlation-Aware Mutual Learning for Semi-supervised Medical Image Segmentation	The method is not easy to reproduce. Thus, it will be better to release the code for reproduction.								The implementation details are well explained. The choice of N for the memory bank (N x  Dlabelled  x C) is not reported, nor it is explained how the memory bank picks the first N pixels to store.								Reproducibility is good, data is public, and code is open-source.											0	0	0	0	0	0	
149-Paper2102	CorSegRec: A Topology-Preserving Scheme for Extracting Fully-Connected Coronary Arteries from CT Angiography	Code and models are not available now.								The paper includes sufficient details on the methods used, parameters, and underlying datasets used for training and evaluation.								Given the model was trained on publicly available data, it should be feasible to reproduce given results. However, since the method utilizes uncommon techniques, one would probably require an considerable amount of time to do it. It would be much easier, if the authors share the code.											0	0	0	0	0	0	
150-Paper2218	CortexMorph: fast cortical thickness estimation via diffeomorphic registration using VoxelMorph	the authors want to publish code and pre-trained models. Further the required code for DeepSCAN and Voxelmorph is also public.								Methods are reproducible, with some guessing/experimentation needed.								Sufficient details of the architecture are not provided to re-implement the method, and no placeholder for a link to a repository is yet included in the manuscript.											0	0	0	0	0	0	
151-Paper0363	Cortical analysis of heterogeneous clinical brain MRI scans for large-scale neuroimaging studies	The checklist indicates that descriptions of algorithms, models, hyper-parameters, failure modes, etc are available. If provided with this information, the reproducibility of the paper should be high.								Excellent, code and data are publicly available.								The authors provide code for this submission. This will help increase the reproducibility of the paper.											0	0	0	0	0	0	
152-Paper2725	Coupling Bracket Segmentation and Tooth Surface Reconstruction on 3D Dental Models	Reproducible.								* Reproducibility is high, given that the paper is clearly written and code is provided.								The only paper out of the ones I have reviewed to provide appropriate code for repeatability and reproducibility. Dataset not available.											0	0	0	0	0	0	
153-Paper1449	COVID-19 Pneumonia Classification with Transformer from Incomplete Modalities	the proposed model has the potential to be applied to other to other  chest abnormalities using multiple modalities.								Can be preproduced.								he authors have presented comprehensive details and resources, indicating that the proposed method can be reproduced with ease.											0	0	0	0	0	0	
154-Paper1030	Cross-adversarial local distribution regularization for semi-supervised medical image segmentation	Could be improved.								I can not sure readers can reproduce this paper.								The proposed method is clear and the implementation details are exhaustive, therefore, I believe the paper can be reproduced.											0	0	0	0	0	0	
155-Paper1398	Cross-Dataset Adaptation for Instrument Classification in Cataract Surgery Videos	The authors provide information about parameters used. They do not provide information about how to obtain the source code for the Barlow Adaptor/BFAL.								One of the datasets is not publicly available. There are no results on public benchmarks while this possibility exists. Therefore, there is limited reproducibility of the results.								One of the used datasets is public, and the authors claim that their code will be publicly available upon acceptance.											0	0	0	0	0	0	
156-Paper1273	Cross-modulated Few-shot Image Generation for Colorectal Tissue Classification	The architecture may be a bit complex to implement from scratch, but the authors mention they will release the code publicly.								Code and data do not seem to be available.  Sounds good.								Seems to be reproducible, not 100% sure											0	0	0	0	0	0	
157-Paper2880	Cross-view Deformable Transformer for Non-displaced Hip Fracture Classification from Frontal-Lateral X-ray Pair	The paper works on closed-source dataset.								Reproducing might be difficult as the paper didn't provide many implementation details, such as specific hyper-parameters of the model blocks and training hyper-parameters.								The authors claim that the code and data will be released upon acceptance. The implementation details discussed in the paper look good.											0	0	0	0	0	0	
158-Paper1811	CT Kernel Conversion Using Multi-Domain Image-to-Image Translation with Generator-Guided Contrastive Learning	I believe that the obtained results can, in principle, be reproduced. Even though key resources (e.g., code) are unavailable at this point, the key details (e.g., proof sketches, experimental setup) are sufficiently well described for an expert to confidently reproduce the main results, if given access to the missing resources.								n/a								Reasonable.											0	0	0	0	0	0	
159-Paper3327	CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows	See above								Reproducible.								The authors used a publicly available dataset as part of the dataset.  Even if their own dataset is not public, they will disclose the pre-trained model and its codes. This will increase the reproducibility even if some details were not mentioned in the text.											0	0	0	0	0	0	
160-Paper2586	CT-guided, Unsupervised Super-resolution Reconstruction of Single 3D Magnetic Resonance Image	Code will be released and the reproduce is possible								The method has been explained well, should be sufficient to reproduce.								The paper has present details on how to implement the method from scratch.											0	0	0	0	0	0	
161-Paper2090	CXR-CLIP: Toward Large Scale Chest X-ray Language-Image Pre-training	The presentation should be improved. This article seems to be written in a bit of a hurry, and there is a lot of scope for improving the presentation of the paper.  There are lots of abbreviations in the main text. I recommend the authors only abbreviate the important terms.  For example, it is better to give a detailed description (or a full name) of TCL and ICL in the Abstract.    The proposed TCL and ICL are not novel.  The image-only contrastive learning has been widely explored in literature.  The text-only contrastive learning has been widely explored in NLP and several medical image-text pre-training papers, e.g., [1].    The experiment should be improved.  Lots of newly published works [2][3] are missing. I strongly recommend the authors compare the proposed approach with these existing works.  I would like to see a statistical significance test, due to the performance gap between the proposed approach and the previous state-of-the-art methods is small. Besides, the statistical significance test can eliminate the rand. impact of few-shot settings.  The analysis is poor. The analysis doesn't provide insights about the contributions of each component or how that affects the final results/addresses the claimed problems (and why).  The paper is written in an optimistic tone that leads the reader to assume the proposed approach is rather good. However, I am more interested in knowing if the approach brings errors. And what type of errors does it bring? And why?    References:  [1] Making the Most of Text Semantics to Improve Biomedical Vision-Language Processing. ECCV, 2022.  [2] Advancing Radiograph Representation Learning with Masked Record Modeling. ICLR, 2023.  [3] Generalized radiograph representation learning via cross-supervision between images and free-text radiology reports. Nature Machine Intelligence, 2022.								(1) No code provided.  (2) The supplementary materials provide more experiment results, text templates for zero-shot classification tasks, and prompt templates for text data augmentation.  (3) The model design in the paper is clear. The model would be reproducible based on the descriptions in the paper.								it seems possible to reproduce.											0	0	0	0	0	0	
162-Paper0489	CycleSTTN: A Learning-Based Temporal Model for Specular Augmentation in Endoscopy	It should be able to reproduce it with some efforts.								The video and many visualization results are provided. The experiment is carried out on a public dataset.								I think the result could be reproduced if proper code was provided.											0	0	0	0	0	0	
163-Paper1426	DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation	The authors claim in the abstract that they will released the code.								The authors claimed will release the codes after acceptance, which might contribute to the reproducibility.								Reproducible based on the paper description.											0	0	0	0	0	0	
164-Paper1312	DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs	The results are on publicly available datasets and the authors promised to share the code.								The relevant details are described clearly, the code has already been published.								Code provided with all relevant implementation and experimental details. Fairly reproducible.											0	0	0	0	0	0	
165-Paper3286	DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation	I am uncertain about the reproducibility of the paper								The reproducibility of this paper is excellent. The authors have committed to release their code and conducted their experiments entirely on publicly available data, with the final results being on the test set of a challenge which is private, and allows for their method to be demonstrably superior on a public leaderboard.								Reproducible											0	0	0	0	0	0	
166-Paper3478	Data AUDIT: Identifying Attribute Utility- and Detectability-Induced Bias in Task Models	The authors have indicated that the full code, including data splits etc., will be made available upon acceptance. The study uses publicly available datasets.								It is recommanded to provide code								Looks clear.											0	0	0	0	0	0	
167-Paper2036	DBTrans: A Dual-Branch Vision Transformer for Multi-modal Brain Tumor Segmentation	Due to the inherent complexity of the proposed method, I would recommend providing the source code. Otherwise, it may be difficult to implement it from scratch.								The reproducibility of this paper is good. The description of the experiment is good.								The reproducibility of this paper is not very good unless the author clearly explains how to handle the relationships between modalities when splitting the embeddings.											0	0	0	0	0	0	
168-Paper1388	DCAug: Domain-aware & Content-consistent Cross-cycle Framework for Tumor Augmentation	All data and codes are made available to public.								This paper uses several public datasets, and will provide training code, which is highly reproducible.								Datasets are public. Codes are not provided, it seems the code could be reproduced.											0	0	0	0	0	0	
169-Paper1588	Debiasing Medical Visual Question Answering via Counterfactual Training	Data sets are publicly available. If authors provide source code and experimental details, the reviewer will be confident in the reproducibility.								This work can be reproducible after authors open their dataset and source code.								I believe this work can be reproduced if the code is given.											0	0	0	0	0	0	
170-Paper1846	Deblurring Masked Autoencoder is Better Recipe for Ultrasound Image Recognition	The authors have agreed to update their code in GitHub. Any publicly available data can be tested using their code. Detailed summary of the hyper parameter settings and ablation study is provided in the supplementary material which ensures reproducibility of the paper.								Probably. the method description is clear. It seems the code will be made public in the future. The experimental dataset used in the study is private.								Code and dataset are not available so not reproducible.											0	0	0	0	0	0	
171-Paper2853	Decoupled Consistency for Semi-supervised Medical Image Segmentation	Knowledgeable reader would be able to reproduce the approach.								very good, results on public dataset and all the details are specified.								The code is NOT promised to be released so I encourage the authors to release the code.											0	0	0	0	0	0	
172-Paper3513	DeDA: Deep Directed Accumulator	Good. Using existing dataset (already published). Code to be made publicly available.								I think that it is difficult to reproduce the results from the paper. A private dataset was used, and I found no (future) link to the code.   The reproducibility statement has some points checked that I could not find in the paper (Same goes for some other papers I reviewed): Hyperparameter tuning, sensitivity to parameter change, baseline method implementation, tendency of results, and significance.  Further, the following points are marked as not applicable but would have been relevant: Runtime, memory footprint, central tendency,								reproducibility looks okay.											0	0	0	0	0	0	
173-Paper2886	Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology	ok, if the code is public								The experiments were conducted on public available dataset.  The authors did not claim the code will be released. Whereas, the described algorithm is easy to implement.								Given the simplicity of the presented method, I believe it can be reproduced without much problem.											0	0	0	0	0	0	
174-Paper1269	Deep Homography Prediction for Endoscopic Camera Motion Imitation Learning	The experiments are conducted on public datasets but the code is not open sourced yet.								The authors have committed to release their code on GitHub. This will allow other researchers to access, review, and build upon the proposed method.								I think that the pipeline described in the paper should be reproducible.											0	0	0	0	0	0	
175-Paper1976	Deep Learning for Tumor-associated Stroma Identification in Prostate Histopathology Slides	I believe the presentation of the paper is clear and will allow reproducibility. Publishing the data/code would also help. Some more information about the MLP used for the adversarial part of the method should also be included.								The paper gives all the details. However, the dataset may not be available to reproducing the result.								There are a multitude of issues with the reproducibility of this paper, in particular a strong disagreement between the self-reported reproducibility response and the paper.   -- While the authors state in the reproducibility response that they provided all relevant statistics, I strongly disagree with this. They did neither provide the number of cases included in dataset A, nor where the samples where taken from or just any information about the study cohort.   -- While the authors state that they provide a complete description of the data collection process, this is entirely missing and thus just a false statement.  -- While the authors state that IRB approval was required for the data acquisition, they do not give any details if it was obtained in the paper.   -- The authors claim that code and models are available, but this is mentioned nowhere in the paper and thus I must assume that they do not aim to release it.   -- The authors claim that they release the dataset alongside the paper (,,Dataset or link to the dataset needed to run the code. - Yes"), but there is no mention of that in the paper.  Overall, I think the reproducibility of the paper is thus poor.											0	0	0	0	0	0	
176-Paper3324	Deep Learning-Based Air Trapping Quantification using Paired Inspiratory-Expiratory Ultra-Low Dose CT	Details regarding the models and algorithms, and datasets used were provided. The code related to this work was not made available. Some details related to the reported experimental results were also provided.								There is no code available nor data or annotations available for download and inspection. Given the relative lack of details on the annotation method this would be challenging work to reproduce.								Fair											0	0	0	0	0	0	
177-Paper2137	Deep Learning-based Anonymization of Chest Radiographs: A Utility-preserving Measure for Patient Privacy	The paper is reproducible to the extent that sufficient detail is provided for someone to repeat the experiment if they are knowledgeable in the background. However, code is desirable with comments. Datasets used are publicly accessible.								The dataset used in this study is publicly available. The author did not mention about the code of this work.								The paper is well written and seems reproducible. Also, the paper used chestX-ray14, a publicly available dataset. I will suggest releasing the code.											0	0	0	0	0	0	
178-Paper0746	Deep Mutual Distillation for Semi-Supervised Medical Image Segmentation	The author's mention of releasing the code, which is beneficial for reproducibility.								The datasets are publicly available and the code is promised to be so, therefore reproducibility seems granted.								The changes to the original method, the used architecture, training setting and datasets are well described. The work should be reproducible.											0	0	0	0	0	0	
179-Paper2151	Deep probability contour framework for tumour segmentation and dose painting in PET images	the link of the code is not available, but I think it will be added.   The dataset is public and parameters of the method are described.								The paper uses a public dataset to validate the proposed method. The method is presented through multiple papers, one of which defines the KsPC method, while the other presents the KsPC-Net. The paper can be considered reproducible; however, providing the code would enhance its reproducibility.								No concerns here because the authors will make the code available.											0	0	0	0	0	0	
180-Paper3177	Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing	Although the results could be easily reproduced, I think the authors do not intend to make the dataset public, as they are solving a well-defined task the necessitates of the hardware and might be too much constrained to the specific application detailed therein. Nonetheless, the community could benefit from following similar approaches.								If the authors will release the code ("not applicable" in the checklist now), I think the reproducibility of the paper is good.								The authors did not indicate that they will share their codes or data if their work may get accepted.											0	0	0	0	0	0	
181-Paper3352	Deep unsupervised clustering for conditional identification of subgroups within a digital pathology image set	The authors meet all criteria on the reproducibility checklist  But the pre-trained model								n/a								The code will be made available if accepted											0	0	0	0	0	0	
182-Paper2493	DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear Functional Brain Network Dynamics	The information included seem to be sufficient for reproducing the results.								Good								All the details required to reproduce the results are provided. I noticed an anonymised github link and assume that the source code will also be made available once the manuscript is published.											0	0	0	0	0	0	
183-Paper1333	DeepSOZ: A Robust Deep Model for Joint Temporal and Spatial Seizure Onset Localization from Multichannel EEG Data	Most detail is provided. No links to data or code, but data is publicly available and can be found via google search								It would be easy to reproduce if they make their code public.								There is no implementation of the code provided or at least mentioned that the authors would do it in the future. Although it is not necessary but it could help the reviewers to verify the results.											0	0	0	0	0	0	
184-Paper0702	Democratizing Pathological Image Segmentation with Lay Annotators via Molecular-empowered Learning	The study presented should be easily reproduced as all details are in the paper.								The paper claimed that the official implementation would be publicly available when ready.								The authors provide access to cell annotations and code implementations. I therefore believe that the paper should be largely reproducible. However, hyperparameters for AI training are not provided within the text, and the use of ImageJ is mostly non reproducible.											0	0	0	0	0	0	
185-Paper0423	Dense Transformer based Enhanced Coding Network for Unsupervised Metal Artifact Reduction	I don't have concern on reproducibility.								Clear to reproduce.								The proposed DTEC-Net is a combination of existing methods, the process is clear, and the release code at the time of publication is mentioned in the abstract. I believe it's repeatable											0	0	0	0	0	0	
186-Paper2990	Deployment of Image Analysis Algorithms under Prevalence Shifts	The reproducibility aspect of the paper is good (public data set, clearly mentions network parameters and cites algorithms that have been used from prior work).								Provided the enclosed code for this work is well commented, this work appears to be highly reproducible. It would benefit from a clearer mathematical description of the methods (already detailed in "weaknesses" section)								Experiments were done with public datasets.  Code will be made available.  Reproducibility is guaranteed.											0	0	0	0	0	0	
187-Paper0698	Detecting domain shift in multiple instance learning for digital pathology using Fr√©chet Domain Distance	The core CLAM method is publicly available and has been widely used as a baseline in MIL studies. Both datasets are available to researchers (the more recent dataset requires a specific request to be made but presumably this will not restrict someone from attempting to reproduce the experiments)  The supplemental file was missing on the CMT site - I assume this would have contained additional information needed to reproduce the study.								The paper is reproducible and the details are enumerated clearly.								The results are reproducible.											0	0	0	0	0	0	
188-Paper1410	Detecting the Sensing Area of A Laparoscopic Probe in Minimally Invasive Cancer Surgery	The authors mention that the dataset will be made available upon acceptance of the paper. In addition, the parameters used in the experiments are discussed in the paper. With the source code available as well, I think that an interested reader will be able to reproduce the results easily.								The presented work has in my opinion a moderately strong reproducibility, mainly since the author(s) provided a public version of the dataset. However, some required details are missing in the manuscript, for example data split.								data set is public available, thus reproducibility can be achieved											0	0	0	0	0	0	
189-Paper1897	Detection of basal cell carcinoma in whole slide images	The reproducibility is hard to predict because the evolutional search does not always give out similar results.								The article includes details on the architecture and its hyperparameters which makes it possible to reproduce.								Based on what was reported by the authors of the article and based on the Reproducibility Checklist, I believe that the reproducibility details are adequate. However, if it were possible to focus my concerns on the experimental part described above, the reproducibility of the paper would also benefit.											0	0	0	0	0	0	
190-Paper1666	Detection-free Pipeline for Cervical Cancer Screening of Whole Slide Images	The article did not provide open source codes, but the relevant methods can refer to the codes of other papers, and the details were described clearly, so the methods can be reproduced.  The article did not use a public dataset, and the data used will not be publicly available, so the accuracy of this article cannot be proven through reproduction.								Reproducibility of the paper is reasonably good. The framework is clearly described.								The author's description of the algorithm is basically reasonable, clear, and reproducible. However, the lack of relevant experimental data cannot directly verify and reproduce the effectiveness of the method.											0	0	0	0	0	0	
191-Paper1896	Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images	The authors mentioned that the code is available on github. So, I will assume it is reproducible. I think that the results will be repeatable in new dataset as it was trained on a relatively large dataset.								Detailed information about the methodology is missing, including the size of the input and output of each stage and layer.  The data used in the paper is from two well-known public repositories for testing, including the segmented masks and the bounding box outlining the regions of interest. However, the information about the data used for training is missed, although the number of cases used for the model training is big enough.								Based on the information provided, nothing to note in this section											0	0	0	0	0	0	
192-Paper0638	Development and Fast Transferring of General Connectivity-based Diagnosis Model to New Brain Disorders with Adaptive Graph Meta-learner	Most datasets are publicly available. Codes are promised to be given after acceptance.								Very good reproducibility. code will be released and dataset description as well as experiment settings are clear.								Their codes will be released after the acceptance.											0	0	0	0	0	0	
193-Paper0210	Devil is in Channels: Contrastive Single Domain Generalization for Medical Image Segmentation	This work is relatively more reproducible because the code and the model will be available.								The authors intend to release the code, otherwise the details of training is written in the paper.								The major experimental details are given.											0	0	0	0	0	0	
194-Paper0938	DHC: Dual-debiased Heterogeneous Co-training Framework for Class-imbalanced Semi-supervised Medical Image Segmentation	This method is easy to reproduce based on the paper.								Our code and models will be released upon acceptance.								Too complex to reproduce.											0	0	0	0	0	0	
195-Paper0420	Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels	The authors stated that they will provide the training and evaluation codes.								The proposed losses are easy to implement.  The results can be verified independently.								The reproducibility of this paper is excellent. All experiments were performed on publicly-available data and the source code has been made publicly available.											0	0	0	0	0	0	
196-Paper1276	DiffDP: Radiotherapy Dose Prediction via a Diffusion Model	I would question the lack of ethics and patient informed consent.								The authors promised to make the research implementation public								The in-house dataset of the rectal cancer will not be available to the readers. However, the training and evaluation codes will help readers reproduce the results on their own datasets or the public datasets.											0	0	0	0	0	0	
197-Paper2600	Differentiable Beamforming for Ultrasound Autofocusing	The proposed method is straightforward to implement and should be reproducible. Although the datasets are synthetic and may require access to raw data from ultrasound machines as well as ground-truth speed-of-sound maps of the phantoms, open-source benchmarks like CUBDL exist. Therefore, obtaining such raw data should not pose a significant challenge.								The source code and data are not available.								Authors do not plan to release the code, therefore the reproducibility would be based on the descriptions of the proposed method. These, however, could be more detailed.											0	0	0	0	0	0	
198-Paper0807	DiffMIC: Dual-Guidance Diffusion Network for Medical Image Classification	Code will be provided upon acceptance.								Good reproducibility.								The authors used three datasets, two of them public and with adequate citations. The other dataset is proprietary, with the authors confirming approval by the IRB. The authors also claim the code will be made available upon acceptance.											0	0	0	0	0	0	
199-Paper2466	DiffMix: Diffusion Model-based Data Synthesis for Nuclei Segmentation and Classification in Imbalanced Pathology Image Datasets	The authors stated that the code will be provided upon acceptance.								In general, it seems feasible to reproduce the results. However,    Some mask design details are missing.  Code is not published  Training time is not reported								The description of the method is clear and the implementation should be straightforward, it would be better if the authors can publish the code somewhere.											0	0	0	0	0	0	
200-Paper0421	DiffULD: Diffusive Universal Lesion Detection	Yes.								The code is not currently available. The used dataset (DeepLesion) is publicly available.								The dataset used in this paper is public available, but the code implementation is unavailable.											0	0	0	0	0	0	
201-Paper1624	DiffuseIR: Diffusion Models For Isotropic Reconstruction of 3D Microscopic Images	There are no obvious issues wrt reproducibility. The datasets are standard. The most complex part of the method is based on publicly available code.								The method is reproducible and can be reimplemented by a skillful graduate student.								The paper is ok with reproducibility. They provide the details about the implementation.											0	0	0	0	0	0	
202-Paper0551	Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI	Problems on the description of the training model make impossible to reproduce the work.								Authors claim they would share the codes in the future. It would be easy to reproduce the results with codes public. Otherwise, it is hard to cover all architecture and training details in the manuscript for reproducing.								The authors admit to publish the code in future. The employed dataset is public.											0	0	0	0	0	0	
203-Paper2509	Diffusion Transformer U-Net for Medical Image Segmentation	The paper should be easy to reproduce.								The reproducibility of the proposed method is uncertain due to the lack of code provided by the authors in the supplementary materials.								Code will be released as claimed in the manuscript. Datasets are all public. The work is reproducible.											0	0	0	0	0	0	
204-Paper2170	Diffusion-based Data Augmentation for Nuclei Image Segmentation	The authors have indicated that they will release both the training code and evaluation code, which is a positive step towards ensuring reproducibility of the results presented in the paper.								The code should be released. The datasets studied are public. There don't appear to be any obstacles to making the results fully reproducible apart from the computational burden of training the diffusion models.								The description of the method is clear, the paper seems reproducible.											0	0	0	0	0	0	
205-Paper2550	Diffusion-Based Hierarchical Multi-Label Object Detection to Analyze Panoramic Dental X-rays	Based on the checklist, this research seems to be reproducible.								The method is clearly explained and data as well as code will be made available.								Good.											0	0	0	0	0	0	
206-Paper1972	DiMix: Disentangle-and-Mix based domain generalizable medical image segmentation	The author provides sufficient implementation details which helps reproduce the results.								Not claimed.								An open dataset is used but the details are limited, would require reading of the dataset paper for details. No indication of how hyperparameters were selected. Hyperparameters are reported.											0	0	0	0	0	0	
207-Paper3033	DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration	Methodology description is too broad to reproduce the results.								A part of the data used in the paper is publicly available (provided by others, not the authors), but both training and evaluation also involve proprietary datasets. No code is available. Architecture and training are described adequately.								The reproductivity of the work is low since description of methodology, including CNN architecture, loss function, preprocessing and training data requirement, is unclear. For example, Eq. 2 and the CNN architecture described do not guarantee that a CNN feature has a unit norm and that Eq. 2 ranges [0,1], but training patches were sampled based on the similarity values ranging [0,1]. For the proposed DISA-LC^2, it is unclear whether the weighting function is based on the local patch variance of a fixed image or a moving image and whether it has to be recomputed for each different pair of moving/fixed images. Also, the paper describes that CNN was trained using unregistered data. Were unregistered data acquired from the same patients (intra-subject pairs) or from different patients (inter-subject pairs)?											0	0	0	0	0	0	
208-Paper1291	DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms using Self-adversarial Learning	The authors plan to make their code public which will certainly help in reproducibility given the complexity of the architecture. The description of the methodology should be sufficient to reproduce the results. Additional details are needed to clarify how the labels were defined during evaluation, as detailed in the comments for the authors. Experiments are conducted on both in-house and public datasets.								The experimental setting section contains a reasonable amount of details about the training strategy. However, the datasets splits are not clear, in particular considering that the DDSM and VTB datasets have official train/test splits and INBreast may benefit from https://arxiv.org/abs/2108.04800.								Maybe											0	0	0	0	0	0	
209-Paper2249	DisC-Diff: Disentangled Conditional Diffusion Model for Multi-Contrast MRI Super-Resolution	The author do not describe the details of the LR. In my opinion, the MRI LR image is very different from natural image, please see Multi-contrast mri super-resolution via a multi-stage integration network MICCAI 2021.								This work is partially reproducible. One experiment is on private clinical data, and no code is available, yet the method is described well.								The authors shared the source code as supplementary material.											0	0	0	0	0	0	
210-Paper1075	Discovering Brain Network Dysfunction in Alzheimer's Disease Using Brain Hypergraph Neural Network	n/a								The data is from a public dataset and the details for reproduction is provided.								The detailed parameter settings are listed. Apart from biomarker interpretation part, the method is reproducible.											0	0	0	0	0	0	
211-Paper2528	Disentangling Site Effects with Cycle-Consistent Adversarial Autoencoder for Multi-site Cortical Data Harmonization	The paper uses partially open data. Code release is not mentioned in the paper, but is mentioned in the reproducibility statement. This should be included in the body of the paper upon release.								Reproducibility seems fine. Pre-processing details are provided. They say that the code will be released. References are provided for cohorts.								The Experimental Setting section is relatively short but seems to contain the necessary information to reproduce experiments (including main hyperparameters of the method), although two of the datasets used for experiments are private. I may have missed this information while reading the paper, but I do not think authors have provided a link to their code.											0	0	0	0	0	0	
212-Paper2523	Distilling BlackBox to Interpretable models for Efficient Transfer Learning	The authors provide the implementation code and the method is clearly described. The reproducibility of the paper is high.								Experiments with supplementary material verified the contributions mentioned in the manuscript.								The authors released their codes, and it may be reproducible yet not fully confirmed.											0	0	0	0	0	0	
213-Paper3339	Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI	Reproducible.								The code should be released.								The author/authors have filled out the reproducibility section thoroughly and have taken steps to ensure their research is transparent and replicable. The dataset, dataset split, and hyper-parameters used to train the model have been clearly discussed in the paper. It would be good to also have the 226 patients' demographic data in the experiments section.											0	0	0	0	0	0	
214-Paper1730	Diversity-preserving Chest Radiographs Generation from Reports in One Stage	The authors used public datasets and the paper is easy to follow, so the approach should be reproducible.								Public data is used. The method is described clearly, but not enough details are given to completely reproduce the work. Given the page limit, it is not bad though. Releasing the code would be helpful.								The paper can be reproduced if the code is released.											0	0	0	0	0	0	
215-Paper0718	DMCVR: Morphology-Guided Diffusion Model for 3D Cardiac Volume Reconstruction	Based on the information provided in the Reproducibility Response, it seems that the authors have taken steps to ensure the reproducibility of their research.								While the dataset used in this work is not publicly accessible, the codes can be re-implemented using the Github repositories of DiffAE. The work appears to be reproducible.								Good.											0	0	0	0	0	0	
216-Paper1258	Do we really need that skip-connection? Understanding its interplay with task complexity	Data is public  Code is offered in github but removed for anonymity								Discussion of clinical significance is not clear to me.								The paper provides sufficient detail and resources for researchers to replicate and build upon their findings.											0	0	0	0	0	0	
217-Paper1780	Domain Adaptation for Medical Image Segmentation using Transformation-Invariant Self-Training	The authors have not released the code yet. But, since the presentation of this paper is clear, I believe this work is reproducible by following the instructions outlined in the paper.								This paper provides most implementation details, including the used dataset, the preprocessing, batch size, learning rate strategy, loss functions and the parameters of the optimizer.								The method is easy to understand therefore implementing the method would not be difficult. Otherwise, the author has included sufficient details regarding hyper parameters in the paper.  According to the reproducibility checklist, the author promised to release code.											0	0	0	0	0	0	
218-Paper1703	Domain-agnostic segmentation of thalamic nuclei from joint structural and diffusion MRI	The authors state that the tool will be made openly available.Data is also available, so the paper should be reproducible.								They provide the ready-to-use tool, so reproducible and helpful.								The authors stated the codes will be distributed publicly.											0	0	0	0	0	0	
219-Paper3114	DOMINO++: Domain-aware Loss Regularization for Deep Learning Generalizability	All the parameters and formula are explained. However, The UNETR hyperparameters such as feature size dimensions and the number of attention heads are not reported. Finally, the hardware information for running the pipeline is also reported.								Reproducibility is expected to be good:    Code is available publicly  Dataset is private (explained in the paper)  Documentation of the method is thorough, clear dataset splits etc. are indicated								Authors will release code if accepted. Other than that, the rest seems to comply with conference standards.											0	0	0	0	0	0	
220-Paper2364	Dose Guidance for Radiotherapy-oriented Deep Learning Segmentation	The authors placeholder link to their github repo, so I assume the training code will be made public upon acceptance. Reproducibility might be possible with the availability of data and some details of their implementations.								The paper is fairly reproducible. The authors claim they will make their code publicly available post-anonymization. However, the use of an in-house non-public dataset will limit the ability to reproduce these results.								No details of ethics or patient consent included.											0	0	0	0	0	0	
221-Paper0595	DRMC: A Generalist Model with Dynamic Routing for Multi-Center PET Image Synthesis	Good. The authors described the method in detail and will share the code and data.								The authors have given enough information to reproduce the work.								The authors included implementation details and also plan to publish the code and data.											0	0	0	0	0	0	
222-Paper1437	Dual Arbitrary Scale Super-Resolution for Multi-Contrast MRI	The authors have provided sample code and a demo that aids reproducibility.								Not sure about this aspect.								This paper has very good reproducibility which provides testing code, training code, and data. Besides that, it also writes down the specific environment needs in a text file.											0	0	0	0	0	0	
223-Paper1255	Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos	The paper provides a detailed description of the proposed method and the experimental setup, including the dataset used, evaluation metrics, and implementation details. However, it does not mention the code or any information on how to access the implementation.								The authors didn't comment on whether the dataset used in the paper is public or whether the repository will be open-sourced. The authors describe the architecture of the model, but it might need more details to implement it as it is in the paper. The work will only be reproducible if the data and repository are available.								The authors did not discuss their code's availability in the paper.  It seems that they used a private dataset. They mentioned the size and the subjects, but the acquisition details are not provided.											0	0	0	0	0	0	
224-Paper1450	Dual Domain Motion Artifacts Correction for MR Imaging Under Guidance of K-space Uncertainty	The paper meets the reproducibility criteria. data is from a publicly available dataset, and the reviewer didn't find commitment by the authors to share the code/traing model upon accaptance.								This paper's methodology appears to be reproducible. It will be good that if the authors make the code publicly available								Nil											0	0	0	0	0	0	
225-Paper0931	DULDA: Dual-domain Unsupervised Learned Descent Algorithm for PET image reconstruction	the reprodcbility is uncelar as model is not published.								Codes are not released								Code is available, so it should be easy to reproduce.											0	0	0	0	0	0	
226-Paper2947	Dynamic Curriculum Learning via In-Domain Uncertainty for Medical Image Classification	Authors have mentioned that they will make their code public. Also they have shared a pseudo-code in the Appendix and there are enough details about the implementation in the text.								The author claimed to release the code and data necessary to reproduce the work. The paper's description is also sufficient to do so.								The paper is reproducible as the authors will provide the code and the experiment involved two publicly available datasets.											0	0	0	0	0	0	
227-Paper1793	Dynamic Functional Connectome Harmonics	Good chance of reproducing the results.								Good								This paper only uses the method on one dataset with a small sample size, and the repeatability needs improvement.											0	0	0	0	0	0	
228-Paper2346	Dynamic Graph Neural Representation Based Multi-modal Fusion Model for Cognitive Outcome Prediction in Stroke Cases	In section 3.1 on Data and Preparation, the author failed to provide a comprehensive description of the index variable division and scoring rules for stroke patients' clinical data. This inadequacy has made it challenging to replicate the results presented in the article.								This work has relatively high reproducibility.								Code will be provided; clear mathematical modeling, dataset description and split, evaluation metrics, hyperparameter configuration and clinical significance discussed; no computational cost was included.											0	0	0	0	0	0	
229-Paper0990	Dynamic Structural Brain Network Construction by Hierarchical Prototype Embedding GCN using T1-MRI	The authors claim to have the source code in github, and use the public dataset ADNI which I think is eligible for reproducing.								The author has published some parameter settings, but the code has not been fully disclosed, making it difficult to determine reproducibility.								The appraoch is reproducible, although some parameter settings are ignored.											0	0	0	0	0	0	
230-Paper0947	EchoGLAD: Hierarchical Graph Neural Networks for Left Ventricle Landmark Detection on Echocardiograms	The authors mention the publication of their code in Section 4.2. They evaluate their approach on one public and one private dataset. Therefore the evaluation of their code on the public dataset should be feasible, given that they clarify the aspects mentioned above. Implementations details are provided in Section 4.2.								The authors employ a private dataset of nearly 30000 PLAX echo images. However, no description is given regarding study design (multi-center or single-center), population enrollment and demographics (normal subjects vs. patients with left ventricular pathologies, and how many of each), image acquisition parameters (spatial and temporal resolution, ultrasound scanners used, etc.) or labelling details (e.g. instructions given to annotator(s), how many annotations were involved and whether there was any type of consensus, etc.). Moreover, no indication of ethical approval is given.  Moreover, as commented above, certain methodological details are lacking. For example, how is the multi-scale loss defined? Do the different scales equally affect the final loss or were distinct weights given to the different resolutions? Were all resolutions (K=7 plus main one) used for loss computation? Regarding inference, were the different scales combined somehow, or do you simply compute the metrics over the landmarks extracted by the main graph?  The same can be said about the experiments: the results reported in Table 1 and 2 of the main text, and Table 1 of the supplementary file, were obtained with the respective methods' official implementation or did the authors implement them? Were all parameters kept the same or were they adapted somehow to handle your private database?								The authors indicate the codes will be available from GitHub, though there is no indication on the self-collecte dataset.											0	0	0	0	0	0	
231-Paper0891	ECL: Class-Enhancement Contrastive Learning for Long-tailed Skin Lesion Classification	The paper uses public datasets and the authors agree to make the codes public, which will make this work easy to reproduce.								The datasets used in the study are publicly available, and the authors have indicated that they will make all necessary code available after publication.								Sounds good											0	0	0	0	0	0	
232-Paper1593	EdgeAL: An Edge Estimation Based Active Learning Approach for OCT Segmentation	The parameters has been clearly presented, the dataset is public, and code will be released.								The implementation details for the models and hyperparameters are generally defined, and the datasets are publicly available. However, it is unclear how the labelled validation set is being constructed from the 20% pool and whether this labelled set is being varied across different labelling budgets.								no obvious issues											0	0	0	0	0	0	
233-Paper2684	Edge-aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI	The authors comply with the checklist. No mention to code or github repository is available.								The paper provided the source code of proposed model.								The authors claim that the codes will be released.											0	0	0	0	0	0	
234-Paper1416	EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness	The authors have provided code and data for reproducibility								The workflow is clearly described and reproducible.								The authors provide both their data and code											0	0	0	0	0	0	
235-Paper1468	Efficient Spatiotemporal Learning of Microscopic Video for Augmented Reality-Guided Phacoemulsification Cataract Surgery	Software for training the described network is not presented. Detailed descriptions of the networks involved are included, and benchmarks were performed on publicly available datasets. Additional supplementary video is included to show performance.								The authors do not state that they will release the code.								The authors have not mentioned that they will release the limbus annotations (considering the reproducibility response and the paper). Hence, the results cannot be reproduced.											0	0	0	0	0	0	
236-Paper0963	Efficient Subclass Segmentation in Medical Images	The experiments are conducted on public datasets. Code is shared via anonymous.4open.science. Overall it is considered very reproducible.								The authors have provided a link to the source code in the paper itself and used two publicly available datasets. Based on the description, the work should be reproducible.								Not sure for the reproducibility.											0	0	0	0	0	0	
237-Paper1980	EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation	Reproducible.								THe code is avaiable (along with the submission).								The authors provided the codes and can be reproducibility.											0	0	0	0	0	0	
238-Paper1304	Elongated Physiological Structure Segmentation via Spatial and Scale Uncertainty-aware Network	#NAME?								I believe that it is possible to reproduce.								This work is reproducible.											0	0	0	0	0	0	
239-Paper0778	Enabling Geometry Aware Learning Through Differentiable Epipolar View Translation	Some details are missing (i.e.: dose level variation in data augmentation, step size of the operator integration...)  However, an implementation from github will be provided.								Most of the listed reproducibility checklist were met.								Details might be missing for data preparation. I suggest adding supporting code for data (and model) to this publication.											0	0	0	0	0	0	
240-Paper3118	Encoding Surgical Videos as Latent Spatiotemporal Graphs for Object and Anatomy-Driven Reasoning	The authors do not claim they will release the code in the paper. The video demo looks interesting and may be reproducible.								The authors relies on public datasets but is not reported if the code will be released or the training settings.								Most of the training parameters are defined (in manuscript/supplementary). Training / test codes are not avaiable at present. I assume it would be made public by the author if the manuscript is accepted.											0	0	0	0	0	0	
241-Paper0178	EndoSurf: Neural Surface Reconstruction of Deformable Tissues with Stereo Endoscope Videos	The submission has a companion website with data, code and results.								Code is available publicly. An anonymous link is provided and is functional (I didn't test the code). This paper uses a public dataset.								Paper is well written and code provided + implementation details provide satisfactory description.											0	0	0	0	0	0	
242-Paper0917	Enhance Early Diagnosis Accuracy of Alzheimer's Disease by Elucidating Interactions between Amyloid Cascade and Tau Propagation	Data are from the ADNI dataset, which is highly heterogenous with different subtrial (ADNI2, ADNI3, ADNIGo)....  It is not clear how you selected these.  Also you selected the patients with enough PET, but not showing from which subgroups.								If the code and specific pre-processing and experiments are open, there is hope.								The paper is aligned with responses in the reproducibility response.											0	0	0	0	0	0	
243-Paper0934	Enhancing Automatic Placenta Analysis through Distributional Feature Recomposition in Vision-Language Contrastive Learning	It seems to the reviewer that the authors are not going to open source the code and processed dataset. Thus, the reproducibility could be improved.								The authors state that they won't release the code for this work in the checklist.								The models and hyper-parameters for training is reported detailed. Code is not available. The reproducibility is not fair without the proposed pan's dataset.											0	0	0	0	0	0	
244-Paper1515	Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images	The paper is not easy to reproduce due to the inherent number of parameters of deep learning approaches. Authors are consistent in their answers.								Low reproducibility    Source code or data set are not publicly available  Not enough explanation on the proposed network architecture								According to the reproducibility checklist filled out by the authors, they provided enough information to enable others to reproduce their experimental results.											0	0	0	0	0	0	
245-Paper1308	EoFormer: Edge-oriented Transformer for Brain Tumor Segmentation	The authors provided a table with some design details of the proposed EoFormer network. The architecture and implementation details are clear. However there is no link or reference to any code. The authors stated that the code will be provided in the reproducibility checklist, along with all the information.   Information about datasets have been included in the paper.								The paper could be difficult to implement for some with multiple blocks and optimization parameters. Making the code available along with the trained model can help the community.Why is the private dataset evaluated with 4-fold validation while the BraTS trained differently? Are the same samples in the split used as other works?								The details required to implement, train and to test the proposed method are provided in the paper. Despite the private dataset, the reproducibility of the method could be evaluated using the BraTS 2020 dataset, which is a public dataset.											0	0	0	0	0	0	
246-Paper1036	EPVT: Environment-aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition	Except the details about the prompt generator are missing, the reviewer thinks that the described algorithm is reproducible.								The experiments were conducted on public datasets. The supplementary includes source codes. Therefore, the paper should have high reproducibility.								The research has demonstrated strong reproducibility by providing their code in the supplementary section and making their data readily available to the public. It showcases a high level of transparency and accessibility from the authors.											0	0	0	0	0	0	
247-Paper0986	Estimated time to surgical procedure completion: An exploration of video analysis methods	Pending adding a few more details about the loss functions, I believe this paper is reproducible. It makes use of several common datasets. Code will be released on publication.								The reproducibility checklist for the dataset is not coherent with the paper. On the checklist, it is mentioned that the information for the public dataset is provided, but the paper does not mention the use of such datasets. Furthermore, the checklist specified that the items were not applicable to new dataset, whereas the paper presents a new dataset, and the description is incomplete (see comments).								Please add more details for the feature extraction part of the paper for better reproducibility.											0	0	0	0	0	0	
248-Paper0896	Estimation of 3T MR images from 1.5T images regularized with Physics based Constraint	It is reproducible.								The authors claimed to release the source code.								Authors claimed to release code on GitHub.											0	0	0	0	0	0	
249-Paper2401	Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images	The source code is not currently available, while the method is mostly reproducible.								Seems OK. Some minor details on the training missing (e.g. batch-size, hardware). These are the sorts of things that would be best included in accompanying code, but the authors make no mention of releasing code.								Authors indicate code to recreate experimental results will be released.											0	0	0	0	0	0	
250-Paper3100	Evolutionary normalization optimization boosts semantic segmentation network performance	I contend that this paper exhibits a high degree of reproducibility, as the authors adhered to the standard experimental procedures and analysis methods, and furnished the pertinent code and data.								The paper meets the standard requirement in terms of reproducibility.								All the datasets used, except 1 are public datasets. They mention code will be available after peer review. So, the paper should be reproducible.											0	0	0	0	0	0	
251-Paper2131	Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation	The details are present in the paper.								No ethics approval statement is provided in the manuscript for the private dataset.								The overall method description is clear. The method is straightforward and It should be easy to reproduce the results.											0	0	0	0	0	0	
252-Paper3184	Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task through Visualizing Functions within the Models	The proposed approach can be applied to other medical imaging tasks to explain the decisions of the deep learning models.								The work can be re-executed and the results can be reproduced.								The paper is likely reproducible since the authors provide a detailed algorithm description and clear visualizations of their results. Reproducibility is essential in scientific research, and it helps other researchers validate and build upon their work.											0	0	0	0	0	0	
253-Paper2216	Exploring Brain Function-Structure Connectome Skeleton via Self-Supervised Graph-Transformer Approach	The method seems reproducible.								The HCP brain images used here is public dataset. No codes is given.								Not applicable											0	0	0	0	0	0	
254-Paper2001	Exploring Unsupervised Cell Recognition with Prior Self-activation Maps	The author will upload code if this work is accepted.  Therefore, the reproducibility is ok.								The method is easy to follow. The configuration for model training is provided in manuscipt.								Difficult given that there are several details that are not clear enough (please refer to Q6). However, the authors promise to provide the code.											0	0	0	0	0	0	
255-Paper2261	Eye-Guided Dual-Path Network for Multi-organ Segmentation of Abdomen	The paper is written clearly and seems reproducible. I will suggest the paper release the code.								According to the reproducibility list, the code will be released. The authors describe the network architecture in a detailed way. It seems that the paper would be reproducible.								It might be possible to reproduce the methods described in the papers. However, the training, validation and testing is not described in sufficient details to be reproduced.											0	0	0	0	0	0	
256-Paper0744	Factor Space and Spectrum for Medical Hyperspectral Image Segmentation	reproducibility depends on the code release.								Authors give hyperparameters, framework and machine used for experiments								Encourage the authors to publicly disclose code, and it is recommended to write method details more clearly. It is recommended to use charts to indicate the structure and steps. This is helpful for future scholars studying this issue and can promote the development of this direction.											0	0	0	0	0	0	
257-Paper1119	FairAdaBN: Mitigating unfairness with adaptive batch normalization and its application to dermatological disease classification	The authors have indicated that they will make all code required for running the experiments available after publication. The used datasets are publicly available.								Overall good, providing code is recommended								Sounds good											0	0	0	0	0	0	
258-Paper2436	Faithful Synthesis of Low-dose Contrast-enhanced Brain MRI Scans using Noise-preserving Conditional GANs	No problem in this field.								The proposed method seems reproducible; however, no description of the result of central tendency and no information on sensitivity regarding parameter range.								The authors mentioned that the training code won't be available. However, the architecture is explained in detail. The loss function and training flow are described well. Therefore, it should be reproducible.											0	0	0	0	0	0	
259-Paper2135	Fast Non-Markovian Diffusion Model for Weakly Supervised Anomaly Detection in Brain MR Images	Good reproducibility.								The authors used two public datasets and included references for both. Regarding the code, the authors will provide the software along with pretrained models.								Datasets are public and authors have mentioned in reproducibility checklist that all code and pre-trained models will be made available.											0	0	0	0	0	0	
260-Paper1737	Fast Reconstruction for Deep Learning PET Head Motion Correction	The paper provides detailed information on the methodology used, including the dataset and experimental setup, as well as specific details about the network architecture and training process. Therefore, it is possible to reproduce their experiments with a similar dataset and computational resources. However, it should be noted that some of the data used in this study may not be publicly available or easily accessible outside of research institutions due to privacy concerns or licensing restrictions.								it is fine								The author stated to meet all reproducibility requirements.											0	0	0	0	0	0	
261-Paper0905	Feature-Conditioned Cascaded Video Diffusion Models for Precise Echocardiogram Synthesis	The authors said that all the code, experiments, and weight files would be released by the time of the conference. In addition, the data used in this work is publicly available.								The author promises to make the code publicly available, which enhances reproducibility.								The author will release their codes and experiments by the time of the conference.											0	0	0	0	0	0	
262-Paper2602	FedContrast-GPA: Heterogeneous Federated Optimization via Local Contrastive Learning and Global Process-aware Aggregation	code not avaialble.								The authors did not provide the code and data for reproduction but it can be reproduced by the algorithm provided in the manuscript.								Generally difficult to reproduce FL results but if the authors share their code that would help.											0	0	0	0	0	0	
263-Paper3399	FEDD - Fair, Efficient, and Diverse Diffusion-based Lesion Segmentation and Malignancy Classification	Overall, the paper is well written, and the methods are mainly well explained. Technical details are enough to replicate the work.  Data subsetting is the main issue in reproducibility. Since cross-validation results are not presented, it is impossible to understand if the results can be reproduced over another random selection of samples in the DDI dataset or if the results generalize to other images as expected.								Source codes were not provided. Although, the experimental materials were conducted on a subset of public dataset. However, the selection process is unknown and the annotated data is not open to the public.								No reproducilibility data or code has been provided thus I am unable to verify claims made by the authors.											0	0	0	0	0	0	
264-Paper0601	Federated Condition Generalization on Low-dose CT Reconstruction via Cross-domain Learning	The proposed method is reproducible with the details provided in the paper.								This paper's methodology is basically reproducible, as it gives a clear procedure for the experiments and lists the settings of parameters, also, the network architecture is shown in the supplementary material. The researchers can reproduce the method easily.								The author provides detailed information such as the model and datasets. Therefore, the reproducibility of the paper is great and sufficient.											0	0	0	0	0	0	
265-Paper0762	Federated Uncertainty-Aware Aggregation for Fundus Diabetic Retinopathy Staging	The experiments were conducted on public datsets and some details of experimental settings are reported.								The major experimental details are given.								The code and dataset setting will be released upon acceptance											0	0	0	0	0	0	
266-Paper0435	FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation	The provided experimental details are sufficient to reproduce the results.								The major experimental details are given.								Positive:  Public datasets used  Authors claimed that the source code would be available on Github  A clear and detailed description of the algorithm.  Negative:  Not all hyperparameters are given. Some important details are missing, such as data preprocessing and augmentation, the update way of learning rate, and so on  How were baselines tuned?											0	0	0	0	0	0	
267-Paper2902	FedIIC: Towards Robust Federated Learning for Class-Imbalanced Medical Image Classification	Some of the model hyperparameters and experimental design considerations are missing. Neither code nor pseudocode/algorithm has been provided, which might make it harder to reproduce the work.								This paper has acceptable reproducibility.								no code given											0	0	0	0	0	0	
268-Paper1214	FedSoup: Improving Generalization and Personalization in Federated Learning via Selective Model Interpolation	Authors have agreed to make their code publicly available upon acceptance. Publicly available datasets are used for validating the proposed method.								The reproducibility is correct. Some important parameters are not disclosed like the model soup size (and its impact on performance).								The reproducibility of this paper is relatively high because most implementation details, such as batch size, learning rate, and optimizer parameters, are provided.											0	0	0	0	0	0	
269-Paper0418	FE-STGNN: Spatio-Temporal Graph Neural Network with Functional and Effective Connectivity Fusion for MCI Diagnosis	The paper was very clearly well written, but the proposed method was complex and had many parameters to be controlled.								To enhance the credibility of the algorithm results, it is recommended that the author provide the code and processed ANDI data. This would allow other researchers to reproduce and verify the findings, ensuring transparency and reliability in the research.								This paper can be easily replicated. Additionally, the authors have agreed to provide the code once the paper is accepted.											0	0	0	0	0	0	
270-Paper1257	FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling	The methods and implementation details are clearly described. Authors promise to make code available later.								Authors mentioned that the code will be made available upon request. The availability of the pre-trained model is unclear.								Not very satisfied											0	0	0	0	0	0	
271-Paper0786	Few Shot Medical Image Segmentation with Cross Attention Transformer	No code								Many of the queries listed in the reproducibility responses are thoroughly addressed in the manuscript.								With more details, I think the paper can be properly reproduced.											0	0	0	0	0	0	
272-Paper1190	Few-Shot Medical Image Segmentation via a Region-enhanced Prototypical Transformer	Good, public code.								Yes								Code available with README intro.											0	0	0	0	0	0	
273-Paper1586	Fine-grained Hand Bone Segmentation via Adaptive Multi-dimensional Convolutional Network and Anatomy-constraint Loss	Dataset used for experiments is not shared.								As far as the codes/ dataset become publicly available, the results are reproducible. Otherwise, I do not think that others can work on top of their results.								They made a plugin in slicer, it is definitely reproducible. Although I don't know if the architecture code and a tutorial on how to train it will also be made available.											0	0	0	0	0	0	
274-Paper2759	Fine-Tuning Network in Federated Learning for Personalized Skin Diagnosis	The paper describes how the approach can be implemented for end-user devices, having access to the actual code would further improve the reproducibility.								Not claimed.								The paper seems to be reproducibe using the information in the paper.											0	0	0	0	0	0	
275-Paper2917	Flexible Unfolding of Circular Structures for Rendering Textbook-Style Cerebrovascular Maps	Code and data are not available from the manuscript. Sharing the code for this method is greatly encouraged.								The authors describe the method, but they don't seem to provide any code. In that sense it is hard for me to judge if the paper can be easily reproduced.								Technical details are sufficiently provided for reproducibility.  An available implementation would be ideal as an open-source repository.											0	0	0	0	0	0	
276-Paper2722	FLIm-based In Vivo Classification of Residual Cancer in the Surgical Cavity during Transoral Robotic Surgery	This paper does not seem to be easily reproducible because it does not appear that the data is available (likely beyond the contributors control). The robot used is described but the software used to create the visualization is not discussed. The GODS network is also explained but there is not reference to an existing implementation or the code used.								The paper gives good amount of details about the experiments. However, there is a lack of experimental and method details.  1.1 It is not clear how many FLIm points are used for training, validation, and testing, respectively.   1.2 How were the aggregated pathology labels spatially registered to in vivo images in the surgical cavity?  1.3 What was the penalty factor in GODS model?  1.4 What are the requirements for computation resources? How long does it take for prediction of one point and one image?								This study is relatively reproducible. They have made no indication that their data will be made public but given the tools and methodology described, the data could be recreated at another institution. The biggest weakness in the reproducibility seems to be the lack of information regarding the division of the data.											0	0	0	0	0	0	
277-Paper0385	Flow-based Geometric Interpolation of Fiber Orientation Distribution Functions	Methods are reproducible.								Authors indicate code has been made available.								The authors provide a clear description of the propose method but checking for some details details may require publishing the code.											0	0	0	0	0	0	
278-Paper3362	FocalErrorNet: Uncertainty-aware focal modulation network for inter-modal registration error estimation in ultrasound-guided neurosurgery	Due to the complexity of the architecture, the information described may not be sufficient to easily reproduce the results.								This paper is reproducible. They use a public clinical dataset and accurately describe the methodology and implementation used.								The paper should be fairly reproducible given the authors' indication of providing code and data in an open-source manner.											0	0	0	0	0	0	
279-Paper1053	FocalUNETR: A Focal Transformer for Boundary-aware Prostate Segmentation using CT Images	I saw in the reproducibility checklist that the authors do not plan to release trained models. I think the weights of the models trained on public datasets should be released to easier the comparison to future works. In addition, information on the statistical significance of reported differences in performance between evaluated methods, the average runtime, and the memory footprint for each approach should also be reported in the paper.								The description to the system is detailed and all important training parameters are provided. It should be easy to reproduce the experiment.								If author provide github as mentioned in the paper, there should not be an issue on the reproducibility.											0	0	0	0	0	0	
280-Paper0944	Forensic Histopathological Recognition via a Context-Aware MIL Network Powered by Self-Supervised Contrastive Learning	the reproducibility of the paper is fine.								While the authors claims the source code will be publicly released on GitHub, the dataset is not given. The reproducibility of the paper is limited.								the reproducibility is intermedicate.											0	0	0	0	0	0	
281-Paper2909	Forward-solution aided deep-learning framework for patient-specific noninvasive cardiac ectopic pacing localization	limited								The paper is missing curcial information to replicate the results (see detailed comments).								According to the authors responses, code and data are not going to be publicly available.											0	0	0	0	0	0	
282-Paper0231	Foundation Ark: Accruing and Reusing Knowledge for Superior and Robust Performance	The paper seems to be reproducible according to the checklist.								The paper states that the code and the models will be publicly available after publication. Moreover, the datasets are public.								Code and data are available.											0	0	0	0	0	0	
283-Paper0676	Foundation Model for Endoscopy Video Analysis via Large-scale Self-supervised Pre-train	It is easy to reproduce the work of this paper if the author release the code.								Based on the description, it seems to be able to reproduce the main technical method. But given that no code was provided, it is unsure if the exact same results could be reproduced.								Because there are private datasets and I think it's very difficult to reproduce.											0	0	0	0	0	0	
284-Paper1860	Fourier Test-time Adaptation with Multi-level Consistency for Robust Classification	It is likely to be reproduced and the code is going to be released.								The fact that the authors have stated their intention to release the code is promising, and I am looking forward to examining the code in the future.								According to the reproducibility checklist filled out by the authors, they have provided sufficient details about their experimental setup.											0	0	0	0	0	0	
285-Paper1285	FreeSeed: Frequency-band-aware and Self-guided Network for Sparse-view CT Reconstruction	Based on the information provided in the paper, it seems that the authors have taken steps to ensure the reproducibility of their research.  (Except of the DuDoFreeSeed network used in the ablation study)								Can be reproduced according to the paper if provided some details.								I think it is reproducible.											0	0	0	0	0	0	
286-Paper1727	Frequency Domain Adversarial Training for Robust Volumetric Medical Segmentation	Code will be not provided. It should be hard for non-familiar audiences to inplement.								Although the datasets and the models used in experiments are public, the authors didn't claim they will open source code in the future. However, I believe the technical details provided in the paper are enough for reproduction.								Maybe. the paper provides sufficient details regarding the model architecture, hyperparameters, and training dataset to enable reproducibility.											0	0	0	0	0	0	
287-Paper1051	Frequency-mixed Single-source Domain Generalization for Medical Image Segmentation	The main idea of FreeSDG is to leverage a frequency-based domain augmentation technique to extend the single-source domain discrepancy and inject robust representations learned from self-supervision into the network to boost segmentation performance. The approach is designed to address the limitations of domain generalization methods that require multiple source domains and may not be feasible in real clinical scenarios. FreeSDG employs a mixed frequency spectrum to augment the single-source domain and incorporate self-supervision to learn context-aware representations. The experimental results demonstrate that the proposed algorithm outperforms state-of-the-art methods and significantly improves segmentation performance on unseen domains. The proposed paper is well written and easy to follow. The authors used public datasets and the paper is easy to follow, however, the approach very depends on architectural design of the model and source code would be very helpful to reproduce the paper. The proposed approach is a combination of several techniques and seems technically novel. Future work is not discussed in the paper. The paper would be a good asset for the conference.								The details about the method implementation are clear.								Reproducibility is minor. The authors did not include code. No details about the augmentation methods are given to reproduce the paper.											0	0	0	0	0	0	
288-Paper2512	From Mesh Completion to AI Designed Crown	The reproducibility of the paper is good.								Seems reproducible.								N/A											0	0	0	0	0	0	
289-Paper3382	From Sparse to Precise: A Practical Editing Approach for Intracardiac Echocardiography Segmentation	The authors have indicated that they may not make their code publicly available. The dataset used for validating the proposed ideas is also not publicly available.								The codes and data used in this paper are not public, which may limit the reproducibility. The proposed method can be re-implemented without too much difficulty.								The author does not choose to release their codes. And I think it could be quite challenging to reproduce the results of this work since the data is not available, either.											0	0	0	0	0	0	
290-Paper1213	From Tissue to Sound: Model-based Sonification of Medical Imaging	In general, the numerical steps are easy to follow. However, the image pipeline was not entirely clear (for instance, how were the images registered to each other?) nor has any software tool and/or programming language been mentioned.								The authors do not provide code or relevant data from their work. They do provide a detailed description of their mathematical derivation and approach and supplemental video demonstrating their algorithm performance.								Physical model definition is presented, however full derivation of the parameters is to be desired. The interaction module especially is not mathematically defined, more precisely regarding the mapping of the input data intensities to parameters of the mass-interaction system.											0	0	0	0	0	0	
291-Paper1165	FSDiffReg: Feature-wise and Score-wise Diffusion-guided Unsupervised Deformable Image Registration for Cardiac Images	The reproducibility is average with some missing details, but the author declares to provide the training code and testing modes, which seems promising.								OK								The code, data, and models will be published in full, and the hyperparameters for training will be given in the paper.											0	0	0	0	0	0	
292-Paper1832	Full Image-index Remainder based Single Low-dose DR/CT Self-supervised Denoising	In this paper, the author provides detailed information such as the model and datasets. Therefore, the method is largely replicable.								While the authors do not provide code, they do provide detailed information about the model's parameters, data sets, and so on. So the work seems to be largely reproducible.								This paper's methodology appears to be reproducible. While the authors did not include the code, they provided comprehensive details on the model, dataset, and evaluation. Therefore, the work seems to be replicable to a significant extent.											0	0	0	0	0	0	
293-Paper2571	Fully Bayesian VIB-DeepSSM	ok								From the description of the method in the paper and by looking at previous work, much of the proposed approach would be reproducible (but it builds on multiple iterations of previous work). Some details about the training are provided.								The methods, dataset and training procedure are described sufficiently well in order to reproduce the experiments.  The supershape data is generated and reproducible.  The authors state that the code will be released after acceptance of the paper.  However, it seems like that the left atrium dataset is private and therefore, results on this dataset cannot be reproduced.											0	0	0	0	0	0	
294-Paper1144	Fundus-Enhanced Disease-Aware Distillation Model for Retinal Disease Classification from OCT Images	Authors state that code would be made available upon acceptance, I think the result is reproducible with public resources.								The method is reproducible, offering details in the manuscript to understand the methodology.  Also, the authors indicate their commitment to publish the code if the work is accepted.   The authors validated the method in a private dataset, but also results in public dataset is provided.								If the dataset is made publicly available, reproducibility will be supported.											0	0	0	0	0	0	
295-Paper2536	Gadolinium-Free Cardiac MRI Myocardial Scar Detection by 4D Convolution Factorization	The authors used a private dataset and claimed they would publish their code and model upon acceptance.								reproducible								The manuscript mentions the code will be available in a repository and the checklist supports this statement.											0	0	0	0	0	0	
296-Paper1224	Gall Bladder Cancer Detection from US Images with Only Image Level Labels	Given that the source code and models were provided with the submission, the reproducibility of the paper seems to be good.								How did you finetune the class-aware DETR branch? It is not clear to me from the paper. Could be useful to include more details such as what data, label, loss did you use.    How does the number of trainable parameters compared to the other baselines in the paper. It is also important to consider size of the model when comparing different algorithm.								The network architecture explanation lacks some technical details. However, since the datasets used in this study are public, and the codes have already been made available, the results should be reproducible.											0	0	0	0	0	0	
297-Paper0742	Gene-induced Multimodal Pre-training for Image-omic Classification	TCIA data is open  Code is not provided								It's good								The authors did include the dataset information, training computational infrastructure, together with the training hyper-parameters. No significant concern regarding the reproducibility of the proposed work.											0	0	0	0	0	0	
298-Paper1981	Generating High-Resolution 3D CT with 12-bit Depth using a Diffusion Model with Adjacent Slice and Intensity Calibration Network	The authors write "not applicable" for all points.								The response of reproducibility checklist is marked as NA. However, I believe author/s should complete section 1 for the algorithm reproducibility.								The model architecture and the data are available and the training procedure is clearly discribed											0	0	0	0	0	0	
299-Paper0172	Generating Realistic Brain MRIs via a Conditional Diffusion Probabilistic Model	The paper provides sufficient details on the architecture and training procedures of the proposed cDPM method, enabling other researchers to replicate the experiments. The authors have also committed to releasing the code for their method as part of the MONAI library, which will enhance reproducibility. However, the paper lacks detailed information on hyper-parameter selection, mean and standard deviation trends, comparison to important baselines (e.g, LDMs), and significance analysis. These details are important for interpreting the results and comparing the method with the state-of-the-art. Additionally, including comparisons of computational and runtime performance could have further clarified the contributions of the proposed method.								Submission indicates that the code will be released as part of MONAI.								Good reproducibility.											0	0	0	0	0	0	
300-Paper1191	Geometric Ultrasound Localization Microscopy	Reproducibility is excellent. This is where the use of PALA is beneficial. This also applies for comparison to existing image formation methods also provided in the Github.								The work is quite reproducible. However, further details on the parameter selection process will facilitate better reproducibility.								The authors have chosen a public dataset and state that they will publish the code. Thus, reproducibility is ensured.											0	0	0	0	0	0	
301-Paper3505	Geometry-adaptive Network for Robust Detection of Placenta Accreta Spectrum Disorders	The Authors use an in-house dataset and plan to publish the code upon acceptance.								The method was quite complex with several modules, which may hinders the reproducibility. However, the authors promised to release the code.								The dataset is not available but the authors have mentioned that they will make the source code public.											0	0	0	0	0	0	
302-Paper1644	Geometry-invariant abnormality detection	good but parameter sensitivity not included.								The lack of experiments details hurts the reproducibitly.								No issues with reproducibility.											0	0	0	0	0	0	
303-Paper0378	GL-Fusion: Global-Local Fusion Network for Multi-view Echocardiogram Video Segmentation	The authors have made their code and some other information available. The data is not available, limiting reproducibility. As mentioned above, the level if detail is far short of sufficient to reproduce the experiments if the code were not provided.								good reproducibility								High rate in reproducibility.											0	0	0	0	0	0	
304-Paper1225	Global k-Space Interpolation for Dynamic MRI Reconstruction using Masked Image Modeling	Very difficult to reproduce.								A clear high level description of the method is provided, although no link to a code repository or mention of the actual ML framework used is provided (as far as I can tell)								The paper is easy to follow, and if the code is released I think this will be reproducible											0	0	0	0	0	0	
305-Paper1904	GLSFormer : Gated - Long, Short Sequence Transformer for Step Recognition in Surgical Videos	I did not see any problem on the reproducibility of the paper.								The authors have filled out a reproducibility checklist upon submission, which is a positive sign for the reproducibility of their work. They have provided detailed information about their experimental setup and evaluation metrics, as well as links to the datasets used in this study. However, while they state that code will be made publicly available after the review process, it is not currently available at the time of publication. Overall, based on the information provided in their checklist and paper itself regarding data availability and experimental details, it seems that reproducing this work would be feasible with some effort. However, without access to code or more detailed implementation instructions beyond what was included in their paper, full reproducibility may be challenging for some readers.								Details of the datasets and evaluation metrics used in the experiments is provided.  Implentation details including chosen hyperparameters for training are available in the paper.											0	0	0	0	0	0	
306-Paper0554	GRACE: A Generalized and Personalized Federated Learning Method for Medical Imaging	Appears to be reproducible.								The datasets are publicly available    The description of hyperparameters and implementation details is meager, so it is important that code to reproduce the experiments will be published.								The paper should be fairly reproducible since the authors state that they have / will provide code. I am not sure I could find that in the paper. May be I missed it and it should be more clearly pointed out.											0	0	0	0	0	0	
307-Paper0784	Gradient and Feature Conformity-Steered Medical Image Classification with Noisy Labels	Seems appropriate								Yes, code will be released								The paper provides sufficient detail in its methodology and experimental setup to ensure reproducibility of the results.											0	0	0	0	0	0	
308-Paper3651	Graph Convolutional Network with Morphometric Similarity Networks for Schizophrenia Classification	The reproducibility is good. Both the key hyper-parameters and the model of computational equipment are described in detail.								Authors provide details about graph structure and parameter values used								Despite no information on the availability of code and data, it provides sufficient details to facilitate the replication of the experiments and the evaluation of the proposed method.											0	0	0	0	0	0	
309-Paper0455	Graph-theoretic automatic lesion tracking and detection of patterns of lesion changes in longitudinal CT studies	Re-implementation could become difficult as algorithms to generate the case-specific graph-structure are complex, too.								The method is described in sufficient detail to support reproducibility.								DLIVER and DLUNG availability ...											0	0	0	0	0	0	
310-Paper1702	GSDG: Exploring A Global Semantic-guided Dual-stream Graph Model for Automated Volume Differential Diagnosis and Prognosis	It appears all the details for reproducibility are included.								Key hyper-parameters are clearly state and the experiments are conducted on public datasets. The authors plan to release the code - reproducing the architecture and training loop solely from the description would be challenging.								The proposed method should be reproducible.											0	0	0	0	0	0	
311-Paper0978	GSMorph: Gradient Surgery for cine-MRI Cardiac Deformable Registration	The reproducibility of the paper will be good, because authors claim the the source code will be available online soon.								ok								The reproducibility of the paper is OK.											0	0	0	0	0	0	
312-Paper1526	Guiding the Guidance: A Comparative Analysis of User Guidance Signals for Interactive Segmentation of Volumetric Images	The authors have indicated their willingness to make code associated with their work publicly available, and have provided detailed description of their datasets and experimental procedures in the submitted manuscript. As a result, this paper demonstrates a high degree of reproducibility.								The authors used publicly available datasets and plan on releasing their source code.								The experiments should be reproducible as the authors used existing signals and existing frameworks and clearly specified the parameter settings and performance metric used. The authors also mentioned that code will be made public.											0	0	0	0	0	0	
313-Paper0348	H2GM: A Hierarchical Hypergraph Matching Framework for Brain Landmark Alignment	Good reproducibility.								The authors agreed to share code.								The author's use a public dataset and state that they will make their code public, thus the work should be reproducible.											0	0	0	0	0	0	
314-Paper1335	HACL-Net: Hierarchical Attention and Contrastive Learning Network for MRI-Based Placenta Accreta Spectrum Diagnosis	good								The data and code used in this manuscript are not accessible, which may affect the reproducibility.								The data is not publicly available, therefore releasing the code would enable others to reproduce this work.											0	0	0	0	0	0	
315-Paper1408	HartleyMHA: Self-Attention in Frequency Domain for Resolution-Robust and Parameter-Efficient 3D Image Segmentation	The authors' report on reproducibility appears to be reasonable.								-								I noted the pre-trained weights and training/evaluation code and training scheme clearly explained. However, without architecture code implementation, it might not be an easy task to replicate.											0	0	0	0	0	0	
316-Paper0540	HC-Net: Hybrid Classification Network for Automatic Periodontal Disease Diagnosis	The paper does not report detailed dataset label categories. It also does not report specific steps for the instance segmentation part of the experiment, which may indeed make it difficult to reproduce the paper.								The authors did not release the code and the used dataset is an in-house dataset.								The proposed method is mainly based on existing techniques and should be easy to reproduce. The authors also will release the code.											0	0	0	0	0	0	
317-Paper3097	H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation	The training and validation loss of the best weight for each method in Table 2 is not reported.    The random seed is not reported.								The model is described in sufficient detail, and the authors outline their experimental procedure clearly. The authors use two public datasets and provide code repository links.								They shared the code and also implementation details are listed in the paper.											0	0	0	0	0	0	
318-Paper0769	HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images	The results are difficult to reproduce, since the dataset is private								The reproducibility of this paper is good.   The proposed network architecture, parameter settings, and experimental details are all described in great detail.								Fair											0	0	0	0	0	0	
319-Paper2583	Hierarchical Vision Transformers for Disease Progression Detection in Chest X-Ray Images	Despite stating so in the reproducibility report, the authors do not report "the range of hyper-parameters considered" or "method to select the best hyper-parameter configuration".  Details regarding compared baselines are missing (hyperparameters, training strategy, model architecture).  Details regarding the ablation study are missing (patch pre-processing).  The authors state that "A description of results with central tendency (e.g. mean) & variation (e.g. error bars).", "An analysis of statistical significance of reported differences in performance between methods." and "A description of the memory footprint." is not applicable, which I do not agree with.								The reproducibility of the paper is good. Authors provides almost all the things needed to repeat the experiments.								Reproducible, the paper included technical details needed for re-implementation.											0	0	0	0	0	0	
320-Paper1489	High-Quality Virtual Single-Viewpoint Surgical Video: Geometric Autocalibration of Multiple Cameras in Surgical Lights	No software is presented. Authors include supplementary video showing performance of their approach and details sufficient for software implementation.								The code+data is released so reproducibility seems fine.								Availability of source code:   The fact that there is no source code provided decreases the reproducibility of the proposed method.    Implementation details:   Since the mathematical equations presented are fairly easy to understand and follow, reproducibility seems assured, at least to some extent. Nevertheless, reproducing the exact same work as it is presented in this paper might still be challenging since important implementation details regarding a fully functioning pipeline are hidden. For example, in section 2.1, page 3, it is mentioned that the SIFT algorithm is being used for feature point detection, followed by feature point matching 'for each of the 10 combinations of the five frames'. Explanations like that could lead to more room for interpretation.  In addition, the used programming language and libraries are not mentioned. On a positive note, the used OS incl. version as well as CPU and RAM details are listed.											0	0	0	0	0	0	
321-Paper1642	High-Resolution Cranial Defect Reconstruction by Iterative, Low-Resolution, Point Cloud Completion Transformers	The authors have provided detailed information about the datasets used, the network architecture, the objective function, and the evaluation metrics, which is essential for reproducibility. Additionally, the authors have provided a detailed description of the pre-processing steps, post-processing steps, and the iterative completion process, which can also aid in reproducibility.  However, it should be noted that the authors have not provided code or data as part of their reproducibility efforts. While this is not a requirement for acceptance, it can significantly enhance the reproducibility of the research. Providing code and data would allow other researchers to directly reproduce the results and also enable them to build upon the existing work. Therefore, it is recommended that the authors consider providing code and data in the future, if possible.								The reproducibility can be rated as sufficient.								good things about reproducibility  o open datasts used  o objective function and training are well described  limiting the ability to reproduce  o code not provided  o network architecture not well described as discussed in weaknesses											0	0	0	0	0	0	
322-Paper2796	HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis	Not applicable								The experiments were conducted on two public available datasets.   The authors claimed the code will be released.								The experimental data are from the public dataset. The authors say the code will be made available.											0	0	0	0	0	0	
323-Paper2410	Histopathology Image Classification using Deep Manifold Contrastive Learning	From the reproducibility note the only standing issue I notice was the sharing of the data and code (training/evaluation). The authors have checked it as YES but I do not see any link in the manuscript. Could it be introduced ?								good reproducibility.								The datasets are public available.  The authors claim that the code will be released.											0	0	0	0	0	0	
324-Paper2330	How Does Pruning Impact Long-Tailed Multi-Label Medical Image Classifiers?	authors declare labels and data splits will be made public upon acceptance								The authors disclose all parameters to generate their statistical study. While the dataset split used for their experimentation is missing to fully reproduce their results, it is mentioned in the paper that it would be made available upon acceptance.								Ok.											0	0	0	0	0	0	
325-Paper1461	How Reliable are the Metrics Used for Assessing Reliability in Medical Imaging?	Overall, the paper seems to be highly reproducible. Notably, the authors provide all training code and models, which allows for cross-checking and building upon the provided results.								The datasets used are public, and the method is anonymously released, which deems the results reproducible.								The work uses publicly available datasets and all code has been made available online.											0	0	0	0	0	0	
326-Paper2251	Identification of Disease-sensitive Brain Imaging Phenotypes and Genetic Factors using GWAS Summary Statistics	It would be good to be more precise on the genetic range that is being examined, e.g. chr19:start-end for the ADNI analysis and the specific locations for the UKB analyses.								It is unclear how reproducible the experiments in the paper are, as the authors did not provide detailed information on the code or data used. This lack of reproducibility makes it difficult for other researchers to validate or build upon the findings.								The authors do not take the reproducibility report seriously in my opinion. The mark yes to everything, also e.g. that they discuss the memory footprint of the method. This is not done in any obvious manner in the manuscript.											0	0	0	0	0	0	
327-Paper1110	IIB-MIL: Integrated instance-level and bag-level multiple instances learning with label disambiguation for pathological image analysis	This paper uses public datasets, and the authors say they will release the code upon acceptance. Therefore, the overall reproducibility is good.								The paper does not provide source code or state that source code will be provided. The reproducibility of the proposed method is relatively difficult without open-source code.								The author promises to opensource the code.											0	0	0	0	0	0	
328-Paper2593	Image2SSM: Reimagining Statistical Shape Models from Images with Radial Basis Functions	The paper doesn't seems to be easily reproducible at this stage, details of the model are missing.								Various entries in the reproducibility form are not really reflected in the paper, I wonder if this is related to the fact that authors claimed that code and data will be publicly shared (which is always very appreciated) and as a result little information has been given in the paper. For instance:  A clear declaration of what software framework and version you used.  [Yes]   Whether ethics approval was necessary for the data.  [Yes]  The exact number of training and evaluation runs.  [Yes]  this information is nowhere to be found.  A lot of key information is not present in the paper and I think that a minimum of it could have been added, regardless of the anonymity status or the fact that authors plan to share data and code (probably on some website).								Details should be sufficient for reproduction.											0	0	0	0	0	0	
329-Paper2308	Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure	reproducible								According to the paper, if the dataset and code will be public, this paper is reproducible. If not, more details about the dataset is needed in the paper.								dataset is private  no code availability mentioned in paper											0	0	0	0	0	0	
330-Paper0869	Implicit Anatomical Rendering for Medical Image Segmentation with Stochastic Experts	the author provided sufficient implementation details, code will be released upon publication								The authors assert that all comparative evaluations were conducted using the released open-source implementation of the proposed method. However, insufficient details are provided regarding methodologies employed to ensure fairness of comparisons between the novel technique and other alternative approaches examined.								The authors provide some details.											0	0	0	0	0	0	
331-Paper1136	Implicit neural representations for joint decomposition and registration of gene expression images in the marmoset brain	1.From the qualitative and quantitative experimental results, I believe that this paper can be reproduced.  2.From the author's detailed description of the method, it is believed that the paper can be reproduced.  3.In the implementation section (2.4) of the paper, the selection of the environment and method parameters for the experiment is provided, which provides important support for the reproducibility of the paper. Therefore, we consider this paper reproducible.								The paper meets the standard criteria of reproducibility								The authors mentioned that the codes and data will be available, and the reproducibility of the paper may be acceptable.											0	0	0	0	0	0	
332-Paper0546	Importance Weighted Variational Cardiac MRI Registration Using Transformer and Implicit Prior	Use of public datasets. While numbers of training/test splits are reported, given these are public datasets it would be helpful to refer to the actual cases.  Results are quantitatively reported, with mean/stdev, and metric referred to, bur there is, in contrary what the authors state in their checklist, no "An analysis of statistical significance of reported differences in performance between methods."								Fair reproducibility. Most of the technical details of the proposed method have been provided. Yet, the authors stated that the source code of the proposed method will be made publicly available following the acceptance of the paper.								The reproducibility of the presented method is poor due to the omission of crucial information about hyperparameter choices.											0	0	0	0	0	0	
333-Paper2605	Improved flexibility and interpretability of large vessel stroke prognostication using image synthesis and multi-task learning	I would not be able to reproduce this study due to notable omissions in the training and inference process for the comparison methods that this study evaluated.								Even with access to the dataset, it would be moderately difficult to reproduce. The biggest challenge is the 2nd stage - how are the outputs of the first model in stage2 combined with which clinical data.								The code would be available and the procedure is well described. Additional implementation information was available in the Appendix.											0	0	0	0	0	0	
334-Paper2502	Improved Multi-Shot Diffusion-Weighted MRI with Zero-Shot Self-Supervised Learning Reconstruction	They provide code, so it is highly reproducible.								Acceptible								The paper provided a link to the code and data. However, the implementations details in the paper are not sufficiently clear, e. g., network hyper-parameters (filter sizes, etc.). The formulation of DC layer should be also given for this task.											0	0	0	0	0	0	
335-Paper1077	Improved Prognostic Prediction of Pancreatic Cancer Using Multi-Phase CT by Integrating Neural Distance and Texture-Aware Transformer	As the data used in the paper is not publicly available, reproducing the results may be challenging. However, if the work is accepted, the code could be released to allow others to test the method.								There is not a good reproducibility, because of these weaknesses as listed above.								The paper uses an in-house dataset, which introduces concern about reproducibility.  Code availability is not mentioned in the manuscript											0	0	0	0	0	0	
336-Paper0747	Improving Automatic Fetal Biometry Measurement with Swoosh Activation Function	The datasets used are publicly available. The function parameters are explained adequately ensuring reproducibility of the work.								One dataset seems private and another public. Some clarification on whether or not the private set can be made available would be helpful. The model setup and training seems reasonably simple enough to replicate. The regularization term itself should be easy to implement and add to any existing modeling frameworks. Would be even better to have access to the full code in the final paper. Overall, I'd score them 'good' in terms of reproducibility.								There are only hyperparameters inside the paper. I can't see any relevant link to the training code and the dataset.											0	0	0	0	0	0	
337-Paper1721	Improving Image-Based Precision Medicine with Uncertainty-Aware Causal Models	The experimental setup is clearly described in the main text; the supplementary material provides further information on the network architecture and learning parameters.								The reproducibility is below average. The experiments were carried out using data from randomized clinical trails that are not publicly available. Code also won't be shared.								The data seems to be well described, so that anyone getting access to the described clinical trial data is in a good position to reproduce.  But as stated above there's a huge amount of information about what the neural network training approach actually consists of; how it works; what it's doing; exactly how to implement it and so on. There's no chance of reproducing these experiments based solely on what is written here.											0	0	0	0	0	0	
338-Paper1899	Improving Outcome Prediction of Pulmonary Embolism by De-Biased Multi-Modality Model	Yes								The authors described clearly the model framework including training model and inference model, and gave the loss function and training details. So there is a good reproducibility.								Dataset used is proprietary so reproducibility may be limited. Values used for variables such as lambda_swap in combined loss function would be valuable. Text only states the values are set to balance the importance of feature aggregation, which may be an important detail to achieved documented performance.											0	0	0	0	0	0	
339-Paper1786	Improving Pathology Localization: Multi-Series Joint Attention Takes the Lead	The private data included and the limited details on network architecture can affect the reproducibility of the paper.								The authors have not provided the following "An analysis of situations in which the method failed."								The reproducibility of this paper can be achieved by following the paper. It will be helpful if some sample implementation is provided.											0	0	0	0	0	0	
340-Paper2610	Incomplete Multimodal Learning for Visual Acuity Prediction after Cataract Surgery Using Masked Self-Attention	The method of the paper is reproducible, but because the data is private, the experimental results are difficult to reproduce for others.								Paper is thorough in providing all attributes used for ease of reproduction of the work.								The authors claim that the code will be released, but there is a lack of publicly available datasets for validation.											0	0	0	0	0	0	
341-Paper0708	Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI	The authors have not share code yet. If the authors can release code, the reproducibility is possible for this paper.								The paper have provided sufficient details about the model, and thus I think the paper can be reproduced.								The paper is reporoduceable.											0	0	0	0	0	0	
342-Paper1952	Inflated 3D Convolution-Transformer for Weakly-supervised Carotid Stenosis Grading with Ultrasound Videos	The dataset is not public available. It's not clear about the reproducibility of the paper.								Reproducibility maybe a challenge due to the many details in the paper.								Seems reproducible.											0	0	0	0	0	0	
343-Paper2539	Infusing physically inspired known operators in deep models of ultrasound elastography	The authors will provide the code and utilize publicly available datasets, promoting transparency and reproducibility in research. Moreover, the required Institutional Review Board (IRB) approval has been obtained for data collection, ensuring adherence to ethical standards.								The reproducibility of the paper is satisfactory .								Items appear to have been provided fully by the authors to ensure reproducibility.											0	0	0	0	0	0	
344-Paper2197	Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images	Lacks important technical details pertaining to the training of the model such as hyperparameters, optimization strategy, etc.  Lacks clarity on how the method is employed at inference time								The paper provides sufficient details about the methodology, datasets, implementation, and evaluation metrics to facilitate reproducibility.								Author claim the code will be released.											0	0	0	0	0	0	
345-Paper1885	Instructive Feature Enhancement for Dichotomous Medical Image Segmentation	Although the source code is not provided, the details of the proposed method are enough to reproduce.  The proposed dataset, termed as Cosmos55k, is not public in this version. It is suggested to provide a clear and anonymous link to show some samples.								The code of this work was not provided. The reproducibility is slightly worse.								The model should be able to reproduce if the dataset is available.											0	0	0	0	0	0	
346-Paper2092	Intelligent Virtual B-scan Mirror (IVBM)	Source code and data could be made available. It seems not to be the case here.								All relevant aspect of reproducibility have been addressed.								several technical details are missing, in particular, those related to the VR pipeline											0	0	0	0	0	0	
347-Paper2128	Interpretable Deep Biomarker for Serial Monitoring of Carotid Atherosclerosis Based on Three-Dimensional Ultrasound Imaging	Reproducibility is good, as the author has committed to publish code and dataset.								The reproducibility of the paper is very good.								Is the dataset publicly available?											0	0	0	0	0	0	
348-Paper1676	Interpretable Medical Image Classification using Prototype Learning and Privileged Information	Great, public code.								Experiments were done with a public dataset.  Code will be made available.  Reproducibility is guaranteed.								The authors state that code will be made available											0	0	0	0	0	0	
349-Paper1303	Inter-slice Consistency for Unpaired Low-Dose CT Denoising using Boosted Contrastive Learning	The paper's methodology is easy to reproduce. Despite the absence of the code in GitHub, the authors have supplied comprehensive details regarding the model, dataset, and evaluation procedure, which significantly enhances the work's replicability.								As per the details given in the paper, the paper is reproducible upto a certain extent.								The authors have furnished in-depth explanations of the model, dataset, and evaluation procedure, significantly facilitating the work's replicability. Although the code is not currently available, implementation should not pose a challenge.											0	0	0	0	0	0	
350-Paper1521	Intraoperative CT augmentation for needle-based liver interventions	The authors provided the majority of necessary details to reproduce the work. Main aspect I did not find was the method to obtain ground truth vessel segmentations from the contrast-enhanced CT scans.								The method is lacking information regarding how the vessels are segmented from the contrast enhanced images. Given that vessel map is one of the two inputs to the neural network that will result in the "intraoperative" vascular tree, it is huge importance to understand how this should be done.								If, as the authors declare, the source code and data available in the publication will be made available, there will be a full possibility of repeating the results.											0	0	0	0	0	0	
351-Paper0552	Intra-operative Forecasting of Standing Spine Shape with Articulated Neural Kernel Fields	Moderate reproducibility for various reasons. At first, the clinical task is less common and I assume not many groups have access to a cohort as in this paper. The cohort itself is not publicly available and consequently it will be difficult to reproduce and compare later. The level of detail given in the paper is not sufficient to be able to re-implement. Code will not be made available.								Given my comments above regarding the clarity of the methods section, I have concerns regarding the reproducibility of this work. Proper attention has to be devoted to explaining the flow of information within the pipeline.								The methods are highly detailed and replication of the forecasting architecture is made as reproducable as possible. Unfortunately, the dataset cannot be made public.											0	0	0	0	0	0	
352-Paper1368	Inverse Consistency by Construction for Multistep Deep Registration	the data sets used for validation are publicly available								The tests appear to me as reproducible.								Good.											0	0	0	0	0	0	
353-Paper2670	InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model	The answers to "For all code related to this work that you have made available or will release if this work is accepted" are all "yes".								The reproducibility of the paper is good.								Largely reproducible, as the base model and inspirations are clearly indicated and cited.											0	0	0	0	0	0	
354-Paper3556	Ischemic stroke segmentation from a cross-domain representation in multimodal diffusion studies	Implementation details are missing; ex., number of filters at every level								The authors have provided a comprehensive description of the model, which includes mathematical formulations of the loss functions and feature representations, as well as a clear graphical illustration. It would be helpful if they could provide a brief explanation of how they applied their data preprocessing in their experiments and provide code for their cross-attention module.								Mathematical computations and the description about the dataset are clearly mentioned in the paper.											0	0	0	0	0	0	
355-Paper0322	Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification	For the experiments on the Camelyon data there appears to be sufficient information and code available to repeat the experiments.								Authors indicates that code will be made available upon acceptance.								the authors promise to provide the source code. But the technique framework, presented in current form, is vague and impossible to reproduce.											0	0	0	0	0	0	
356-Paper2307	JCCS-PFGM: A Novel Circle-Supervision based Poisson Flow Generative Model for Multiphase CECT Progressive Low-Dose Reconstruction with Joint Condition	Lack of model details and experiment settings.								Not enough for reproduction.								Code is available, so it should be easy to reproduce the results.											0	0	0	0	0	0	
357-Paper0563	Joint Dense-Point Representation for Contour-Aware Graph Segmentation	The paper has no problem on reproducibility.								YES								I consider the paper is reproducible as the code is released at anonymous Github.											0	0	0	0	0	0	
358-Paper2062	Joint optimization of a Œ≤-VAE for ECG task-specific feature extraction	I believe the authors will make codes available if the paper is accepted.								Authors will make their code publicly available.								The authors mentioned that the implementation code will be made publicly available in GitHub if accepted.    It is not clear if the datasets used in the paper are publicly available or only restricted to institution access.											0	0	0	0	0	0	
359-Paper3011	Joint prediction of response to therapy, molecular traits, and spatial organisation in colorectal cancer biopsies	the reproducibility of the paper is fine.								Good								The use of two private datasets makes this study non-reproducible.  The authors promise all code available upon request.											0	0	0	0	0	0	
360-Paper1177	Joint Representation of Functional and Structural Profiles for Identifying Common and Consistent 3-Hinge Gyral Folding Landmark	Good								The reproducibility of the paper is bad.  The authors did not share the code.  The implementation details of the methods are not presented.								Not applicable											0	0	0	0	0	0	
361-Paper0356	Joint Segmentation and Sub-Pixel Localization in Structured Light Laryngoscopy	The authors have decided to make the relevant models and data publicly available, assuming the acceptance of the paper for publication.								The paper seems to be reproducible.								After clarification on the model confusions I have, I believe the authors have an in-depth clarification of their model and training paradigm. Thus I believe reproducibility and reimplementation of this work would be very doable.											0	0	0	0	0	0	
362-Paper2314	Knowledge Boosting: Rethinking Medical Contrastive Vision-Language Pre-Training	This paper is reproducible.								The reproducibility of the paper is credible.								Good. The key hyper-parameters are introduced. However, the technical details should be clarified.											0	0	0	0	0	0	
363-Paper3714	L3DMC: Lifelong Learning using Distillation via Mixed-Curvature Space	The paper provides sufficient details, and certainly in combination with the publicly available code and data, the reproducibility can be considered excellent.								There is no code available to validate but the authors provided a supplement material for better clarification which is appreciative.								The algorithmic details are well explained. The testing data sets are public. The algorithm should be reproducible. The concern is the numerical stability for the computation in hyperbolic space.											0	0	0	0	0	0	
364-Paper2334	Label-Free Nuclei Segmentation Using Intra-Image Self Similarity	The authors claim to release the codes.								The paper seems to have a good reproducibility. The authors promise that they will release the training code and evaluation code.								Authors do not mention whether to make the code publicly available.											0	0	0	0	0	0	
365-Paper2188	Label-preserving Data Augmentation in Latent Space for Diabetic Retinopathy Recognition	All listed criteria of the reproducibility checklist have been fulfilled. Author fully comply and provided evidence.								Seems reproducible since publicly available dataset and model are used								This paper can be easily replicated. Additionally, the authors will provide the code once the paper is accepted.											0	0	0	0	0	0	
366-Paper1581	LABRAD-OR: Lightweight Memory Scene Graphs for Accurate Bimodal Reasoning in Dynamic Operating Rooms	The paper is reproducable, as it is evaluated on the public dataset.								At present, code is not made available. However, the author has indicated that the code will be made public upon paper acceptance.								The authors claim, "We will publish our code upon acceptance." No code is found currently.											0	0	0	0	0	0	
367-Paper3278	Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection	The paper give good guidelines for reproducibility if the work								The datasets used in the paper are public and the code will be made available although there might not be enough details in the paper to re-implement the method.								Reproducible.											0	0	0	0	0	0	
368-Paper0933	Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality	It could be easy to reproduce the results based on the paper.								The authors indicate their resources will be shared.								The authors intend to release the code and the implementations details are provided. The results should be reproducible.											0	0	0	0	0	0	
369-Paper3610	Learnable Query Initialization for Surgical Instrument Instance Segmentation	The author claim that they will make the code public after the paper is accepted.								The authors intend to make all relevant materials available once the paper is published.								The authors declare that the codes and models will be published after acceptance of the paper. They use public datasets, EndoVis17 and EndoVis18. The hyperparameters are reported in the paper.											0	0	0	0	0	0	
370-Paper0417	Learnable Subdivision Graph Neural Network for Functional Brain Network Analysis and Interpretable Cognitive Disorder Diagnosis	The authors have indicated that training/inference code and models will be made available for reproducibility.								The paper was very clearly well written, but the proposed method was complex and seems difficult for readers to re-implement.								The authors do not discuss the reproducibility in this work.											0	0	0	0	0	0	
371-Paper1024	Learned Alternating Minimization Algorithm for Dual-Domain Sparse-View CT Reconstruction	Supplementary document has some further proofs. However, No files to confirm the result/code reproducibility.								The authors promised to make implementations public								The explanations of the notations are not detailed enough, which may hinder reproducibility.											0	0	0	0	0	0	
372-Paper1604	Learning Asynchronous Common and Individual Functional Brain Network for AD Diagnosis	Good.								I think they did well on the reproducibility of the paper								Many technical details are missing. For example, how to construct a common FBN? How to deal with the cross spatiotemporal asynchronous FBN matrix, which dimensions (nNnN) are expanded.  In addition, a parameter in experimental settings is confusing. i.e., The author claimed feature dimension D is set as 12, while matrix X_0 belongs to NTD is 90128*6.											0	0	0	0	0	0	
373-Paper0224	Learning Deep Intensity Field for Extremely Sparse-View CBCT Reconstruction	The authors have described their method clearly.								The authors have provided a detailed outline of their experimental procedure and parameters.								N.A.											0	0	0	0	0	0	
374-Paper1323	Learning Expected Appearances for Intraoperative Registration during Neurosurgery	The author(s) have provided sufficient details in the paper to reproduce the implementations, as well as have made code and data publicly available. The work has therefore a high reproducibility.								The reproducibility depends on whether the code and dataset are to be open sourced. Otherwise, training two networks for generating synthetic datasets and pose estimation, and making the whole pipeline working take a lot of efforts in fine-tuning.								The reproducibility of the paper is unclear.											0	0	0	0	0	0	
375-Paper1989	Learning Large Margin Sparse Embeddings for Open Set Medical Diagnosis	If the code is available online, it will be easy to reproduce the results.								yes								This paper can be reproducible.											0	0	0	0	0	0	
376-Paper0625	Learning normal asymmetry representations for homologous brain structures	Ok.								The authors stated that the method will be freely available only after acceptance of the manuscript.  Most data used in this study are freely available online which would enables to reproduce most of the experiments.  No demographics of the data used is provided																			0	0	0	0	0	0	
377-Paper1418	Learning Ontology-based Hierarchical Structural Relationship for Whole Brain Segmentation	The authors' report on reproducibility appears to be reasonable.								Code link is provided in the paper. Public datasets are used to evaluate the algorithms.								Authors claimed that the code will be available at Github.											0	0	0	0	0	0	
378-Paper2873	Learning Reliability of Multi-Modality Medical Images for Tumor Segmentation via Evidence-Identified Denoising Diffusion Probabilistic Models	The lack of code or pre-trained models as supplemental material is a concern for the reproducibility of the results. Based on the reproducibility response, the authors agree to release the related code if this work is accepted.								The idea is clearly introduced but no codes provided.								Will be reproducible if the code is released.											0	0	0	0	0	0	
379-Paper2158	Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk	Mathematical setting is clear  Datasets are clearly mentioned								Authors included a supplementary material.								Not reproducible as the method description is unclear.											0	0	0	0	0	0	
380-Paper0924	Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation	The implementation and experimental details are described clearly and the authors promise to publish code.								Good.								The paper is reproducible since the author has agreed to release code upon acceptance.											0	0	0	0	0	0	
381-Paper1688	Learning with Domain-Knowledge for Generalizable Prediction of Alzheimer's Disease from Multi-Site Structural MRI	It is very difficult to reproduce this work given that both the code and the data are not available								Yes. It can be reprodcused if the datasets are available. The authors mentioned the details of their proposed model.								Authors use their own dataset and train the proposed model by using it.											0	0	0	0	0	0	
382-Paper0459	Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images	It is fine								I think the code and data are not provided. The description is not sufficient for reproducibility.								I can't tell. In the submission system, their answer to "releasing training code/model" is "Yes", but they don't claim to open the source code/model online in the manuscript.											0	0	0	0	0	0	
383-Paper1429	Lesion-aware Contrastive Learning for Diabetic Retinopathy Diagnosis	The system is not sufficiently well describe, which means it is difficult to replicate. The dataset used is public, meaning that from that perspective it is reproducible.								The paper provides sufficient details regarding the methods, dataset, and experimental setup, which contributes positively to the reproducibility of the study. The authors have also provided the source code of this method.								The paper could be easily reproducible with the parameters and information reported in the paper.											0	0	0	0	0	0	
384-Paper3172	LightNeuS: Neural Surface Reconstruction in Endoscopy using Illumination Decline	Limited: Parameters for network training are missing. Parameters for Photometric model are missing.								Seems okay.								The reproducibility of this paper is acceptable. With enough details, it should be easy for a domain expert to reproduce the results.											0	0	0	0	0	0	
385-Paper0353	Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network	This paper meets the reproducibility requirements. It gives details about the implementation that allows us to reproduce the experiments.								No additional comments.								not sure											0	0	0	0	0	0	
386-Paper0561	LLCaps: Learning to Illuminate Low-Light Capsule Endoscopy with Curved Wavelet Attention and Reverse Diffusion	Authors provided a link to the GitHub repo,								The details of the method have been clarified clearly and the link of the code implementation has provided in the Supplementary Materials, which brings the fine reproducibility of the paper.								This work is reproducible.											0	0	0	0	0	0	
387-Paper1317	Localized Questions in Medical Visual Question Answering	The code has been promised to be made available. The experiments seem reproducible with it. The answers to the checklist questions seem reasonable.								I think the result could be reproduced if proper code was provided.								I believe this work could be reproduced if the code is given.											0	0	0	0	0	0	
388-Paper1736	Localized Region Contrast for Enhancing Self-Supervised Learning in Medical Image Segmentation	The authors have agreed to make their code publicly available upon acceptance. Publicly available datasets are used for validating the proposed method.								The reproducibility of the paper is acceptable.								No codes are provided but it's easy to reproduce.											0	0	0	0	0	0	
389-Paper2564	Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures From Routine EHRs for Pulmonary Nodule Classification	The reproducibility of this work is relatively high if they will release the source code upon acceptance as they claimed.								Reproducible								This paper utilizes both public (NLST) and private datasets, and the authors have made their code available. It is unclear whether the private data is readily accessible to others. There is no explicit mention of code sharing. Model parameters were also not explicitly discussed, but this likely due to limited space.											0	0	0	0	0	0	
390-Paper2419	LOTUS: Learning to Optimize Task-based US representations	As noted in the paper, the source code and data used for these experiments are publicly available. Therefore, the reproducibility of the paper is good.								The paper is well-described for potential reproduction; using public datasets, if available, would have further facilitated this process.								The authors mentioned that the code and dataset are publicly available. It is hoped that the dataset includes the manually segmented in-vivo ultrasound images (500 for the aorta, 400 for vessels) mentioned in the manuscript as this would be a valuable contribution. In case the authors are not planning to release that data, it would be beneficial for the reproducibility of their work to use other publicly available datasets such as Breast Ultrasound Dataset B [1] or Dataset BUSI [2].  [1] Yap, M.H., Pons, G., Marti, J., Ganau, S., Sentis, M., Zwiggelaar, R., Davison, A.K. and Marti, R.(2017), Automated Breast Ultrasound Lesions Detection using Convolutional Neural Networks. IEEE journal of biomedical and health informatics. doi: 10.1109/JBHI.2017.2731873  [2] Al-Dhabyani W, Gomaa M, Khaled H, Fahmy A. Dataset of breast ultrasound images. Data in Brief. 2020 Feb;28:104863. DOI: 10.1016/j.dib.2019.104863.											0	0	0	0	0	0	
391-Paper0785	Low-dose CT image super-resolution network with dual-guidance feature distillation and dual-path content communication	Not sure about this aspect.								It is hard to re-implement without more details given (please see the weakness)								According to the source code provided by the authors, the paper can be reproduced perfectly.											0	0	0	0	0	0	
392-Paper1483	LSOR: Longitudinally-Consistent Self-Organized Representation Learning	Error bars are missing on the results. Given the database size, this information should be of interest.								The article provides a relatively detailed introduction on data processing, network structure, and training, which enhances reproducibility.								I believe that the obtained results can, in principle, be reproduced.											0	0	0	0	0	0	
393-Paper3007	LUCYD: A Feature-Driven Richardson-Lucy Deconvolution Network	It provides the source code.								The reproducibility of this work is good with code publicized.								This work can be reproduced.											0	0	0	0	0	0	
394-Paper3448	M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector	The authors provide detailed information on their proposed approach and evaluation methodology, which should make it possible for other researchers to reproduce their results.								Maybe								In general, the method and experiments are well described, but some details about the in-house data are missing. It would be good to add that still.											0	0	0	0	0	0	
395-Paper1607	M3D-NCA: Robust 3D Segmentation with Built-in Quality Control	This paper uses public datasets and the authors agree to make the codes and trained model public upon acceptance, which will make this work easy to reproduce.								I do believe that it is possible to reproduce the methods and the results based on the paper.								The network architecture and training parameters are not all provided in detail. The number of parameters was mentioned in the paper, but I was not able to derive the same number of the description of the paper. E.g., the 2 level architecture was described as having 12480 parameters, but I could only identify 12064 from the description in the paper. A description of the architecture in a table with the exact size of the input, output and parameters tensors of each layer would be helpful. Other missing information are how weights are initalized, how the first state of the cell array is initalized, how sampling of the patches are performed and many more. However, the complexity of learning-based methods in general make it almost impossible to provide all the details without losing focus of the main contribution of the paper.											0	0	0	0	0	0	
396-Paper3565	Machine Learning for Automated Mitral Regurgitation Detection from Cardiac Imaging	The paper seems to be rather straight-forward to reproduce. Since it is possible to get access to the datasets, it would be great if the extra labels could be made available to the public, since significant effort has to be taken to annotate the data as was done here in this study to achieve comparable same consistency.								Poor reproducibility in general. This reviewer understands that sharing data might be impossible, but code publication would likely be a useful resource for other researchers.								Good.											0	0	0	0	0	0	
397-Paper0872	Make-A-Volume: Leveraging Latent Diffusion Models for Cross-Modality 3D Brain MRI Synthesis	Good. Consider providing anonymized code for the reviewers.								This method is not reproducible. Although the method is explained fairly clearly, the pre-trained autoencoder is not available nor is its training well-describe. Also, without code no reproducibility guarantees can be made.								The paper seems to be reproducible. However, everything seems to be N/A for open-sourcing the code, which is a bit worrying in the reproducibility side.											0	0	0	0	0	0	
398-Paper1299	Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification	It seems that the related data (gaze data) will not be released, which makes it difficult to reproduce the result.								Experiments should be fairly reproducible. The weakest point regarding reproducibility is collection of gaze information, since the description of the reading protocol/acquisition set up is rather succinct.								The authors provide some amount of information about training setup. Code is provided allowing for better comprehension of the experiments. However, image preprocessing details appear to be absent which is quite penalizing for an algorithm treating mammography images.											0	0	0	0	0	0	
399-Paper0981	Many tasks make light work: Learning to localise medical anomalies from multiple synthetic tasks	Easy to reproduce. I appreciate that the authors have included their code.								The authors indicate to publicize their code upon acceptance.								Code has been provided with anonymous GitHub - making it easy to reproduce the results.											0	0	0	0	0	0	
400-Paper0416	Masked Frequency Consistency for Domain-Adaptive Semantic Segmentation of Laparoscopic Images	The paper demonstrates good reproducibility as the authors state their intention to open-source the code, and the evaluation conducted using publicly available datasets.								In the abstract, the authors state that the relevant program code will be uploaded to GitHub, which will facilitate method reproducibility.								This paper provides enough detail for reproduction.											0	0	0	0	0	0	
401-Paper2138	Masked Vision and Language Pre-training with Unimodal and Multimodal Contrastive Losses for Medical Visual Question Answering	The authors provide detailed structure of the proposed network and losses in the paper as well as the reproducibility checklist except the momentum model in Fig. 1. which is suspected as MoCo[19].								In general, it seems feasible to reproduce the results from this paper. However, it is not mentioned that code will be released.								Lack of novelty in the methods: Although the paper applies existing self-supervised learning techniques to the medical VQA domain, the individual methods, such as masked vision and language pre-training and multimodal contrastive losses, are not novel in themselves. The work could benefit from introducing new or innovative techniques to further advance the field.  Disobeying paper format rules: The paper does not adhere to the formatting guidelines, which can negatively impact the paper's overall presentation and its chances of being accepted for publication. Following the proper formatting rules is essential for maintaining consistency and clarity in academic publications.  Confusing and low-quality figures: The paper contains confusing and low-quality figures, making it difficult for readers to understand the visualizations and interpret the results. Improving the quality and clarity of the figures would enhance the overall presentation of the paper.  Insufficient experiments: The paper could benefit from additional experiments to further validate the proposed approach and its performance. This may include experiments with different random seeds, alternative pre-training strategies, and evaluation on a wider range of medical VQA tasks. More comprehensive experiments would provide stronger evidence for the effectiveness of the proposed method.											0	0	0	0	0	0	
402-Paper2185	Maximum Entropy on Erroneous Predictions: Improving model calibration for medical image segmentation	From the description, given that one is familiar with a neural net for medical image segmentation, this work seems quite reproducible as one can simply compute the proposed penalization terms and incorporate into the loss when training the model. Model architecture details are fairly well described.								Equations are clearly stated and seem clear to implement.  The code is shared.								The paper is reproducible.											0	0	0	0	0	0	
403-Paper3185	Maximum-entropy estimation of joint relaxation-diffusion distribution using multi-TE diffusion MRI	no specific effort for reproducibility can be seen. Neither data or any tools will be made available.								The paper lacks details on the implementation of the optimization algorithms. There was no converge criterion discussed or number of iteration or any hyper parameters. This makes the results hard to reproduce.								The reproducibility of this paper is not clear.											0	0	0	0	0	0	
404-Paper2640	MDA-SR: Multi-level Domain Adaptation Super-Resolution for Wireless Capsule Endoscopy Images	The authors provide the source code.								Author has convey, clear, specific and complete information about data, code, models and computational methods and analysis that support the contents and result presented in the paper.								This paper is reproducible with the help of available code and detailed experimental description.											0	0	0	0	0	0	
405-Paper1943	MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets	This work can be reproduced								The authors detailed both the architecture and the adopted training procedure.								The Authors used 4 publicly available datasets and state that will publish the code upon the acceptance.											0	0	0	0	0	0	
406-Paper2585	MedGen3D: A Deep Generative Framework for Paired 3D Image and Mask Generation	Key resources are available and sufficient details are described such that an expert should be able to reproduce the main results.								The authors promise to release codes								The reproducibility details could be further explained, namely the type of GPU used and the training time the whole model took.											0	0	0	0	0	0	
407-Paper1834	Medical Boundary Diffusion Model for Skin Lesion Segmentation	The experiments are carried out on publicly available data. There are sufficient details provided in the manuscript about the experiments, and the authors claim to release the code as well as trained models upon acceptance.								It is believed that this work can be reproducibility.								It's reproducibility.											0	0	0	0	0	0	
408-Paper0377	Medical Phrase Grounding with Region-Phrase Context Contrastive Alignment	The reproducibility of the paper is credible.								The paper is reproducible. It is not clear whether the code will be released								The paper has given ample details of their implementation process and seems reproducible. The code will be released after the acceptance.											0	0	0	0	0	0	
409-Paper0253	MedIM: Boost Medical Image Representation via Radiology Report-guided Masking	The paper seems to be reproducible given the data and code are publicly available.								The supplementary materials of this paper do not provide relevant explanations, it is suggested to provide reproducible evidence.								Didn't see the code or data links in the submission system.											0	0	0	0	0	0	
410-Paper1656	MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation	The reproducibility of the paper is good.								Reproducible								Fairly reproducible as 5-fold testing has been conducted, however errors/std have not been reported nor has statistical significance been reported.											0	0	0	0	0	0	
411-Paper2107	Memory Replay for Continual Medical Image Segmentation through Atypical Sample Selection	The authors have shared implementation details, but reproducing their work without their source code would be difficult.								The reproducibility is good, readers can basically reproduce the work by reading the paper.								All the datasets used on the paper are public and clearly documented and referenced.  While no mention is made on the paper the authors said they would make the code publicly available upon acceptance. Even without the code, the methods are clearly explained and it should be easy to reproduce the results.											0	0	0	0	0	0	
412-Paper0831	MEPNet: A Model-Driven Equivariant Proximal Network for Joint Sparse-View Reconstruction and Metal Artifact Reduction in CT Images	The authors promise to publicly release the codes after the paper being accepted.								Based on the text, it is challenging to replicate the implementation without looking at the code. Releasing the source code would be an effective way to ensure reproducibility.								I think it can be reproduced.											0	0	0	0	0	0	
413-Paper2627	Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer	The authors have chosen to make their code and other relevant details publicly available. This suggests that the results are replicable and verifiable.								Reproducibility is high: code will be released on GitHub, the method, parameters are carefully described and dataset is publicly available.								The code will be made public and the dataset is public.											0	0	0	0	0	0	
414-Paper3629	Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy	Sufficient detail is provided.								The author will release codes of this model and then all experiments can be reproduced.								The paper would not be too difficult to reproduce.											0	0	0	0	0	0	
415-Paper0950	MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging	Models and algorithms: the models are mathematically correct, and an algorithm is provided in the paper, which helps for the reproducibility.  Datasets: They used well-known public datasets, and also provided links in the Supplementary material.  Code: authors provide a GitHub repository with very clear instructions about how to run the model, with examples.  Reported experimental results: tables are very descriptive and include the essential metrics for evaluation and comparison.								The work was evaluated on a publicly available dataset. Evaluation was done using publicly available pre-trained models. Code will be available after acceptance.								The authors provide relatively detailed details of the experiment and anonymous codes for reproducing MetaLR are released.											0	0	0	0	0	0	
416-Paper3709	M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models and Latent Space Geometry Optimization	The method is reproducible.								it can be reproduced using the provided information.								Datasets and splits used are widely used in the literature and should be easily reproducible. Hyper-parameters are clearly defined. Nevertheless, the code is not provided and I believe it should be added to improve the quality of this work.											0	0	0	0	0	0	
417-Paper0699	M-GenSeg: Domain Adaptation For Target Modality Tumor Segmentation With Annotation-Efficient Supervision	I believe the paper is reproducible.								The reproducibility of this work is compromised, as the architecture is rather complex and not enough details are provided in the manuscript to replicate it. Also, no code nor pretrained models are made available.								Code will be released.											0	0	0	0	0	0	
418-Paper1023	Microstructure Fingerprinting for Heterogeneously Oriented Tissue Microenvironments	Most of the tools used are publicly available, and the authors indicate they will share their specific code.								The used dataset is public, but not sure if the authors will release their code.								The reproducibility of the paper is high as the Authors provide in-depth details of the methods (experimental setups, etc..).											0	0	0	0	0	0	
419-Paper1480	Minimal-supervised Medical Image Segmentation via Vector Quantization Memory	Overall, the method is sound and can be re-implemented. But more implementation details on the method should be provided.								The authors provide the implementation details and hyperparameters used in the experiments. They are also willing to publicly share the code.								The dataset is public. The author does not provide code and model. The hyperparameters are provided in main paper for training. I think the paper is reproducible, but might be a bit hard due to the complex method.											0	0	0	0	0	0	
420-Paper0197	Mining Negative Temporal Contexts For False Positive Suppression In Real-Time Ultrasound Lesion Detection	This work is highly reproducible. The authors use a public dataset. Though they produce custom annotations, the annotations will be made available (are included in provided supplementary material). Code is likewise available. Lastly, paper is detailed and clear.								Codes are shared.								Given the code, it seems to be guaranteed											0	0	0	0	0	0	
421-Paper0691	MI-SegNet: Mutual Information-Based US Segmentation for Unseen Domain Generalization	The work was evaluated partly on publicly available datasets. Code will be available after acceptance.								The authors have provided code and pointed out source of datasets. The description also appears to be fairly clear								Good											0	0	0	0	0	0	
422-Paper1643	Mitigating Calibration Bias Without Fixed Attribute Grouping for Improved Fairness in Medical Imaging Analysis	Maybe, the algorithm is not complex.								Looks fine.								The paper seems to be reproducible, and the authors have made an effort to provide all necessary information for others to reproduce their experiments. However, I have not seen any publicly available code or links.											0	0	0	0	0	0	
423-Paper0338	Mitosis Detection from Partial Annotation by Dataset Generation via Frame-Order Flipping	The paper is quite clear and should be reproducible with some effort. However, it would be nice if the authors publish their code.								Seems to be fine (but no code provided)								Some parts of the applied methodology are not described with sufficiently level of detail; see, in particular, my comment 4.											0	0	0	0	0	0	
424-Paper1606	Mitral Regurgitation Quantification from Multi-channel Ultrasound Images via Deep Learning	Models and algorithms: it would be good to include an algorithm to show the steps of the pipeline.  Datasets: authors said 'Yes' for a downloadable version of the dataset, but it is not present in the paper and not referenced.  Code: authors said 'Yes' for the inclusion of code, but in the submission there is no code to run and test.  Reported experimental results: The authors chose 'Yes' for every statement, which is false. The average runtime, the number of run, the analysis of situations where the method failed, etcetera, are not presented.								The model is difficult to be reproduced.The dataset and code are not available.								The authors did not mention or include any link to a repository in the manuscript, but relevant code will be publicly available, as stated in the reproducibility check. Uploading the trained models may improve the reproducibility and transparency of the manuscript.											0	0	0	0	0	0	
425-Paper3659	Mixing Temporal Graphs with MLP for Longitudinal Brain Connectome Analysis	how the node features and edge weights are extracted are not clearly presented								The reproducibility of the paper is fine to me.								The author has guaranteed to release code for reproduce.											0	0	0	0	0	0	
426-Paper0376	MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis	Seems reasonable to me.								The source and data are only available upon request, which limits the reproducibility.								Although the paper does not provide the source code, the proposed method can be easily implemented, and the paper also provides a sufficient description of the experimental settings.											0	0	0	0	0	0	
427-Paper0833	MoCoSR: Respiratory Motion Correction and Super-Resolution for 3D Abdominal MRI	The authors could have provided more information about important hyperparameters such as batch size and learning rate. Unfortunately, no code seems available to replicate or build upon the proposed approach.								Code will be available on GitHub.								As stated in the paper, the code will be available on GitHub.  The work depends on private datasets. It is unsure whether they will make it public.											0	0	0	0	0	0	
428-Paper1693	Modeling Alzheimers' Disease Progression from Multi-task and Self-supervised Learning Perspective with Brain Networks	The description is clear.								The method is evaluated on a public dataset, and the work will be reproducible if the authors provide open-sourced code repository.								Very good reproducibility. The authors pledge to make code public and details of experimental settings are provided.											0	0	0	0	0	0	
429-Paper2229	ModeT: Learning Deformable Image Registration via Motion Decomposition Transformer	The author stated that the code will be made available and reproducibility seems to be possible.								The author did state that they will publish the code after acceptance, which is a positive sign for reproducibility. Additionally, the paper mentions the datasets and evaluation metrics used in the experiments, which allows for the replication of the experiments by other researchers.								Given that the authors plan to release the source code of this work, the results presented in the paper can be reproduced.											0	0	0	0	0	0	
430-Paper0339	Modularity-Constrained Dynamic Representation Learning for Interpretable Brain Disorder Analysis with Functional MRI	The authors have indicated that implementation code will be made available for reproducibility								code unavailable								No major concerns. No link to code repository at the time of review.											0	0	0	0	0	0	
431-Paper2490	ModusGraph: Automated 3D and 4D Mesh Model Reconstruction from cine CMR with Improved Accuracy and Efficiency	It's not mentioned in the paper.								Mostly seems good, but there are a few important details missing, as mentioned in the weaknesses section.								Code will be provided and thus reproducible.											0	0	0	0	0	0	
432-Paper1196	Morphology-inspired Unsupervised Gland Segmentation via Selective Semantic Grouping	meet the requirement								The authors claim to release the codes.								Code will be available upon acceptance.											0	0	0	0	0	0	
433-Paper2481	Motion Compensated Unsupervised Deep Learning for 5D MRI	Two MRI data sets were used for evaluation. The reproducibility is limited.								The author stated to meet all reproducibility requirements.								While there are no links to code or data provided, the authors promised to provide code and pre-trained models upon acceptance.											0	0	0	0	0	0	
434-Paper2545	MPBD-LSTM: A Predictive Model For Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans	The experimental setup and the steps to reproduce is clear in the paper. The work can be reproduced with the mentioned system configuration.								Reproducible.								The model parameters and experimental settings are provided. Code will be released. Dataset will be available on request.											0	0	0	0	0	0	
435-Paper1372	MRIS: A Multi-modal Retrieval Approach for Image Synthesis on Diverse Modalities	The code is not publicly available								A public database, the OsteoArthritis Initiative is used for the validation of the proposed approach.								Not hard to reproduce the baseline if author release the paired seg mask and x-ray.											0	0	0	0	0	0	
436-Paper2645	MSKdeX: Musculoskeletal (MSK) decomposition from an X-ray image for fine-grained estimation of lean muscle mass and muscle volume	The code will be made available. Although data may not be released due to IRB requirements, the paper is highly reproducible.								The authors have included an anonymised link to the source code. It is not clear whether a pre-trained system utilising their data is also included. The latter would be a great contribution to the community as the system relies on paired CT and X-ray data which are not commonly available.								The authors provide sufficient details that support the reproducibility of the results. A URL of the source code repository will be released as well.											0	0	0	0	0	0	
437-Paper2719	MulHiST: Multiple Histological Staining for Thick Biological Samples via Unsupervised Image-to-Image Translation	The authors promised that PyTorch code of proposed MulHiST method will be available upon acceptance. So far, reproducibility is based on description of the method in Section 2. It is very elementary as limited by the format of the paper. On descriptive level I can only judge meaningfulness and novelty of their proposal. Up to certain extent described results on performed experiments back up the statements and suggest that presented results will be reproducible.								The authors did provide sufficient information with details in data preprocessing and model training. The computing infrastructures, model training hyper-parameters are clearly stated for experiment reproducibility purposes.								not good. Since the in-house dataset were used, more details on the data acquisition should be given											0	0	0	0	0	0	
438-Paper1108	Multi-Head Multi-Loss Model Calibration	code will be given so under that condition reproducibility is not an issue.								This work uses publicly available datasets, readily available model architectures, and the authors express intention to share all the relevant code. Highly reproducible.								The reproducibility is very good as,    the method is described sufficiently well to be reimplemented without the code,  the code will be released after acceptance,  publicly available datasets are used,  common network architectures are used, and  all important hyper-parameters are reported.											0	0	0	0	0	0	
439-Paper1835	Multi-IMU with Online Self-Consistency for Freehand 3D Ultrasound Reconstruction	The dataset is not public and it seems it is not going to be made public. This is a downside.								The method seems quite difficult to implement. There is not enough information in the paper to reproduce it, specially the network architecture. Authors claim they will free the code which is very positive but even if the code is available the use of 4 sensors introduces many sources of error during testing. Even if other reseachers achieve to get good pre-calibrated values for the IMU, how do they make a good training? Which is the quality of your Imu data?								The reproducibility of the paper is unclear.											0	0	0	0	0	0	
440-Paper1341	Multimodal brain age estimation using interpretable adaptive population-graph learning	The hyperparameters of proposed model are clearly claimed and most of settings about baselines are claimed. And code will be publicly available.								The paper utilizes the UK Biobank dataset that is a large dataset and available upon applying as a researcher. The authors state that their code will be available. Adequate details on the architecture as well as experimental procedures are presented in the paper								1) The paper provides a detailed description of the proposed method, including the architecture of the graph construction and the graph convolutional network (GCN).  2) The dataset used for evaluation, the UK Biobank (UKBB), is a well-known and widely used dataset in the medical imaging domain.  3) The paper presents clear evaluation metrics (MAE, r score, accuracy, AUC, F1-score) and compares the proposed method to relevant baselines.  4) The authors describe the implementation details, including the GCN architecture, optimizer, learning rate, and the number of epochs.  5) The ablation studies give additional insight into the method's performance under different conditions, enhancing the understanding of the method's behavior.  6) The exact dataset split (i.e., subject IDs) used for training, validation, and test sets is provided.  7) The code for the implementation will be made publicly available.											0	0	0	0	0	0	
441-Paper3254	Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk	Implementation details are disclosed in the paper. In particular, the architecture based on nnUNet can be easily reproduced.  Apart the PDDCA dataset which is publicly-available, either the code nor the data will be disclosed.								Considering the limited word count of the manuscript, the provided descriptions are satisfactory to replicate the model given the fact that the model was constructed within nnUNet framework. Sufficient details about the results quantification were provided.								The used dataset is private, nonetheless an evaluation on a public dataset is done. The authors claim in their reproducibility response to provide access to the code which is helpful to get the parametrization of the nnUnet used for the training, as it is dataset dependent. Without the code and the paper only it would be hard to reproduce exact results.											0	0	0	0	0	0	
442-Paper2572	Multimodal Deep Fusion in Hyperbolic Space for Mild Cognitive Impairment Study	I think it is reproducible. The supllementary material has also been provided.								YES								Code related to this workwill release if this work is accepted											0	0	0	0	0	0	
443-Paper0314	Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis	The experimental data are from the public challenges. The authors say the code will be made available.								The authors did provide a complete information to reproduce the experiment. Only tiny missing detail is the learning rate decay strategy for HER2 staining image generation task.								The paper does not contain any information about releasing the code. Some details about the method implementation have been reduced but more information will be needed for reproducibility.											0	0	0	0	0	0	
444-Paper0826	Multi-Modal Semi-supervised Evidential Recycle Framework for Alzheimer's Disease Classification	It would be helpful if you could provide more information about the data used in your study, including the data collection procedures, data cleaning and preprocessing methods, and any relevant information about the variables used in the analysis. By including this information, you can increase the transparency and credibility of your research and allow other researchers to build upon your work								No code provided, so hard to comment on reproducibility of the paper.								reproducibility on the public dataset in this study should be excellent if the code is made available											0	0	0	0	0	0	
445-Paper2360	Multi-modal Variational Autoencoders for normative modelling across multiple imaging modalities	The code is given and the datasets can be accessed so it should be easy to reproduce this work.								Satisfactory								Code is available with clear instructions.											0	0	0	0	0	0	
446-Paper0803	Multi-modality contrastive learning for sarcopenia screening from hip X-rays and clinical information	The paper seems to be reproducible since it is clearly written, and the authors have shown the implementation details. Also, the authors intend to release the code. The authors did not mention if the dataset used for evaluation will be released.								The paper uses in-house dataset.								If the authors will share the code, as announced in the paper, it should be possible to reproduce the results.											0	0	0	0	0	0	
447-Paper2014	Multi-objective point cloud autoencoders for explainable myocardial infarction prediction	The paper can be reproduced								Good reproducibility of the paper								The authors provided details about the data and cases selected from the UK Biobank. They also provide hyperparameters of the DNN used during training.											0	0	0	0	0	0	
448-Paper0738	Multi-perspective Adaptive Iteration Network for Metal Artifact Reduction	The authors have provided sufficient details on the proposed method's implementation and evaluation, which should allow for reproducibility of the experiments. The authors plan to provide the code for the proposed method in the future. In the paper, they describe the datasets, experimental setup, and parameters used in detail. Additionally, they reported quantitative results and provided visual comparisons with existing methods. Overall, this information can aid other researchers in recreating and evaluating the proposed method on different datasets.								This paper's methodology appears to be reproducible. While the authors did not include the code, they provided comprehensive details on the model, dataset, and evaluation. Therefore, the work seems to be replicable to a significant extent. Moreover, the authors plan to provide the code for the proposed method in the future.								The authors have filled out the reproducibility form.											0	0	0	0	0	0	
449-Paper1294	Multiple Prompt Fusion for Zero-Shot Lesion Detection Using Vision-Language Models	Given that the authors enough implemental details, the datasets are publicly available, and the description in method section is clear, the reproducibility of the paper is ensured.								The work was evaluated on a publicly available dataset. According to the checklist, code will be released after acceptance. This information is not included in the paper.								It is not mentioned anywhere in the paper whether the code will be open-sourced. At the same time, many finer details about the ensemble clustering, language based fusion are not provided and without them the results cannot be reproduced.											0	0	0	0	0	0	
450-Paper0483	Multi-scale Cross-restoration Framework for Electrocardiogram Anomaly Detection	The authors have mentioned that the benchmark dataset and code will be made available.   They use public datasets to test the proposed method.								The proposed benchmark dataset and source code will be made publicly avilable.								Very good. The benchmark dataset and source code will be made publicly available.											0	0	0	0	0	0	
451-Paper1496	Multi-Scale Prototypical Transformer for Whole Slide Image Classification	The authors promised source code and pre-trained models								The main idea should be easy to implement and the datasets are public.								Yes, the authors provide experimental settings that are detailed and can be reproduced.											0	0	0	0	0	0	
452-Paper3115	Multi-Scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision	To reiterate, although the main factors contributing to the performance improvement are not entirely clear, if adequately addressed and clarified during the revision process, the results seem to be reproducible.								Models were trained on a private dataset, testing was performed on two public datasets.  Code of the model has not been maid available.								reproduciable											0	0	0	0	0	0	
453-Paper2784	Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image based Cancer Survival Prediction	The authors provide some descriptions on the hyper paramters used and the public datasets. However, some details on the specific GCN and  transformer are missing. For example what is th non linearity used in the GCN layer? what is the number of ehads in the transoformer?  The authors also provide a repo with code, which is interesting; however, when looking at it in detail, it is currently in an  unusable way because there are no details on how to run the code, some scripts seem to be missing e.g. in the run.sh  the scripts interpretable_transformer.py and graph_transformer.py are mentioned but are not available in the repo.								The authors are providing code so this should be reproducible.								The code was already made publicly available, indicating a potential high reproducibility.											0	0	0	0	0	0	
454-Paper2315	Multi-shot Prototype Contrastive Learning and Semantic Reasoning for Medical Image Segmentation	Good reproducibility								The method seems relatively straightforward and the pipeline is not overly complicated. Additionally, code is made available and all datasets are public, so there should be no concerns regarding reproducibility.								Given the availability of code, it appears that reproducibility of the presented results could be relatively straightforward.											0	0	0	0	0	0	
455-Paper1663	MultiTalent: A Multi-Dataset Approach to Medical Image Segmentation	This work has great reproducibility since the datasets are publicly available and the method description is clear.								Yes, I believe the paper can be reproduced.								easy to reimplement											0	0	0	0	0	0	
456-Paper0968	Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation	In its current form, this work is not reproducible. The authors claimed that they will release their code if accepted.								The authors promise to share the code as well as the dataset upon acceptance.								The authors claimed that they will release the source code upon publication. There is no clear declaration of what software frameworks and versions used. Descriptions are lacking necessary details for reproducibility.											0	0	0	0	0	0	
457-Paper2485	Multi-task Joint Prediction of Infant Cortical Morphological and Cognitive Development	The authors did not provide the source code.   But the authors clearly described the building blocks and loss function used in the paper.								The authors go at lengths to provide verbal descriptions of the used underlying developments, and explaining the organization of their framework. No source code is provided. Thus, the reproducibility can be estimated as slightly above average.								Tested on a public dataset, and the authors have mentioned in the reproducibility checklist that the codes will be made available.											0	0	0	0	0	0	
458-Paper2548	Multi-task Learning of Histology and Molecular Markers for Classifying Diffuse Glioma	I rate the reproducibility of this work high. It is the highest of the 5 papers I've reviewed. The supplemental material (including code) is complete. Some of the weaknesses in the presentation of the methods could hinder some attempts at reproducing.								The reproducibility of the paper seems to be guaranteed due to the availability of the source codes and datasets.								The author submitted the code as a separate attachment, ensuring the good reproducibility of the article.											0	0	0	0	0	0	
459-Paper2095	Multi-view Guidance for Self-supervised Monocular Depth Estimation on Laparoscopic Images via Spatio-temporal Correspondence	The four backbone networks are not clearly referenced. Considering the complicated structure and heavy hyperparameters, this manuscript is very difficult to reproduce.								The author provides the code of the proposed method.								The paper should be reproducible given that the paper is clearly written with enough details.											0	0	0	0	0	0	
460-Paper0534	Multi-View Vertebra Localization and Identification from CT Images	While authors made the effort to provide "Implementation Details" (Sec 3.2 could go to Sup Mat), it would be hard to reproduce results without the code:    the contrastive learning has several hyperparameters not detailed  how the views are rendered is not precisely described  the implementation of the sequential loss would not be straightforward								good things about reproducibility  o open datasts used  o objective function and training are well described  o preproccessing and post-processing are well described  limiting the ability to reproduce  o code not provided								The authors have used a public dataset (VerSe) for their evaluation.  Since the pipeline is complex, it would really be beneficial to have the authors' code in order to be able to reproduce the results.  The reproducibility checklist filled by the authors does state that the code will be released but:    the submission/paper does not mention it;  some answers of the reproducibility checklist seem inaccurate (for instance error bars, runtime, memory footprint, etc... were claimed to be reported but actually were not) so I am not sure how this can be trusted.											0	0	0	0	0	0	
461-Paper2286	MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis	The authors use an internal dataset. In the checklist, they select to provide the codes, data, and model. However, these informations do not appear in the paper.								N/A								I believe that this paper has the potential to contribute to the community through its reproducibility, especially if the authors open-source their code and software. This would allow other researchers to easily replicate their results and build upon their findings.											0	0	0	0	0	0	
462-Paper3175	NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models	The paper is somewhat reproducible, since the authors use a public dataset and they provide enough details of the implementation and promise to make the code public.								Sufficient detail to reproduce.								The reproducibility is good.											0	0	0	0	0	0	
463-Paper0518	Neural LerPlane Representations for Fast 4D Reconstruction of Deformable Tissues	Availability of source code and data sets:   Since the authors indicated that their source code incl. used datasets will be released if this work is accepted, they should provide specific details such as links to a github repo (or similar) and their data sets before this paper is accepted. In section 3.2, on page 7, the authors wrote "The code will be released later." This sentence is not clear since it can mean that the code will be released before the paper is published, or the code will maybe be released after the paper is published. The sentence should be changed in order to provide the reader with clearer information.    Implementation details:  1.) In section 3.2 on page 7 the concrete Ubuntu version should be mentioned.   2.) On a positive note, concrete values of neural network hyper-parameters are described which increases reproducibility.								The key point of this work is clear. The technical route of the design is also clear, and it can be reproducible.																			0	0	0	0	0	0	
464-Paper1757	Neural Pre-Processing: A Learning Framework for End-to-end Brain MRI Pre-processing	The authors used public datasets, provide their code to the reviewer and give their training parameters. Therefore their method is fully reproducible.								The paper should be reproducible, as the authors mentions that they will make the code publicly available. The paper uses all publicly available datasets.								The reproducibility of this work is hard to achieve, specially the preprocessed dataset.											0	0	0	0	0	0	
465-Paper0596	NeuroExplainer: Fine-Grained Attention Decoding to Uncover Cortical Development Patterns of Preterm Infants	Currently reproducing these results would not be straightforward.  The authors should release a link to code  The authors should fix their notation, in the absence of code this needs to be much clearer.  The authors should give more details about the data set and which examples were used for train and test. As dHCP is open this could be released with the code.								The method is reproducible if the code made public.								Could be reproduced upon released codes and data.											0	0	0	0	0	0	
466-Paper3205	NISF: Neural Implicit Segmentation Functions	The paper is written clearly and has enough information to reproduce								The paper appears to be reproducible, as it utilizes a publicly available dataset and presents a method that is relatively straightforward to implement.  However, it would be better to have other datasets with segmentations from human experts.								As stated in the weaknesses, the network architecture is not fully described.											0	0	0	0	0	0	
467-Paper0754	Noise Conditioned Weight Modulation for Robust and Generalizable Low Dose CT Denoising	The proposed method seems easy to be implemented in any backbones.								This work is reproducible.								This paper uses public datasets and the baseline network is currently publicly available. The description of the method is relatively clear and the framework is easy to reproduce.											0	0	0	0	0	0	
468-Paper2943	Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT	This paper has a good reproducibility.  The methods are well described and the application of one free available dataset makes is possible to compare results for other algorithms in the future.  One aspect that could improve the reproducibility is that although the methods are very well described, they are described in a very theoretical way which may difficult its replicability for others. If the code is released in the future, it may help to overcome this issue.								The paper has provided sufficient details.								OK (no comment is made about whether code will be made publicly available).											0	0	0	0	0	0	
469-Paper2654	Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and Deformable Image Registration	The answers made in this list seems to be mostly correct.  However, sometimes the authors say not applicable and I don't understand why this point for example is not applicable:  An analysis of situations in which the method failed.  [Not Applicable]								The code will be released if accepted, the baseline method implementation are already available online and the evaluation relies on public dataset.								Very good											0	0	0	0	0	0	
470-Paper1059	Nonuniformly Spaced Control Points based on Variational Cardiac Image Registration	The datasets used for evaluation are publicly available.  The details given in the paper are confusing and I do not feel able to exactly reimplement the proposed method even taking VoxelMorphDiff codes as starting point.  For the evaluation, the authors provided a clear description of metrics and tendency. Statistical significance was stated when needed.  The time and memory complexity of the proposed method are not given.  The clinical significance of the method can be inferred from the introduction. However, the proposed method needs further validation in more different datasets for considering moving to clinical application.								The reproducibility is average with some missing details, but the author declares to provide the training code and testing modes, which seems promising.								More details are needed to completely reproduce the presented method.											0	0	0	0	0	0	
471-Paper3365	On the Relevance of Temporal Features for Medical Ultrasound Video Recognition	Software will be published open source and is therefore reproducible.								Should be okay if code is provided.								NA											0	0	0	0	0	0	
472-Paper2006	One-shot Federated Learning on Medical Data using Knowledge Distillation with Image Synthesis and Client Model Adaptation	Most implementation details are presented.								Public datasets were used and data should be released. Should report confidence intervals to see if results are statistically signficant.								Appears to be reproducible.											0	0	0	0	0	0	
473-Paper0652	One-Shot Traumatic Brain Segmentation with Adversarial Training and Uncertainty Rectification	In-house data are utilized. It is suggested to make the codes publicly available if the paper is accepted for publication to ensure reproducibility.								The network structure is quite complex, which is difficult to reimplement and reproduce the results from scratch.								The authors have not released the data and code yet. Even though the manuscript is presented well, there may be some difficulty in reproducing the work since the method itself is complicated.											0	0	0	0	0	0	
474-Paper0081	OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification	In terms of reproducibility, the paper seems to be reasonably well-documented and could potentially be reproduced by other researchers. Authors include details on the hyperparameter settings, such as the number of epochs, optimizer, momentum, weight decay, initial learning rate, and batch size, which are important details for the reproducibility of the experiments.								The paper appears to be reproducible because the authors have stated that the code will be made available and the experiments are based on a publicly available dataset. This means that other researchers can access and verify the results presented in the paper.								The idea of this paper can be reproduced by following the paper, the evaluation dataset is public, and their code will be released.											0	0	0	0	0	0	
475-Paper2884	Open-Ended Medical Visual Question Answering Through Prefix Tuning of Language Models	The proposed method is not difficult to understand and has been clearly described in this paper. This work plans to make the code of this paper publicly available. The reproducibility shall not be an issue.								It is mentioned that the code will be made publicly available.  However, some details should be mentioned more explicitly: for example, how were positional embeddings and token types handled in the language model?								Code will be made available, and the datasets are public.											0	0	0	0	0	0	
476-Paper2895	Optical Coherence Elastography Needle for Biomechanical Characterization of Deep Tissue	The OCE probe design and the experimental setup can be easily reproduced based on the detailed descriptions in the manuscript. However, the data processing scheme lacks clarity due to the inappropriate usage of notations.								I think that as long as one remains on a purely elastic, highly linear and non-viscous (and a fortiori very homogeneous) gel, the approach works very well and I consider it to be highly relevant, very well thought out and very well done. However, I have serious reservations about its application and reproducibility on liver tissue, whether ex or in vivo (for the reasons previously mentioned in the limiting points). In my opinion, the proofs as to the reproducibility on liver tissue (or in a general way on biological tissue) remain entirely to be made (even if this first very preliminary stage on gel remains obviously necessary).  To sum up: the tests presented here are clearly enough to be completely reproducible, but in my opinion not yet proven to be exportable on biological tissue, and in the first place in the liver (which remains the first stated objective).								Not be able to comment since this is mainly an engineering and hardware work.											0	0	0	0	0	0	
477-Paper3392	Optical Ultrasound Imaging for Endovascular Repair of Abdominal Aortic Aneurysms: A Pilot Study	Since the paper is very clear, the only aspects that complicate reproducibility are the effort involved in creating such an OpUS catheter, benchtop experimental setup and animal experimental setup. All of these are simply intinsic to the presented work.								As mentioned, this paper is clearly presented with a good problem definition, literature review and assessment of results plus suggestions for next steps. The experiments appear reproduceable.								Re-implementing this design may not be easy for individuals. However, if this design is ready for wide-scale manufacturing in the future, it would have a high clinical impact.											0	0	0	0	0	0	
478-Paper2383	Optimizing the 3D Plate Shape for Proximal Humerus Fractures	good things about reproducibility  o the paper uses established methods  o the paper has extensive supplemental material  limiting the ability to reproduce  o a closed dataset is used  o many aspects of the data processing, organization and algorithm lack sufficient detail for reproducibility								Datasets are not available.  Source code is not available.  Implementation details are partially described.								No codes provided in the supplimentary.											0	0	0	0	0	0	
479-Paper2161	Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping	The data, experiments and evaluation are documented very well.								The data used were clearly described in their composition and the subjected imaged, and the preprocessing applied are clearly outlined. The feature generation is clearly described with details of the methodology, and the deep learning model used is noted. The authors note that the code will be released upon acceptance.								May be reproducible given hyper parameters											0	0	0	0	0	0	
480-Paper0904	Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction like Radiologists	The reproducibility seems OK. It would also be valuable if they made the dataset with annotations available.								Enough details are provided for reproducing the paper.								The experimental settings and some parameters are not defined.											0	0	0	0	0	0	
481-Paper1049	Partial Vessels Annotation-based Coronary Artery Segmentation with Self-training and Prototype Learning	The code is claimed open yet and the dataset used remains private.								The manuscript includes details on the implementation, parameters and hardware used. Additoinal details on the dataset characteristics and ethics would be useful.								The dataset is private and the code and model are not released.  The exact model architecture is not provided. Not a problem if code is released.  Hyper-parameter strategy is not mentioned, but maybe no hyper-parameter search was performed (which would be fine)  Time/cost/memory not reported  No statistical significance tests											0	0	0	0	0	0	
482-Paper2606	Partially Supervised Multi-Organ Segmentation via Affinity-aware Consistency Learning and Cross Site Feature Alignment	The method is not easy to implement simply based on the paper. The authors claim they'll release codes in the future.								It is difficult to fully reproduce the work as its own dataset split is used.								The idea of the paper is clear and not hard to follow. The authors also claim clearly in the reproducability statement that the code will be released. Hence, the reproducability of this paper should be good.											0	0	0	0	0	0	
483-Paper2143	PAS-Net: Rapid Prediction of Antibiotic Susceptibility from Fluorescence Images of Bacterial Cells Using Parallel Dual-branch Network	Not sure if the work is reproducible, the paper is clearly written but authors do not provide the code. It would require some effort to code it from scratch and probably make a few assumptions.								According to the answers to the reproducibility checklist, there will be no code to be released, which makes the reproducibility of the paper a little challenge.								Acceptable											0	0	0	0	0	0	
484-Paper2294	Path-based Heterogeneous Brain Transformer Network for Resting-State Functional Connectivity Analysis	This manuscript seems to stack path convolution and transform which are from the existing methods. The details of the method are not clear. It is hard to perform the reproducibility of the paper.								The model detail is enough.								The authors do not provide the details on reproducibility.											0	0	0	0	0	0	
485-Paper1847	Pathology-and-genomics Multimodal Transformer for Survival Outcome Prediction	The authors mentioned that the code will be publicly available.								The authors provide information on the public repository for the datasets they gathered for this study as well as description of the preprocessing steps. They also state that their code will be available once their paper is published.								With the source code release, paper has sufficient details for reproducibility. Datasets used (TCGA) are publicly available.											0	0	0	0	0	0	
486-Paper0295	Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis	I think this paper is easily reproduced.								The author cannot publish the code of the proposed method. I recommend the author to add the detail of the implementation to the supplementary material. For example, the numbers of the network layers, the equation of the loss function.								The paper is more reproducible but still needs to clarify certain specific implementations, such as the number of transformer blocks used.											0	0	0	0	0	0	
487-Paper3291	PCMC-T1: Free-breathing myocardial T1 mapping with Physically-Constrained Motion Correction	The authors stated that "Our code and trained models will be made publicly available  upon acceptance".								Given the author's statement on reproducibility in the last sentence of the abstract, reproducibility is not a major concern.								The manuscript mentions the code will be available in a repository and the checklist supports this statement. Once uploaded, it will guarantee reproducibility.											0	0	0	0	0	0	
488-Paper0871	Pelphix: Surgical Phase Recognition from X-ray Images in Percutaneous Pelvic Fixation	The authors state they will make their code and data available. I do not see any problem with the reproducibility of the work.								The authors have stated that their code and data will be made available, but no timeframe is provided.								The authors have made a good effort to describe their methods in detail. But without source code, such a complex methodology is impossible to reproduce. I hope I didn't miss anything because the authors answered all reproducibility questions with a "yes". However, I could not find any references to either source code or data.											0	0	0	0	0	0	
489-Paper1608	Pelvic Fracture Reduction Planning Based on Morphable Models and Structural Constraints	The manuscript gives sufficient details to reproduce the proposed method. Data for the generation of the statistical shape models are publicly available, and the author(s) also published the data used for the clinical study. I, therefore, believe the work has a very high reproducibility.								Reproducibility of the work is difficult if not impossible since the method is not clearly described.								The data will be published but not the code. It is difficult to say how easy it will be to reproduce the exact results by re-implementing the GPMM. Statistical test were provided along with boxplots showing the error distributions.											0	0	0	0	0	0	
490-Paper1597	Pelvic Fracture Segmentation Using a Multi-scale Distance-weighted Neural Network	Code will be made available, and the CTPelvic1K dataset is public. I encourage the authors to make their annotations of fractures available.								Paper is reproducable.								The dataset is in-house due to the unavailability of relevant annotations. The code has been published online. The employed hyper-parameters are given.											0	0	0	0	0	0	
491-Paper2601	Performance Metrics for Probabilistic Ordinal Classifiers	Simple method that can be easily reproduced.								It is surely reproducible.								The paper uses publicly available datasets to and all their code is available online in a GitHub repository, linked in their paper.											0	0	0	0	0	0	
492-Paper0291	Personalized Patch-based Normality Assessment of Brain Atrophy in Alzheimer's Disease	More experimental details are needed, such as how many times of running in terms of computing the final rates in Table 1?								The algorithmic details and the mathematical formulae are well explained. The testing data sets are public available, so the work is easy to be reproduced by a graduate student.								While the proposed method appears to be reproducible, it would be helpful to include certain important information, such as the runtime and parameters used for sulcal skeleton extraction, to ensure that others can easily replicate the results.											0	0	0	0	0	0	
493-Paper1482	PET Image Denoising with Score-Based Diffusion Probabilistic Models	The authors are able to provide the details of training architecture and hyperparameters in the paper. it would be very easy to reproduce the paper if the authors had provided the source code and some data.								Good, but only one dataset								Reproducibility is satisfied.											0	0	0	0	0	0	
494-Paper0128	PET-diffusion: Unsupervised PET Enhancement based on the Latent Diffusion Model	reproducibility is very poor both datasets and model are not published. The author's reproducibility checklist is inconsistent with the actual paper.								OK								The architecture and dataset is clear enough and the CT cross attention is well explained to replicate the proposed method. However, as far as I know, the Poisson diffusion (Equation 1) is neither explicit nor referenced. I assume that the training of both autoencoders is done separately and prior to the training of the diffusion model.											0	0	0	0	0	0	
495-Paper1717	Physics-based Decoding Improves Magnetic Resonance Fingerprinting	The architecture is clear and the formulation is well defined.								Authors mentioned that the code will be made available upon acceptance.								The code will be made available upon acceptance.											0	0	0	0	0	0	
496-Paper3215	Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T	No concerns about reproducibility.								The author provide some code in the supplementary materials, but it is not easy to reproduce the results since the data are not to be released.								The authors provide verbal description of their neural network model, which may require significant effort to reproduce. Formal equation derivations are poorly annotated, which also may potentially reduce reproducibility.											0	0	0	0	0	0	
497-Paper1728	Physics-Informed Neural Networks for Tissue Elasticity Reconstruction in Magnetic Resonance Elastography	The network architecture was explained but dataset and code are not available.								The paper is providing all information to re-code the method.								For me, many elements are missing to guarantee the reproducibility of the results: the database used, the frequency used in MRE (or multi-frequency? then which one?), the boundary conditions used, the type of MRI and sequence used (changing considerably the visualizable wavelength, resolution, SNR, FOV,... and thus the result of the investigations and comparisons with existing algorithms), the direct models used,...											0	0	0	0	0	0	
498-Paper2744	Pick and Trace: Instance Segmentation for Filamentous Objects with a Recurrent Neural Network	The authors mention that the they provide collected data once paper accepted. The coding resources are not found within the provided supplemental files.								The method is described well enough to be reproduced. The dataset is not described in enough detail. The authors do not provide any code for method or dataset.  I would advise to publish these upon acceptance and link to them in the paper.								The paper is well written and the method explained in detail, which facilitates the reproducibility of the approach. Additionally, the authors stated their will to provide the data and the code as soon as the paper is accepted.   On the other hand, the proposed method seems easily transferable across specimens and biological structures as long as they are filaments with a starting and an ending point.											0	0	0	0	0	0	
499-Paper0855	Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation	All details are provided.								The paper propovides sufficient implementation details.								The paper has provided sufficient information and resources to allow for reproducibility of the proposed method.											0	0	0	0	0	0	
500-Paper0969	PIViT: Large Deformation Image Registration with Pyramid-Iterative Vision Transformer	Some details of the network are missing, such as the nonlinearities used following convolutions, as well as numbers of channels and how these were chosen. Details of dimensions involved in the SWIN transformers were missing. Manuscript did not contain a placeholder for a repo.								The authors don't say that they will make the code available or already have done it. Furthermore, no statistical analysis was performed. It's not clear to me if the parameters of the other methods were changed or kept like in the original paper.    For all code related to this work that you have made available or will release if this work is accepted, check if you include:  Specification of dependencies.  [Yes]   Training code.  [Yes]   Evaluation code.  [Yes]   (Pre-)trained model(s).  [Yes]   Dataset or link to the dataset needed to run the code.  [Yes]   README file including a table of results accompanied by precise command to run to produce those results.  [Yes]  For all reported experimental results, check if you include:  The range of hyper-parameters considered, method to select the best hyper-parameter configuration, and specification of all hyper-parameters used to generate results.  [Yes]   Information on sensitivity regarding parameter changes.  [Yes]   The exact number of training and evaluation runs.  [Yes]   Details on how baseline methods were implemented and tuned.  [Yes]   The details of train / validation / test splits.  [Yes]   A clear definition of the specific evaluation metrics and/or statistics used to report results.  [Yes]   Discussion of clinical significance.  [Yes]   A description of the computing infrastructure used (hardware and software).  [Yes]   An analysis of situations in which the method failed.  [Yes]   A description of the memory footprint.  [No]   The average runtime for each result, or estimated energy cost.  [Yes]   An analysis of statistical significance of reported differences in performance between methods.  [Yes]								Many quantitative details about the architecture are not provided (patch and window size in the LCD, number of features, etc.). While it is stated that the code will be made available, I believe it is beneficial to also provide technical details in the paper (eventually in supplementary material).											0	0	0	0	0	0	
501-Paper0755	PLD-AL: Pseudo-Label Divergence-Based Active Learning in Carotid Intima-Media Segmentation for Ultrasound Images	The papers appears detailed enough for the result to be reproducible.								Authors meet all reproducibility criterias.								Overall, the paper provides enough information to allow someone to replicate the study with similar datasets and settings. Some exact details of the data preprocessing, augmentation, and hyperparameter tuning are not specified. For example, how many epochs were used? Is it 1000 training iterations?											0	0	0	0	0	0	
502-Paper0820	PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents	codes and data are not available but comparison were made to publicly available datasets.								The authors will provide the necessary code in a repository and the dataset will be made public. Thus, the approach should be fully reproducible.								More information and details about the experimental setup need to be provided for better reproducibility. Specifically, the paper has provided fewer experimental details for downstream tasks, such as VQA. In the supplementary material, the answer prompt and question prompt are not yet clear, further hindering the ability to replicate the experiment.											0	0	0	0	0	0	
503-Paper0700	Point Cloud Diffusion Models for Automatic Implant Generation	The authors provide the reviewers with an anonymous link with the implementation and rely on public data for training.								Very Good.								yes											0	0	0	0	0	0	
504-Paper1260	Polar Eyeball Shape Net for 3D Posterior Ocular Shape Representation	While the authors explain the overall system, the steps taken and most important aspects, the reproducibility of their work can be called 'fair' at best. Without making the data set and the code public, a lot of implementation details have to be reinvented by anyone who wants to reproduce the results.								* While there is a lack of some technical details, the supplementary materials provide additional information to help improve the reproducibility.								Reproducible.											0	0	0	0	0	0	
505-Paper0407	Polar-Net: A Clinical-Friendly Model for Alzheimer's Disease Detection in OCTA Images	Some components of paper are available, like the FAZ detection model, while others not, like the dataset. If the paper is accepted I am sure the method could act as a reference, and be replicated by the community.								The authors promise to release the codes.								Upon release of the code, the reproducibility can be verified.											0	0	0	0	0	0	
506-Paper2628	Position-aware masked autoencoder for histopathology WSI representation learning	One of the datasets is public and the authors promised source will be released								The authors claimed will release the codes after acceptance, which might contribute to the reproducibility.  Yet, the hyper-parameters are not given.								Satisfactory: The author described their method details clearly, and the dataset is publicly available. However, the author did not claim whether they will make their code publicly available.											0	0	0	0	0	0	
507-Paper0739	Positive Definite Wasserstein Graph Kernel for Brain Disease Diagnosis	I think it is reproducible.								As I said, the equations are not well explained sometimes, which makes it difficult to follow the paper. That means that some details will be difficult to replicate. No code is provided.								The algorithm 1 is sketchy, too high level, many algorithmic details should be explained more thoroughly. It will be difficult for a graduate student to reproduce the result.											0	0	0	0	0	0	
508-Paper2156	POV-Surgery: A Dataset for Egocentric Hand and Tool Pose Estimation During Surgical Activities	All good								The authors mentioned that the code and dataset will be publicly available.								Availability of source code:   The authors mention in the abstract that the code and the dataset will be publicly available. Therefore, before this paper gets accepted, the authors should provide links to the source code and the dataset. If this information is provided, the authors have done a great job to ensure reproducibility.    Implementation details:   As already mentioned under the main weaknesses of this paper, some relevant implementation details are missing in the text, such as the used OS incl. version, used programming languages incl. version, hardware (GPU, RAM etc.).   Only a few details are mentioned, for example that blender is used incl. bpycv packages, but the blender version is missing. The use of bpycv suggests that python was used as the main programming language, but this should be mentioned in the paper.    Hardware setup:   As already mentioned under the main weaknesses of this paper, the fact that body motion capturing is required for the proposed pipeline could decrease reproducibility because this requires additional hardware (four stereo cameras). However, this might just be a minor point.											0	0	0	0	0	0	
509-Paper2392	Predicting Diverse Functional Connectivity from Structural Connectivity Based on Multi-Contexts Discriminator GAN	The reproducibility of the paper allows other researchers to replicate the experiments and verify the results.								Not very convincing. How GAN collapse?								OK for reproducibility											0	0	0	0	0	0	
510-Paper0987	Prediction of Cognitive Scores by Joint Use of Movie-watching fMRI Connectivity and Eye Tracking via Attention-CensNet	According to the reproducibility checklist, the reproducibility of the paper is acceptable.								Good reproducibility. Public data were used and codes will be released.								Authors provided details of data processing and how the models were trained. I would assume, one could repeat the experiments by following the steps explained in the paper.											0	0	0	0	0	0	
511-Paper2495	Prediction of Infant Cognitive Development with Cortical Surface-based Multimodal Learning	I believe that the obtained results can, in principle, be reproduced.								I think the proposed method can be reproduced.								There is no code released.											0	0	0	0	0	0	
512-Paper3691	Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping	It is hard to duplicate their model and its performance based on their description. In addition, it will provide limited source code to reproduce their paper.								Reproducibility is uncertain.								Code and internal datasets used for training are not available.											0	0	0	0	0	0	
513-Paper0246	Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement	The datasets used in this papar are public and the author plan to open-source their implementation after review.								The results of this paper may be reproducible.								Highli reproducible											0	0	0	0	0	0	
514-Paper2788	Prior-driven Dynamic Brain Networks for Multi-Modal Emotion Recognition	I think it can be easily reproduced.								there need a bit more detailed information for reproducibility of the paper.								In Fig. 1, what is the 'spatial and temporal' features extracted by STFENet? It is unclear to readers.  In the 2nd paragraph of Results, the authors said 'there comes a significant performance degradation'. This statement without a statistical test is not rigorous. The authors should apply statistics on the performance metrics in order to demonstrate statistically the superiority of the proposed framework. Table 1 and 2.											0	0	0	0	0	0	
515-Paper0926	Privacy-preserving Early Detection of Epileptic Seizures in Videos	The paper has provided most of the details.								The paper provides details on the models used and the corresponding hyperparameter choices. Details on data sharing and data splits might be missing. The OF dataset can be released and the code.								it would be better if there is code availability											0	0	0	0	0	0	
516-Paper3018	Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation	The authors claimed "The source code will be available upon acceptance of the paper" in the absratct.								n/o								Reproduction is possible but providing code becomes easier.											0	0	0	0	0	0	
517-Paper1653	Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening	The paper does not provide enough information about the data used in the study. This lack of information makes it difficult to obtain and use the same data for their own studies.  Some experimental details in the paper are not clear enough.								Reproducible with some efferts, the code was not published.								The model in this paper is mainly divided into three parts,    The pre-training model part is clearly described and can be reproduced  The skip self-attention (SSA) part only uses high-level and low-level information in the construction of Q, K, and V. The attention part is the classic soft attention, which can be reproduced  Contrastive Learning is an important means to improve performance, but the specific implementation is not very clear, and there may be recurrence problems.    In general, the difficulty of reproducibility is mainly in the Contrastive Learning part, it is recommended to add. At the same time, it is also recommended to open source the model parameters of the pre-training part to enhance reproducibility.											0	0	0	0	0	0	
518-Paper1058	Progressively Coupling Network for Brain MRI Registration in Few-shot Situation	The authors use publicly available datasets for their experiments and promise to release training and test code. Reproducibility should therefore be given.								The data sets are publicly available. The results should be reproducable if the code is made public and if some paramaters, such as the weights of the different loss components, are added.								Lacking sufficient implementation/code details. The authors could make their source code publicly available if this paper is accepted.											0	0	0	0	0	0	
519-Paper2123	Prompt-based Grouping Transformer for Nucleus Detection and Classification	If the code is available online and all of the hyperparameters tuning explain, it will be easy to use it.								In terms of data, we used public datasets for our study, so it's highly reproducible. 2. It would be even better if the code was publicly available.								Authors have filled out a reproducibility checklist without any glaring issues.											0	0	0	0	0	0	
520-Paper2450	Prompt-MIL: Boosting Multi-Instance Learning Schemes via Task-specific Prompt Tuning	The results is reproducible. The experiments were conducted on three public datasets. Additionally, the authors will publish the source code.								Codes are not available but datasets used in this study are publicly available.								Author has convey, clear, specific and complete information about data, code, models and computational methods and analysis that support the contents and result presented in the paper											0	0	0	0	0	0	
521-Paper2734	PROnet: Point Refinement using Shape-guided Offset Map for Nuclei Instance Segmentation	If the code will be provided after accept, it is O.K.								the code is not available  the method used to set the hyperparameter values is not specified. In particular for the hyperparameters: 20 epochs before using the offset map loss, learning rate, Gaussian kernel size r, weight decay, threshold, weights of the three loss functions  the method to obtain the shifted center point annotations is not described								The authors have indicated that they will release both the training code and evaluation code, which is a positive step towards ensuring reproducibility of the results presented in the paper.											0	0	0	0	0	0	
522-Paper2474	ProtoASNet: Dynamic Prototypes for Inherently Interpretable and Uncertainty-Aware Aortic Stenosis Classification in Echocardiography	The reproducibility sheet well matches the submission. The authors agreed to publish their code on acceptance. Additionally, one of the used datasets has been public. Furthermore, the authors added descriptive supplementary material. Therefore, reproducibility of the results is most likely given.								The authors have used one public dataset and they will make their code public by sharing their github repo. So I believe their work is reproducible.								The authors employ a private dataset of 2572 studies. However, limited description is given regarding image acquisition (equipment used, frame rate or other imaging characteristics relevant in the context of the video classifier proposed), methods employed for quality control (Doppler-based assignment performed by a single observer or multiple, whether consensus was required), etc.  Similarly, several methodological/experimental details are lacking, hampering the adequate comprehension or reproduction of the authors' methods/results (note that most details can probably be understood once the code is made public, but the document should be as much self-explainable as possible). See specific comments below.											0	0	0	0	0	0	
523-Paper0935	Punctate White Matter Lesion Segmentation in Preterm Infants Powered by Counterfactually Generative Learning	Aside from some minor details about hyperparameterization, the code should be easily reproducible. However, having access to the code would be very beneficial to accelerate future work. The biggest barrier in this work is likely the implementation using TensorFlow, as the library is much less widespread among the community.								No concern								Reproducible    Training and Evaluation codes available  Model description included											0	0	0	0	0	0	
524-Paper0839	QCResUNet: Joint Subject-level and Voxel-level Prediction of Segmentation Quality	The method is well described and all information that can be expected for a conference paper are provided.								Authors provide details of the training regimes, architectures, and hyperparameters used in their work. Datasets have been described.								A public dataset (BraTS 2021) was used for the validation.  The code and pre-trained model will be made available publicly.											0	0	0	0	0	0	
525-Paper1244	Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes	Fair								Dataset is not available, Code will be available if paper is accepted.								Code will be available upon acceptance.											0	0	0	0	0	0	
526-Paper1582	Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology Reporting	Reproducible								The method proposed in this article is relatively clear and has good reproducibility. The main challenge is that the way of constructing the dataset has relatively poor transferability and relies heavily on medical issues in small-scale medical scenarios.								I think this paper can be reproduced if algorithm be made public available. It will be better to give more details to the algorithm description.											0	0	0	0	0	0	
527-Paper0772	RBGNet: Reliable Boundary-Guided Segmentation of Choroidal Neovascularization	The reproducibility of the paper is somewhat limited due to the lack of an open-source implementation of RBGNet. While the paper provides detailed descriptions of the proposed method and experimental setup, it would be beneficial for other researchers to have access to the code in order to reproduce the results and build upon the work.   However, the paper does provide a detailed description of the dataset used for evaluation, including information on how it was collected and annotated. This information could be used by other researchers to obtain similar data for their own experiments.  Overall, without the open-source implementation and dataset, The reproducibility of the paper is limited.								The method is well described with references to previous work used to create the proposed architecture. There seems to be a few small details missing including bottleneck layer size and number of samples performed with dropout.								The article does not provide enough information on some key aspects of the proposed technique, such as the data preprocessing, the hyperparameters, and the evaluation metrics. It would be helpful if the authors could elaborate on these points in the paper or in the supplementary material. The code alone may not be sufficient to reproduce or apply the technique in different settings.											0	0	0	0	0	0	
528-Paper2443	RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection	Code is not provided								The authors did not mention code release or potential links for access in the paper nor in the supplementary. If the paper is accepted, the authors can consider add code links.								Authors mentioned that the code will be made available upon acceptance.											0	0	0	0	0	0	
529-Paper2431	Realistic endoscopic illumination modeling for NeRF-based data generation	The definitions of t_i and i are ambiguous in Sec 2.1.								The paper is well written, and all necessary detail is provided to reproduce the results and the evaluation.								The paper describes the training details of the methods, but miss the description of the data source of the depth information used for supervision. It claims the the data and code would be released.											0	0	0	0	0	0	
530-Paper1508	Reconstructing the Hemodynamic Response Function via a Bimodal Transformer	good								Although the author did not provide open-source code, the paper is well-written and contains clear descriptions of the methodology used. Therefore, I believe that this study is reproducible with the information provided in the article.								No code is available during review.											0	0	0	0	0	0	
531-Paper1978	Recruiting the best teacher modality: A customized knowledge distillation method for IF based nephropathy diagnosis	The authors have promised to release the source codes and data after the reviewing process, so I think this work should be reproducible.								The authors provided a clear description of the proposed method and used a publicly available dataset. The authors will release data after the reviewing process.								The authors describe their experimental setup, and even though the code is not disclosed, I think their lab is reproducible											0	0	0	0	0	0	
532-Paper0567	Rectifying Noisy Labels with Sequential Prior: Multi-Scale Temporal Feature Affinity Learning for Robust Video Segmentation	the reproducibility is good given that code is provided								It's not difficult to reproduce.								The authors agreed to make the code repository public.											0	0	0	0	0	0	
533-Paper3264	Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras	After carefully examining the reproducibility checklist submitted by the authors and considering the requirements for reproducibility, I must state that reproducing the results of this paper may be difficult.  While the authors have provided a detailed methodology and experimental setup, they have not included code or data to support the results. Without access to the data and code, it may be challenging to reproduce the experiments described in the paper. Additionally, some of the experiments rely on proprietary software or tools that may not be easily accessible to others.  Furthermore, the paper lacks a clear description of the hardware and software used in the experiments, which could affect the ability to reproduce the results. Additionally, there is no mention of the version control system used to manage the code and data, which could make it difficult to track changes and reproduce specific versions of the experiments.  In summary, while the authors have made efforts to ensure the reproducibility of their results, the lack of code and data, as well as some missing details about the experimental setup, may make reproducing the experiments challenging.								The work is easy to reproduce since the manuscript describes the experimental setup in detail and provides the specific information about each hardware component. About the algorithm, although some equations and notations are not clear, they are still understandable and can be reproduced with the assist of the data and code that will be provided by the authors.																			0	0	0	0	0	0	
534-Paper0923	Regressing Simulation to Real: Unsupervised Domain Adaptation for Automated Quality Assessment in Transoesophageal Echocardiography	The authors state that they will provide code upon publication, ensuring reproducibility								Reproducibility checklist is thorough								The authors would provide the dataset and the code.											0	0	0	0	0	0	
535-Paper2119	Regular SE(3) Group Convolutions for Volumetric Medical Image Analysis	yes								In general, neural network articles contain too few details to be reproduced due to the complexities of the models. I do, however, believe I will be able to get a knowledgeable master student to re-implement and reproduce similar results based on the article's description.								The code will be shared upon acceptance. The dataset is public.											0	0	0	0	0	0	
536-Paper1699	Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast	Good								The reproducibility is moderate. source code and data set are not provided. However, the method and experiment set up are described very clear, therefore the reproduction of the algorithm and the experiment are possible.								The reproducibility depends on whether the code and dataset are to be open sourced.											0	0	0	0	0	0	
537-Paper1155	Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture	The code will be shared if accepted.								They promise to make data and code available.								It would be good to disclose the version of the OSQP solver and what language interface was used. All the software and tools involved for the diffusion data processing should be clearly described.											0	0	0	0	0	0	
538-Paper0238	Reliable Multimodality Eye Disease Screening via Mixture of Student's t Distributions	The reproducibility of the paper is high because the authors will release the code after acceptance and one dataset is public.								The paper provides some details on the implementation and training of EyeMoSt but does not share the code or data publicly. The paper should make the code and data available online to facilitate reproducibility and verification of the results. The paper should also provide more details on the hyperparameters used for training EyeMoSt such as learning rate, batch size, and regularization.								Although the authors did not provide sufficient implementation details of this work, they promised to release the codes. I therefore consider this work to be reproducible.											0	0	0	0	0	0	
539-Paper1862	Representation, Alignment, Fusion: A Generic Transformer-based Framework for Multi-modal Glaucoma Recognition	The paper provides sufficient details regarding the methods, dataset, and experimental setup, which contributes positively to the reproducibility of the study. However, it is not clear if the authors have made the code publicly available, which could limit the ease of reproducing the results. In addition, the authors mention using standard pre-trained models and frameworks like PyTorch and timm, which should facilitate replication if the code is shared. The specific dataset splits is provided in supplementary material. Nevertheless, based on the provided information, the study can be considered moderately reproducible.								The reproducibility is promising, the details of the network, the loss function, the dataset is well explained.								Easy to reproduce											0	0	0	0	0	0	
540-Paper2936	RESToring Clarity: Unpaired Retina Image Enhancement using Scattering Transform	Reasonable.								It could be reproduced if the source code is provided.								Upon release of the code, the reproducibility can be verified.											0	0	0	0	0	0	
541-Paper1654	Rethinking Semi-Supervised Federated Learning: How to co-train fully-labeled and fully-unlabeled client imaging data	Very good. The authors provided code and promised to make publicly available upon acceptence.								Code is provided.								This paper should be reproducible as the authors will release the code.											0	0	0	0	0	0	
542-Paper1016	Retinal Age Estimation with Temporal Fundus Images Enhanced Progressive Label Distribution Learning	Reproducibility of the results reported in this paper is moderate. The author didn't provide source code yet and dataset will not be available. The framework contains three main parts and the detail definition in section 2.3 just gives a reference, which decreases the reproducibility.								The paper provides sufficient details on the methodology and experimental setup to allow for reproducibility.								The authors should release the code to ensure the reproducibility of the paper											0	0	0	0	0	0	
543-Paper0184	Retinal Thickness Prediction from Multi-modal Fundus Photography	The paper includes sufficient implementation details.								Method is well described. Dataset and source code is not available.								It's not easy to reproduce this paper, because many details are missed.											0	0	0	0	0	0	
544-Paper2359	Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models	The study uses publicly available datasets, and code to reproduce the experiments was provided to the reviewers. The authors have indicated that the code will be made publicly available.								The authors provide the source code as supplemental material. The README accompanying the code is well organized and allows any reader to reproduce the experiments described in the paper.								public data sets are used, which is good. It may still be difficult to fully reproduce the paper.											0	0	0	0	0	0	
545-Paper0469	Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction	OK								There is no mention of making the source code available. Althought the dataset is public, the specific patients used are not.								Network training, especially GAN part, can be challgenging for reproduciblity											0	0	0	0	0	0	
546-Paper1360	Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection	The authors do not provide their code as well as any link to repositories of the SOTA models of their comparative analysis. No information provided on the hyperparameter setting. Reproducibility is thus limited.								Despite no information on the availability of code and data, it provides sufficient details to facilitate the replication of the experiments and the evaluation of the proposed method.								Models were developed on public datasets to ensure reproducibility.											0	0	0	0	0	0	
547-Paper0548	Revisiting Distillation for Continual Learning on Visual Question Localized-Answering in Robotic Surgery	Good. The author provided the code in the supplemental material. I would like to know if the results of the other methods in the comparison experiment are reproducible?								The work could be reproduce with the open source of authors' self-annotate data.								The proposed framework involves multiple techniques and components, which may make it more difficult to implement and integrate into existing surgical education systems.											0	0	0	0	0	0	
548-Paper2275	Revisiting Feature Propagation and Aggregation in Polyp Segmentation	Authors have not referred to the code in the paper but will presumably release the code post-acceptance.								The benchmark datasets used in the paper are publicly available, however, there is no mention in the paper about the availability of the code for reproducibility.								The authors provide detailed information on their methodology, train/test procedure, and used datasets, resulting in a reproducible work.											0	0	0	0	0	0	
549-Paper1540	Revolutionizing Space Health (Swin-FSR): Advancing Super-Resolution of Fundus Images for SANS Visual Assessment Technology	The code is to be publicly released.								All aspects of reproducibility have been addressed.								Most of details of the method have been clarified clearly and the code will be publicly released, which brings the fine reproducibility of the paper.											0	0	0	0	0	0	
550-Paper1670	Right for the Wrong Reason: Can Interpretable ML Techniques Detect Spurious Correlations?	Pretty good								Reproducibility is guaranteed.								The code will be made available.											0	0	0	0	0	0	
551-Paper3152	Robust and Generalisable Segmentation of Subtle Epilepsy-causing Lesions: a Graph Convolutional Approach	The code will be available but the the segmentation annotation is going to be hard to obtain even if the researcher try to reproduce based on their own data.								Sufficient details are given but I didn't find links to code or data								No code link was provided in the manuscript. The authors indicated that they will share the code to public after the paper is accepted.											0	0	0	0	0	0	
552-Paper2082	Robust Cervical Abnormal Cell Detection via Distillation from Local-scale Consistency Refinement	Code is not available now.								Given the current status, it is impossible to reproduce the result. Many details are not given. For example, what value is chosen for K, H, and W. Are the H and W the same for both ROI and the cell patches in the Eq. (7).   In addition, there is no description to how the SOTA methods are trained. Are they also heavily tuned on this dataset. Or the hyper-parameters are kept the same as the original papers where a different dataset was used.								relatively good given the technique details were provided											0	0	0	0	0	0	
553-Paper1184	Robust estimation of the microstructure of the early developing brain using deep learning	Authors stated code will be released upon acceptance.								The responses to the reproducibility checklist appear correct.								The paper is easy to reproduce - most important details are provided.											0	0	0	0	0	0	
554-Paper0461	Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus	In its current state, there are gaps that need to be addressed, but no code or appropriate data accompanies this paper to test for reproducibility.								I think implementing the GCIE would be straight-forward. Reproducing, though, the specific results presented would be very difficult due to lack of details of the classifier and data set.								The reproducibility is fine.											0	0	0	0	0	0	
555-Paper0358	Robust Hough and Spatial-To-Angular Transform Based Rotation Estimation for Orthopedic X-Ray Images	The author should add more comparison methods.								Not reproducible since training dataset is not publicly available								It is clear that they provided experimental settings for training the models, such as computational resources, hyper parameters for training the models, details of augmentation, etc.											0	0	0	0	0	0	
556-Paper0354	Robust Segmentation via Topology Violation Detection and Feature Synthesis	meet the requirement								The main idea of calculating Euler Characteristic in CNN is simple and seems easy to re-implement.								The code will be public. The experiment performed on two public datasets.											0	0	0	0	0	0	
557-Paper2813	Robust T-Loss for Medical Image Segmentation	The authors used two public datasets, provided most of the implementation details needed to reproduce the results. They provide a toy example for the loss function but it not clear if they plan to release the code.								The authors provided the loss function implementation along with a toy example, which makes it highly reproducible.								The authors have done a good job providing details about the train-test splits including the stratification for Shenzhen, the training hyperparameters (learning rate, batch size, optimizer), the hardware used (GPU), the repeated experiments (3 random seeds), and the statistical testing. The code implementation of the loss is also helpful.											0	0	0	0	0	0	
558-Paper2279	Robust vertebra identification using simultaneous node and edge predicting Graph Neural Networks	The reproducibility of the method seems to be easily done, the authors provide enough details to do so.								The methods within appear highly reproducible, especially for the work of the VerSe dataset; however, much of the overall reproducibility of the study will depend on the release of the author's dataset.								It is possible to reproduce the proposed approach if the data is available. Datatset + annotations will be published. Some detail remain unclear: The initial pedicle keypoint annotation process via postprocessing of segmentation mask is not clear. How are the spinal segment pseudo probabilities for the node feature generated? Does the heatmap network distinguish 3 different keypoint classes (body, left, right pedicle)? how many images does the hard subset contain? Related work summary could be improved, currently only listed.											0	0	0	0	0	0	
559-Paper0318	S2ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-supervised Polyp Segmentation	The paper is detailed enough to reproduced the method and experiments. Authors have also included a link to their code repo (the reviewer has not checked the code).								I have checked that the anonymous source code can be viewed.								The reviewer released the code to help reproduce the results.											0	0	0	0	0	0	
560-Paper2838	S3M: Scalable Statistical Shape Modeling through Unsupervised Correspondences	The entire code will be open-source.								* This work is reproducible.								While the utilized (public) datasets are described in depth, the algorithmic details get not explained in-depth, thus reducing the level of reproducibility											0	0	0	0	0	0	
561-Paper0472	SAMConvex: Fast Discrete Optimization for CT Registration using Self-supervised Anatomical Embedding and Correlation Pyramid	The reproducibility of the paper is satisfactory. The paper includes complete description on datasets and implementation details.								Lacking sufficient implementation/code details. The authors could make their source code publicly available if this paper is accepted.								The authors agreed to share their code.											0	0	0	0	0	0	
562-Paper0344	SATTA: Semantic-Aware Test-Time Adaptation for Cross-Domain Medical Image Segmentation	Good. Code is provided.								I think the obtained results can be reproduced.								Code has been attached in the supplementary.											0	0	0	0	0	0	
563-Paper1263	Scale Federated Learning for Label Set Mismatch in Medical Image Classification	The reproducibility of the paper looks okay.								The authors claim the code will be made available upon acceptance.																			0	0	0	0	0	0	
564-Paper2366	Scale-aware Test-time Click Adaptation for Pulmonary Nodule and Mass Segmentation	Due to the expensive experiments, there may not be much reproducibility. However, if only the adaptation of the "click" part is considered, it could be possible. However, it would still be difficult because a lot of data, including private data, has been used. Additionally, the proposed method is complex, involving multiple components, such as a multi-scale neural network and test-time click adaptation, which could make it difficult for other researchers to replicate or build upon the work.  Also, since the model code is not publicly available, this will significantly affect the reproducibility or reusability of the methods. It will be challenging to produce all those identical inferences since they tested the model with many different subsets of the same data.  On the other hand, since one of the data used is publicly available. That can affect reproducibility in a good way. Also, since altering the architecture of the network is not required to implement this method, the model can be developed and adapted to other imaging tasks too. Similar techniques can be developed to be used in different fields.  Lastly, the proposed method contains multiple complicated components, including a multi-scale neural network and test-time click adaptation, which could make it difficult for other researchers to replicate or build upon the work.								The code and pre-trained model will be made available.								The authors state that they will release the code upon acceptance and two out of three datasets are open source so reproducibility should be ok, although some minor details are missing.											0	0	0	0	0	0	
565-Paper2551	Scaling Up 3D Kernels with Bayesian Frequency Re-Parameterization for Medical Image Segmentation	The paper should be very reproducible: the method has been tested on public datasets, and the code will be released upon acceptance.								-The paper gives enough details which can help its reproducibility. This includes, for instance, information about the dataset splits provided in the supplementary material.    Furthermore, the proposed architecture is visually represented by blocks (Fig. 2) or mathematically (Eq. 4), which aid the understanding and implementation of the proposed model. Furthermore, the authors intend to release its source code.  Additional information is further provided regarding the training procedures of the model, i.e. optimisers.  Finally, the impact on the segmentation results by tuning the model parameters are described. This information can be used for validating how far/close an own implementation is from to the reported results.								Nil											0	0	0	0	0	0	
566-Paper1923	SCOL: Supervised Contrastive Ordinal Loss for Abdominal Aortic Calcification Scoring on Vertebral Fracture Assessment Scans	Given the fact that the paper mostly applies existing methods, it won't be too difficult to reproduce the work.								No issues besides the lack of a testing set and details on hyperparamter tuning.								Hyper-parameters, computational equipments, and codes are (will be) available for the reproducibility of this study. Also, the methods are clearly explained and easy to follow.											0	0	0	0	0	0	
567-Paper2625	Scribble-based 3D Multiple Abdominal Organ Segmentation via Triple-branch Multi-dilated Network with Pixel- and Class-wise Consistency	Reproducibility description is reasonable and the results on a publicly available dataset make the work accessible.								Code will be released.								The work can be reproduced, the results can be generated for analysis by the experts.											0	0	0	0	0	0	
568-Paper0185	Second-course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information	The overall framework could be reproduced, yet lacks some training information, e.g., patch size.								The paper is reproducible based on the parameter settings provided in the paper.								The authors have presented a clear and detailed description of their proposed model architecture. However, the primary dataset used in this study, which includes 1 and 2 courses of esophageal cancer RT plan CTs, is not commonly used for segmentation purposes. Furthermore, the authors have not disclosed the primary dataset or training codes, which could limit the reproducibility of their study. It would be beneficial for the authors to provide additional information regarding their dataset and training process to enable others to reproduce their results accurately.											0	0	0	0	0	0	
569-Paper0392	SEDSkill: Surgical Events Driven Method for Skill Assessment from Thoracoscopic Surgical Videos	The code will be available but the dataset is not sure.								The source code is not provided. Also, it is not clear whether the dataset will be public or not.								The author claims to release the codes upon the paper acceptance. The dataset involved in the paper is collected by the authors instead of public. Since the proposed method is specifically designed for the MVR application, it would be valuable to make the dataset available upon request to facilitate future research in this application. On the other hand, more descriptions about the dataset as well as the experiment setup can be attached in the supplementary material.											0	0	0	0	0	0	
570-Paper0954	Segment Membranes and Nuclei from Histopathological Images via Nuclei Point-level Supervision	"For existing datasets, citations as well as descriptions if they are not publicly available." Selected as "Yes". But, I think it should be "N/A", since no existing dataset is used.  "For all code related to this work ...", there is not enough information for me to verify								Since the methods are depicted clearly, it is not hard to follow this work.								Nothing.											0	0	0	0	0	0	
571-Paper2453	Segmentation Distortion: Quantifying Segmentation Uncertainty under Domain Shift via the Effects of Anomalous Activations	I believe the findings are reproducible. The code will be made publicly available and the data already is. The authors also include download links.								The authors stated that they report on the sensitivity regarding hyperparameters. However, this was not reparted w.r.t. the major design choices (see "Weaknesses").								The work should be reproducible as the authors will make the code available.											0	0	0	0	0	0	
572-Paper2085	Segmentation of Kidney Tumors on Non-Contrast CT Images using Protuberance Detection Network	With the details provided by the author, it is possible to reproduce the results with the dataset of KiTS.								The authors make use of publicly available data for their experiments which greatly helps the reproducibility of their work, but as far as I can tell, their code has not been made publicly available. It would be helpful if the authors released this as well as the synthetic dataset that they generated.								The proposed method could be easily re-implemented based on provided architecture and training information  The code is not provided  Data comes from the publicly-available KITS dataset											0	0	0	0	0	0	
573-Paper0544	SegmentOR: Obtaining Efficient Operating Room Semantics Through Temporal Propagation	The authors commit to release the dataset and relevant code. Reproducibility should be straightforward.								Could be reproduced upon released codes and data.								Reproducibility is good given that the code and dataset will be released.											0	0	0	0	0	0	
574-Paper0584	SegNetr: Rethinking the local-global interactions and skip connections in U-shaped networks	This paper does not provide sufficient information to evaluate its reproducibility. The source code is not available, and the method section lacks the corresponding equations.								Implementation details are clear and sufficient.								There seems no problem about the reproducibility of the paper, but the authors are strongly suggested to open their codes during the rebuttal session.											0	0	0	0	0	0	
575-Paper0399	Self- and Semi-Supervised Learning for Gastroscopic Lesion Detection	The authors mention the release a new large dataset with partial annotations verified by experts. However, they do not clarify how and when the dataset will be made available, neither do they clarify whether the code for the proposed framework will be published along with the paper.  Implementation details and training parameters are available in the supplementary material.								it can be reproducible as the work is clear.								The reproducibility looks good. The authors will release the dataset and the code. Essential experimental settings are included.											0	0	0	0	0	0	
576-Paper3009	Self-adaptive Adversarial Training for Robust Medical Segmentation	The paper provides some details on the experimental setup and methodology, which could help with reproducibility.								The paper provides sufficient implementation details.								Unsatifactory. They claim that they reported 'The range of hyper-parameters considered, method to select the best hyper-parameter', 'the mean & variation of results', 'the average running time' and 'the memory footprint'. However, I cannot find these information at all.  By the way, the authors claim that they will release the training code, evaluation code and model weights after acceptance.											0	0	0	0	0	0	
577-Paper0503	Self-aware and Cross-sample Prototypical Learning for Semi-supervised Medical Image Segmentation	The mathematical formulation of the proposed method is clear, and thus could be reproduced.								un-known								The manuscript provides some information that could facilitate the reproducibility of the method, including the use of the UNet backbone, the connection of CPCC and SPCC to their respective equations, and the presentation of hyperparameters. However, the lack of access to the source code limits the extent to which the method can be reproduced, which raises concerns about the robustness and reliability of the reported results.											0	0	0	0	0	0	
578-Paper3102	Self-distillation for surgical action recognition	All good								The authors confirmed in the form that they will make the code public available.								Details of the network architecture, dataset used and choise of training parameters are provided in the paper. However, details about the hardware required to train the proposed model is missing.											0	0	0	0	0	0	
579-Paper1544	Self-feedback Transformer: A Multi-label Diagnostic Model for Real-world Pancreatic Neuroendocrine Neoplasms Data	positive if code are released								More detailed description of details like GPU memory requirements, computational time should be included. Open-sourcing the code is highly encouraged.								The reproducibility of the study would be low due to the lack of available source codes and datasets.											0	0	0	0	0	0	
580-Paper1619	Self-pruning Graph Neural Network for Predicting Inflammatory Disease Activity in Multiple Sclerosis from Brain MR Images	Methods are reasonably well-described. There is no statement of whether the code or data will be available.								According to the reproducibility Response, the data for this paper are not publicly available and would therefore present reproducing the results.																			0	0	0	0	0	0	
581-Paper1357	Self-supervised dense representation learning for live-cell microscopy with time arrow prediction	It seems that the authors intend to release the code								Good								It is indicated in the abstract that the code will be made openly accessible. But the code is not submitted along with the manuscript.											0	0	0	0	0	0	
582-Paper2757	Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning	Code is not yet available but the authors state, in the reproducibility checklist, that it will be made available.								The reproducibility of this paper is fine with me.								All relevant checklist is clicked. But Hyper-parameters and the training process should be reported at least in appendix.											0	0	0	0	0	0	
583-Paper2074	Self-Supervised Learning for Endoscopic Video Analysis	The algorithm is borrowed but it can not be reproduced because the private datasets are not available.								No code is provided and the reliance of all the important results on a proprietary dataset limits the potential for results replication.								As mentioned earlier, there is no implementation of the code provided or at least mentioned that the authors would do it in the future.											0	0	0	0	0	0	
584-Paper1517	Self-Supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET	The authors provided sufficient information about the network architecture, training setup etc.								Reasonable.								It is OK.											0	0	0	0	0	0	
585-Paper2363	Self-supervised learning via inter-modal reconstruction and feature projection networks for label-efficient 3D-to-2D segmentation	I think that the reproducibility of this paper is relatively easy, because it is mainly based on existed framework or idea, and the code will also be provided.								The author state to release the code on GitHub. The carbon footprint and the training time are also reported in the supplementary article								The details of the method have been clarified clearly and the code implementation will be available on GitHub, which brings the fine reproducibility of the paper.											0	0	0	0	0	0	
586-Paper3131	Self-Supervised MRI Reconstruction with Unrolled Diffusion Models	This paper explained in detail about the implementation/datasets in the method; however, the open code that can reproduce the results are not provided yet.								The results of the paper are reproducible.								Although all items in reproducibility checklist are checked, how to reproduce the results are unclear.    How is the data undersampled? (which undersampling pattern)  How to reproduce the training? Batch-size, learning-rates, scheduler, epochs, the hyper-parameters used in the network (alpha and beta, heads of Transformers, hidden layer dimension, etc..) etc. are not given.											0	0	0	0	0	0	
587-Paper2144	Self-Supervised Polyp Re-Identification in Colonoscopy	This work has insufficient repeatability. They do not use any public datasets, and do not intend to share their codes. Furthermore, the description of the methodology part lacks detailed settings. Moreover, the presented mathematical notations are out of the standard. One can implement the proposed method for its re-experiment.								The paper provides basic information for the method re-implementation; however, due to the absence of code and the use of a custom dataset, its reproducibility is significantly limited.								Nothing major to comment.    Authors provide enough details about the training procedure which follows standard practice and provides references on certain decisions.  I assume the dataset will not be publicly released. However, the annotated test set would be a great contribution to the community.											0	0	0	0	0	0	
588-Paper3443	Self-supervised Sim-to-Real Kinematics Reconstruction for Video-based Assessment of Intraoperative Suturing Skills	To improve reproducibility, additional elaboration is required in the training and testing processes.								The dataset is not accessible, but they promise to release the code and pre-trained model.								The authors claim to release the code upon the paper acceptance. Besides, the data collection process and experiment details are explicitly described. To facilitate reproducing the work, it would be valuable to make the VR data and part of real data available (link or email request).											0	0	0	0	0	0	
589-Paper0452	Semantic difference guidance for the uncertain boundary segmentation of CT left atrial appendage	anonymized sources to reproduce & details on the choice of hyperparameters in the supplementary material.								Code is given which make the experiments easy to reproduce								The dataset introduced by the paper is not available to the research community to accelerate the research direction further. The code is available which can be implemented for other datasets.											0	0	0	0	0	0	
590-Paper3070	Semantic segmentation of surgical hyperspectral images under geometric domain shifts	The code will be released but the data is not public (as far as I understand) so the reproducibility is weak.								The authors provide a very clear description for reproducing the paper. They will include information about running experiments and tuning hyperparameters in their code base that will be publicly released.								Relevant information for reproducibility is included.											0	0	0	0	0	0	
591-Paper2069	Semantic Virtual Shadows (SVS) for Improved Perception in 4D OCT Guided Surgery	From the technical aspect, this paper is highly reproducible. However, the results of this paper are mainly user experiments, which are subjective and difficult to be reproduced.								Overall, the authors list several details that facilitate a potential reproduction of the proposed concept. On a positive note, it is worth mentioning that the provided mathematical equations are well-described and increase reproducibility of important algorithmic components. However, there are a couple of this that could be improved in order to increase reproducibility:  1.) Availability of source code:   While there is no need to provide source code, it would have greatly increased reproducibility. In addition, as already mentioned under the main weaknesses of this paper, providing more details regarding hyper-parameters (and maybe training checkpoints) would have increased reproducibility.  2.) Implementation details:   The used graphics card is mentioned, as well as software library details such as Pytorch, TensorRT and OpenGL incl. their respective versions. However, The C++ version is missing and the used OS incl. version.  3.) Level of descriptive detail in the Methodology section:   Some parts of the proposed methods are not described accurately enough to ensure reproducibility. Example: Page 6, text lines 4 and 5: "...while preserving surface highlights similar to [12].": The word "similar" in this sentence leaves a lot of room for interpretation and reduces reproducbility. This should be described in more detail.								The authors have provided comprehensive data to allow this work to be preproduced.											0	0	0	0	0	0	
592-Paper1965	Semi-supervised Class Imbalanced Deep Learning for Cardiac MRI Segmentation	There are some missing details that make reproducing the results difficult. Especially, I didn't quite understand the pseudo-label refinement step. Also, the authors didn't promise to publish their code upon acceptance. I strongly suggest sharing the code since implementing the method from the description in the paper is a bit difficult.								Good. Datasets are publicly available, and methods are described with acceptable detail.								It might be hard to reproduce as the code would not be available.											0	0	0	0	0	0	
593-Paper1041	Semi-supervised Domain Adaptive Medical Image Segmentation through Consistency Regularized Disentangled Contrastive Learning	Good reproducibility. Public dataset for development and evaluation. Code is available upon acceptance.								Although the authors mention that the code will be released, they did not specify in the reproducibility checklist. I suggest the authors to release code for public benefits if accepted.								Reproducible according to paper description.											0	0	0	0	0	0	
594-Paper1180	Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions	It will be not very difficult to reproduce the results of the paper, with some concerns below:    not sure if code will be publicly available (not mentioned in the paper, though mentioned in the reproducibility doc)  No details about how the small portion of labeled images were selected and how many repeats were performed.  No statistical significance reported for ablation studies								It is O.K. if the code will be available after acceptance.								Good Reproducibility											0	0	0	0	0	0	
595-Paper1345	SENDD: Sparse Efficient Neural Depth and Deformation for Tissue Tracking	To enhance the reproducibility and accessibility of the proposed method, it is recommended that the authors open-source their implementation. By providing the source code and detailed documentation, the research community can more easily replicate and build upon the findings presented in the paper.								The paper in current form is hard to reproduce and the code will not be made available. I have concerns about reproducibility.								The author did not provide the code about the proposed method. However, the new dataset will be publicly released before MICCAI.											0	0	0	0	0	0	
596-Paper0388	SFusion: Self-attention based N-to-One Multimodal Fusion Block	Outstanding reproducibility as they provided code and used open-source datasets for their work.								Good reproducibility. The authors provide the model code with instructions for running it.								The reproducibility of the paper is adequate with open code.											0	0	0	0	0	0	
597-Paper1406	Shape-Aware 3D Small Vessel Segmentation with Local Contrast Guided Attention	Overall the idea and the network seem to be valid and reproducible. But there is a discontinuity between the illustration in Figure 3 and Figure 2, which is confusing to the readers and might be a blocker for reproducibility.								The paper uses two public and two private datasets, and the source-code is not supplied in the manuscript. Therefore, it is only possible to completely reproduce the main results if all the data and scripts are provided.								Yes											0	0	0	0	0	0	
598-Paper2329	Shape-based pose estimation for automatic standard views of the knee	The reproducibility is limited because the description of the proposed methods is hard to follow and not complete (e.g., parameters are missing, training not described).								Good.  Enough details about the methodology, implementation, hyperparameters, split, synthetic data generation and data augmentation are provided.								The proposed pipeline is clear to follow and the paper clearly answered some questions beforehand that reveiwer would like to know about the pipeline design.											0	0	0	0	0	0	
599-Paper0495	Shifting More Attention to Breast Lesion Segmentation in Ultrasound Videos	N/A								The authors will release the dataset and model.								The authors claim to open-source the code and data.											0	0	0	0	0	0	
600-Paper0202	SHISRCNet: Super-resolution And Classification Network For Low-resolution Breast Cancer Histopathology Image	The proposed methods is built upon existing methods, which is of high reproducibility. But their dataset is unique.								This work may be reproducibility.								A public dataset was used in this study. The author did not mention releasing the codes.											0	0	0	0	0	0	
601-Paper2245	SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI	In house dataset makes it challenging, but the authors will release their code upon acceptance, which will help greatly.								The details of experimental setup are provided. The description of data and algorithm are also clearly explained.								While the implementation details are clear, the authors have stated that the data is private, and they plan to release the code at a later time.											0	0	0	0	0	0	
602-Paper0626	Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model	The authors mostly ticked 'Yes' while often it does not correspond to the reality (e.g., the cohort is not well described, no variation estimate is proposed when presenting the results, no statistical analysis is performed, etc).								The paper provides a lot of details of the implementation. Some components are only described in passing and vaguely (such as adversarial and perceptual losses with citations to very general papers).								The proposed methods were validated using external datasets. However, the two private datasets which were used to train and test the model are not available. It is difficult to assess the reproducibility of the paper.											0	0	0	0	0	0	
603-Paper2313	Simulation-based parameter optimization for fetal brain MRI super-resolution reconstruction	The paper has provided enough detail to ensure reproducibility.								Yes								Nil											0	0	0	0	0	0	
604-Paper1199	Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations	Yes, the authors claimed to release the code.								This manuscript seems to be reproduceable with publicly available dataset and open-source code.								The authors have not provided the parameter settings. Did the authors implement a cross-validation procedure to optimize parameter selection for individual baselines? Omission of this step might introduce biases.											0	0	0	0	0	0	
605-Paper1748	Skin Lesion Correspondence Localization in Total Body Photography	The experiment on the public dataset should be reproducible given that the method is described in a clear manner.								Source codes were not provided. However, the experiments were conducted on a public dataset, which may allow to reproduce the results.								The reproducibility of this paper is good. The authors have reported the values of all the hyperparameters in Supplementary Table 1. However, both the datasets are quite small, with the IRTBP only containing 3 subjects (going by Fig. 3 (b)).											0	0	0	0	0	0	
606-Paper1447	SLPD: Slide-level Prototypical Distillation for WSIs	The paper should be reproducible if the code is made public.								The proposed method has been built on the publicly available well-known method "Hierarchical Image Pyramid Transformer (HIPT)". Therefore, one can reproduce the proposed approach with default parameters, as mentioned in the paper.								Good, codes will be available upon publication and details are provided in the paper to help readers to reproduce the paper.											0	0	0	0	0	0	
607-Paper0397	SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation	The reproducibility of the model can be done after following the content of the paper, except for several places that need to be clarified clearly. Also, the authors claimed that a sample implementation will be provided upon acceptance.  However, a private liver dataset from the authors' hospital was used in the paper, and we cannot reproduce the results in Table 1 & 2 without this private dataset.								The authors claim that they will public the code and pre-trained model, but they use in-house dataset for evaluation.								The used software is mentioned. In addition, some parameters are mentioned. However, some more details should be included such as the specific versions of the software libraries used and the exact hyperparameters used for training the models.  In addition, the paper does not provide a link to the code or dataset used for the experiments. However, the authors mention that the code will be made available.											0	0	0	0	0	0	
608-Paper1385	Smooth Attention for Deep Multiple Instance Learning: Application to CT Intracranial Hemorrhage Detection	Given that the data is a publicly available challenge dataset, and the code is made available via github, the paper is fully reproducible.								Experimental settings are provided aprovided in the paper. The authors mentioned that the codes will be available as well.								This paper shows moderate reproducibility. Many important model and training details have been provided. The code is not available currently, and the authors claim the code will be presented. The dataset used in this paper is publicly available.											0	0	0	0	0	0	
609-Paper1777	SMRD: SURE-based Robust MRI Reconstruction with Diffusion Models	The paper uses pretrained diffusion model checkpoints and datasets that are publicly available, and the proposed algorithm is clearly explained in pseudo-code to ensure easy reproducibility. The used numerical values are presented in the result section.								All relevant details and parameters are defined in the manuscript. However, code access and/or documentation about used datasets (e.g. in code repository) are not provided. Reproducibility checklist is correctly answered.								Reproducibility is acceptable.											0	0	0	0	0	0	
610-Paper1007	Soft-tissue Driven Craniomaxillofacial Surgical Planning	The proposed method should be reproducible, but the method is more complex and open source code is recommended.								not easy to follow just according to the text. But the authors said they would provide the related code								Mostly, this work will be reproduced.											0	0	0	0	0	0	
611-Paper3696	Solving Low-Dose CT Reconstruction via GAN with Local Coherence	Authors provide detailed information on the datasets, including data sources. The proposed method is clearly described. All relevant results are reported. However, it may still be challenging to reproduce the experiments without the source code.								Confirmed that reproducibility checklist is completed and accurate.								This work is reproduciable.											0	0	0	0	0	0	
612-Paper0985	Source-Free Domain Adaptation for Medical Image Segmentation via Prototype-Anchored Feature Alignment and Contrastive Learning	Judging from the checklist, there seems to be no major issues with reproducibility.								Code will be public upon the acceptance as claimed by the authors.								The code is not provided.  The detailed U-Net structure, e.g., down-sample layers, BN or IN for normalization, is not provided.  The detailed training strategy is provided.											0	0	0	0	0	0	
613-Paper0888	Source-Free Domain Adaptive Fundus Image Segmentation with Class-Balanced Mean Teacher	yes								Models and algorithms: the models are mathematically correct, and descriptions of the model parameters used are provided, which helps for the reproducibility.  Datasets: They used cited public datasets.  Code: no code was attached.  Reported experimental results: tables are very descriptive and include the essential metrics for evaluation and comparison.								not so much											0	0	0	0	0	0	
614-Paper1589	Spatiotemporal Hub Identification in Brain Network by Learning Dynamic Graph Embedding on Grassmannian Manifold	The authors provided necessary information for the reproducibility.								The paper is reproducable.								The implementation and reproducibility of the methods would be difficult without the access to the codes.											0	0	0	0	0	0	
615-Paper2515	Spatiotemporal Incremental Mechanics Modeling of Facial Tissue Change	Yes reproducibility report follows the text corresponding to the key points acknowledged by the authors.								Most of the important parameters are given and presented in a clear, straight-forward manner and the authors state that code will be released (in the reproducibility checklist). Data is not available, but the method can be reproduced.								Partially reproducible    The 3D models dataset will not be available.  It is mentioned in the submission summary that the code of training and validation will be available, adding this information in the paper would be appreciated.  The networks architectures and hyper parameters are well described to allow the reimplementation.  The reproducibility of the biomechanical simulations is based on the details from [6].											0	0	0	0	0	0	
616-Paper1337	Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation	The method is clearly described, and the authors intend to make their code publicly available.								I think this paper can be reproduced with enough efforts.								The authors included all relevant details regarding reproducibility.											0	0	0	0	0	0	
617-Paper0216	Speech Audio Synthesis from Tagged MRI and Non-Negative Matrix Factorization via Plastic Transformer	No code provided, so hard to comment on reproducibility. However, there are theoretical proofs for the algorithms mentioned in the paper.								Seems hard to reproduce, the authors do not specify if they will free the code and neither the images								The authors have shared helpful implementation details, but the reproduction of the work is impossible without the release of the dataset and code.											0	0	0	0	0	0	
618-Paper2887	Spinal nerve segmentation method and dataset construction in endoscopic surgical scenarios	Though the authors did not provide code for reproducing the experimental results presented in the paper, there are clear description of the implementation details in the main paper. I fairly believe the experimental results of this paper are reproducible.								cannot be judged								The data and code are not public.											0	0	0	0	0	0	
619-Paper1236	SPR-Net: Structural Points based Registration for Coronary Arteries across Systolic and Diastolic Phases	The dataset used in the article is non-public and the designed network structure is complex, therefore it would be difficult to implement it. It is expected to evaluate the proposed methods on some public datasets and make code available.								The authors described the building blocks and architecture of the proposed network clearly. Implementation details such as training and evaluation schema as well as used hardware are also described. However, neither the process of data acquisition is described nor the data is published. The source code of the implementation is also not provided. In total, the reproducibility of the proposed method incl. the described evaluation schema are low.								While the authors explain the overall system, the steps taken and most important aspects, the reproducibility of their work will be very much helped by making code and data available. From the text in the paper it is not clear whether the code will be publicly available.											0	0	0	0	0	0	
620-Paper1006	StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-Ensemble	The authors provide clear descriptions on the hyper parameters used and the public datasets.  They also engage to publish their code upon acceptance.								Public dataset is utilized. Code will be made public upon acceptance.								The Python code is promised by authors to be available after the paper is published. Regarding clarity of presentation in Section Method, the readers are presumed to be familiar with many advanced concepts and, therefore, the whole learning process is presented with three general equations. I understand that character of the conference dictates that, but it is demanding for interested readers to gain deep understanding from such presentation. Experimental part of the work is described clearly.  In Section 3 Implementations, it is said that Adam optimizer, which is gradient based, is used for model optimization. However, in eq. (3) the loss function is based on L1-norm that is not differentiable at zero, i.e. its gradient at zero is not defined. I am not sure whether authors are aware of that fact, and how that can affect reproducibility of the the whole learning process?											0	0	0	0	0	0	
621-Paper1948	STAR-Echo: A Novel Biomarker for Prognosis of MACE in Chronic Kidney Disease Patients using Spatiotemporal Analysis and Transformer-Based Radiomics Models	The LVW segmentation for most images are predicted by a deep learning model. The authors mention that these are manually checked and corrected. Is there an specific protocol that was used? Or how many images needed the correction, and are the corrected masks available?  The dataset split details do not seem to be available.								There is not information on sensitivity regarding parameter changes and neither the exact number of training and evaluation runs.								The authors state they would make the code publicly available. The data set (Chronic Renal Insufficiency cohort) may be open to collaboration.											0	0	0	0	0	0	
622-Paper3313	Structured State Space Models for Multiple Instance Learning in Digital Pathology	ok								The authors state that their code is available at a specific URL, which suggests that their work is reproducible to some extent.								The paper's code is publicly available on Github, and the datasets used in this study are already publicly accessible, indicating a high level of reproducibility for this paper.											0	0	0	0	0	0	
623-Paper2117	Structure-decoupled Adaptive Part Alignment Network for Domain Adaptive Mitochondria Segmentation	Poor. Code is not provided.								All the datasets used in this work are public, and the source code is not provided for paper review.								OK											0	0	0	0	0	0	
624-Paper3113	StructuRegNet: Structure-guided Multimodal 2D-3D Registration	No mention of ethics or patient informed consent.								The paper does not have high reproducibility due to a lack of publicly available code and a lack of detailed information on the image registration network.								The authors will not make code and data publicly available.											0	0	0	0	0	0	
625-Paper0622	Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform	ok								Easy to reproduce.								This paper is based on public dataset.											0	0	0	0	0	0	
626-Paper0654	Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation	The authors would provide the code, but would not provide the data.								The manuscript provides sufficient details to implement the proposed architecture. However, the paper does not offer complete information regarding coarse mask generation, which could potentially hinder reproducibility. Nevertheless, the authors have stated that they will release the code after the paper is accepted.								Good reproducibility with potential open source code as indicated in abstract.											0	0	0	0	0	0	
627-Paper1433	Style-based Manifold for Weakly-supervised Disease Characteristic Discovery	The authors of the paper have made an effort to enhance the reproducibility of their work by providing the source code, pre-trained models, and datasets used in the experiments. However, reproducing the experiments may require significant computational resources and expertise, as the model was trained on a large dataset and involves complex architecture and techniques such as the use of a learned disease manifold.  Additionally, some of the experimental details and parameters are not clearly specified, which could make it challenging for other researchers to replicate the results exactly. Moreover, while the paper provides some qualitative and quantitative evaluation of the proposed method, more comprehensive and systematic evaluation on larger and more diverse datasets is necessary to fully assess its generalizability and robustness.  In summary, while the authors have made an effort to enhance the reproducibility of their work, reproducing the experiments may require significant resources and expertise, and more comprehensive evaluation is needed to fully assess the reproducibility and generalizability of the proposed method								The authors will make the code available, the dataset is available. So all seems to be OK here.								The code for the paper could not be found now but might be released in the future if accepted.											0	0	0	0	0	0	
628-Paper2544	SurfFlow: A Flow-Based Approach for Rapid and Accurate Cortical Surface Reconstruction from Infant Brain MRI	The description of the SurfFlow implementation is too sketchy to be reproduceable, unless authors (really) publish their code.								The paper seems to be well reproducible.								Good.  Would be much strengthened if the authors released the code to the reviewers.											0	0	0	0	0	0	
629-Paper2331	Surgical Action Triplet Detection by Mixed Supervised Learning of Instrument-Tissue Interactions	The reproducibility is good given that the code will be released.								The paper provides enough implementation details to reproduce the results.								The model and experiment setup are described. However train/test code is not avaible. I assume, it would be made public upon paper acceptance.											0	0	0	0	0	0	
630-Paper2207	Surgical Activity Triplet Recognition via Triplet Disentanglement	I did not see any problems with the reproducibility of the work.								I believe this paper is reproducible. Methods are clearly described, and code will be released on publication. The paper uses a common datasets that is known in the area.								The experiment of the paper is carried out on the public dataset CholecT45. Also the authors claim to release the training code of proposed method. Therefore, it would be easy to reproduce the work and compare the performance with the presented results in the paper.											0	0	0	0	0	0	
631-Paper0188	Surgical Video Captioning with Mutual-Modal Concept Alignment	Some information were provided to allow reproducibility thanks to the source code and the use of one public dataset.  However, the authors indicated that the following points were included, but are not:  * An analysis of situations in which the method failed.: The qualitative comparison only presents cases where the method work. On supplementary material, failed cases were present but not analyzed.  * Discussion of clinical significance: not included								The authors will release the code upon acceptance (indicated in the paper / checklist), and also the dataset (indicated in the checklist).  It is however unclear, if the authors intend to release their newly collected large Neurosurgery Video Captioning Dataset, or only refer to the already public EndoVis Image Captioning Dataset. I would strongly encourage the authors to publish the Neurosurgery Video Captioning Dataset, if possible.								The authors commit to releasing the neurosurgery dataset and code which will allow results reproducibility.											0	0	0	0	0	0	
632-Paper1492	SurgicalGPT: End-to-End Language-Vision GPT for Visual Question Answering in Surgery	The authors clearly describe their experimental and hardware setup and the parameter configurations of the model. Further, the authors, upon acceptance, will publish the code, datasets, and the pre-trained model. With this information, I'm confident that the results in this paper can be reproduced.								The reproducibility is good given the released codes.																			0	0	0	0	0	0	
633-Paper0466	SwinMM: Masked Multi-view with Swin Transformers for 3D Medical Image Segmentation	The method is evaluated on public datasets, the source code is available (even if the main readme is quite empty, the source code is already downloadable)								The paper's reproducibility is strong, thanks to the open-sourcing of code and the use of public datasets for all experiments.								The paper appears to be reproducible. The link to the code is included.											0	0	0	0	0	0	
634-Paper1667	SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation	Datasets are publicly available.  Training recipes are based on previous work, with citation to corresponding repos.  Code not yet available.  Value of some main hyperparameters not described (see comments)								The paper is clearly written and has enough information to reproduce								Authors report the results on 6 public datasets. Authors do not provide code to reproduce the results, nor the neural networks weights.											0	0	0	0	0	0	
635-Paper1380	SwIPE: Efficient and Robust Medical Image Segmentation with Implicit Patch Embeddings	Based on the information provided by the authors, the paper has been submitted with a completed reproducibility checklist. The authors have listed implementation details that can be followed easily.								Code and Data are available, used training routine and hyperparameters well described.								Code should be easy to reproduce from the details in the paper, and it will be released on github.											0	0	0	0	0	0	
636-Paper1534	Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-based Hierarchical Fusion Network with Attention Mechanism	As mentioned, the reference synthetic CE-MRI used for comparing results is not explained, to reproduce the experiment.								No code or data was provided along with the paper.								The proposed model used T1WI and multi-b-value DWI images as input, while the T1WI information is not reflected in the title.  The term "contrast-enhanced MRI (CE-MRI)" is less common and we usually use DCE-MRI.  Some sentences in this manuscript are not precisely expressed, such as "However, the use of gadolinium-based contrast agents (GBCA) requires iv-cannulation, which is a burden to patients, time consuming and cumbersome in a screening situation" or "We invented (a or the) hierarchical fusion module,"  You said, On the other hand, the information provided by multi-sequences may be redundant and may not contain the relevant information of CE-MRI. But is there a basis for the premise of this hypothesis?  Another confusing sentence: invented hierarchical fusion module, weighted difference module and multi-sequence attention module to enhance the fusion at different scale, to control the contribution of different sequence and maximising the usage of the information within and across sequences. Lots of little mistakes, like plural nouns without the 's'.  What's the meaning of "ln function"? Is it the log function?  Why use a generative adversarial training strategy? A direct calculation of the MSE loss between DCE-MRI and the generated image should be sufficient to generate the desired image.  The loss function LD(G, D), used for training the Discriminator, should have an extra negative sign.  In the sentence "The numbers of filters are 32, 64, 128, 256 and 512, respectively", the numbers should be revised into channels.  Can't understand the part of "2.3 Visualization".  In the sentence "The trade-off parameter l1 was set to 100 during training, and the trade-off parameter of the reconstruction loss in the reconstruction module is set to 5.", what's the difference between the two trade-off parameters?  "The batch was set to 8 for 100 epochs"? Do you want to say "the batch size"?  What is the meaning of "thereby optimizing logistics and minimizing potential risks to patients."?  In the right part of Fig.3., you note the (ceT1-T1). What is the meaning of (ceT1-T1)? Is it the subtracted image between the GT and the model outputs? If they are the subtracted images, the highlighted parts of them mean more difference. If they are the output images of models, the details inside the chest are worse.  Finally, DCE-MRI usually has images at multiple time points, representing different stages of contrast inflow and outflow from the lesion. In this manuscript, only one DCE-MRI image at the one-time point was generated. So, at what point in time did you generate the image? Whether there is a basis for relevant support. Why can't all time points be generated?											0	0	0	0	0	0	
637-Paper1741	Synthesising Rare Cataract Surgery Samples with Guided Diffusion Models	The data and hyperparameters will reportedly be accessible to all.								The author well elaborate the experiments performed.								Nothing to note on this section											0	0	0	0	0	0	
638-Paper3484	Synthetic Augmentation with Large-scale Unconditional Pre-training	Reproducible. The code and pre-trained model release would be appreciated.								The paper describes the model architecture and references the appropriate implementation details. Still, the paper in general is missing an analysis of sensitivity to hyper-parameters or variance with respect to stochastic inputs (weight initialization, training data selection, stochastic gradient decent, etc) resulting in scores without any uncertainty.								the authors are committed to provide source code, the reproducibility should be fine											0	0	0	0	0	0	
639-Paper2389	TabAttention: Learning Attention Conditionally on Tabular Data	The author provided a code for integrating TabAttention in CNNs on github. I think the article is reproducible.								dataset is private  code is publicly available and anonymously on github								The code is publicly available.											0	0	0	0	0	0	
640-Paper0919	TauFlowNet: Uncovering Propagation Mechanism of Tau Aggregates by Neural Transport Equation	The reproducibility of the paper is good.								The model seems to be easy to implement and reproduce. Data preparation might be harder to replicate, and I think that publishing supporting code would be very helpful.								OK											0	0	0	0	0	0	
641-Paper2196	TCEIP: Text Condition Embedded Regression Network for Dental Implant Position Prediction	The paper is well-written. But, I will suggest the code and dataset be released to support reproducibility.								The authors released some training parameter information, but did not release the code.								none											0	0	0	0	0	0	
642-Paper0880	TCL: Triplet Consistent Learning for Odometry Estimation of Monocular Endoscope	Good								Although the codes are not released, a clear description of the method, a declaration of what software framework, and implementing details are provided. The data for evaluation are publicly available. Thus, it is possible to re-implement the method.								The author has given the code of the proposed method.											0	0	0	0	0	0	
643-Paper3608	Temporal Uncertainty Localization to Enable Human-in-the-loop Analysis of Dynamic Contrast-enhanced Cardiac MRI Datasets	The code is not available								The dataset is in-house and the code has not been publically available.								There is no code available and therefore not as easily reproducible ].											0	0	0	0	0	0	
644-Paper2911	Tensor-based Multimodal Learning for Prediction of Pulmonary Arterial Wedge Pressure from Cardiac MRI	The prediction method utilized in the study is SVM, which requires training for different features and is time-consuming. Have the authors considered using different deep-learning based methods, such as FC layer?  The discussion of the results in the study is limited.								The authors state they will make the code and the data set publicly available if accepted.								According to the reproducibility checklist, the authors will open-source their work.											0	0	0	0	0	0	
645-Paper2005	Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image	The authors are plannig to provide the codes via GitHub.								reproducibility is good								Should be able to reproduce											0	0	0	0	0	0	
646-Paper1254	Text-guided Foundation Model Adaptation for Pathological Image Classification	The paper used a publicly available dataset PatchGastricADC22. The source code information is not provided.								Authors used an open source dataset and code, therefore results should be reproducible.								"The average runtime for each result, or estimated energy cost.", "A description of the memory footprint." and "An analysis of situations in which the method failed." can be and should be reported, instead of "Not Applicable".  The authors provide an empty github link for the source code repo, I understand it means that you can fill it if accepted, but I remember that it is not allowed to provide the link.											0	0	0	0	0	0	
647-Paper1613	The Role of Subgroup Separability in Group-Fair Medical Image Classification	Reproducible								Should be able to reproduce the experiments upon codes released.								Sufficiently reproducible											0	0	0	0	0	0	
648-Paper1157	Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound	Dataset used is not available publicly.								Satisfactory.								The paper is easy to reproduce because the authors provide a detailed methodological flow and sufficient network details.											0	0	0	0	0	0	
649-Paper1212	Thyroid Nodule Diagnosis in Dynamic Contrast-enhanced Ultrasound via Microvessel Infiltration Awareness	yes								Satisfactory.								The details on the parameter selection process will make the work reproducible.											0	0	0	0	0	0	
650-Paper1314	Topology Repairing of Disconnected Pulmonary Airways and Vessels: Baselines and a Dataset	Authors have agreed to make the code and data public.								If the data is made available, I see no problem with the reproducibility of the method.								The authors plan to release their dataset. Before that, the results are not reproducible, since both original data and the method for adding discontinuities into the data are not yet available.											0	0	0	0	0	0	
651-Paper0181	Topology-Preserving Automatic Labeling of Coronary Arteries via Anatomy-aware Connection Classifier	As the metrics reported are not valid they cannot be reproduced.								The reproducibility of the paper is strong based on the provided information in the reproducibility checklist. The authors have addressed most of the crucial aspects, which includes:    Clear descriptions of the software framework, assumptions, and mathematical setting, algorithm, and/or model.  Detailed information about the datasets, including relevant statistics, and links to downloadable versions if public.  Code availability, including specification of dependencies  Comprehensive reporting of experimental results, such as hyper-parameter selection and sensitivity analysis								The manuscript presents details of the implementation and parameters used. Atleast some of the dataset is publically available, and authors state the additional ground truth data used for this manuscript will be made publically available.											0	0	0	0	0	0	
652-Paper1351	Topology-Preserving Computed Tomography Super-resolution Based on Dual-stream Diffusion Model	The authors have stated that they will make all the scripts (both training and testing) and the generated datasets public.								The author will make the code publicly available so the work will be fully reproducible. Also, the architecture design is clear. Publicly available dates are referenced and properly described. It is not clear in the paper if the in-house constructed dataset will be made available too.								This paper does not describe the specific network architecture but provides implementation details in the appendix, which includes the train-val-test partition, input size, implementation framework, learning rate, optimizer, hardware and so on. However, other hyper-parameters are not given. The source code may be publicly available later. Additionally, this paper has two in-house datasets that are not publicly available but provides details in the appendix, including the number of scans, ages, sex, spatial resolution, image size, inter-slice thickness, tube voltage, CT scanner and so on.											0	0	0	0	0	0	
653-Paper0994	Toward Fairness Through Fair Multi-Exit Framework for Dermatological Disease Diagnosis	The reproducibility of this paper is quite low. There are several key details that are missing (see weaknesses): the loss function, the number of samples in and the class-wise distribution of training, validation, and testing sets, the number of training runs and if the experiments were repeated.  In the reproducibility checklist, the authors have replied "Yes" to several items that are not present in the paper:    "A clear declaration of what software framework and version you used." -> missing.  "Information on sensitivity regarding parameter changes." -> missing.  "The exact number of training and evaluation runs." -> missing.  "The details of train / validation / test splits." -> missing.  "A description of results with central tendency (e.g. mean) & variation (e.g. error bars)." -> missing.  "An analysis of statistical significance of reported differences in performance between methods." -> missing.								The authors are conducting a computational study with datasets from the public domain so all experiments should be fully reproducible. The authors claim that all of the information required to replicate the experiments is available. It would be helpful to include a link to where this can be found in the paper.								The study uses publicly available datasets, and the authors have indicated that all code required to run the experiments will be made available after publication.											0	0	0	0	0	0	
654-Paper0225	Towards Accurate Microstructure Estimation via 3D Hybrid Graph Transformer	Overall, the paper seems to be well-documented and provides the necessary information to reproduce the results.								the authors meet all the criteria on the reproducibility checklist.								I think the paper should be reproducible upon the code releases.											0	0	0	0	0	0	
655-Paper1614	Towards AI-driven radiology education: A self-supervised segmentation-based framework for high-precision medical image editing	The authors provide enough information regarding the reproducibility of their results, as their synthesized images and code will be publicly available.								The code is not yet made available due to anonymization. However, other details for reproducibility are provided in accordance with the author statement.								The proposed method is evaluated on in-house datasets, and the author did not promise to release the data.   Many hyper-parameters need to be determined, the paper should clarify it.											0	0	0	0	0	0	
656-Paper0094	Towards Expert-Amateur Collaboration: Prototypical Label Isolation Learning for Left Atrium Segmentation with Mixed-Quality Labels	No code or dataset is provided.								Yes								The authors have described the details of the experimental setup and the implementation. Although, the paper uses a public dataset, the source code is not provided. Therefore, it is only possible to reproduce the experiments if the scripts are available.											0	0	0	0	0	0	
657-Paper3191	Towards frugal unsupervised detection of subtle abnormalities in medical imaging	The reproducibility checklist has been filled but not codes were attached.								This paper is difficult to replicate due to the advanced mathematical operations. But, since the authors have mentioned that the code would be available, this method could be replicable.								The exact steps of the algorithm used for the EM are not outlined clearly. The data is used publicly available. It could be possible to reproduce the algorithm on the data, but the parameters used etc are not known.											0	0	0	0	0	0	
658-Paper1591	Towards Generalizable Diabetic Retinopathy Grading in Unseen Domains	The training hyperparameters are given. All the datasets are public and their references are given. However, more details on the software framework (Torch, Tensorflow, etc.) and version was not given, and the code to the data augmentation module (FundusAug) which is very crucial and can affect the whole pipeline is not given. Overall, the implemented ideas are relatively simple and someone can implement them, still important details are missing to reproduce the exact results of the method.								No code is available. The details of implementation is not clear.								The manuscript include sufficient details for the reproducibility of the work. Public datasets were analyzed in the experiments.											0	0	0	0	0	0	
659-Paper3244	Towards multi-modal anatomical landmark detection for ultrasound-guided brain tumor resection with contrastive learning	The paper is thorough and contains pretty much all details necessary to be reproduced. A minor detail I did not find were the ranges of the image augmentations in training.								The work should be reproducible with reasonable efforts considering the checklist provided by the authors.								A public dataset is used and it is stated that the code is going to be released. Reproducibility is ensured.											0	0	0	0	0	0	
660-Paper0283	Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering	Too many parameters should be tuned, so not easy to reproduce.								The authors provide implementation details in their Experiments section which make it relatively straightforward to reproduce, and they mention that they intend to publish their code soon which will further assist in reproducibility.								good.											0	0	0	0	0	0	
661-Paper0611	TPRO: Text-prompting-based Weakly Supervised Histopathology Tissue Segmentation	The paper has provided most of the details.								The authors have shared details about the training algorithm, hyperparameters and the hardware used. They can also share the different libraries and their versions used in experimentation.								Most details required for reproducibility are explained except for Vision Encoder (total blackbox). Supplementary presents additional hyperparameters in Table 1. Is code going to be provided?											0	0	0	0	0	0	
662-Paper1522	Trackerless Volume Reconstruction from Intraoperative Ultrasound Images	The authors claim "Code will be publicly released." Considering the datasets are primarily private across research groups, I think the code should contribute to the paper reproducibility.								This work has good reproducibility.   To be reproducible, the code should be publicly available. And the dataset is important as well.								The authors mention that the source code with parameters will be released upon the acceptance of the paper. In the text, the methods are described well with parameter values used for training. With access to the source code and parameter sets along with the clear description of the methods in the paper, I believe, that an interested reader will be able to reproduce the result without much effort.											0	0	0	0	0	0	
663-Paper3122	Tracking adaptation to improve SuperPoint for 3D reconstruction in endoscopy	The experimental setup needs to be written to improve the clarity of the paper. Without that it is difficult to reproduce the results.								I believe the work can be reproduced based on the authors' explanation								The paper appears reproducible, with clear reference to the training data, software and methods used.  The reproducibility checklist implies that code will be released for this method, however this is not mentioned in the paper. The intention may be to add this sentence to the camera ready version.											0	0	0	0	0	0	
664-Paper3146	TractCloud: Registration-free Tractography Parcellation with a Novel Local-global Streamline Point Cloud Representation	The clinical dataset is not open publicly available. It prevents the reproducibility assessment of the impact in clinical setting								Authors detailed the framework clearly, and will release code on GitHub. The formulation and experimental design are easy to follow, with all the details covered in the paper.								Data is openly available and code will be published											0	0	0	0	0	0	
665-Paper1501	Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors	The reproducibility is not so well, considering that their codes are not public accesible and the method description is not very clear.								Good								The paper does not provide source code or state that source code will be provided. I believe, the reproducibility of the proposed method is medium without open-source code.											0	0	0	0	0	0	
666-Paper3086	Transferability-Guided Multi-Source Model Adaptation for Medical Image Segmentation	The paper's algorithm implementation is clear and well-documented, making it relatively easy for others to reproduce the results.								The reproducibility seems good according to the reproducibility response.								I am convinced of the reproducibility of the paper. However, due to the complexity of the framework, I find it difficult to understand some details. Therefore, I suggest that the authors publish their code to improve reproducibility and facilitate understanding of the methodology.											0	0	0	0	0	0	
667-Paper0211	Transformer-based Annotation Bias-aware Medical Image Segmentation	The code is attached as supplemental material.  The datasets are public available.								The paper has a high reproducibility and the training details are provided. The code of the implemented networks is also provided in the supplementary materials.								The network structure is quite complex, which is difficult to be reimplemented from scratch and reproduce the results.											0	0	0	0	0	0	
668-Paper1015	Transformer-based Dual-domain Network for Few-view Dedicated Cardiac SPECT Image Reconstructions	The paper lacks detailed information about the architecture, making it difficult to replicate it.								Yes, the authors claimed that they will release the code.								Reasonable.											0	0	0	0	0	0	
669-Paper2405	Transformer-based end-to-end classification of variable-length volumetric data	The reproducibility of the paper is feasible according to implementation details.								The reproducibility of this paper is promising, The architecture of the network, the implementation details and the data for training and evaluation are described in detail.								It seems the authors are not able to release their code.  Considering the missing details, the paper in its current version might not be easily reproduced.											0	0	0	0	0	0	
670-Paper2643	Transformer-based tooth segmentation, identification and pulp calcification recognition in CBCT	The authors have claimed that they will share their github repo.								Assuming that the authors follow through with their announcement in the paper and share the code, it should be feasible to reproduce the results.								The authors reported most of the experimental parameters, thus making the study highly reproducible.											0	0	0	0	0	0	
671-Paper1235	TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification	The proposed method could be easily re-implemented based on provided architecture and training information  Both code and data are not provided								no code.								The authors mention in the reproducibility checklist that the code will be released. The authors provided the necessary details such as hyperparameter settings, training epochs, hardware utilized, batch size etc. The authors also provided extensive ablation study in the supplementary material. The results should be reproducible with these details.											0	0	0	0	0	0	
672-Paper0918	TransNuSeg: A Lightweight Multi-Task Transformer for Nuclei Segmentation	The method should be easy to reproduce.								Reproducible, code is provided.								The code is shared. I have no concern on reproducibility.											0	0	0	0	0	0	
673-Paper0529	Treasure in Distribution: A Domain Randomization based Multi-Source Domain Generalization for 2D Medical Image Segmentation	The authors have declared related options as found from the checklist.								It is mentioned in the abstract that the code will be made available, and the study is primarily based on public datasets.								The authors will share code. However, I don't see the link to downloadable version of the dataset in the paper although the authors indicated "Yes" in the reproducibility checklist.											0	0	0	0	0	0	
674-Paper2676	Treatment Outcome Prediction for Intracerebral Hemorrhage via Generative Prognostic Model with Imaging and Tabular Data	The authors have provided codes in their supplementary material. The reproducibility of this work is promising.								The code is currently available and the procedure is well described.								can be reproduced somehow given the data and public code											0	0	0	0	0	0	
675-Paper3480	Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer	The method for constructing the graph is clearly described and could be reproduced. But the usage of the features extracted from the graph is missing. No code publicly available.								The data set seems to be proprietary (it is not provided). Therefore, reproducibility is poor.								#NAME?											0	0	0	0	0	0	
676-Paper1044	TriDo-Former: A Triple-Domain Transformer for Direct PET Reconstruction from Low-Dose Sinograms	The paper lacks open-source codes, and it appears that the data used may be private. However, since the proposed method is not overly complex, and the implementation details are provided in the paper, it is theoretically possible to reproduce the results.								The paper seems to be reproducible since the architecture has been described in details. The authors also provide further information for reproducibility under section 2.4 Details of Implementation								The paper includes sufficient details to ensure reproducibility.											0	0	0	0	0	0	
677-Paper0925	Trust your neighbours: Penalty-based constraints for model calibration	Ok								Good, the code is supplied and additional materials.								The reproducibility is great since the author provided the core implementation.											0	0	0	0	0	0	
678-Paper2739	TSegFormer: 3D Tooth Segmentation in Intraoral Scans with Geometry Guided Transformer	Non reproducible								Nothing to add								Although the authors have not released any code or pretrained model, they have provided details regarding the training such as loss function, learning rate, hyper parameter tuning, number of epochs etc in the supplementary material. The authors showed the dental disease distribution of the challenging cases on which they conducted visual scoring by clinicians.  Though the mean and error bar of the performance metrics is not provided in this case, the results might be sufficient given that the dataset is large i.e. 16000 IOS scans.The authors have specified details of the convolution layers such as input size and output size, number of nearest neighbors for the knn, kernel size and the attention layer details. From these details it seems the work could be reproducible. Adding some more details e.g. GPU used and batch size would be helpful.											0	0	0	0	0	0	
679-Paper2611	Twelve-Lead ECG Reconstruction from Single-Lead Signals Using Generative Adversarial Networks	Good.  The authors said:  For all code related to this work that you have made available or will release if this work is accepted, check if you include: YES (for Specification of dependencies, Training code, Evaluation code, (Pre-)trained model(s)).								Dataset is not publicly available. No information about code release in the manuscript.								Reproducibility is low. The authors neither provide the source code for their novel EKGAN model nor seems the dataset they used for validation and testing to be publicly available. It is highly desirable for this information to be made publicly available should the paper be published.											0	0	0	0	0	0	
680-Paper3085	Ultrasonic tracking of a rapid-exchange microcatheter with simultaneous pressure sensing for cardiovascular interventions	The reproducibility of the paper is ok.								The details of hardware design and tracking image processing code are not included in this paper.   Implementing this system design may not be easy for individuals. However, if the system can be manufactured, it has the potential for high clinical impact.								The methods in the paper are only reproducible for those who have access to special instrumentation. There are no algorithmic contributions.											0	0	0	0	0	0	
681-Paper1417	UM-CAM: Uncertainty-weighted Multi-resolution Class Activation Maps for Weakly-supervised Fetal Brain Segmentation	The author plan to release the source code after review.								Although the data were not able to provide, it is reasonable to reproduce the method with the code and model of the authors.								Although it is stated that the code for the method and experiments is available, I did not find this information in the paper. The methods described in the paper seem sufficient to reproduce the results. The reproducibility points given are mostly valid.  The following items were marked in the reproducibility response, but I missed them in the paper:   I) Hyperparameter tuning II) Sensitivity to parameter changes III) Number of runs IV) Baseline implementation V) Failure situations.											0	0	0	0	0	0	
682-Paper1836	Uncertainty and Shape-Aware Continual Test-Time Adaptation for Cross-Domain Segmentation of Medical Images	The authors used public datasets and state to release their code. Thus, results should be reproducible.								Good reproducibility: the methods are clear enough to be re-implemented (code will be provided anyway upon acceptance) and datasets are publicly available.								The framework appears to be reproducible using the information provided in the paper.											0	0	0	0	0	0	
683-Paper1553	Uncertainty Inspired Autism Spectrum Disorder Screening	Yes, since the authors list the used dataset, and important parameters.								I believe that the obtained results can, in principle, be reproduced.								This paper provides sufficient details about the models, datasets, and evaluation.											0	0	0	0	0	0	
684-Paper0240	Uncertainty-informed Mutual Learning for Joint Medical Image Classification and Segmentation	Looks good								The network structure is quite complex, which is difficult to reimplement and reproduce the results from scratch.								The authors do not release their code.  Its anterior work, TBraTS [27], releases the code on the segmentation with uncertainty estimation.  The training on the joint framework, i.e., first do the MUT computation, and then do the seg loss, and finally do the cls loss may make the whole training complicated.											0	0	0	0	0	0	
685-Paper1116	Uncovering Heterogeneity in Alzheimer's Disease from Graphical Modeling of the Tau Spatiotemporal Topography	Dataset are from two subsets from ADNI which is publicly available, we hope to see a github with the code								The data sets and preprocessing method are sufficiently described, but providing the code would be absolutely necessary to ensure the paper reproducibility.								The authors mention choosing certain hyper-parameters such as the unpaired costs and distance matrix weights. The work would be more reproducible if they provided more detail on how these parameters were selected - are these specific to their dataset/experiments?											0	0	0	0	0	0	
686-Paper0920	Uncovering Structural-Functional Coupling Alterations for Neurodegenerative Diseases	The manuscript itself is not sufficient for reproducibility but as the authors have declared that they will share the codes, it must be re-runable. Nevertheless, thought the data used is open data, the ADNI dataset is quite complicated and specifying that 250 subjects from ADNI are used is not sufficient to identify these subjects.   Hence, reproducing the results may not be straight forward.								uses ADNI data but unclear which samples - also unclear if code will be made publicly available								Details about the implementation of GNN and Kuramoto models can be added to improve reproducibility. Providing code should be recommended.											0	0	0	0	0	0	
687-Paper3056	Understanding Silent Failures in Medical Image Classification	All work for this paper uses publicly available data and all code will be made available online. In the supplementarily materials the paper presents details training parameters for each of the trained models.								No concerns here as the code will be available.								The code has been provided and in this way makes it easy for other researchers to utilise.											0	0	0	0	0	0	
688-Paper2711	Unified Brain MR-Ultrasound Synthesis using Multi-Modal Hierarchical Representations	The paper mentions that the dataset used in this experiment will be published on TCIA in 2023, and the code is publicly available. A detailed description of the algorithm and model structure used in the paper was provided. But in Supplementary, only one modality encoder is shown.								The authors will provide the code and dataset.								The authors will make their code available.											0	0	0	0	0	0	
689-Paper2908	Unified surface and volumetric inference on functional imaging data	Some details are sketchy, but methods should generally be reproducible.								Reproducibility does not look good.								This work is reproducible as equations are provided, and the additional software that is used are all open source software tools.  Information about the simulated data that was used is provided.  Mentions the models used including the hardware used to run the method.											0	0	0	0	0	0	
690-Paper0530	UniSeg: A Prompt-driven Universal Segmentation Model as well as A Strong Representation Learner	Code and model will be released.								thorough Implementation Details								From the description and the response in the checklist, I believe this work is reproducible.											0	0	0	0	0	0	
691-Paper1057	Unpaired Cross-modal Interaction Learning for COVID-19 Segmentation on Limited CT images	The supplementary material provides architecture details for the encoder, decoder, and classification head. Therefore, I think the reproducibility may be satisfactory.								Needs more details about the data, data preprocessing, and code implementation								The reproducibility of the proposed framework by reading only the paper is not an easy task. Availability of the code and demo would be very appreciated by the community.											0	0	0	0	0	0	
692-Paper2499	Unsupervised 3D out-of-distribution detection with latent diffusion models	The authors mention that they will make code available upon acceptance. This would indeed increase reproducibility of the experiments and somehow counterbalance the fact that performance is evaluated on a private dataset.								Latent transformer model has open-source codes and this paper also gives details on model architecture and hyperparamters. Therefore, reimplementing the proposed method is not very difficult. However, part of the dataset is not public and I'm not sure if the author will enclose the dataset in the future.								Good reproducibility											0	0	0	0	0	0	
693-Paper1171	Unsupervised 3D registration through optimization-guided cyclical self-training	The data are public, but the code does not appear to be distributed somewhere.								The datasets used for evaluation are publicly available.  The authors provided the code and models in an anonymous GitHub repo. However, all functionalities are gathered into a single file of 674 lines of code. A huge training / testing method has been writing and it is impossible to figure out the flow of the algorithm and connect the lines of code with the manuscript. I do not feel able to exactly reproduce the training phase to start.  For the evaluation, the authors provided a clear description of metrics and tendency. Statistical significance was stated when needed.  The average runtime in the testing phase was provided. However, it is important to know the runtime in the training phase and the memory footprint. These magnitudes are not provided.  The clinical significance of the method can be inferred from the introduction. However, the proposed method needs further validation in more different datasets for considering moving to clinical application.								The authors have released the source code of this work. The results presented in the paper can be reproduced by others.											0	0	0	0	0	0	
694-Paper2309	Unsupervised classification of congenital inner ear malformations using DeepDiffusion for latent space representation	The author is satisfied with the information provided by the authors.								This work is reproducible.								The method in this study is not complicated and is reproducible. But since the data are not balanced and sample sizes are small for some classes, results might not be robust.											0	0	0	0	0	0	
695-Paper1729	Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features	Essential network configurations and hyper-parameters are shared.								Reproducibility is rather weak and significantly lower as promised in the reproducibility checklist. The checklist contains only "yes"es, even at questions that are not applicable for this work. However, the manuscript is missing many of the promised information, such as description of the compute hardware, A description of results with central tendency (e.g. mean) & variation, Details on how baseline methods were implemented and tuned, A description of the memory footprint, Discussion of clinical significance, The average runtime for each result, or estimated energy cost, a note that code will be released and more.								The parameters given in this paper are only the size of the input image, the learning rate and the number of iterations, while the specific parameters of the model (such as the size of the convolution kernel and the weight of the loss function) are not explained.											0	0	0	0	0	0	
696-Paper0946	Unsupervised Domain Adaptation for Anatomical Landmark Detection	The authors used public datasets and state to release their code. Thus, results should be reproducible.								The image datasets are publicly available.  Parameter details are specified but no link to code is provided.  Section 2 and Section 3.1 are informative enough to facilitate reproduction.								The paper has provided most of the details.											0	0	0	0	0	0	
697-Paper3159	Unsupervised Domain Transfer with Conditional Invertible Neural Networks	Only a general description of the network is given. The lack of architectural details makes reproducibility somewhat challenging. Hope the code will be released to resolve this.  Same applies to the data, as I understand the method is tested on two in-house datasets. So reproducibility is not possible.  By default, I am biased to trust authors. Still, without providing access to the method and data, nothing stops any authors from potentially putting arbitrary numbers in the result section.								Although the key hyperparameters are stated in the supplementary material, I recommend that the authors release the codes and data for the method.								The reproducibility of the paper is not clearly mentioned in the paper											0	0	0	0	0	0	
698-Paper2299	Unsupervised Learning for Feature Extraction and Temporal Alignment of 3D+t Point Clouds of Zebrafish Embryos	Author has convey, clear, specific and complete information about data, code, models and computational methods and analysis that support the contents and result presented in the paper.								It is difficult to reproduce for the following reasons:    The model/framework is not clearly explained or illustrated  The code is not published.  The synthesized dataset is not clearly explained.								Meet all criteria.											0	0	0	0	0	0	
699-Paper0297	UOD: Universal One-shot Detection of Anatomical Landmarks	As mentioned above, the paper is well written, particularly in terms of reproducibility. I would ask the authors to please share the code in the rebuttal as anonymous github account, as a good practice.								The author checked yes to all the Reproducibility Response questions. The only concern is the chest dataset they use might not available since the link they provide does not work.								o The paper conducted experiments on public datasets.  o The authors will release the code upon the acceptance.											0	0	0	0	0	0	
700-Paper2751	UPCoL: Uncertainty-informed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation	The paper addresses relevant points with respect to reproducibiility.								This paper is reproducibility								It will be better if the authors can release their code for reproducibility.											0	0	0	0	0	0	
701-Paper0843	Utilizing Longitudinal Chest X-Rays and Reports to Pre-Fill Radiology Reports	The paper seems to be reproducible since it is clearly written, and the authors have shown the implementation details. Also, the authors intend to release the code and dataset used for the evaluation.								Implementation details are provided and thus the reproducibility looks good.								Dataset and code will be made publicly available.											0	0	0	0	0	0	
702-Paper2942	UWAT-GAN: Fundus Fluorescein Angiography Synthesis via Ultra-wide-angle Transformation Multi-scale GAN	Code is included.								The author provided the code, but the data used in the paper is difficult to obtain, so the reproduction of the original paper is a certain challenge.								Very good with train/inference code available											0	0	0	0	0	0	
703-Paper0139	UXDiff: Synthesis of X-ray Image from Ultrasound Coronal Image of Spine with Diffusion Probabilistic Network	Code and data are not provided. However, authors don't propose complex new methods that would be too challenging to reproduce. The problem is that readers will not have volume projection spine images, so even if they reproduce the methods, it is difficult to verify the results. I think a test dataset should be released in the public in this case.								The paper contains good amount of implementation details. Moreover, the authors will provide code, which may improve the reproducibility of the paper.								The method is described clearly although I am not entirely sure the paper is reproducible fully. Some details of the network are missing (initialization, wether dimensioning of layers has changed to fit the current image size, any preprocessing or data normalization, etc). Also the dataset is proprietary so experiments are not reproducible.											0	0	0	0	0	0	
704-Paper2283	Vertex Correspondence in Cortical Surface Reconstruction	Multiple open-source datasets were used for training, testing, and validation of the model. This, along with the detailed model description, allows for the high reproducibility of the study. The code used is also publicly available. There is a clear description of the mathematical framework, with the exception that model weights were not included in the equation/ calculations written in the paper.								The answers given by the authors seem consistent with what is present in the paper. Code will be made available on GitHub, and the methods and results are well described for an 8-page paper.								The authors use publicly available datasets, and build on the V2C code which is also publicly available.											0	0	0	0	0	0	
705-Paper0384	VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis	Generally meeting the requirements.								Looks no problem								there are some problems to reproduce this paper since some details are missed and also the structure is not introdeced clearly											0	0	0	0	0	0	
706-Paper1198	VF-HM: Vision Loss Estimation using Fundus Photograph for High Myopia	The code is not available and the parameters of the network are not provided. The ground truth is visual field test which is not highly reliable. Myopic maculopathy stage is labelled by an ophthalmologist.								There is no code repo + data access provided, whereas the implementation details as well as parameters are given.								The paper provides a detailed description of the proposed method and the experimental setup, including the dataset used, evaluation metrics, and implementation details. However, it does not metion to the code or any information on how to access the implementation.											0	0	0	0	0	0	
707-Paper3121	Virtual Heart models help elucidate the role of border zone in sustained monomorphic Ventricular Tachycardia	Generally not reproducible. The authors do cite the methods they use to generate their simulations, but those depend on user discretion at the time of assessing fit between each combination of model parameters. There is no description about the MRI parameters to generate the images, nor any example of such.								It was not clear if the authors intend to make their modeling framework or data open to the community								The model and datasets are well described, but they provide no code nor raw data.											0	0	0	0	0	0	
708-Paper2976	VISA-FSS: A Volume-Informed Self Supervised Approach for Few-Shot 3D Segmentation	The overall pipeline is complicated and some parts lack clarity, but not all the implementations details nor the code are provided.								My only major concern with the manuscript is regarding reproducibility, as the neural network architecture and general framework proposed by the authors is composed of multiple non-trivial blocks. As no code is made available, a faithful reconstruction of the experimental procedure in this work would likely require a lot of hyperparameter tuning and coding expertise, hampering the replication of this research mainly for researchers with access to fewer computational resources (i.e. GPU).								The authors answered no to all questions in the reproducibility checklist. This means that the author would not release any code. Although the authors claimed all hyper parameters and protocols are following [18], it would be difficult to reproduce entirely the results. Especially, the registration module is not thoroughly discussed. However, the idea is well explained, means it would not be difficult to test the similar idea in other applications.  [18] https://arxiv.org/abs/2007.09886											0	0	0	0	0	0	
709-Paper2328	Vision Transformer based Multi-Class Lesion Detection in IVOCT	As pointed out in the weaknesses section, the reproducibility checklist is fully checked while information on publishing data, code or ethics approval are not mentioned in the manuscript. Furthermore, no information on hyperparameters is given in the paper which makes reproducibility of the results very difficult.								This work is reproducible.								It is really hard to comment on the reproducibility, as the statements between the reproducibility checklist and the actual paper are in completely opposite directions.   If one purely looks at the paper it is as poor as it gets: No public data, no public code, no details on the data split, no details on the value ranges for the data augmentation, etc. Looking at the reproducibility checklist all of that will be provided.											0	0	0	0	0	0	
710-Paper2226	Visual Grounding of Whole Radiology Reports for 3D CT Images	The code and dataset have not been made publicly available.   As stated above, the paper lacks many critical details on how certain subnetworks are trained and how the comparison experiments are conducted.								This paper does not release the datasets, code, and links to the image annotation software (Synapse 3D V6.8, FUJIFILM corporation, Japan), which results in poor reproducibility.								The results are reproducible only if the code and the dataset are released.											0	0	0	0	0	0	
711-Paper2041	Visual-Attribute Prompt Learning for Progressive Mild Cognitive Impairment Prediction	Good. The code will be released, and the dataset is public.								The authors promise to provide the source code. The reproducibility is okay.								Should not be difficult to reproduce if code is released.											0	0	0	0	0	0	
712-Paper3421	vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-level Representations in Medical Images	The authors have promised to release code and models, thus is fully reproducible.								The author will release the code and the pre-trained model. Looking forward to it.								The authors agree to release the code in the checklist.											0	0	0	0	0	0	
713-Paper1574	Wall thickness estimation from short axis ultrasound images via temporal compatible deformation learning	reproducibility is good.								The paper lacks of details about how to measure LVWT based on the obtained segmentations. Is the estimation of LVWT automatic or manual? After clearly presented that, it may be reproducible. In addition, training details should be presented to prove the reproducible capability. Since there are two sub modules for rigid and deformable registration and no deformation field is provided for directly supervision, I think there are tricks to train the model, i.e. maybe the two modules are not trained simultaneously. Something like that should be referred to make the paper convincing.								The data collection process is briefly described and the dataset is not provided.											0	0	0	0	0	0	
714-Paper3150	WarpEM: Dynamic Time Warping for Accurate Catheter Registration in EM-guided Procedures	Moderate reproducibility; the data are not made available but the algorithms and hardware are well described.								Though no code is publicly available, a motivated and informed student could reimplement it in a reasonable time.  The phantom used is based on a publicly available data set (Johns Hopkins University Data archive).								The reproducibility of the paper is satisfactory.											0	0	0	0	0	0	
715-Paper1867	Wasserstein Distance-Preserving Vector Space of Persistent Homology	All the theoretic formulations and algorithmic details are thoroughly explained, the data sets are publically available, there are open source libraries for persistent homology, so the work is easy to be reproduced by a graduate student who is familiar with the basic concept of persistent homology.								The authors did not provide a link to their code but will share it after acceptance as indicated by their answers to the reproducibility checklist.								This depends on whether the author will release the code or not.											0	0	0	0	0	0	
716-Paper3183	Weakly Supervised Cerebellar Cortical Surface Parcellation with Self-Visual Representation Learning	Section 3.1 provides some details on the network architecture. Details on the hyperparams used in training are not provided. Some details are missing Are the authors planning to make the code								Several crucial details, including hyperparameters, network architecture, and learning rates, are missing, and the code is not available, which significantly undermines the reproducibility of this work.								yes											0	0	0	0	0	0	
717-Paper2557	Weakly Supervised Lesion Localization of Nascent Geographic Atrophy in Age-Related Macular Degeneration	Method is well described. No code is provided.								Reproducible.								The authors employed cross-validation on their internal dataset to evaluate the performance of their model. However, no external data was used for validation, which may impact the reproducibility and generalizability of the findings.											0	0	0	0	0	0	
718-Paper0177	Weakly Supervised Medical Image Segmentation via Superpixel-guided Scribble Walking and Class-wise Contrastive Regularization	Good reproducibility								I believe the method is not explained clearly enough (see weaknesses) to be easily reproduced without having code available.								The reproducibility is good. The authors build on top of the dual decoder framework DBMS [1] which has open-source code and it could easily be extended with the description of their method in the paper. They will also publish their code. The dataset they use is publicly available.  [1] Luo et al. Scribble-supervised medical image segmentation via dual-branch network and dynamically mixed pseudo labels supervision, MICCAI 2022											0	0	0	0	0	0	
719-Paper3550	Weakly-supervised Drug Efficiency Estimation with Confidence Score: Application to COVID-19 Drug Discovery	No code provided, if there is, then it is possible to improve the reproducibility.								Good.								Not certain of its reproducibility (only one dataset, one metric to validate, no code furnish).											0	0	0	0	0	0	
720-Paper1279	Weakly-supervised positional contrastive learning: application to cirrhosis classification	The experimental settings and model architectures(tinynet) are introduced in the paper. The reproducibility will be better if the author could further elaborate the loss function.								The authors validated their approach on three different datasets, including a public LIHC dataset.  The authors will make their code available.								ok											0	0	0	0	0	0	
721-Paper0147	WeakPolyp: You Only Look Bounding Box for Polyp Segmentation	The author has provided some of the details. However, there are some of the information missing such as what is the number of testing case and hard testing case in the Polyp-SEG dataset. Moreover, how do they define if it is an easy case or hard case?								The bounding box generation strategy is not given and some results are achieved on a private dataset. To guarantee reproducibility, code release may be required.								The comments											0	0	0	0	0	0	
722-Paper1367	What Do AEs Learn? Challenging Common Assumptions in Unsupervised Anomaly Detection	Although the paper does not address important implementation details, the paper contains GitHub project repository link.								The authors provide an anonymous repository with all the code and links to the datasets.								The authors already have a source code that seems ready to be released, but implementation details are still missing from the paper.											0	0	0	0	0	0	
723-Paper0873	Whole-Heart Reconstruction with Explicit Topology Integrated Learning	The results should be reproducible.								It seems OK								The authors have provided most of the details that are needed for the paper to be reproducible. However, they are split between the paper and the supplementary material in somewhat of an odd manner. For example, the paper discusses the loss functions but not the optimization. However, deep learning cannot be done without the minimization of the loss function by an optimization method. Etcetera.											0	0	0	0	0	0	
724-Paper1646	X2Vision : 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior	The reimplementation of this work is moderate since there was missing information on how the differentiable Cone-beam projection was set up.								Training the generative model may not be easy for other people to reproduce the results. It would be better if the author could provide the code for training the generator or resease the weights.								N.A.											0	0	0	0	0	0	
725-Paper1587	Xplainer: From X-Ray Observations to Explainable Zero-Shot Diagnosis	What was the actual prompt tuning setting to generate the good response is not clear.								to an extent								Not much experimental details are provided. It may be hard to reproduce.											0	0	0	0	0	0	
726-Paper3129	X-Ray to CT Rigid Registration Using Scene Coordinate Regression	There are appended registration result figures in the manuscript. The manuscript does not mention the publication of the code if accepted.								While not all information is provided (e.g., code), authors did report in the manuscript what they stated in the reproducibility form.								Should be reproducible given that the method is relatively straightforward											0	0	0	0	0	0	
727-Paper0235	YONA: You Only Need One Adjacent Reference-frame for Accurate and Fast Video Polyp Detection	Yes the authors will make aspects of their code and details available on acceptance								The authors performs experimental evaluation by using existing open-access datasets. They have the intend to publish their code after the acceptance. With the open-access datasets and shared code, it can offer the repeatability.								Public dataset: Authors train and evaluate the models by using three public datasets; SUN Colonoscopy Video Database, LDPolypVideon, and d CVC-VideoClinicDB.  Good explanation of models: The proposed model is explained and authors will provide codes if this paper is accepted.											0	0	0	0	0	0	
728-Paper0193	You Don't Have to Be Perfect to Be Amazing: Unveil the Utility of Synthetic Images	The authors will release code upon acceptance. Paper seems to adhere to guidelines of the conference.								Not certianly sure about the reproducibility.								The authors have provided information that allows a very high degree of reproducibility (including github repositories and data sources).											0	0	0	0	0	0	
729-Paper1950	You've Got Two Teachers: Co-evolutionary Image and Report Distillation for Semi-supervised Anatomical Abnormality Detection in Chest X-ray	Despite its conceptual simplicity, the proposed training method has many parts working together. Authors refer to another paper for their hyperparameter selection since they have used the default settings there. The authors also state that the code will be released but it is difficult to assess the reproducibility currently.								The authors will share their code and implementation to the research community which will help ensure the reproducibility of the work.								The authors will release the code and model upon acceptance. The training configurations discussed in the paper should be good for the reproducibility.											0	0	0	0	0	0	
730-Paper2592	Zero-shot Nuclei Detection via Visual-Language Pre-trained Models	The schematic of the framework is a good guidance for implementing a similar pipeline. However, a lack of detail in how the self training is accomplished can mean that the tables in the paper may not be easy to reproduce without accompanying code.								Although the claim in the paper states that the code is available at a particular repository address, it is important to note that the code has not yet been shared in the supplementary material. As a result, there is a possibility that this claim may not be fulfilled in the future. Its dataset is publicly available.								Key modules, GLIP, BLIP and YOLOX follow default setting. It should be easy to reproduce the results.											0	0	0	0	0	0	