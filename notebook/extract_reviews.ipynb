{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_review_text = {\n",
    "    \"contribution\" : \"Please describe the contribution of the paper\",\n",
    "    \"strenghts\" : \"Please list the main strengths of the paper\",\n",
    "    \"weakness\" : \"Please list the main weaknesses of the paper\",\n",
    "    \"clarity\" : \"Please rate the clarity and organization of this paper\",\n",
    "    \"repro\" : \"Please comment on the reproducibility of the paper\",\n",
    "    \"detailed\" : \"Please provide detailed and constructive comments for the authors\",\n",
    "    \"rate\" : \"Rate the paper on a scale of 1-8, 8 being the strongest\",\n",
    "    \"justifictation\" : \"Please justify your recommendation.\",\n",
    "    \"number of paper\": \"Number of papers in your stack\",\n",
    "    \"ranking\" : \"What is the ranking of this paper in your review stack?\",\n",
    "    \"confidence\" : \"Reviewer confidence\",\n",
    "    \"rate rebuttal\" : \"[Post rebuttal] After reading the authorâ€™s rebuttal, state your overall opinion of the paper if it has been changed\",\n",
    "    \"justification rebuttal\" : \"[Post rebuttal] Please justify your decision\",\n",
    "}\n",
    "\n",
    "list_categories_str = [ \"contribution\", \"strenghts\", \"weakness\", \"repro\", \"detailed\", \"justifictation\" ]\n",
    "list_categories_scores = [\"clarity\", \"rate\", \"confidence\", \"rate rebuttal\"]\n",
    "\n",
    "columns_reviews = [\"id\", \"category\", \"title\" ,\"review 1\" ,\"review 2\" , \"review 3\", ]\n",
    "columns_statistics = [\"id\", \"category\", \"title\" , \"words1\", \"words2\", \"words3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all the html files from the year chosen\n",
    "def get_accepted_paper_list(year: str = \"2023\"):\n",
    "    \"\"\"\n",
    "    Get the list of all html files\n",
    "    \"\"\"\n",
    "\n",
    "    miccai_website_path = \"https://conferences.miccai.org\"\n",
    "    path_online_list = miccai_website_path + f\"/{year}/papers/\"\n",
    "\n",
    "    reponse = urllib.request.urlopen(path_online_list)\n",
    "    contenu_web = reponse.read().decode('UTF-8')\n",
    "    soup = BeautifulSoup(contenu_web, \"html.parser\")\n",
    "\n",
    "    all = soup.find_all('a')\n",
    "    paper_list = [(miccai_website_path + link.get('href')) for link in all if link.get('href').endswith('html')]\n",
    "\n",
    "    return paper_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_ = \"2023\"\n",
    "paper_list = get_accepted_paper_list(year=year_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews(paper, df_reviews, df_stats, year=\"2023\",  category= \"repro\"):\n",
    "    \n",
    "    # open html webpage and extract with BeautifulSoup\n",
    "    reponse = urllib.request.urlopen(paper)\n",
    "    contenu_web = reponse.read().decode('UTF-8')\n",
    "    soup = BeautifulSoup(contenu_web, \"html.parser\")\n",
    "\n",
    "    if year == \"2023\" :\n",
    "        paper_title = soup.find(\"title\").get_text().rstrip(\"MICCAI 2023 - Accepted Papers, Reviews, Author Feedback\").rstrip(' |')\n",
    "    elif year == \"2022\" :\n",
    "        paper_title = soup.find(\"title\").get_text().rstrip(\"MICCAI 2022 - Accepted Papers and Reviews\").rstrip(' |')\n",
    "\n",
    "    paper_id = Path(paper).name[:13]\n",
    "    text = list_review_text[category]\n",
    "    repro_reviews_paragraph = soup.find_all(lambda tag: tag.name == \"li\" and text in tag.text)\n",
    "    repro_exact_text = soup.find(lambda tag: tag.name == \"strong\" and text in tag.text).get_text()\n",
    "\n",
    "    i=0\n",
    "    for review in repro_reviews_paragraph[:3]:\n",
    "        i +=1\n",
    "        tmp_review = unidecode(review.get_text().strip(repro_exact_text))\n",
    "        tmp_review = tmp_review.strip(\"\\n\")\n",
    "        tmp_review = tmp_review.replace(\"\\n          \\n\",\" \")\n",
    "        tmp_review = tmp_review.replace(\"\\t\", \" \")\n",
    "        tmp_review = tmp_review.replace(\"\\n\\n\\n\\n\",\" \")\n",
    "        tmp_review = tmp_review.replace(\"\\n\\n\\n\",\" \")\n",
    "        tmp_review = tmp_review.replace(\"\\n\\n\",\" \")\n",
    "        tmp_review = tmp_review.replace(\"\\n\",\" \")\n",
    "        tmp_review = tmp_review.replace(\"\\t\", \" \")\n",
    "\n",
    "        df_reviews.loc[(paper_id, unidecode(paper_title)), (category, f\"review {i}\")]=tmp_review\n",
    "        df_stats.loc[(paper_id, unidecode(paper_title)), (category, f\"review {i}\")]=len(str(tmp_review).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_reproducibility_paragraph(paper_list, year= \"2023\"):\n",
    "    # Extract the reproducibility paragraph from the reviews and export as csv file\n",
    "    iterables = [list_categories_str, [\"review 1\", \"review 2\", \"review 3\"]]\n",
    "\n",
    "    index_line = pd.MultiIndex.from_product(iterables, names=[\"category\", \"review\"])\n",
    "    index_column = pd.MultiIndex.from_product( [[], []], names=[\"id\", \"title\"])\n",
    "\n",
    "    df_reviews = pd.DataFrame(index = index_column, columns=index_line)\n",
    "    df_stats = pd.DataFrame(index = index_column, columns=index_line)\n",
    "\n",
    "    for paper in paper_list:\n",
    "        for category in list_categories_str:\n",
    "             \n",
    "            extract_reviews(paper, df_reviews, df_stats, year, category)\n",
    "\n",
    "    return df_reviews, df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create th output directory \n",
    "output_directory = Path(f\"../miccai{year_}/\")\n",
    "if not output_directory.is_dir():\n",
    "    os.mkdir(output_directory)\n",
    "path_all_reviews = output_directory / 'all_reviews.csv'\n",
    "path_all_stats = output_directory / 'count_words.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract reviews and count word for year 2023\n"
     ]
    }
   ],
   "source": [
    "# extract 33 min  \n",
    "if (not path_all_reviews.is_file()) or (not path_all_stats.is_file()):\n",
    "\n",
    "    print(f\"Extract reviews and count word for year {year_}\")\n",
    "    df_all_reviews, df_all_stats = extract_reproducibility_paragraph(paper_list, year_)\n",
    "\n",
    "    df_all_reviews.to_csv(path_all_reviews, index = True, sep=\"\\t\", encoding='utf-8')\n",
    "    df_all_stats.to_csv(path_all_stats, index = True, sep=\"\\t\", encoding='utf-8')\n",
    "\n",
    "else:\n",
    "    import pandas as pd\n",
    "    print(f\"Import tsv from {output_directory}\")\n",
    "\n",
    "    df_all_reviews = pd.read_csv(path_all_reviews, sep= \"\\t\",  header=[0, 1], index_col=[0,1], skip_blank_lines=True)\n",
    "    df_all_stats = pd.read_csv(path_all_stats, sep= \"\\t\",  header=[0, 1], index_col=[0,1], skip_blank_lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repro_copy_paste(df_all_reviews, output_directory= \"../results\", threshold:int  = 10 ):\n",
    "\n",
    "    from copy import copy\n",
    "    df_all_reviews_wo_copy_paste = copy(df_all_reviews)\n",
    "    df_bad_reviews = pd.DataFrame(columns=columns_reviews)\n",
    "    df_bad_reviews.set_index([\"id\", \"category\"], inplace= True)\n",
    "    \n",
    "    for id, id_df in df_all_reviews.groupby(level=0):\n",
    "        for _, title in id_df.index.values:\n",
    "            for category in list_categories_str:\n",
    "                if category != \"repro\" :\n",
    "                    for i in range(1,3):\n",
    "                        repro = id_df.loc[(id,title), (\"repro\", f\"review {i}\")]\n",
    "                        cate = id_df.loc[(id, title), (category, f\"review {i}\")]\n",
    "                        if len(str(repro)) > threshold : \n",
    "                            if str(repro) in str(cate):\n",
    "                                df_bad_reviews.loc[(id, title), (category, f\"review {i}\")] = id_df.loc[(id, title), (category, f\"review {i}\")]\n",
    "                                try :\n",
    "                                    df_all_reviews_wo_copy_paste.drop((id, title), inplace=True)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "        \n",
    "    df_all_reviews_wo_copy_paste.to_csv(os.path.join(output_directory ,f'all_reviews_wo_copy_paste.csv'), index = True, sep=\"\\t\", encoding='utf-8')\n",
    "    df_bad_reviews.to_csv(os.path.join(output_directory ,f'copy_paste_reviews_{threshold}.csv'), index = True, sep=\"\\t\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/03/3_l2qbvj5sjf070rq3vks9rc001396/T/ipykernel_47235/1742350489.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'The code is not provided. The method is built upon the training segmentation label.' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_bad_reviews.loc[(id, title), (category, f\"review {i}\")] = id_df.loc[(id, title), (category, f\"review {i}\")]\n",
      "/var/folders/03/3_l2qbvj5sjf070rq3vks9rc001396/T/ipykernel_47235/1742350489.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Insufficient Dataset Description: The authors have not provided an adequate description of the dataset utilized in the study, which may hinder the reader's understanding of the context and the applicability of the proposed method. Furthermore, the lack of information regarding the preprocessing steps implemented in the research could adversely affect the reproducibility of the method, thereby limiting its potential adoption by other researchers. Disorganized Introduction Section: The Introduction section of the paper appears to be lacking in organization and clarity, making it difficult for the reader to grasp the importance and motivation behind the proposed method. A well-structured Introduction that clearly outlines the research problem, its significance, and the authors' approach to addressing it is crucial for setting the context and engaging the readers. Inadequate Description of Previous Methods: While the paper compares the proposed method with earlier approaches in the field, the authors have not provided sufficient information about these previous methods. A brief but informative overview of the earlier approaches would have been valuable in helping the reader understand the limitations of existing methods and the reasons behind the development of the proposed method. This additional context would further emphasize the novelty and potential benefits of the authors' work. Addressing these weaknesses in the paper would greatly enhance its overall quality and increase its potential to make a meaningful contribution to the existing body of literature in the field' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_bad_reviews.loc[(id, title), (category, f\"review {i}\")] = id_df.loc[(id, title), (category, f\"review {i}\")]\n"
     ]
    }
   ],
   "source": [
    "# Get the list of review where the reviewer had copy/paste the review repro from another review\n",
    "get_repro_copy_paste(df_all_reviews=df_all_reviews, output_directory=output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_checklist(df_all_reviews, output_directory= \"../results\", category = \"repro\"):\n",
    "\n",
    "    df_checklist  = pd.DataFrame(columns=columns_reviews)\n",
    "    df_checklist.set_index([\"id\", \"category\"], inplace= True)\n",
    "    for id, id_df in df_all_reviews.groupby(level=0):\n",
    "        for _, title in id_df.index.values:\n",
    "            for i in range(1,4):\n",
    "                review = str(df_all_reviews.loc[(id, title), (category, f\"review {i}\")])\n",
    "\n",
    "                if (\"check-list\" in review) or (\"checklist\" in review) or (\"check list\" in review):\n",
    "                    df_checklist.loc[(id, title), (category, f\"review {i}\")] = df_all_reviews.loc[(id, title), (category, f\"review {i}\")]\n",
    "\n",
    "    df_checklist.to_csv(os.path.join(output_directory ,f'nb_checklist_{category}.csv'), index = True, sep=\"\\t\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/03/3_l2qbvj5sjf070rq3vks9rc001396/T/ipykernel_47235/1742228500.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Reproducibility should be possible, as training and evaluation code is provided (based on the checklist).' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_checklist.loc[(id, title), (category, f\"review {i}\")] = df_all_reviews.loc[(id, title), (category, f\"review {i}\")]\n"
     ]
    }
   ],
   "source": [
    "# Count the number of occurrences of the word checklist in the repro reviews\n",
    "count_checklist(df_all_reviews=df_all_reviews, output_directory=output_directory, category=\"repro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rating_excel(df_all_reviews, output_directory=\"../results\"):\n",
    "    df_repro_excel = df_all_reviews.loc[:, (\"repro\")]\n",
    "    df_repro_excel.to_excel(os.path.join('../rating' ,f'reviwes_repro_{year_}.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the excel file with the repro reviews to create the rating file\n",
    "create_rating_excel(df_all_reviews= df_all_reviews, output_directory= output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "# pas de resultats dans ce notebook\n",
    "\n",
    "\n",
    "# spliter les fonctions \n",
    "# print plus de trucs pour que ca soit plus beau et lisible \n",
    "\n",
    "\n",
    "# dans rating_analysisn \n",
    "# correler la longueur de la review repro a la longueur totale\n",
    "# Donner des examples au hasard\n",
    "#   - entre 40 et 60 centiles\n",
    "#   - entre 0 et 30 centiles\n",
    "# extraire les scores !!!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproducibility-reviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
