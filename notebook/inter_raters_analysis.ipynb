{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boostrap function for cohen kappa score \n",
    "def bootstrap_cqk(y_true, y_pred, quad=False, num_resamples = 999):\n",
    "    Y = np.array([y_true, y_pred]).T\n",
    "\n",
    "    weighted_kappas = []\n",
    "    for i in range(num_resamples):\n",
    "        Y_resample = np.array(random.choices(Y, k=len(Y)))\n",
    "        y_true_resample = Y_resample[:, 0]\n",
    "        y_pred_resample = Y_resample[:, 1]\n",
    "        if quad==False:\n",
    "            weighted_kappa = cohen_kappa_score(y_true_resample.astype(str), y_pred_resample.astype(str))\n",
    "        else: \n",
    "            weighted_kappa = cohen_kappa_score(y_true_resample.astype(str), y_pred_resample.astype(str), weights='quadratic')\n",
    "        weighted_kappas.append(weighted_kappa)\n",
    "\n",
    "    return np.mean(weighted_kappas), np.std(weighted_kappas), np.percentile(weighted_kappas, 2.25), np.percentile(weighted_kappas, 97.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create confusion matrix \n",
    "def create_confusion_matrix(list_1: list , list_2: list)-> pd.DataFrame:\n",
    "    if not len(list_1)==len(list_2):\n",
    "        print(\"reviwer 1 and 2 may haven't rated the same list of subjects\")\n",
    "\n",
    "    else:\n",
    "        list_attributs = []\n",
    "        for i in list_1:\n",
    "            if i not in list_attributs:\n",
    "                list_attributs.append(i)\n",
    "        for i in list_2:\n",
    "            if i not in list_attributs:\n",
    "                list_attributs.append(i)\n",
    "\n",
    "\n",
    "        size = len(list_attributs)\n",
    "        matrix = pd.DataFrame(np.zeros((size + 1, size + 1)))\n",
    "        for k in range(size):\n",
    "            for l in range(size):\n",
    "                att_1 = list_attributs[k]\n",
    "                att_2 = list_attributs[l]\n",
    "                for i in range(len(list_1)):\n",
    "                    if (list_1[i]== att_1):\n",
    "                        if list_2[i] == att_2 :\n",
    "                                matrix.loc[k,l]+=1\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                matrix.loc[size, i] += matrix.loc[j, i]\n",
    "                matrix.loc[i, size] += matrix.loc[i, j]\n",
    "        for i in range(size):      \n",
    "            matrix.loc[size, size] += matrix.loc[i, size]\n",
    "        matrix = matrix / len(list_1)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the overall proportion of agreement expected by chance\n",
    "def expected_proportion(matrix: pd.DataFrame):\n",
    "    pe = 0\n",
    "    k = len(matrix)-1\n",
    "    for i in range(k):\n",
    "        pe += matrix.loc[i, k] * matrix.loc[k, i]\n",
    "    return pe\n",
    "\n",
    "# function to calculate the overall proportion of observed agreement \n",
    "def observed_proportion(matrix: pd.DataFrame):\n",
    "    po = 0\n",
    "    k = len(matrix) - 1\n",
    "    for i in range(k):\n",
    "        po += matrix.loc[i, i]\n",
    "    return po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the standard error\n",
    "def sd_cohen(po, pe):\n",
    "    sd_= sqrt((po*(1-po))/((1-pe)*(1-pe)))\n",
    "    return sd_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sd_fleiss(po, pe, matrix):\n",
    "    y1 = 0\n",
    "    y2 = 0 \n",
    "    k = len(matrix) -1\n",
    "\n",
    "    for i in range (k):\n",
    "        for j in range(k):\n",
    "            if j != i:\n",
    "                carre = (matrix.loc[k,i] + matrix.loc[j,k])\n",
    "                carre = carre*carre\n",
    "                y1 += matrix.loc[i,j] * carre\n",
    "        carre2 = (matrix.loc[k,i] + matrix.loc[i,k])  \n",
    "        carre2 = carre2*carre2   \n",
    "        y2 += matrix.loc[i,i] * carre2\n",
    "    y3 = ((po*pe) - (2*pe) + po)\n",
    "    y3 = y3*y3\n",
    "    x = (po*(1-pe)*(1-pe)) + ((1-po)*(1-po)* y1) - (2*(1-pe)*(1-po)*y2) - y3\n",
    "    \n",
    "    if x < 0:\n",
    "        x = 0\n",
    "    res = sqrt(x)\n",
    "    sd_ = res/((1-pe)*(1-pe))\n",
    "    return sd_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculcate the kappa score\n",
    "def kappa(po, pe):\n",
    "    return (po-pe)/(1-pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to write stats in the dataframe\n",
    "def write_stat(df_final, category, method, kappa_, low_, high_, se_):\n",
    "    df_final.loc[category, (\"kappa score\", method)]=kappa_\n",
    "    df_final.loc[category, (\"ci low\", method)]=low_\n",
    "    df_final.loc[category, (\"ci high\", method)]=high_\n",
    "    df_final.loc[category, (\"se\", method)]=se_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "       36, 37, 38, 39, 40, 41],\n",
      "      dtype='int64')\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Enter the path to the tsv file with the rating from the first reviwer\n",
    "path_tsv = \"../rating/rating_90/rating_90_O.tsv\"\n",
    "df_rating_1 = pd.read_csv(path_tsv, sep = \"\\t\", index_col=False, header= None)\n",
    "print(df_rating_1.columns)\n",
    "print(len(df_rating_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the tsv file with the rating from the second reviwer\n",
    "path_tsv = \"../rating/rating_90/rating_90_E.tsv\"\n",
    "df_rating_2 = pd.read_csv(path_tsv, sep = \"\\t\", index_col=False, header= None)\n",
    "#df_rating_2 = df_rating_2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of categories you want to make statistics for\n",
    "list_categories = [\n",
    "        \"Models and algorithms\",\n",
    "        \"Datasets\",\n",
    "        \"Code\",\n",
    "        \"Experimental results\",\n",
    "        \"Error bars or statistical significance\",\n",
    "        \"Code is or will be available\",\n",
    "        \"Statement\",\n",
    "        \"Comments\",\n",
    "        \"Meta-categories\",\n",
    "    ]\n",
    "list_methods = [\"bootstrap\", \"cohen\", \"fleiss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Models and algorithms', 'Datasets', 'Code', 'Experimental results',\n",
      "       'Error bars or statistical significance',\n",
      "       'Code is or will be available', 'Statement', 'Comments',\n",
      "       'Meta-categories'],\n",
      "      dtype='object')\n",
      "MultiIndex([('kappa score', 'bootstrap'),\n",
      "            ('kappa score',     'cohen'),\n",
      "            ('kappa score',    'fleiss'),\n",
      "            (     'ci low', 'bootstrap'),\n",
      "            (     'ci low',     'cohen'),\n",
      "            (     'ci low',    'fleiss'),\n",
      "            (    'ci high', 'bootstrap'),\n",
      "            (    'ci high',     'cohen'),\n",
      "            (    'ci high',    'fleiss'),\n",
      "            (         'se', 'bootstrap'),\n",
      "            (         'se',     'cohen'),\n",
      "            (         'se',    'fleiss')],\n",
      "           names=['stat', 'method'])\n"
     ]
    }
   ],
   "source": [
    "# function to create the DataFrame \n",
    "\n",
    "list_stats = [\"kappa score\", \"ci low\", \"ci high\", \"se\"]\n",
    "\n",
    "index_line = pd.Index(list_categories)\n",
    "index_column = pd.MultiIndex.from_product( [list_stats, list_methods], names=[\"stat\", \"method\"])\n",
    "\n",
    "df_final = pd.DataFrame(index=index_line, columns=index_column)\n",
    "\n",
    "print(df_final.index)\n",
    "print(df_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Models and algorithms review :\n",
      "Number of reviews = 270\n",
      "kappa = 0.7544080604534007\n",
      "kappa bootstrap = 0.7564141291325301\n",
      "ci bootstrap = [0.6637332013171947, 0.8381103001465815]\n",
      "standard error (bootstrap) = 0.04469373024089908\n",
      "standard error (cohen) = 0.04578681833590641\n",
      "**************************************************\n",
      "For Datasets review :\n",
      "Number of reviews = 270\n",
      "kappa = 0.9085872576177285\n",
      "kappa bootstrap = 0.9070841362859365\n",
      "ci bootstrap = [0.84977569724945, 0.9586728789708813]\n",
      "standard error (bootstrap) = 0.027062463690914217\n",
      "standard error (cohen) = 0.02699469316029271\n",
      "**************************************************\n",
      "For Code review :\n",
      "Number of reviews = 270\n",
      "kappa = 0.9107142857142856\n",
      "kappa bootstrap = 0.909991929971716\n",
      "ci bootstrap = [0.857930902019855, 0.9555482383931512]\n",
      "standard error (bootstrap) = 0.026141215670303867\n",
      "standard error (cohen) = 0.025195287895238696\n",
      "**************************************************\n",
      "For Experimental results review :\n",
      "Number of reviews = 270\n",
      "kappa = 0.8637248539909151\n",
      "kappa bootstrap = 0.8622801733975665\n",
      "ci bootstrap = [0.7835131890785159, 0.9289770048870333]\n",
      "standard error (bootstrap) = 0.03667767436502678\n",
      "standard error (cohen) = 0.03546424664835681\n",
      "**************************************************\n",
      "For Error bars or statistical significance review :\n",
      "Number of reviews = 270\n",
      "kappa = 1.0\n",
      "kappa bootstrap = 0.8622801733975665\n",
      "ci bootstrap = [0.7835131890785159, 0.9289770048870333]\n",
      "standard error (bootstrap) = 0.03667767436502678\n",
      "standard error (cohen) = 0.0\n",
      "**************************************************\n",
      "For Code is or will be available review :\n",
      "Number of reviews = 270\n",
      "kappa = 0.8688536840532057\n",
      "kappa bootstrap = 0.8664551687860028\n",
      "ci bootstrap = [0.7928708916761787, 0.9307413927156133]\n",
      "standard error (bootstrap) = 0.03512232756501183\n",
      "standard error (cohen) = 0.03548698465277313\n",
      "**************************************************\n",
      "For Statement review :\n",
      "Number of reviews = 270\n",
      "kappa = 0.736981934112646\n",
      "kappa bootstrap = 0.7357994376475071\n",
      "ci bootstrap = [0.6619998453545102, 0.8058514589538623]\n",
      "standard error (bootstrap) = 0.03671461005325724\n",
      "standard error (cohen) = 0.036277017882491984\n",
      "**************************************************\n",
      "For Comments review :\n",
      "Number of reviews = 270\n",
      "kappa = 0.8155936590100292\n",
      "kappa bootstrap = 0.8154006791545824\n",
      "ci bootstrap = [0.7579387511732666, 0.8693159381519465]\n",
      "standard error (bootstrap) = 0.027993807398059355\n",
      "standard error (cohen) = 0.027729763312196995\n",
      "**************************************************\n",
      "20\n",
      "19\n",
      "For Review 3 review :\n",
      "Number of reviews = 270\n",
      "kappa = 0.8014027898179528\n",
      "kappa bootstrap = 0.8003631774234397\n",
      "ci bootstrap = [0.729151279236493, 0.8663405285567243]\n",
      "standard error (bootstrap) = 0.03426511734780613\n",
      "standard error (cohen) = 0.0355320225157398\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for category in range(len(list_categories)):\n",
    "    all_reviews_1 = []\n",
    "    all_reviews_2 = []\n",
    "    for i in range(3):\n",
    "\n",
    "        if list_categories[category] == \"Meta-categories\":\n",
    "            column_id = i + 29\n",
    "        else: \n",
    "            column_id = i*9 + 3 + category\n",
    "        \n",
    "        list_review_1 = df_rating_1.loc[2:, column_id].values.tolist()\n",
    "        list_review_2 = df_rating_2.loc[2:, column_id].values.tolist()\n",
    "\n",
    "        all_reviews_1 = all_reviews_1 + list_review_1\n",
    "        all_reviews_2 = all_reviews_2 + list_review_2\n",
    "\n",
    "    if list_categories[category] == \"Meta-categories\":\n",
    "        test = all_reviews_1.count(\"Unusable\")\n",
    "        test2 = all_reviews_2.count(\"Unusable\")\n",
    "        print(test)\n",
    "        print(test2)\n",
    "\n",
    "    N = len(all_reviews_1)\n",
    "    if list_categories[category] != \"Error bars or statistical significance\":\n",
    "        kappa_btp, se_btp, low_btp, high_btp = bootstrap_cqk(y_true=all_reviews_1, y_pred=all_reviews_2)\n",
    "        write_stat(df_final, list_categories[category], \"bootstrap\", kappa_btp, low_btp, high_btp, se_btp)\n",
    "        \n",
    "    confusion_matrix = create_confusion_matrix(list_1=all_reviews_1, list_2=all_reviews_2)\n",
    "    po_ = observed_proportion(confusion_matrix)\n",
    "    pe_ = expected_proportion(confusion_matrix)\n",
    "    kappa_ = kappa(po_, pe_)\n",
    "        \n",
    "    sd_cohen_ = sd_cohen(po_, pe_)\n",
    "    se_cohen = sd_cohen_ / sqrt(N)\n",
    "    write_stat(df_final, list_categories[category], \"cohen\", kappa_, -1.96 * se_cohen + kappa_, 1.96 * se_cohen + kappa_, se_cohen )\n",
    "\n",
    "    sd_fleiss_ = sd_fleiss(po_, pe_, confusion_matrix)\n",
    "    se_fleiss = sd_fleiss_ / sqrt(N)\n",
    "    write_stat(df_final, list_categories[category], \"fleiss\", kappa_, -1.96 * se_fleiss + kappa_, 1.96 * se_fleiss + kappa_, se_fleiss)\n",
    "\n",
    "\n",
    "    print(f\"For {df_rating_1.loc[1, column_id]} review :\")\n",
    "    print(f\"Number of reviews = {N}\")\n",
    "    print(f\"kappa = {kappa_}\")\n",
    "    print(f\"kappa bootstrap = {kappa_btp}\")\n",
    "    print(f\"ci bootstrap = [{low_btp}, {high_btp}]\")\n",
    "    print(f\"standard error (bootstrap) = {se_btp}\")\n",
    "    #print(f\"standard error (fleiss) = { sd_fleiss_ / sqrt(N)}\")\n",
    "    print(f\"standard error (cohen) = {sd_cohen_ / sqrt(N)}\")\n",
    "    print(\"**************************************************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Meta-categories review :\n",
      "Number of reviews = 270\n",
      "kappa = 0.8014027898179528\n",
      "kappa bootstrap = 0.798857084307565\n",
      "ci bootstrap = [0.7278347705408873, 0.8632107446950131]\n",
      "standard error (bootstrap) = 0.03362957163367115\n",
      "standard error (cohen) = 0.0355320225157398\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "all_reviews_1 = []\n",
    "all_reviews_2 = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    column_id = i + 29\n",
    "    \n",
    "    list_review_1 = df_rating_1.loc[2:, column_id].values.tolist()\n",
    "    list_review_2 = df_rating_2.loc[2:, column_id].values.tolist()\n",
    "\n",
    "    all_reviews_1 = all_reviews_1 + list_review_1\n",
    "    all_reviews_2 = all_reviews_2 + list_review_2\n",
    "\n",
    "\n",
    "\n",
    "N = len(all_reviews_1)\n",
    "if list_categories[category] != \"Error bars or statistical significance\":\n",
    "    kappa_btp, se_btp, low_btp, high_btp = bootstrap_cqk(y_true=all_reviews_1, y_pred=all_reviews_2)\n",
    "    write_stat(df_final, list_categories[category], \"bootstrap\", kappa_btp, low_btp, high_btp, se_btp)\n",
    "        \n",
    "confusion_matrix = create_confusion_matrix(list_1=all_reviews_1, list_2=all_reviews_2)\n",
    "po_ = observed_proportion(confusion_matrix)\n",
    "pe_ = expected_proportion(confusion_matrix)\n",
    "kappa_ = kappa(po_, pe_)\n",
    "        \n",
    "sd_cohen_ = sd_cohen(po_, pe_)\n",
    "se_cohen = sd_cohen_ / sqrt(N)\n",
    "write_stat(df_final, list_categories[category], \"cohen\", kappa_, -1.96 * se_cohen + kappa_, 1.96 * se_cohen + kappa_, se_cohen )\n",
    "\n",
    "sd_fleiss_ = sd_fleiss(po_, pe_, confusion_matrix)\n",
    "se_fleiss = sd_fleiss_ / sqrt(N)\n",
    "write_stat(df_final, list_categories[category], \"fleiss\", kappa_, -1.96 * se_fleiss + kappa_, 1.96 * se_fleiss + kappa_, se_fleiss)\n",
    "\n",
    "\n",
    "print(f\"For Meta-categories review :\")\n",
    "print(f\"Number of reviews = {N}\")\n",
    "print(f\"kappa = {kappa_}\")\n",
    "print(f\"kappa bootstrap = {kappa_btp}\")\n",
    "print(f\"ci bootstrap = [{low_btp}, {high_btp}]\")\n",
    "print(f\"standard error (bootstrap) = {se_btp}\")\n",
    "#print(f\"standard error (fleiss) = { sd_fleiss_ / sqrt(N)}\")\n",
    "print(f\"standard error (cohen) = {sd_cohen_ / sqrt(N)}\")\n",
    "print(\"**************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Agreement review :\n",
      "Number of reviews = 90\n",
      "kappa sklearn = 0.6330275229357798\n",
      "kappa = 0.63302752293578\n",
      "kappa bootstrap = 0.6273168503460074\n",
      "ci bootstrap = [0.4609630251423987, 0.7815014188799111]\n",
      "standard error (bootstrap) = 0.08056032604616432\n",
      "standard error (fleiss) = 0.0\n",
      "standard error (cohen) = 0.08318942207177639\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# add agreement review\n",
    "\n",
    "list_agreement_1 = df_rating_1.loc[2:, 38].values.tolist()\n",
    "list_agreement_2 = df_rating_2.loc[2:, 38].values.tolist()\n",
    "\n",
    "list_bis_1 = []\n",
    "list_bis_2 = []\n",
    "for i in range(len(list_agreement_1)):\n",
    "    if list_agreement_1[i]!= \"Unusable\" and list_agreement_2[i]!= \"Unusable\":\n",
    "        list_bis_1.append(list_agreement_1[i])\n",
    "        list_bis_2.append(list_agreement_2[i])\n",
    "\n",
    "# If you uncomment the 2 next lines, then the Unusable agreement will be removed\n",
    "# list_agreement_1=list_bis_1\n",
    "# list_agreement_2=list_bis_2\n",
    "\n",
    "\n",
    "N = len(list_agreement_1)\n",
    "kappa_btp, se_btp, low_btp, high_btp = bootstrap_cqk(y_true=list_agreement_1, y_pred=list_agreement_2)\n",
    "write_stat(df_final, \"Agreement\", \"bootstrap\", kappa_btp, low_btp, high_btp, se_btp)\n",
    "\n",
    "confusion_matrix = create_confusion_matrix(list_1=list_agreement_1, list_2=list_agreement_2)\n",
    "po_ = observed_proportion(confusion_matrix)\n",
    "pe_ = expected_proportion(confusion_matrix)\n",
    "kappa_ = kappa(po_, pe_)\n",
    "\n",
    "kappa_2 = cohen_kappa_score(list_agreement_1, list_agreement_2)\n",
    "sd_cohen_ = sd_cohen(po_, pe_)\n",
    "se_cohen = sd_cohen_ / sqrt(N)\n",
    "write_stat(df_final, \"Agreement\", \"cohen\", kappa_, -1.96 * se_cohen + kappa_, 1.96 * se_cohen + kappa_, se_cohen)\n",
    "\n",
    "sd_fleiss_ = sd_fleiss(po_, pe_, confusion_matrix)\n",
    "se_fleiss = sd_fleiss_ / sqrt(N)\n",
    "write_stat(df_final, \"Agreement\", \"fleiss\", kappa_, -1.96 * se_fleiss + kappa_, 1.96 * se_fleiss + kappa_, se_fleiss)\n",
    "\n",
    "print(f\"For {df_rating_1.loc[1, 38]} review :\")\n",
    "print(f\"Number of reviews = {N}\")\n",
    "print(f\"kappa sklearn = {kappa_2}\")\n",
    "print(f\"kappa = {kappa_}\")\n",
    "print(f\"kappa bootstrap = {kappa_btp}\")\n",
    "print(f\"ci bootstrap = [{low_btp}, {high_btp}]\")\n",
    "print(f\"standard error (bootstrap) = {se_btp}\")\n",
    "print(f\"standard error (fleiss) = { sd_fleiss_ / sqrt(N)}\")\n",
    "print(f\"standard error (cohen) = {sd_cohen_ / sqrt(N)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Repo provided and not empty review :\n",
      "Number of reviews = 90\n",
      "kappa = 1.0\n",
      "kappa bootstrap = 1.0\n",
      "ci bootstrap = [1.0, 1.0]\n",
      "standard error (bootstrap) = 0.0\n",
      "standard error (fleiss) = 0.0\n",
      "standard error (cohen) = 0.0\n"
     ]
    }
   ],
   "source": [
    "# add repo provided review\n",
    "\n",
    "list_agreement_1 = df_rating_1.loc[2:, 40].values.tolist()\n",
    "list_agreement_2 = df_rating_2.loc[2:, 40].values.tolist()\n",
    "N = len(list_agreement_1)\n",
    "kappa_btp, se_btp, low_btp, high_btp = bootstrap_cqk(y_true=list_agreement_1, y_pred=list_agreement_2)\n",
    "write_stat(df_final, \"repo provided and not empty\", \"bootstrap\", kappa_btp, low_btp, high_btp, se_btp)\n",
    "\n",
    "confusion_matrix = create_confusion_matrix(list_1=list_agreement_1, list_2=list_agreement_2)\n",
    "po_ = observed_proportion(confusion_matrix)\n",
    "pe_ = expected_proportion(confusion_matrix)\n",
    "kappa_ = kappa(po_, pe_)\n",
    "\n",
    "sd_cohen_ = sd_cohen(po_, pe_)\n",
    "se_cohen = sd_cohen_ / sqrt(N)\n",
    "write_stat(df_final, \"repo provided and not empty\", \"cohen\", kappa_, -1.96 * se_cohen + kappa_, 1.96 * se_cohen + kappa_, se_cohen)\n",
    "\n",
    "sd_fleiss_ = sd_fleiss(po_, pe_, confusion_matrix)\n",
    "se_fleiss = sd_fleiss_ / sqrt(N)\n",
    "write_stat(df_final, \"repo provided and not empty\", \"fleiss\", kappa_, -1.96 * se_fleiss + kappa_, 1.96 * se_fleiss + kappa_, se_fleiss)\n",
    "\n",
    "print(f\"For {df_rating_1.loc[1, 40]} review :\")\n",
    "print(f\"Number of reviews = {N}\")\n",
    "print(f\"kappa = {kappa_}\")\n",
    "print(f\"kappa bootstrap = {kappa_btp}\")\n",
    "print(f\"ci bootstrap = [{low_btp}, {high_btp}]\")\n",
    "print(f\"standard error (bootstrap) = {se_btp}\")\n",
    "print(f\"standard error (fleiss) = { sd_fleiss_ / sqrt(N)}\")\n",
    "print(f\"standard error (cohen) = {sd_cohen_ / sqrt(N)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final df to csv file \n",
    "df_final.to_csv(\"../rating/rating_90/inter_raters_analysis.csv\", index = True, sep=\";\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "# split cells and delete some function \n",
    "# carreful about path "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproducibility-reviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
