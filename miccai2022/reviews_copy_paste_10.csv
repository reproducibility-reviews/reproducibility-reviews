id	category	title	review1	review2	review3	weakness	review 1	strenghts	review 2	detailed	justifictation
056-Paper0386	AutoGAN-Synthesizer: Neural Architecture Search for Cross-Modality MRI Synthesis					1: The main ideas of the paper are known or incremental advances over past work.  Besides, the incorporation of the K-spcace has also been employed in some medical image processing works. 2: The number of images are too small to obtain meaningful training results. There are only 75 samples of BRATS2018 dataset and 25 samples of IXI dataset for training. 3: The experimental setup details are incomplete. For example, the value of  and  in Equation(3) is unclear. The authors should provide the value of the hyper-parameters for the reproduction. 4: The code and the data are not available to aid reproducibility.	1: The main ideas of the paper are known or incremental advances over past work.  Besides, the incorporation of the K-spcace has also been employed in some medical image processing works. 2: The number of images are too small to obtain meaningful training results. There are only 75 samples of BRATS2018 dataset and 25 samples of IXI dataset for training. 3: The experimental setup details are incomplete. For example, the value of  and  in Equation(3) is unclear. The authors should provide the value of the hyper-parameters for the reproduction. 4: The code and the data are not available to aid reproducibility.				
138-Paper2325	Deep Reinforcement Learning for Small Bowel Path Tracking using Different Types of Annotations							The manuscript is well-organised and information is easy to find within the respective sections Sufficient details have been provided in order for the work to be reproducible The problem being solved is well-motivated and properly justified using previous work	The manuscript is well-organised and information is easy to find within the respective sections Sufficient details have been provided in order for the work to be reproducible The problem being solved is well-motivated and properly justified using previous work		
283-Paper0492	Learning Robust Representation for Joint Grading of Ophthalmic Diseases via Adaptive Curriculum and Feature Disentanglement					details of the network needs to be clearer			details of the network needs to be clearer		
295-Paper0586	Less is More: Adaptive Curriculum Learning for Thyroid Nodule Diagnosis					The author should supplement more information about the contributed dataset, such as the source of data, device(s) used, image acquisition parameters, instructions to annotators, and methods for quality control. The paper writing can be further improved.	The author should supplement more information about the contributed dataset, such as the source of data, device(s) used, image acquisition parameters, instructions to annotators, and methods for quality control. The paper writing can be further improved.				
382-Paper1435	Personalized Diagnostic Tool for Thyroid Cancer Classification using Multi-view Ultrasound					The conducted experiments are quite limited. The reproduced AdaMML has poor performance, but no explanation is given. The description of the data collection process is not completed, such as descriptions of the experimental setup, device(s) used, image acquisition parameters, subjects/objects involved, instructions to annotators, and methods for quality control. Were the 4529 sets of multiview US images collected from 4529 patients or not?			The conducted experiments are quite limited. The reproduced AdaMML has poor performance, but no explanation is given. The description of the data collection process is not completed, such as descriptions of the experimental setup, device(s) used, image acquisition parameters, subjects/objects involved, instructions to annotators, and methods for quality control. Were the 4529 sets of multiview US images collected from 4529 patients or not?		
392-Paper0672	Position-prior Clustering-based Self-attention Module for Knee Cartilage Segmentation						Based on some experimental results and some related work that this paper referred, I think the PCAM is a flexible plug-in module, and could be treated and utilized as a self-attention module to strengthen the relative features for the segmentation targets in certain layer. Although the authors only apply the PCAM for the knee cartilages segmentation problem, I think this module could be further used for other organ/tissue segmentation. The reproducibility of the PCAM is not difficult.	Based on some experimental results and some related work that this paper referred, I think the PCAM is a flexible plug-in module, and could be treated and utilized as a self-attention module to strengthen the relative features for the segmentation targets in certain layer. Although the authors only apply the PCAM for the knee cartilages segmentation problem, I think this module could be further used for other organ/tissue segmentation. The reproducibility of the PCAM is not difficult.			
419-Paper1023	RemixFormer: A Transformer Model for Precision Skin Tumor Differential Diagnosis via Multi-modal Imaging and Non-imaging Data					"However, there are some places that are not clearly expressed. In Section 2.2, ""When DWP is turned on (based on p > Tp, p  [0,1])"", what does p mean here? How is the p obtained? What are the global features and local features? In fig. 2, what does patch token mean? It's never shown in the main text. Section 2.3 is very confusing.  For example, the authors mentioned gc or gd are generated by GAP layer, gm is generated by LN layer. But in the formulas below, it's zx and gx' that are generated by LN and GAP. I don't know if the gx' here represents the same gc, gd, gm mentioned before, or it means something else.  Also, I suggest to add the notations lc, ld, and lm(if there is one) to the figure 2."	"However, there are some places that are not clearly expressed. In Section 2.2, ""When DWP is turned on (based on p > Tp, p  [0,1])"", what does p mean here? How is the p obtained? What are the global features and local features? In fig. 2, what does patch token mean? It's never shown in the main text. Section 2.3 is very confusing.  For example, the authors mentioned gc or gd are generated by GAP layer, gm is generated by LN layer. But in the formulas below, it's zx and gx' that are generated by LN and GAP. I don't know if the gx' here represents the same gc, gd, gm mentioned before, or it means something else.  Also, I suggest to add the notations lc, ld, and lm(if there is one) to the figure 2."			"However, there are some places that are not clearly expressed. In Section 2.2, ""When DWP is turned on (based on p > Tp, p  [0,1])"", what does p mean here? How is the p obtained? What are the global features and local features? In fig. 2, what does patch token mean? It's never shown in the main text. Section 2.3 is very confusing.  For example, the authors mentioned gc or gd are generated by GAP layer, gm is generated by LN layer. But in the formulas below, it's zx and gx' that are generated by LN and GAP. I don't know if the gx' here represents the same gc, gd, gm mentioned before, or it means something else.  Also, I suggest to add the notations lc, ld, and lm(if there is one) to the figure 2."	"However, there are some places that are not clearly expressed. In Section 2.2, ""When DWP is turned on (based on p > Tp, p  [0,1])"", what does p mean here? How is the p obtained? What are the global features and local features? In fig. 2, what does patch token mean? It's never shown in the main text. Section 2.3 is very confusing.  For example, the authors mentioned gc or gd are generated by GAP layer, gm is generated by LN layer. But in the formulas below, it's zx and gx' that are generated by LN and GAP. I don't know if the gx' here represents the same gc, gd, gm mentioned before, or it means something else.  Also, I suggest to add the notations lc, ld, and lm(if there is one) to the figure 2."
436-Paper0559	SAPJNet: Sequence-Adaptive Prototype-Joint Network for Small Sample Multi-Sequence MRI Diagnosis					"this paper proposed to use Transformer and additive-angular-margin loss for small sample multi-sequence MR image classification. However, this paper has several major flaws and fails to illustrate their point: The first component, Transformer model, is claimed to filter intra-sequence features and aggregate inter-sequence features, based on attention mechanism. But I didn't see any details about how to achieve these 2 goals in section 2.1. The overall writing quality is poor and difficult to follow. Similarly, neither the section 2.2, prototype optimization strategy, illustrates how to approximate the intra-class prototype and alienate the inter-class prototype. For example, the query sample q^a and support sample s^b corresponding to which modalities, the loss_2 should be explicitly expressed like loss_1, and why you choose the additive-angular-margin loss instead of the ordinary cross-entropy loss for classification. Fig 2 is very ambiguous and lacks sufficient explanation. E.g., what are the vectors besides the local significance block, how to aggregate into global correlation (through concatenation, pooling, or others), where does the support prototype come from, where are the 2 stages in Prototype optimization strategy, and how to approximate intra-class prototypes and alienate inter-class prototypes. The experiment section lacks the explanation of 3 modalities of data (SAX, LAX, and LGE). Some minor issues: a. P2, 1st paragraph, the hyperparameter p's explanation is ambiguous. b. Section 2.2 mentions robust classification. So what kind of attack methods you are dealing with? c. Section 2.2 2nd paragraph says ""two outputs of the SAT ..."" what does the two outputs referring to? d. Still in Section 2.2 2nd paragraph, ""The former is reserved for ..."". After this, where is the latter one? What's the purposes of two stages here? e. Table 3 didn't explain what's VOT."	"this paper proposed to use Transformer and additive-angular-margin loss for small sample multi-sequence MR image classification. However, this paper has several major flaws and fails to illustrate their point: The first component, Transformer model, is claimed to filter intra-sequence features and aggregate inter-sequence features, based on attention mechanism. But I didn't see any details about how to achieve these 2 goals in section 2.1. The overall writing quality is poor and difficult to follow. Similarly, neither the section 2.2, prototype optimization strategy, illustrates how to approximate the intra-class prototype and alienate the inter-class prototype. For example, the query sample q^a and support sample s^b corresponding to which modalities, the loss_2 should be explicitly expressed like loss_1, and why you choose the additive-angular-margin loss instead of the ordinary cross-entropy loss for classification. Fig 2 is very ambiguous and lacks sufficient explanation. E.g., what are the vectors besides the local significance block, how to aggregate into global correlation (through concatenation, pooling, or others), where does the support prototype come from, where are the 2 stages in Prototype optimization strategy, and how to approximate intra-class prototypes and alienate inter-class prototypes. The experiment section lacks the explanation of 3 modalities of data (SAX, LAX, and LGE). Some minor issues: a. P2, 1st paragraph, the hyperparameter p's explanation is ambiguous. b. Section 2.2 mentions robust classification. So what kind of attack methods you are dealing with? c. Section 2.2 2nd paragraph says ""two outputs of the SAT ..."" what does the two outputs referring to? d. Still in Section 2.2 2nd paragraph, ""The former is reserved for ..."". After this, where is the latter one? What's the purposes of two stages here? e. Table 3 didn't explain what's VOT."	"this paper proposed to use Transformer and additive-angular-margin loss for small sample multi-sequence MR image classification. However, this paper has several major flaws and fails to illustrate their point: The first component, Transformer model, is claimed to filter intra-sequence features and aggregate inter-sequence features, based on attention mechanism. But I didn't see any details about how to achieve these 2 goals in section 2.1. The overall writing quality is poor and difficult to follow. Similarly, neither the section 2.2, prototype optimization strategy, illustrates how to approximate the intra-class prototype and alienate the inter-class prototype. For example, the query sample q^a and support sample s^b corresponding to which modalities, the loss_2 should be explicitly expressed like loss_1, and why you choose the additive-angular-margin loss instead of the ordinary cross-entropy loss for classification. Fig 2 is very ambiguous and lacks sufficient explanation. E.g., what are the vectors besides the local significance block, how to aggregate into global correlation (through concatenation, pooling, or others), where does the support prototype come from, where are the 2 stages in Prototype optimization strategy, and how to approximate intra-class prototypes and alienate inter-class prototypes. The experiment section lacks the explanation of 3 modalities of data (SAX, LAX, and LGE). Some minor issues: a. P2, 1st paragraph, the hyperparameter p's explanation is ambiguous. b. Section 2.2 mentions robust classification. So what kind of attack methods you are dealing with? c. Section 2.2 2nd paragraph says ""two outputs of the SAT ..."" what does the two outputs referring to? d. Still in Section 2.2 2nd paragraph, ""The former is reserved for ..."". After this, where is the latter one? What's the purposes of two stages here? e. Table 3 didn't explain what's VOT."		"this paper proposed to use Transformer and additive-angular-margin loss for small sample multi-sequence MR image classification. However, this paper has several major flaws and fails to illustrate their point: The first component, Transformer model, is claimed to filter intra-sequence features and aggregate inter-sequence features, based on attention mechanism. But I didn't see any details about how to achieve these 2 goals in section 2.1. The overall writing quality is poor and difficult to follow. Similarly, neither the section 2.2, prototype optimization strategy, illustrates how to approximate the intra-class prototype and alienate the inter-class prototype. For example, the query sample q^a and support sample s^b corresponding to which modalities, the loss_2 should be explicitly expressed like loss_1, and why you choose the additive-angular-margin loss instead of the ordinary cross-entropy loss for classification. Fig 2 is very ambiguous and lacks sufficient explanation. E.g., what are the vectors besides the local significance block, how to aggregate into global correlation (through concatenation, pooling, or others), where does the support prototype come from, where are the 2 stages in Prototype optimization strategy, and how to approximate intra-class prototypes and alienate inter-class prototypes. The experiment section lacks the explanation of 3 modalities of data (SAX, LAX, and LGE). Some minor issues: a. P2, 1st paragraph, the hyperparameter p's explanation is ambiguous. b. Section 2.2 mentions robust classification. So what kind of attack methods you are dealing with? c. Section 2.2 2nd paragraph says ""two outputs of the SAT ..."" what does the two outputs referring to? d. Still in Section 2.2 2nd paragraph, ""The former is reserved for ..."". After this, where is the latter one? What's the purposes of two stages here? e. Table 3 didn't explain what's VOT."	
459-Paper1441	Semi-Supervised PR Virtual Staining for Breast Histopathological Images						As said before, the dataset not seems to be free and public			As said before, the dataset not seems to be free and public	
486-Paper1659	Supervised Deep Learning for Head Motion Correction in PET					"Language problems need to be checked, many long sentences are not clearly expressed and are confusing. The experiments section needs more clarifications: The subject group contains patients with normal cognition, cocaine dependence, and cognitive diseases. I would like to know if any strategy was used in splitting the training and test sets? For example, keeping a diversity of patient types in each subset. In the ablation study (Table 1), the test MSE value for ""more data, FWT, Deep Encoder and Normal sampling"", which is located in the second row, has a much higher value than the others. Can the authors explain this? The results In fig. 2(a) are for subject 1. Also, there is another subject 1 in Table S1. I assume they are different subjects since one is for single-subject experiments and one is for multi-subject experiments. But referring to them the same name still causes confusion. In section 3.2, the authors claimed that subject 2 has a mean MSE of 0.02. But Table S1 shows the mean MSE of subject 2 is 1.114. They are contradictory. I assume they are also different objects as I mentioned above. The confusions need to be addressed. ""The results for Subject 2 (mean MSE 0.02) show that the network is capable of accurately predicting motion from training subjects even though the motion relative to the reference frame was never used for training."" Does this mean that in the experiment in figure 2, the moving images of subject 2 have been resampled and different from the images that are used during training? The detail of the experiment settings needs to be clarified."	"Language problems need to be checked, many long sentences are not clearly expressed and are confusing. The experiments section needs more clarifications: The subject group contains patients with normal cognition, cocaine dependence, and cognitive diseases. I would like to know if any strategy was used in splitting the training and test sets? For example, keeping a diversity of patient types in each subset. In the ablation study (Table 1), the test MSE value for ""more data, FWT, Deep Encoder and Normal sampling"", which is located in the second row, has a much higher value than the others. Can the authors explain this? The results In fig. 2(a) are for subject 1. Also, there is another subject 1 in Table S1. I assume they are different subjects since one is for single-subject experiments and one is for multi-subject experiments. But referring to them the same name still causes confusion. In section 3.2, the authors claimed that subject 2 has a mean MSE of 0.02. But Table S1 shows the mean MSE of subject 2 is 1.114. They are contradictory. I assume they are also different objects as I mentioned above. The confusions need to be addressed. ""The results for Subject 2 (mean MSE 0.02) show that the network is capable of accurately predicting motion from training subjects even though the motion relative to the reference frame was never used for training."" Does this mean that in the experiment in figure 2, the moving images of subject 2 have been resampled and different from the images that are used during training? The detail of the experiment settings needs to be clarified."			"Language problems need to be checked, many long sentences are not clearly expressed and are confusing. The experiments section needs more clarifications: The subject group contains patients with normal cognition, cocaine dependence, and cognitive diseases. I would like to know if any strategy was used in splitting the training and test sets? For example, keeping a diversity of patient types in each subset. In the ablation study (Table 1), the test MSE value for ""more data, FWT, Deep Encoder and Normal sampling"", which is located in the second row, has a much higher value than the others. Can the authors explain this? The results In fig. 2(a) are for subject 1. Also, there is another subject 1 in Table S1. I assume they are different subjects since one is for single-subject experiments and one is for multi-subject experiments. But referring to them the same name still causes confusion. In section 3.2, the authors claimed that subject 2 has a mean MSE of 0.02. But Table S1 shows the mean MSE of subject 2 is 1.114. They are contradictory. I assume they are also different objects as I mentioned above. The confusions need to be addressed. ""The results for Subject 2 (mean MSE 0.02) show that the network is capable of accurately predicting motion from training subjects even though the motion relative to the reference frame was never used for training."" Does this mean that in the experiment in figure 2, the moving images of subject 2 have been resampled and different from the images that are used during training? The detail of the experiment settings needs to be clarified."	
