id	category	title	review1	review2	review3
14	repro	A Novel Knowledge Keeper Network for 7T-Free But 7T-Guided Brain Tissue Segmentation 	based on the checklist, yes.		
15	repro	A Penalty Approach for Normalizing Feature Distributions to Build Confounder-Free Models 			The code and data can be released according to the reproducibility checklist.
50	repro	Atlas-powered deep learning (ADL) - application to diffusion weighted MRI 	Although the architecture is simple (U-Net), the full method is rather complex. Without the code, it seems unlikely one can reproduce the experiments. Although the authors mentioned in the reproducibility checklist that the code was made available, they did not mention it in the paper.		
61	repro	Automatic Segmentation of Hip Osteophytes in DXA Scans using U-Nets 		Overall, I consider reproducibility of the study as high. Several remarks below. The exact model architecture is not given explicitly, eventhough it is understandable from the text to some extent. The authors have checked the code release in the checklist, however, there is no link to the source code in the article. Software versions are not specified for the critical components of the pipeline.	
69	repro	Bi-directional Encoding for Explicit Centerline Segmentation by Fully-Convolutional Networks 			According to the reproducibility checklist, the authors do not plan to provide their training or evaluation code. The method itself is fairly straightforward and well described, and a re-implementation should be possible. Most hyperparameters used for training the models are provided in the supplementary material, however, only the CLIP data set is available for reproducing results.
77	repro	CACTUSS: Common Anatomical CT-US Space for US examinations 			The authors reference the US simulation algorithm and CUT network and provide parameters for each. As noted in their checklist code is not provided . Overall this limits reproducibility of their work. It would be of great interest to the community if they provided access to their framework to allow others to leverage well-curated CT (or MR?!) datasets for US applications.
84	repro	CASHformer: Cognition Aware SHape Transformer for Longitudinal Analysis 			All parts of the model architecture blocks are well described as well as the training procedure (mostly in the supplementary materials). The dataset is exhaustively detailed as well as the splits and the proposed evaluation process. As stated in the reproducibility checklist, not all hyper-parameters tuning / setting is reported, e.g. the loss weight lambda was empirically set.
89	repro	Characterization of brain activity patterns across states of consciousness based on variational auto-encoders 		The paper meet the crieria on the checklist.	
92	repro	CIRDataset: A large-scale Dataset for Clinically-Interpretable lung nodule Radiomics and malignancy prediction 		Apparently, the authors have not understood how to fill out the checklist: all questions are answered with yes, yet most of the information is missing in the paper (e.g. only everage values are given for comparison and no variation, no tests for statistical significance, ...) On a positive note, datasets and code will be released, which should answer many of the open questions.	
95	repro	Clinical-realistic Annotation for Histopathology Images with Probabilistic Semi-supervision: A Worst-case Study 			More details about each training step, e.g., pre-training, fine-tuning, MC dropout configuration, need to be clarified for reproducibility. The authors checked almost all boxes in the checklist, in which it says the code would be made available. If that is the case, reproducibility is not an issue.
98	repro	Combining mixed-format labels for AI-based pathology detection pipeline in a large-scale knee MRI study 		Overall, very high reproducibiliy score. The checklist provided by the authors is in a agreement with the provided details. Few aspects regarding the private dataset and the data management are to be clarified. See the comments in next section.	
109	repro	Contrast-free Liver Tumor Detection using Ternary Knowledge Transferred Teacher-student Deep Reinforcement Learning 	Most reproducibility checklist are fulfilled.		
119	repro	Curvature-enhanced Implicit Function Network for High-quality Tooth Model Generation from CBCT Images 		I have some concerns about the reproducibility of the paper. The implementation and technical details of the method are not given in the paper. In the checklist, they claim that they will publish the data, training code, and network model. However, this information is not given in the text.	
132	repro	Deep Learning-based Facial Appearance Simulation Driven by Surgically Planned Craniomaxillofacial Bony Movement 			The paper provides many details on their implementation, hence there is no major reason to argue about paper reproducibility. Authors report the different hyperparameters used (both in the data processing phase and network training and evaluation phase). Details on the dimension of each modules of the architecture are also provided. Although authors declared that they shared dataset and code in the reproducibility checklist, I do not see any link to such resources in the paper. I would expect that authors share their implementations upon acceptance.
133	repro	Deep learning-based Head and Neck Radiotherapy Planning Dose Prediction via Beam-wise Dose Decomposition 	"The authors have essentially answered ""yes"" to every question in the reproducibility checklist. However, in reality most of the relevant points have not been included in the manuscript. While not all raised questions can be addressed in the manuscript, the checklist should be filled out correctly. I believe the most interesting information to add to the manuscript would be how the proposed method's hyperparameters were tuned (especially the loss function hyperparameters alpha and beta), how the baselines were implemented and tuned and additional discussion of the clinical significance (see comments above)."		Seems okay since author promised to provide the data and code in the reproducibility checklist. Otherwise, it is unclear to say since some key network architecture details are not provided in the paper itself.
141	repro	Deep-learning Based T1 and T2 Quantification from Undersampled Magnetic Resonance Fingerprinting Data to Track Tracer Kinetics in Small Laboratory Animals 		The checklist states that the dataset is downloadable, but I did not see an (anonymized) link in the manuscript Same for code and models The exact architecture of the UNet (number of features per layer) is not provided.  Not a problem if code is released. Hyper-parameter strategy is not mentioned, but maybe no hyper-parameter search was performed (which would be fine) Time/cost/memory not reported No statistical significance tests	The checklist mentions the code will not be available in a repository as it is still under development, which limits reproducibility.
142	repro	DeepMIF: Deep learning based cell profiling for multispectral immunofluorescence images with graphical user interface 		The reproducibility of the paper is good. The authors provided necessary details from the reproducibility checklist.	
144	repro	DeepRecon: Joint 2D Cardiac Segmentation and 3D Volume Reconstruction via A Structure-Specific Generative Method 	Good, the author's answers to the reproducibility checklist correspond to the content of their paper.		
145	repro	Deformer: Towards Displacement Field Learning for Unsupervised Medical Image Registration 	Good reproducibility. Many technical details of the proposed method are reported and the authors claimed that the code will release if the work is accepted in the reproducibility checklist.		
155	repro	DGMIL: Distribution Guided Multiple Instance Learning for Whole Slide Image Classification 	The authors have clarified that the code will be available in the reproducibility checklist.		
163	repro	DisQ: Disentangling Quantitative MRI Mapping of the Heart 		The manuscript mentions the code will be available in a repository and the checklist supports this statement. There are some little details not explained in the paper, but it may be out of the scope of a conference paper. Once uploaded, it will guarantee reproducibility.	
166	repro	Domain Adaptive Nuclei Instance Segmentation and Classification via Category-aware Feature Alignment and Pseudo-labelling 	The authors do not provide the description of results with central tendency (e.g. mean) & variation in the paper, which they answered Yes in the checklist. It would be a plus to add mean and variance to the results.		
187	repro	Efficient Biomedical Instance Segmentation via Knowledge Distillation 			Some details are missing. The authors seems just check everything 'yes' in the checklist. Missing one of the loss function definition. Missing software framework and version. No new dataset proposed. Missing training time for the proposed distillation method.
189	repro	Electron Microscope Image Registration using Laplacian Sharpening Transformer U-Net 	use of public challenge data unclear if code is to be made available no significance testing (not claimed in checklist but unclear why not carried out)		
196	repro	End-to-End Segmentation of Medical Images via Patch-wise Polygons Prediction 			Some details are missing. The authors seems just check everything 'yes' in the checklist. Missing one of the loss function definition, i.e. L_{BCE}. Missing software framework and version. No new dataset proposed. Missing training time for the proposed network.
197	repro	Enforcing connectivity of 3D linear structures using their 2D projections 		Apparently, the authors have not understood how to fill out the checklist: for many questions answered with yes, the information is actually missing in the paper (e.g. no tests for statistical significance, memory footprint, analysis of situations in which the method failed, etc.). Since no code will be published, these details will remain unknown.	
199	repro	Ensembled Prediction of Rheumatic Heart Disease from Ungated Doppler Echocardiography Acquired in Low-Resource Settings 	"Overall reasonably good. The model was clearly described although code has not been made available. One point of concern though - in the checklist, the authors answered ""Yes"" to ""The range of hyper-parameters considered, method to select the best hyper-parameter configuration, and specification of all hyper-parameters used to generate results."" I agree that they specified final hyperparameter values but I did not see any description of the range of values tested or how the hyperparameters were optimised (see detailed comments below)."		The authors filled out the reproducibility checklists, but will not release their codes and dataset in the future. Then implementation details of all models in the paper are well described. It is easy to follow the paper and reproduce their work.
210	repro	Fast Spherical Mapping of Cortical Surface Meshes using Deep Unsupervised Learning 			The paper meets the requirements of the checklist.
211	repro	Fast Unsupervised Brain Anomaly Detection and Segmentation with Diffusion Models 			While the code is not publicly available (and the reproducibility checklist says so), I believe the authors might have used the original repositories for VQ-VAE and DDPM which are publicly available. Even though implementation details are not given, it might be possible to reproduce the method partially. Furthermore, the results are presented using public datasets.
214	repro	Federated Medical Image Analysis with Virtual Sample Synthesis 			All questions in the reproducibility checklist are positive and implementation details are given in the paper.
220	repro	Fine-grained Correlation Loss for Regression 		In the reproducibility checklist, the authors mentioned that the code has been made available or will release if this work is accepted. I think it is great if they release the code if this work is accepted. Unfortunately, there are no details regarding how the authors acquired data. I assume that the dataset was dedicated to this study since there are no citations or download links. If it is the case, it can be mentioned in the manuscript explicitly. The validations seem well-documented except for concern regarding the reported batch size, which has been explained in detail in the comments.	According to the checklist, the authors will opensource their codes in the future. In the paper, the authors also provide enough details for reproduction.
221	repro	Flat-aware Cross-stage Distilled Framework for Imbalanced Medical Image Classification 		Good. Experiments were performed on public datasets and the authors plan to release code after peer-review according to the checklist.	
232	repro	Geometric Constraints for Self-supervised Monocular Depth Estimation on Laparoscopic Images with Dual-task Consistency 	The authors have confirmed in the checklist that they will share the code to the public. The dataset used in the work is from a public challenge.		
244	repro	How Much to Aggregate: Learning Adaptive Node-wise Scales on Graphs for Brain Networks 		According to the reproducibility checklist and information from the paper, the results should be reproducible after the potential acceptance.	
253	repro	Implicit Neural Representations for Medical Imaging Segmentation 			The source code is available according to the author's answer to the reproducibility checklist.
262	repro	Interpretable Graph Neural Networks for Connectome-Based Brain Disorder Analysis 			The submission meets all criteria on the reproducibility checklist.
277	repro	Knowledge Distillation to Ensemble Global and Interpretable Prototype-based Mammogram Classification Models 			In the reproducibility checklist, the authors claim to release the training/evaluation codes with pretrained models which is a plus. Since the proposed method is a sophisticated ensemble learning framework with multiple loss functions, source code release could be a great help.
292	repro	Lesion Guided Explainable Few Weak-shot Medical Report Generation 			Authors provided a checklist for reproducibility. The description of the methods, implementation and validation studies are also satisfactory.
298	repro	LifeLonger: A Benchmark for Continual Disease Classification 	The code of the paper will be made available publicly.  From the checklist authors claim that the software framework and runtime/memory footprint statistics are included, however both are not included in the paper.		
301	repro	Local Attention Graph-based Transformer for Multi-target Genetic Alteration Prediction 		The reproducibility of the paper is good. The authors provided necessary details from the reproducibility checklist.	
312	repro	Mapping in Cycles: Dual-Domain PET-CT Synthesis Framework with Cycle-Consistent Constraints 	The description of the training details in this paper is insufficient. Moreover, the authors did not give any positive response regarding the code release in the reproducibility checklist. So I think this paper does not have good reproducibility.		
330	repro	Multidimensional Hypergraph on Delineated Retinal Features for Pathological Myopia Task. 		The checked points in the reproducibilty checklist match perfectly the information provided in the paper.	The reproducibility checklist was accurately filled out.  One thing that could improve reproducibility of the paper is to make the full code available after publication.
333	repro	Multimodal Brain Tumor Segmentation Using Contrastive Learning based Feature Comparison with Monomodal Normal Brain Images 			All the necessary checklist for the resproducibilty are provided.
338	repro	Multi-Modal Unsupervised Pre-Training for Surgical Operating Room Workflow Analysis 	The authors present the method in such a manner that it should be reproducible. All the details provided on the checklist were truthful.		
339	repro	Multimodal-GuideNet: Gaze-Probe Bidirectional Guidance in Obstetric Ultrasound Scanning 			The experiments design and data generation are clearly described in the paper, which matches what the authors claimed in the reproducibility checklist.
350	repro	NerveFormer: A Cross-Sample Aggregation Network for Corneal Nerve Segmentation 			The detailed network architecture is not included in the paper. But the authors commit to releasing the code in the reproducibility checklist.
354	repro	Neuro-RDM: An Explainable Neural Network Landscape of Reaction-Diffusion Model for Cognitive Task Recognition 			Upon reading the paper and the checklist, I found several inconsistencies. For example, I found no description of the parameter settings, architecture, range of parameter values, sensitivity to parameters, memory footprint or compute software in the paper.
361	repro	On Surgical Planning of Percutaneous Nephrolithotomy with Patient-Specific CTRs 	The paper describes the generation of point clouds using Slicer3D. More detail would help with respect to filters and marching operations used to segment the CT data. Answers to reproducibility checklist make sense and the authors do a good job explaining the algorithm and tools they used.		
364	repro	One-Shot Segmentation of Novel White Matter Tracts via Extensive Data Augmentation 		The authors use open available data of the HPC. The authors use TractSeg as backbone, for which code is available. No code is provided in for the framework their paper is based on, nor in their paper. However, mathematical definitions are provided and based on the checklist the reproducibility seems to be given.	
374	repro	Orientation-guided Graph Convolutional Network for Bone Surface Segmentation 			The paper has a reasonable level of repeatability, providing details about the hyperparameters and systems used. The authors also indicate that code will be made available. The dataset appears to be acquired internally but the authors indicate in the reproducibility checklist that the dataset could be accessed by others.
384	repro	PET denoising and uncertainty estimation based on NVAE model using quantile regression loss 	"The authors ticked ""Yes"" for most items of the reproductibility checklist, which is sometimes in contradiction with what is provided in the paper (e.g. range of hyper-parameters considered). It seems that the code will be made available."		
389	repro	Point Beyond Class: A Benchmark for Weakly Semi-Supervised Abnormality Localization in Chest X-Rays 	The author did not mention the code in the paper, but according to the checklist, it seems they will release the code after acceptation. Please make clear. I suggest that at least release the splitting of the training set and the test set, which may help in pursuing the goal of setting a benchmark for the field.		
403	repro	Prototype Learning of Inter-network Connectivity for ASD Diagnosis and Personalized Analysis 			Reproducibility is fairly good - based on the checklist/submission it appears code will be shared with acceptance. However, there is some missing experimental analysis (e.g. parameter sensitivity, statistical significance, when does method fail) that could be added to improve the paper.
404	repro	Pseudo Bias-Balanced Learning for Debiased Chest X-ray Classification 			The authors provide all the source code in the checklist and supplemental materials. And they use public dataset which is beneficial for reproducing the work.
431	repro	RT-DNAS: Real-time Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation 			Ok. Authors mention in the reproducibility checklist that the code will be available.
443	repro	SeATrans: Learning Segmentation-Assisted diagnosis model via Transformer 			The authors have used public data and they will make their code public, according to their answers in the checklist. So I believe their work is reproducible.
445	repro	Self-Ensembling Vision Transformer (SEViT) for Robust Medical Image Classification 			As listed reproducibility checklist, the work should be in good reproducibility.
456	repro	Semi-supervised learning with data harmonisation for biomarker discovery from resting state fMRI 			The authors have checked off all relevant items on the reproducibility checklist, including sharing of code, and the reporting in the paper matches the checklist, so should be highly reproducible.
461	repro	Sensor Geometry Generalization to Untrained Conditions in Quantitative Ultrasound Imaging 	"In the reproducibility checklist, authors claim that they share a sample test dataset and their code. The current version of the manuscript has no links to open source repositories, but I expect authors would make data and code available upon acceptance. I see it very difficult to replicate the method and reproduce the results by only following the description provided in the paper, due to the complexity of the proposed architecture. Moreover, authors declare that ethical approval is ""not applicable"" to their work. Actually, since their evaluation include real patient data, ethical approval should be present."		
463	repro	SGT: Scene Graph-Guided Transformer for Surgical Report Generation 		According to the reproducibility checklist, the source code and pretrained models will be made publicly available, which is essential to guarantee the reproducibility of the results. Additionally, the method was developed using a public benchmark dataset for surgical report generation, which promotes research in the area.	
466	repro	ShapePU: A New PU Learning Framework Regularized by Global Consistency for Scribble Supervised Cardiac Segmentation 	The work was evaluated on a publicly available dataset. Following the checklist, I assume that the code will be available after acceptance.		
474	repro	Spatial-hierarchical Graph Neural Network with Dynamic Structure Learning for Histological Image Classification 		The checked points in the reproducibilty checklist match perfectly the information provided in the paper.	
480	repro	Stereo Depth Estimation via Self-Supervised Contrastive Representation Learning 		The authors provide implementaion details in the paper and also agree to release codes and pretrained models in the reproducibility checklist.	
491	repro	Surgical-VQA: Visual Question Answering in Surgical Scenes using Transformer 		According to the reproducibility checklist, the source code and pretrained models will be made publicly available, which is essential to guarantee the reproducibility of the results. Additionally, the method was developed using a public benchmark dataset for surgical VQA, which promotes research in the area. Despite not including any intention to publicly release the data in the main text, the reproducibility checklist mention that they will be released upon acceptance. Furthermore, there should be included more statistics about the new data. How were these annotations generated? This information will be valuable for new research on this task.	
494	repro	Swin Deformable Attention U-Net Transformer (SDAUT) for Explainable Fast MRI 	Some model specifications are missing in the paper. But the authors have agreed to release codes and models in the checklist.		The reproducibility checklist shows the authors will upload their code and implementation details online. The experimental settings are listed in the manuscript, but the hyper-parameters for the proposed method are missing.
511	repro	TMSS: An End-to-End Transformer-based Multimodal Network for Segmentation and Survival Prediction 			"The reproducibility checklist well matches the contribution. I would like to argue, however, that significance analyses (""Not applicable"") are well applicable, and thus, that the depiction of measures of confidence would have been adequate."
518	repro	TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis Framework Using Spectral Embedding and Vision Transformers 			The code and data will be released according to the reproducibility checklist.
519	repro	TransEM: Residual Swin-Transformer based regularized PET image reconstruction 			The authors made an effort to make their paper reproductible, which lots of setup values. I did not find in the paper or in supplementary material a way to access the code, whereas it seems to be done according to the reproducibility checklist filled in by the authors. Maybe this is not possible at this stage. The authors detailed the hyperparameters values of the neural network, of the method, and the initialization of the image, which is very important. However, were  several runs make ? Or was the initialization of the neural network weights fixed ? About the PET simulation, some simulation setup is missing, like the system matrix modelling, the number of line of responses.
535	repro	UNeXt: MLP-based Rapid Medical Image Segmentation Network 		The reviewer agrees with the checklist and is happy with the reproducibility of the paper overall.	
549	repro	USG-Net: Deep Learning-based Ultrasound Scanning-Guide for an Orthopedic Sonographer 			Although based on the reproducibility checklist, the authors demonstrate a commitment to publishing their code publicly, it is unclear whether the dataset will also me made available. The hyperparameters used appear to be missing in the manuscript.
550	repro	Using Guided Self-Attention with Local Information for Polyp Segmentation 		Some model details are missing. The authors do state in the reproducibility checklist that they will release the code.	
559	repro	Warm Start Active Learning with Proxy Labels & Selection via Semi-Supervised Fine-Tuning 			The authors have satisfied the reproducibility checklist.
570	repro	White Matter Tracts are Point Clouds: Neuropsychological Score Prediction and Critical Region Localization via Geometric Deep Learning 	By using the openly available data from the Human Connectome Project and a brief description of the statistics of the subjects used, reproducibility seems to be possible. In addition, the settings and software framework are described in Section 2.5. The authors' answers on the reproducibility checklist confirm the given reproducibility. It would be beneficial, if the code would be provided on github.		
