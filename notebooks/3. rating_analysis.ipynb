{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Definition of functions to calculate the kappa score.\n",
    "########################################################################\n",
    "\n",
    "def kappa(po: float, pe:float):\n",
    "    \"\"\"\n",
    "    Calculate the kappa score.\n",
    "    Kappa is a statistic that measures inter-rater agreement for categorical items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        po: Overall proportion of observed agreement.\n",
    "        pe: Overall proportion of agreement expected by chance.\n",
    "    Returns\n",
    "    ------- \n",
    "    The kappa score.\n",
    "    \"\"\"\n",
    "    return (po - pe) / (1 - pe)\n",
    "\n",
    "def expected_proportion(matrix: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculate the overall proportion of agreement expected by chance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        matrix: Confusion matrix (DataFrame).\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    The expected proportion (pe).\n",
    "    \"\"\"\n",
    "    pe = 0\n",
    "    k = len(matrix) - 1\n",
    "    for i in range(k):\n",
    "        pe += matrix.loc[i, k] * matrix.loc[k, i]\n",
    "    return pe\n",
    "\n",
    "def observed_proportion(matrix: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculate the overall proportion of observed agreement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        matrix: Confusion matrix (DataFrame).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The observed proportion (po).\n",
    "    \"\"\"\n",
    "    po = 0\n",
    "    k = len(matrix) - 1\n",
    "    for i in range(k):\n",
    "        po += matrix.loc[i, i]\n",
    "    return po\n",
    "\n",
    "def create_confusion_matrix(list_1: list, list_2: list, list_attributs:list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a confusion matrix in percentage.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        list_1: List of labels from reviewer 1.\n",
    "        list_2: List of labels from reviewer 2.\n",
    "        list_attributs: List of attribute labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The confusion matrix as a DataFrame (in %).\n",
    "    \"\"\"\n",
    "    if not len(list_1) == len(list_2):\n",
    "        print(\"Reviewer 1 and 2 may not have rated the same list of subjects.\")\n",
    "    else:\n",
    "        size = len(list_attributs)\n",
    "        \n",
    "        # Initialize the confusion matrix with zeros.\n",
    "        matrix = pd.DataFrame(np.zeros((size + 1, size + 1)), index=list_attributs + [\"total\"], columns=list_attributs + [\"total\"])\n",
    "        \n",
    "        # Populate the confusion matrix based on reviewer ratings.\n",
    "        for k in range(size):\n",
    "            for l in range(size):\n",
    "                att_k = list_attributs[k]\n",
    "                att_l = list_attributs[l]\n",
    "                for i in range(len(list_1)):\n",
    "                    if list_1[i] == att_k:\n",
    "                        if list_2[i] == att_l:\n",
    "                            matrix.loc[att_k, att_l] += 1\n",
    "        \n",
    "        # Calculate row and column totals, and total observations.\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                att_i = list_attributs[i]\n",
    "                att_j = list_attributs[j]\n",
    "                matrix.loc[\"total\", att_i] += matrix.loc[att_j, att_i]\n",
    "                matrix.loc[att_i, \"total\"] += matrix.loc[att_i, att_j]\n",
    "                matrix.loc[\"total\", \"total\"] += matrix.loc[att_i, att_j]\n",
    "\n",
    "        # Convert the matrix to percentages if the number of observations matches the total.\n",
    "        if len(list_1) == matrix.loc[\"total\", \"total\"]:\n",
    "            matrix = round(matrix * 100 / len(list_1), 2)\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Definition of functions to calculate the confidence interval.\n",
    "########################################################################\n",
    "\n",
    "def ci_bp(proportion: float, N: int):\n",
    "    \"\"\"\n",
    "    Confidence interval (binomial proportion).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        proportion: (float) The observed proportion.\n",
    "        N: (int) The total number of observations.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ci_bp_low : (float) The lower bound of the confidence interval.\n",
    "    ci_bp_high : (float) The upper bound of the confidence interval.\n",
    "    \"\"\"\n",
    "    ci_bp_low = (-1.96 * sqrt(proportion * (1 - proportion) / N) + proportion) * 100\n",
    "    ci_bp_high = (1.96 * sqrt(proportion * (1 - proportion) / N) + proportion) * 100\n",
    "\n",
    "    return ci_bp_low, ci_bp_high\n",
    "\n",
    "def ci_bootstrap(data:list, val, num_resamples=1000):\n",
    "    \"\"\"\n",
    "    Confidence interval (bootstrap).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : (list) The original data.\n",
    "    val : The value for which the confidence interval is calculated.\n",
    "    num_resamples : int, optional\n",
    "        The number of bootstrap resamples, by default 1000.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ci_bootstrap_low : (float) The lower bound of the confidence interval.\n",
    "    ci_bootstrap_high : (float) The upper bound of the confidence interval.\n",
    "    \"\"\"\n",
    "    K = len(data)\n",
    "    outputs = []\n",
    "\n",
    "    # Generate bootstrap samples and calculate the statistic of interest.\n",
    "    for i in range(num_resamples):\n",
    "        Y_resample = random.choices(data, k=K)\n",
    "        out = Y_resample.count(val)\n",
    "        outputs.append(out * 100 / K)\n",
    "\n",
    "    # Calculate the percentiles to obtain the confidence interval.\n",
    "    ci_bootstrap_low = np.percentile(outputs, 2.25)\n",
    "    ci_bootstrap_high = np.percentile(outputs, 97.5)\n",
    "    \n",
    "    return ci_bootstrap_low, ci_bootstrap_high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Definition of function to calculate the kappa score and the confidence \n",
    "# interval for 3 raters.\n",
    "########################################################################\n",
    "\n",
    "def kappa_fleiss_3(data_1, data_2, data_3):\n",
    "    \"\"\"\n",
    "    Bootstrap function for Cohen's kappa score for 3 raters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_1 : array-like\n",
    "        Labels from rater 1.\n",
    "    data_2 : array-like\n",
    "        Labels from rater 2.\n",
    "    data_3 : array-like\n",
    "        Labels from rater 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The mean of the kappa across bootstrap samples.\n",
    "    \"\"\"\n",
    "\n",
    "    from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "\n",
    "    data_T = np.array([data_1, data_2, data_3]).T\n",
    "    data_fleiss_ = aggregate_raters(data_T)\n",
    "    kappa_fleiss_ = fleiss_kappa(data_fleiss_[0])\n",
    "    return kappa_fleiss_\n",
    "\n",
    "def ci_bootstrap_3(data_1, data_2, data_3, num_resamples=1000):\n",
    "    \"\"\"\n",
    "    Confidence interval for a 3 raters kappa (bootstrap).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_1 : array-like\n",
    "        Labels from rater 1.\n",
    "    data_2 : array-like\n",
    "        Labels from rater 2.\n",
    "    data_3 : array-like\n",
    "        Labels from rater 3.\n",
    "    num_resamples : int, optional\n",
    "        The number of bootstrap resamples, by default 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        95% CI lower bound (2.5 percentile of the sorted bootstrap distribution).\n",
    "    float\n",
    "        95% CI upper bound (97.5 percentile of the sorted bootstrap distribution).\n",
    "    \"\"\"\n",
    "    Y = np.array([data_1, data_2, data_3]).T\n",
    "    list_kappa = []\n",
    "\n",
    "    # Generate bootstrap samples and calculate the kappa for each sample.\n",
    "    for i in range(num_resamples):\n",
    "        Y_resample = np.array(random.choices(Y, k=len(Y)))\n",
    "        data_1 = Y_resample[:, 0]\n",
    "        data_2 = Y_resample[:, 1]\n",
    "        data_3 = Y_resample[:, 2]\n",
    "\n",
    "        kappa = kappa_fleiss_3(data_1.astype(str), data_2.astype(str), data_3.astype(str))\n",
    "        list_kappa.append(kappa)\n",
    "\n",
    "    # Calculate the percentiles to obtain the confidence interval.\n",
    "    return np.percentile(list_kappa, 2.5), np.percentile(list_kappa, 97.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Definition of lists\n",
    "########################################################################\n",
    "\n",
    "# List representing binary choices (0 or 1) for specific content categories\n",
    "list_0_1 = [\n",
    "    \"Models and algorithms\",\n",
    "    \"Datasets\",\n",
    "    \"Code\",\n",
    "    \"Experimental results\",\n",
    "    \"Error bars or statistical significance\",\n",
    "    \"Code is or will be available\"\n",
    "]\n",
    "\n",
    "# List representing different levels or types of statements\n",
    "statement_list = [\n",
    "    \"3. (+) statement\",\n",
    "    \"2. (-) statement\",\n",
    "    \"1. (none) statement\",\n",
    "    \"0. Unusable (statement)\",\n",
    "]\n",
    "\n",
    "# List representing different levels or types of comments\n",
    "comments_list = [\n",
    "    \"4. (-/+) comments\",\n",
    "    \"3. (+) comments\",\n",
    "    \"2. (-) comments\",\n",
    "    \"1. (none) comments\",\n",
    "    \"0. Unusable (comments)\",\n",
    "]\n",
    "\n",
    "# List representing meta-categories\n",
    "meta_categories_list = [\n",
    "    \"(+) meta\",\n",
    "    \"(-) meta\",\n",
    "    \"Unusable (meta)\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook analyzes the 3 reviews of 90 different papers based on the file ../human_rating/rating_90/rating_90_O.csv\n",
      "Outputs will be saved in ../miccai2023/stats_rating.\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Definition of paths.\n",
    "########################################################################\n",
    "\n",
    "# Enter the path to the TSV file with the rating from the first observer\n",
    "# You can change to analyze the ratings of another observer\n",
    "path_csv = \"../human_rating/rating_90/rating_90_O.csv\"\n",
    "df_rating_1 = pd.read_csv(path_csv, sep=\"\\t\", index_col=False, header=None)\n",
    "\n",
    "# Display information about the analysis\n",
    "print(f\"This notebook analyzes the 3 reviews of {len(df_rating_1)-2} different papers based on the file {path_csv}\")\n",
    "\n",
    "# Set up the output directory path\n",
    "output_directory = Path(f\"../miccai2023/stats_rating\")\n",
    "\n",
    "# Check if the output directory exists, if not, create it\n",
    "if not output_directory.is_dir():\n",
    "    os.mkdir(output_directory)\n",
    "\n",
    "# Print the output directory path\n",
    "print(f\"Outputs will be saved in {output_directory}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For category Models and algorithms, 28.89% of reviewers (78/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [23.48%, 34.30%]\n",
      "Confidence intervals (bootstrap): [23.51%, 34.07%]\n",
      "\n",
      "For category Datasets, 33.33% of reviewers (90/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [27.71%, 38.96%]\n",
      "Confidence intervals (bootstrap): [27.78%, 39.26%]\n",
      "\n",
      "For category Code, 46.67% of reviewers (126/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [40.72%, 52.62%]\n",
      "Confidence intervals (bootstrap): [41.11%, 52.59%]\n",
      "\n",
      "For category Experimental results, 25.56% of reviewers (69/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [20.35%, 30.76%]\n",
      "Confidence intervals (bootstrap): [20.37%, 31.11%]\n",
      "\n",
      "For category Error bars or statistical significance, 1.85% of reviewers (5/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [0.24%, 3.46%]\n",
      "Confidence intervals (bootstrap): [0.37%, 3.70%]\n",
      "\n",
      "For category Code is or will be available, 23.33% of reviewers (63/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [18.29%, 28.38%]\n",
      "Confidence intervals (bootstrap): [18.52%, 28.52%]\n",
      "\n",
      "+----------------------------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews                        |   number |   percent |   ci low |   ci high |\n",
      "|----------------------------------------+----------+-----------+----------+-----------|\n",
      "| Models and algorithms                  |       78 |     28.89 | 23.5102  |   34.0741 |\n",
      "| Datasets                               |       90 |     33.33 | 27.7778  |   39.2593 |\n",
      "| Code                                   |      126 |     46.67 | 41.1111  |   52.5926 |\n",
      "| Experimental results                   |       69 |     25.56 | 20.3704  |   31.1111 |\n",
      "| Error bars or statistical significance |        5 |      1.85 |  0.37037 |    3.7037 |\n",
      "| Code is or will be available           |       63 |     23.33 | 18.5185  |   28.5185 |\n",
      "+----------------------------------------+----------+-----------+----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Statistics on the rating for the 0/1 categories\n",
    "########################################################################\n",
    "\n",
    "# Initialize the output dataframe to store statistics with zeros\n",
    "df_category = pd.DataFrame(np.zeros((len(list_0_1), 4)), index=list_0_1, columns=[\"number\", \"percent\", \"ci low\", \"ci high\"])\n",
    "\n",
    "# Iterate over each category and calculate statistics\n",
    "for category in range(len(list_0_1)):\n",
    "    # List to store all reviews for the current category from all reviewers\n",
    "    all_reviews_1 = []\n",
    "    \n",
    "    # Iterate over each reviewer (3 in total)\n",
    "    for i in range(3):\n",
    "        # Extract the ratings for the current category from the corresponding column\n",
    "        column_id = i * 9 + 3 + category\n",
    "        list_review_1 = df_rating_1.loc[2:, column_id].values.tolist()\n",
    "        all_reviews_1 = all_reviews_1 + list_review_1\n",
    "\n",
    "    # Calculate the number of '1' and percentage of '1' for the current category\n",
    "    count_ = all_reviews_1.count(\"1\")\n",
    "    percent_ = round(count_ * 100 / len(all_reviews_1), 2)\n",
    "\n",
    "    # Populate the output dataframe with the calculated statistics\n",
    "    df_category.loc[list_0_1[category], \"number\"] = count_\n",
    "    df_category.loc[list_0_1[category], \"percent\"] = percent_\n",
    "\n",
    "    # Print information about the category and its statistics\n",
    "    print(f\"For category {list_0_1[category]}, {percent_}% of reviewers ({count_}/{len(all_reviews_1)}) have commented on at least one of the items of the category.\")\n",
    "\n",
    "    # Calculate confidence intervals using binomial proportion and bootstrap methods\n",
    "    proportion = count_ / len(all_reviews_1)\n",
    "    ci_bp_low, ci_bp_high = ci_bp(proportion, len(all_reviews_1))\n",
    "    ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(all_reviews_1, '1')\n",
    "\n",
    "    # Populate the output dataframe with confidence interval values (only bootstrap)\n",
    "    df_category.loc[list_0_1[category], \"ci low\"] = ci_bootstrap_low\n",
    "    df_category.loc[list_0_1[category], \"ci high\"] = ci_bootstrap_high\n",
    "\n",
    "    # Print confidence intervals\n",
    "    print(f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "    print(f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "    print()\n",
    "\n",
    "# Rename the index of the dataframe\n",
    "df_category.index.rename(f\"For {len(all_reviews_1)} reviews\", inplace=True)\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "path_category = output_directory / '1-category.csv'\n",
    "df_category.to_csv(path_category, index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Print the dataframe in tabular format\n",
    "print(tabulate(df_category, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for statements (on 270 reviewers):\n",
      "\n",
      "- 48.89% of reviews (132/270) in category 3. (+) statement\n",
      "Confidence intervals (binomial proportion): [42.93%, 54.85%]\n",
      "Confidence intervals (bootstrap): [42.59%, 54.82%]\n",
      "\n",
      "- 11.85% of reviews (32/270) in category 2. (-) statement\n",
      "Confidence intervals (binomial proportion): [8.00%, 15.71%]\n",
      "Confidence intervals (bootstrap): [8.15%, 15.56%]\n",
      "\n",
      "- 37.04% of reviews (100/270) in category 1. (none) statement\n",
      "Confidence intervals (binomial proportion): [31.28%, 42.80%]\n",
      "Confidence intervals (bootstrap): [31.66%, 42.96%]\n",
      "\n",
      "- 2.22% of reviews (6/270) in category 0. Unusable (statement)\n",
      "Confidence intervals (binomial proportion): [0.46%, 3.98%]\n",
      "Confidence intervals (bootstrap): [0.74%, 4.07%]\n",
      "\n",
      "- 48.89% of reviews (132/270) provided a statement\n",
      "Confidence intervals (binomial proportion): [42.93%, 54.85%]\n",
      "Confidence intervals (bootstrap): [42.59%, 54.45%]\n",
      "\n",
      "+-------------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews         |   number |   percent |   ci low |   ci high |\n",
      "|-------------------------+----------+-----------+----------+-----------|\n",
      "| 3. (+) statement        |      132 |     48.89 |    42.59 |     54.82 |\n",
      "| 2. (-) statement        |       32 |     11.85 |     8.15 |     15.56 |\n",
      "| 1. (none) statement     |      100 |     37.04 |    31.66 |     42.96 |\n",
      "| 0. Unusable (statement) |        6 |      2.22 |     0.74 |      4.07 |\n",
      "+-------------------------+----------+-----------+----------+-----------+\n",
      "\n",
      "Fleiss' Kappa: -0.051648054755043166\n",
      "Confidence intervals (bootstrap): [-0.14, 0.03]\n",
      "\n",
      "Review 1 VS review 2\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "|                         |   3. (+) statement |   2. (-) statement |   1. (none) statement |   0. Unusable (statement) |   total |\n",
      "|-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------|\n",
      "| 3. (+) statement        |              18.89 |              10    |                 18.89 |                      0    |   47.78 |\n",
      "| 2. (-) statement        |               6.67 |               2.22 |                  4.44 |                      0    |   13.33 |\n",
      "| 1. (none) statement     |              20    |               0    |                 16.67 |                      1.11 |   37.78 |\n",
      "| 0. Unusable (statement) |               0    |               1.11 |                  0    |                      0    |    1.11 |\n",
      "| total                   |              45.56 |              13.33 |                 40    |                      1.11 |  100    |\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "\n",
      "Review 2 VS review 3\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "|                         |   3. (+) statement |   2. (-) statement |   1. (none) statement |   0. Unusable (statement) |   total |\n",
      "|-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------|\n",
      "| 3. (+) statement        |              25.56 |               4.44 |                 13.33 |                      2.22 |   45.56 |\n",
      "| 2. (-) statement        |               5.56 |               1.11 |                  6.67 |                      0    |   13.33 |\n",
      "| 1. (none) statement     |              21.11 |               3.33 |                 13.33 |                      2.22 |   40    |\n",
      "| 0. Unusable (statement) |               1.11 |               0    |                  0    |                      0    |    1.11 |\n",
      "| total                   |              53.33 |               8.89 |                 33.33 |                      4.44 |  100    |\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "\n",
      "Review 1 VS review 3\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "|                         |   3. (+) statement |   2. (-) statement |   1. (none) statement |   0. Unusable (statement) |   total |\n",
      "|-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------|\n",
      "| 3. (+) statement        |              21.11 |               5.56 |                 21.11 |                      0    |   47.78 |\n",
      "| 2. (-) statement        |               5.56 |               1.11 |                  4.44 |                      2.22 |   13.33 |\n",
      "| 1. (none) statement     |              25.56 |               2.22 |                  7.78 |                      2.22 |   37.78 |\n",
      "| 0. Unusable (statement) |               1.11 |               0    |                  0    |                      0    |    1.11 |\n",
      "| total                   |              53.33 |               8.89 |                 33.33 |                      4.44 |  100    |\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Statistics on the rating for the statements category\n",
    "########################################################################\n",
    "\n",
    "# Initialize the output dataframe to store statistics on statements with zeros.\n",
    "df_statement = pd.DataFrame(np.zeros((len(statement_list), 4)), index=statement_list, columns=[\"number\", \"percent\", \"ci low\", \"ci high\"])\n",
    "\n",
    "# Extract the statements category for the 3 reviewers\n",
    "reviews_statement = []\n",
    "list_statement_1 = df_rating_1.loc[2:, 9].values.tolist()\n",
    "list_statement_2 = df_rating_1.loc[2:, 18].values.tolist()\n",
    "list_statement_3 = df_rating_1.loc[2:, 27].values.tolist()\n",
    "reviews_statement = list_statement_1 + list_statement_2 + list_statement_3\n",
    "\n",
    "# Display information about the analysis\n",
    "N_statement = len(reviews_statement)\n",
    "print(f\"Statistics for statements (on {N_statement} reviewers):\")\n",
    "print()\n",
    "\n",
    "# Iterate over each rating level in the statements list and calculate statistics\n",
    "for rating in statement_list:\n",
    "    # Calculate number and percentage of reviews for the current rating level\n",
    "    count_ = reviews_statement.count(rating)\n",
    "    percent_ = round(count_ * 100 / N_statement, 2)\n",
    "\n",
    "    # Populate the output dataframe with the calculated statistics\n",
    "    df_statement.loc[rating, \"number\"] = count_\n",
    "    df_statement.loc[rating, \"percent\"] = percent_\n",
    "\n",
    "    # Print information about the rating level and its statistics\n",
    "    print(f\"- {percent_}% of reviews ({count_}/{N_statement}) in category {rating}\")\n",
    "\n",
    "    # Calculate confidence intervals using binomial proportion and bootstrap methods\n",
    "    proportion = count_ / len(reviews_statement)\n",
    "    ci_bp_low, ci_bp_high = ci_bp(proportion, len(reviews_statement))\n",
    "    ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(reviews_statement, rating)\n",
    "\n",
    "    # Populate the output dataframe with confidence interval values (only bootstrap)\n",
    "    df_statement.loc[rating, \"ci low\"] = round(ci_bootstrap_low, 2)\n",
    "    df_statement.loc[rating, \"ci high\"] = round(ci_bootstrap_high, 2)\n",
    "\n",
    "    # Print confidence intervals\n",
    "    print(f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "    print(f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "    print()\n",
    "\n",
    "# Calculate percentage and confidence intervals for reviewers that provided a statement\n",
    "new_reviews_statement = []\n",
    "for i in range(N_statement):\n",
    "    if (reviews_statement[i] == \"3. (+) statement\") or (reviews_statement[i] == \"2. (-) statement \"):\n",
    "        new_reviews_statement.append(1)\n",
    "    else:\n",
    "        new_reviews_statement.append(0)\n",
    "\n",
    "new_count_ = new_reviews_statement.count(1)\n",
    "new_percent_ = round(new_count_ * 100 / N_statement, 2)\n",
    "\n",
    "# Display information about reviews that provided a statement\n",
    "print(f\"- {new_percent_}% of reviews ({new_count_}/{N_statement}) provided a statement\")\n",
    "\n",
    "# Calculate confidence intervals for reviews that provided a statement\n",
    "proportion = new_count_ / N_statement\n",
    "ci_bp_low, ci_bp_high = ci_bp(proportion, N_statement)\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(new_reviews_statement, 1)\n",
    "print(f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "print(f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "print()\n",
    "\n",
    "# Display statistics dataframe for statements\n",
    "df_statement.index.rename(f\"For {N_statement} reviews\", inplace=True)\n",
    "print(tabulate(df_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "path_statements = output_directory / '2-statements.csv'\n",
    "df_statement.to_csv(path_statements, index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Calculate Fleiss' Kappa for the statements\n",
    "kappa_fleiss_statement = kappa_fleiss_3(list_statement_1, list_statement_2, list_statement_3)\n",
    "print(f\"Fleiss' Kappa: {kappa_fleiss_statement}\")\n",
    "\n",
    "### Sanity check ###\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# kappa_sk_statement = cohen_kappa_score(list_statement_1, list_statement_2)\n",
    "# print(f\"kappa sklearn: {kappa_sk_statement}\")\n",
    "\n",
    "# Calculate confidence intervals for Fleiss' Kappa\n",
    "ci_low_fleiss_statement, ci_high_fleiss_statement = ci_bootstrap_3(list_statement_1, list_statement_2, list_statement_3)\n",
    "print(f\"Confidence intervals (bootstrap): [{ci_low_fleiss_statement:.2f}, {ci_high_fleiss_statement:.2f}]\")\n",
    "print()\n",
    "\n",
    "# Display confusion matrices for pairwise comparisons of reviews\n",
    "print(\"Review 1 VS review 2\")\n",
    "m1_statement = create_confusion_matrix(list_statement_1, list_statement_2, statement_list)\n",
    "print(tabulate(m1_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 2 VS review 3\")\n",
    "m2_statement = create_confusion_matrix(list_statement_2, list_statement_3, statement_list)\n",
    "print(tabulate(m2_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 1 VS review 3\")\n",
    "m3_statement = create_confusion_matrix(list_statement_1, list_statement_3, statement_list)\n",
    "print(tabulate(m3_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for comments (on 270 reviewers):\n",
      "\n",
      "- 22.96% of reviews (62/270) in category 4. (-/+) comments\n",
      "Confidence intervals (binomial proportion): [17.95%, 27.98%]\n",
      "Confidence intervals (bootstrap): [18.15%, 28.15%]\n",
      "\n",
      "- 30.74% of reviews (83/270) in category 3. (+) comments\n",
      "Confidence intervals (binomial proportion): [25.24%, 36.24%]\n",
      "Confidence intervals (bootstrap): [25.56%, 35.94%]\n",
      "\n",
      "- 18.52% of reviews (50/270) in category 2. (-) comments\n",
      "Confidence intervals (binomial proportion): [13.89%, 23.15%]\n",
      "Confidence intervals (bootstrap): [13.70%, 22.96%]\n",
      "\n",
      "- 22.22% of reviews (60/270) in category 1. (none) comments\n",
      "Confidence intervals (binomial proportion): [17.26%, 27.18%]\n",
      "Confidence intervals (bootstrap): [17.41%, 27.41%]\n",
      "\n",
      "- 5.56% of reviews (15/270) in category 0. Unusable (comments)\n",
      "Confidence intervals (binomial proportion): [2.82%, 8.29%]\n",
      "Confidence intervals (bootstrap): [2.96%, 8.52%]\n",
      "\n",
      "- 72.22% of reviews (195/270) provided a comment\n",
      "Confidence intervals (binomial proportion): [66.88%, 77.56%]\n",
      "Confidence intervals (bootstrap): [66.67%, 77.42%]\n",
      "\n",
      "+------------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews        |   number |   percent |   ci low |   ci high |\n",
      "|------------------------+----------+-----------+----------+-----------|\n",
      "| 4. (-/+) comments      |       62 |     22.96 |    18.15 |     28.15 |\n",
      "| 3. (+) comments        |       83 |     30.74 |    25.56 |     35.94 |\n",
      "| 2. (-) comments        |       50 |     18.52 |    13.7  |     22.96 |\n",
      "| 1. (none) comments     |       60 |     22.22 |    17.41 |     27.41 |\n",
      "| 0. Unusable (comments) |       15 |      5.56 |     2.96 |      8.52 |\n",
      "+------------------------+----------+-----------+----------+-----------+\n",
      "Fleiss' Kappa: 0.0474911357043086\n",
      "Confidence intervals (bootstrap): [-0.03%, 0.12%]\n",
      "\n",
      "Review 1 VS review 2\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "|                        |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 4. (-/+) comments      |                4.44 |              7.78 |              4.44 |                 7.78 |                     1.11 |   25.56 |\n",
      "| 3. (+) comments        |                6.67 |              8.89 |              4.44 |                 6.67 |                     1.11 |   27.78 |\n",
      "| 2. (-) comments        |                4.44 |              6.67 |              5.56 |                 4.44 |                     0    |   21.11 |\n",
      "| 1. (none) comments     |                2.22 |              7.78 |              5.56 |                 4.44 |                     2.22 |   22.22 |\n",
      "| 0. Unusable (comments) |                0    |              1.11 |              2.22 |                 0    |                     0    |    3.33 |\n",
      "| total                  |               17.78 |             32.22 |             22.22 |                23.33 |                     4.44 |  100    |\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n",
      "Review 2 VS review 3\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "|                        |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 4. (-/+) comments      |               10    |              2.22 |              1.11 |                 4.44 |                     0    |   17.78 |\n",
      "| 3. (+) comments        |                4.44 |             14.44 |              2.22 |                 6.67 |                     4.44 |   32.22 |\n",
      "| 2. (-) comments        |                5.56 |              5.56 |              3.33 |                 4.44 |                     3.33 |   22.22 |\n",
      "| 1. (none) comments     |                2.22 |             10    |              5.56 |                 4.44 |                     1.11 |   23.33 |\n",
      "| 0. Unusable (comments) |                3.33 |              0    |              0    |                 1.11 |                     0    |    4.44 |\n",
      "| total                  |               25.56 |             32.22 |             12.22 |                21.11 |                     8.89 |  100    |\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n",
      "Review 1 VS review 3\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "|                        |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 4. (-/+) comments      |                4.44 |              7.78 |              3.33 |                 6.67 |                     3.33 |   25.56 |\n",
      "| 3. (+) comments        |                8.89 |             11.11 |              2.22 |                 3.33 |                     2.22 |   27.78 |\n",
      "| 2. (-) comments        |                5.56 |              4.44 |              3.33 |                 5.56 |                     2.22 |   21.11 |\n",
      "| 1. (none) comments     |                6.67 |              6.67 |              3.33 |                 5.56 |                     0    |   22.22 |\n",
      "| 0. Unusable (comments) |                0    |              2.22 |              0    |                 0    |                     1.11 |    3.33 |\n",
      "| total                  |               25.56 |             32.22 |             12.22 |                21.11 |                     8.89 |  100    |\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Statistics on the rating for the comments category\n",
    "########################################################################\n",
    "\n",
    "# Initialize the output dataframe to store statistics on comments with zeros.\n",
    "df_comments = pd.DataFrame(np.zeros((len(comments_list), 4)), index=comments_list, columns=[\"number\", \"percent\", \"ci low\", \"ci high\"])\n",
    "\n",
    "# Extract the comments category for the 3 reviews\n",
    "reviews_comments = []\n",
    "list_comment_1 = df_rating_1.loc[2:, 10].values.tolist()\n",
    "list_comment_2 = df_rating_1.loc[2:, 19].values.tolist()\n",
    "list_comment_3 = df_rating_1.loc[2:, 28].values.tolist()\n",
    "reviews_comments = list_comment_1 + list_comment_2 + list_comment_3\n",
    "\n",
    "# Display information about the analysis\n",
    "print(f\"Statistics for comments (on {len(reviews_comments)} reviewers):\")\n",
    "print()\n",
    "N_comments = len(reviews_comments)\n",
    "\n",
    "# Iterate over each rating level in the comments list and calculate statistics\n",
    "for rating in comments_list:\n",
    "    # Calculate number and percentage of reviews for the current rating level\n",
    "    count_ = reviews_comments.count(rating)\n",
    "    percent_ = round(count_ * 100 / N_comments, 2)\n",
    "\n",
    "    # Populate the output dataframe with the calculated statistics\n",
    "    df_comments.loc[rating, \"number\"] = count_\n",
    "    df_comments.loc[rating, \"percent\"] = percent_\n",
    "\n",
    "    # Print information about the rating level and its statistics\n",
    "    print(f\"- {percent_}% of reviews ({count_}/{N_comments}) in category {rating}\")\n",
    "\n",
    "    # Calculate confidence intervals using binomial proportion and bootstrap methods\n",
    "    proportion = count_ / N_comments\n",
    "    ci_bp_low, ci_bp_high = ci_bp(proportion, N_comments)\n",
    "    ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(reviews_comments, rating)\n",
    "\n",
    "    # Populate the output dataframe with confidence interval values\n",
    "    df_comments.loc[rating, \"ci low\"] = round(ci_bootstrap_low, 2)\n",
    "    df_comments.loc[rating, \"ci high\"] = round(ci_bootstrap_high, 2)\n",
    "\n",
    "    # Print confidence intervals\n",
    "    print(f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "    print(f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "    print()\n",
    "\n",
    "# Calculate percentage and confidence intervals for reviews that provided a comment\n",
    "new_reviews_comments = []\n",
    "for i in range(N_comments):\n",
    "    if (\n",
    "        reviews_comments[i] == \"4. (-/+) comments\"\n",
    "        or reviews_comments[i] == \"3. (+) comments\"\n",
    "        or reviews_comments[i] == \"2. (-) comments\"\n",
    "    ):\n",
    "        new_reviews_comments.append(1)\n",
    "    else:\n",
    "        new_reviews_comments.append(0)\n",
    "\n",
    "new_count_ = new_reviews_comments.count(1)\n",
    "new_percent_ = round(new_count_ * 100 / N_comments, 2)\n",
    "\n",
    "# Display information about reviews that provided a comment\n",
    "print(f\"- {new_percent_}% of reviews ({new_count_}/{N_comments}) provided a comment\")\n",
    "\n",
    "# Calculate confidence intervals for reviews that provided a comment\n",
    "proportion = new_count_ / N_comments\n",
    "ci_bp_low, ci_bp_high = ci_bp(proportion, N_comments)\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(new_reviews_comments, 1)\n",
    "print(f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "print(f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "print()\n",
    "\n",
    "# Display statistics dataframe for comments\n",
    "df_comments.index.rename(f\"For {N_comments} reviews\", inplace=True)\n",
    "print(tabulate(df_comments, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "path_comments = output_directory / '3-comments.csv'\n",
    "df_comments.to_csv(path_comments, index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Calculate Fleiss' Kappa for the comments\n",
    "kappa_fleiss_comment = kappa_fleiss_3(list_comment_1, list_comment_2, list_comment_3)\n",
    "print(f\"Fleiss' Kappa: {kappa_fleiss_comment}\")\n",
    "\n",
    "# Calculate confidence intervals for Fleiss' Kappa\n",
    "ci_low_fleiss_comment, ci_high_fleiss_comment = ci_bootstrap_3(list_comment_1, list_comment_2, list_comment_3)\n",
    "print(f\"Confidence intervals (bootstrap): [{ci_low_fleiss_comment:.2f}%, {ci_high_fleiss_comment:.2f}%]\")\n",
    "print()\n",
    "\n",
    "# Display confusion matrices for pairwise comparisons of reviews\n",
    "print(\"Review 1 VS review 2\")\n",
    "m1_comment = create_confusion_matrix(list_comment_1, list_comment_2, comments_list)\n",
    "print(tabulate(m1_comment, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 2 VS review 3\")\n",
    "m2_comment = create_confusion_matrix(list_comment_2, list_comment_3, comments_list)\n",
    "print(tabulate(m2_comment, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 1 VS review 3\")\n",
    "m3_comment = create_confusion_matrix(list_comment_1, list_comment_3, comments_list)\n",
    "print(tabulate(m3_comment, headers='keys', tablefmt='psql'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of statements VS comments\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "| number                  |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 3. (+) statement        |                  21 |                52 |                 7 |                   52 |                        0 |     132 |\n",
      "| 2. (-) statement        |                   8 |                 0 |                21 |                    3 |                        0 |      32 |\n",
      "| 1. (none) statement     |                  33 |                31 |                22 |                    5 |                        9 |     100 |\n",
      "| 0. Unusable (statement) |                   0 |                 0 |                 0 |                    0 |                        6 |       6 |\n",
      "| total                   |                  62 |                83 |                50 |                   60 |                       15 |     270 |\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n",
      "39.39% of reviewers (52/132) made a positive statement but didn't provide a comment to substantiate their statement.\n",
      "Confidence intervals (binomial proportion): [31.06%, 47.73%]\n",
      "Confidence intervals (bootstrap): [30.66%, 47.73%]\n",
      "\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "| in %                    |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 3. (+) statement        |                7.78 |             19.26 |              2.59 |                19.26 |                     0    |   48.89 |\n",
      "| 2. (-) statement        |                2.96 |              0    |              7.78 |                 1.11 |                     0    |   11.85 |\n",
      "| 1. (none) statement     |               12.22 |             11.48 |              8.15 |                 1.85 |                     3.33 |   37.04 |\n",
      "| 0. Unusable (statement) |                0    |              0    |              0    |                 0    |                     2.22 |    2.22 |\n",
      "| total                   |               22.96 |             30.74 |             18.52 |                22.22 |                     5.56 |  100    |\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Analysis of statement category VS comment category\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# Initialize with zeros a DataFrame to store the cross-tabulation of statements and comments\n",
    "df_stat_com = pd.DataFrame(np.zeros((len(statement_list) + 1, len(comments_list) + 1)), index=statement_list + [\"total\"], columns=comments_list + [\"total\"])\n",
    "df_stat_com.index.rename(\"number\", inplace=True)\n",
    "\n",
    "# Populate the cross-tabulation DataFrame based on the reviews' statements and comments\n",
    "for i in range(len(reviews_comments)):\n",
    "    df_stat_com.loc[reviews_statement[i], reviews_comments[i]] += 1\n",
    "    df_stat_com.loc[\"total\", reviews_comments[i]] += 1\n",
    "    df_stat_com.loc[reviews_statement[i], \"total\"] += 1\n",
    "\n",
    "# Set the total count for the total row and column\n",
    "df_stat_com.loc[\"total\", \"total\"] = len(reviews_comments)\n",
    "\n",
    "# Display the cross-tabulation of statements and comments\n",
    "print(\"Analysis of statements VS comments\")\n",
    "print(tabulate(df_stat_com, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "# Identify reviewers who made a positive statement but didn't provide a comment\n",
    "reviews_statement_no_comments = []\n",
    "for i in range(len(reviews_comments)):\n",
    "    if reviews_statement[i] == \"3. (+) statement\":\n",
    "        if (reviews_comments[i] == \"1. (none) comments\" or reviews_comments[i] == \"0. (Unusable) comments\"):\n",
    "            reviews_statement_no_comments.append(1)\n",
    "        else:\n",
    "            reviews_statement_no_comments.append(0)\n",
    "\n",
    "# Calculate percentage and confidence intervals for reviewers who made a positive statement but didn't provide a comment\n",
    "new_count_ = reviews_statement_no_comments.count(1)\n",
    "new_percent_ = round(new_count_ * 100 / len(reviews_statement_no_comments), 2)\n",
    "print(f\"{new_percent_}% of reviewers ({new_count_}/{len(reviews_statement_no_comments)}) made a positive statement but didn't provide a comment to substantiate their statement.\")\n",
    "\n",
    "proportion = new_count_ / len(reviews_statement_no_comments)\n",
    "ci_bp_low, ci_bp_high = ci_bp(proportion, len(reviews_statement_no_comments))\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(reviews_statement_no_comments, 1)\n",
    "print(f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "print(f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "print()\n",
    "\n",
    "# Save the cross-tabulation DataFrame to a CSV file\n",
    "path_statements_comments = output_directory / '4-statements_comments.csv'\n",
    "df_stat_com.to_csv(path_statements_comments, index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Create a new DataFrame to store the percentage representation of statements and comments\n",
    "df_stat_com_percent = df_stat_com\n",
    "df_stat_com_percent.index.rename(\"in %\", inplace=True)\n",
    "df_stat_com_percent = round(df_stat_com * 100 / len(reviews_comments), 2)\n",
    "\n",
    "# Display the percentage representation of statements and comments\n",
    "print(tabulate(df_stat_com_percent, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta categories calculated values aren't the same as in the provided tsv file.\n",
      "Statistics for meta-categories (on 270 reviewers):\n",
      "\n",
      "- 60.37% of reviews (163/270) in category (+) meta\n",
      "Confidence intervals (multinomial proportion): [54.54%, 66.20%]\n",
      "Confidence intervals (bootstrap): [54.44%, 66.30%]\n",
      "\n",
      "- 31.11% of reviews (84/270) in category (-) meta\n",
      "Confidence intervals (multinomial proportion): [25.59%, 36.63%]\n",
      "Confidence intervals (bootstrap): [25.36%, 37.04%]\n",
      "\n",
      "- 8.52% of reviews (23/270) in category Unusable (meta)\n",
      "Confidence intervals (multinomial proportion): [5.19%, 11.85%]\n",
      "Confidence intervals (bootstrap): [5.19%, 11.85%]\n",
      "\n",
      "+-------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews   |   number |   percent |   ci low |   ci high |\n",
      "|-------------------+----------+-----------+----------+-----------|\n",
      "| (+) meta          |      163 |     60.37 |    54.44 |     66.3  |\n",
      "| (-) meta          |       84 |     31.11 |    25.36 |     37.04 |\n",
      "| Unusable (meta)   |       23 |      8.52 |     5.19 |     11.85 |\n",
      "+-------------------+----------+-----------+----------+-----------+\n",
      "kappa fleiss: 0.021688128877534983\n",
      "Confidence intervals (bootstrap): [-0.08%, 0.13%]\n",
      "\n",
      "Review 1 VS review 2\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "|                 |   (+) meta |   (-) meta |   Unusable (meta) |   total |\n",
      "|-----------------+------------+------------+-------------------+---------|\n",
      "| (+) meta        |      33.33 |      23.33 |              3.33 |   60    |\n",
      "| (-) meta        |      22.22 |      10    |              1.11 |   33.33 |\n",
      "| Unusable (meta) |       3.33 |       2.22 |              1.11 |    6.67 |\n",
      "| total           |      58.89 |      35.56 |              5.56 |  100    |\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "\n",
      "Review 2 VS review 3\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "|                 |   (+) meta |   (-) meta |   Unusable (meta) |   total |\n",
      "|-----------------+------------+------------+-------------------+---------|\n",
      "| (+) meta        |      40    |      12.22 |              6.67 |   58.89 |\n",
      "| (-) meta        |      18.89 |      13.33 |              3.33 |   35.56 |\n",
      "| Unusable (meta) |       3.33 |       2.22 |              0    |    5.56 |\n",
      "| total           |      62.22 |      27.78 |             10    |  100    |\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "\n",
      "Review 1 VS review 3\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "|                 |   (+) meta |   (-) meta |   Unusable (meta) |   total |\n",
      "|-----------------+------------+------------+-------------------+---------|\n",
      "| (+) meta        |      38.89 |      18.89 |              2.22 |   60    |\n",
      "| (-) meta        |      18.89 |       7.78 |              6.67 |   33.33 |\n",
      "| Unusable (meta) |       4.44 |       1.11 |              1.11 |    6.67 |\n",
      "| total           |      62.22 |      27.78 |             10    |  100    |\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Statistics on the rating for the meta category\n",
    "########################################################################\n",
    "\n",
    "# Initialize with zeros a DataFrame to store the statistics on the rating for the meta category\n",
    "df_meta = pd.DataFrame(np.zeros((len(meta_categories_list), 4)), index=meta_categories_list, columns=[\"number\", \"percent\", \"ci low\", \"ci high\"])\n",
    "\n",
    "# Combine the ratings for the meta category from the three reviews\n",
    "reviews_meta = []\n",
    "list_meta_1 = df_rating_1.loc[2:, 29].values.tolist()\n",
    "list_meta_2 = df_rating_1.loc[2:, 30].values.tolist()\n",
    "list_meta_3 = df_rating_1.loc[2:, 31].values.tolist()\n",
    "reviews_meta = list_meta_1 + list_meta_2 + list_meta_3\n",
    "\n",
    "# Convert reviews_meta to match provided categories for consistency\n",
    "reviews_meta_python = []\n",
    "for i in range(len(reviews_statement)):\n",
    "    if reviews_statement[i] == \"3. (+) statement\":\n",
    "        reviews_meta_python.append(\"(+) meta\")\n",
    "    elif reviews_statement[i] == \"2. (-) statement \":\n",
    "        reviews_meta_python.append(\"(-) meta\")\n",
    "    elif reviews_comments[i] == \"3. (+) comments\":\n",
    "        reviews_meta_python.append(\"(+) meta\")\n",
    "    elif reviews_comments[i] == \"2. (-) comments\" or reviews_comments[i] == \"4. (-/+) comments\":\n",
    "        reviews_meta_python.append(\"(-) meta\")\n",
    "    else:\n",
    "        reviews_meta_python.append(\"Unusable (meta)\")\n",
    "\n",
    "# Check and update reviews_meta if necessary\n",
    "if not (reviews_meta == reviews_meta_python):\n",
    "    reviews_meta = reviews_meta_python\n",
    "    print(\"Meta categories calculated values aren't the same as in the provided tsv file.\")\n",
    "\n",
    "print(f\"Statistics for meta-categories (on {len(reviews_meta)} reviewers):\")\n",
    "print()\n",
    "\n",
    "# Calculate and display statistics for the meta category\n",
    "N_meta = len(reviews_meta)\n",
    "for rating in meta_categories_list:\n",
    "    count_ = reviews_meta.count(rating)\n",
    "    percent_ = round(count_ * 100 / N_meta, 2)\n",
    "    df_meta.loc[rating, \"number\"] = count_\n",
    "    df_meta.loc[rating, \"percent\"] = percent_\n",
    "    print(f\"- {percent_}% of reviews ({count_}/{N_meta}) in category {rating}\")\n",
    "\n",
    "    proportion = count_ / N_meta\n",
    "    ci_bp_low, ci_bp_high = ci_bp(proportion, N_meta)\n",
    "    ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(reviews_meta, rating)\n",
    "\n",
    "    df_meta.loc[rating, \"ci low\"] = round(ci_bootstrap_low, 2)\n",
    "    df_meta.loc[rating, \"ci high\"] = round(ci_bootstrap_high, 2)\n",
    "\n",
    "    print(f\"Confidence intervals (multinomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "    print(f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "    print()\n",
    "\n",
    "# Save the statistics DataFrame to a CSV file\n",
    "df_meta.index.rename(f\"For {N_meta} reviews\", inplace=True)\n",
    "print(tabulate(df_meta, headers='keys', tablefmt='psql'))\n",
    "\n",
    "path_meta = output_directory / '5-meta.csv'\n",
    "df_meta.to_csv(path_meta, index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Calculate Fleiss' Kappa for the meta category\n",
    "kappa_fleiss_meta = kappa_fleiss_3(list_meta_1, list_meta_2, list_meta_3)\n",
    "print(f\"kappa fleiss: {kappa_fleiss_meta}\")\n",
    "\n",
    "# Calculate confidence intervals for Fleiss' Kappa\n",
    "ci_low_fleiss_meta, ci_high_fleiss_meta = ci_bootstrap_3(list_meta_1, list_meta_2, list_meta_3)\n",
    "print(f\"Confidence intervals (bootstrap): [{ci_low_fleiss_meta:.2f}%, {ci_high_fleiss_meta:.2f}%]\")\n",
    "print()\n",
    "\n",
    "# Display confusion matrices for pairwise comparisons of reviews\n",
    "print(\"Review 1 VS review 2\")\n",
    "m1_meta = create_confusion_matrix(list_meta_1, list_meta_2, meta_categories_list)\n",
    "print(tabulate(m1_meta, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 2 VS review 3\")\n",
    "m2_meta = create_confusion_matrix(list_meta_2, list_meta_3, meta_categories_list)\n",
    "print(tabulate(m2_meta, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 1 VS review 3\")\n",
    "m3_meta = create_confusion_matrix(list_meta_1, list_meta_3, meta_categories_list)\n",
    "print(tabulate(m3_meta, headers='keys', tablefmt='psql'))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+----------+-----------+\n",
      "| kappa fleiss    |   kappa |   ci low |   ci high |\n",
      "|-----------------+---------+----------+-----------|\n",
      "| Statements      |   -0.05 |    -0.14 |      0.03 |\n",
      "| Comments        |    0.05 |    -0.03 |      0.12 |\n",
      "| Meta-categories |    0.02 |    -0.08 |      0.13 |\n",
      "+-----------------+---------+----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Creating table of kappa values\n",
    "########################################################################\n",
    "\n",
    "# Create a DataFrame to store kappa Fleiss values and confidence intervals for different categories\n",
    "df_kappas = pd.DataFrame(np.zeros((3, 3)), index=[\"Statements\", \"Comments\", \"Meta-categories\"], columns=[\"kappa\", \"ci low\", \"ci high\"])\n",
    "\n",
    "# Populate the DataFrame with kappa Fleiss values and confidence intervals for the statements category\n",
    "df_kappas.loc[\"Statements\", \"kappa\"] = kappa_fleiss_statement\n",
    "df_kappas.loc[\"Statements\", \"ci low\"] = ci_low_fleiss_statement\n",
    "df_kappas.loc[\"Statements\", \"ci high\"] = ci_high_fleiss_statement\n",
    "\n",
    "# Populate the DataFrame with kappa Fleiss values and confidence intervals for the comments category\n",
    "df_kappas.loc[\"Comments\", \"kappa\"] = kappa_fleiss_comment\n",
    "df_kappas.loc[\"Comments\", \"ci low\"] = ci_low_fleiss_comment\n",
    "df_kappas.loc[\"Comments\", \"ci high\"] = ci_high_fleiss_comment\n",
    "\n",
    "# Populate the DataFrame with kappa Fleiss values and confidence intervals for the meta-categories\n",
    "df_kappas.loc[\"Meta-categories\", \"kappa\"] = kappa_fleiss_meta\n",
    "df_kappas.loc[\"Meta-categories\", \"ci low\"] = ci_low_fleiss_meta\n",
    "df_kappas.loc[\"Meta-categories\", \"ci high\"] = ci_high_fleiss_meta\n",
    "\n",
    "# Round the values in the DataFrame for better presentation\n",
    "df_kappas = round(df_kappas, 2)\n",
    "\n",
    "# Rename the index for clarity\n",
    "df_kappas.index.rename(\"kappa fleiss\", inplace=True)\n",
    "\n",
    "# Display the kappa Fleiss values and confidence intervals in tabular format\n",
    "print(tabulate(df_kappas, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Save the kappa Fleiss values and confidence intervals to a CSV file\n",
    "path_kappas = output_directory / '6-kappas.csv'\n",
    "df_kappas.to_csv(path_kappas, index=True, sep=\";\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for code (on 90 papers):\n",
      "\n",
      " - for 47.78% (95% CI (bootstrap): [37.78%, 57.78%]) of the papers (43/90), the repository exists and is not empty.\n",
      " - for 20.00% (95% CI (bootstrap): [12.22%, 28.89%]) of the papers (18/90), the link to the repository is provided but it is empty or wrong.\n",
      " - for 32.22% (95% CI (bootstrap): [23.33%, 42.22%]) of the papers (29/90), no link/code was provided.\n",
      "\n",
      " - for 67.78% (95% CI (bootstrap): [58.89%, 76.67%]) of the papers (61/90), an associated repository for the code was provided.\n",
      "\n",
      " - for 29.51% (95% CI (bootstrap): [18.03%, 40.98%]) of the papers for which a link was provided (18/61), the link to the repository is provided but it is empty or wrong.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Statistics on the rating for the code category\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# Define column indices for code-related information\n",
    "column_id_link = 38\n",
    "code_link_df = df_rating_1.loc[2:, column_id_link].values.tolist()\n",
    "\n",
    "column_id_avail = 39\n",
    "code_avail_df = df_rating_1.loc[2:, column_id_avail].values.tolist()\n",
    "\n",
    "# Define code categories\n",
    "code_list = [\n",
    "    \"bad link\",\n",
    "    \"good link\",\n",
    "    \"no link\",\n",
    "]\n",
    "\n",
    "# Display statistics for code availability on papers\n",
    "print(f\"Statistics for code (on {len(code_link_df)} papers):\")\n",
    "print()\n",
    "\n",
    "# Create a list to store code categories for each paper\n",
    "list_code = []\n",
    "\n",
    "# Determine code categories based on code links and availability\n",
    "for i in range(len(code_avail_df)):\n",
    "    if str(code_link_df[i]).startswith(\"http\"):\n",
    "        if code_avail_df[i] == \"1\":\n",
    "            list_code.append(\"good link\")\n",
    "        if code_avail_df[i] == \"0\":\n",
    "            list_code.append(\"bad link\")\n",
    "    else:\n",
    "        list_code.append(\"no link\")\n",
    "\n",
    "# Calculate the number of papers\n",
    "nb_papers = len(list_code)\n",
    "\n",
    "# Display statistics for each code category\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code, \"good link\")\n",
    "print(f\" - for {(list_code.count('good link') * 100 / nb_papers):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code.count('good link')}/{nb_papers}), the repository exists and is not empty.\")\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code, \"bad link\")\n",
    "print(f\" - for {(list_code.count('bad link') * 100 / nb_papers):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code.count('bad link')}/{nb_papers}), the link to the repository is provided but it is empty or wrong.\")\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code, \"no link\")\n",
    "print(f\" - for {(list_code.count('no link') * 100 / nb_papers):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code.count('no link')}/{nb_papers}), no link/code was provided.\")\n",
    "print()\n",
    "\n",
    "# Create a binary list to represent the presence or absence of code links\n",
    "list_code_binary = [1 if x in [\"good link\", \"bad link\"] else 0 for x in list_code]\n",
    "\n",
    "# Display statistics for the presence of code links\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code_binary, 1)\n",
    "print(f\" - for {(100 * list_code_binary.count(1) / len(list_code_binary)):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code_binary.count(1)}/{len(list_code_binary)}), an associated repository for the code was provided.\")\n",
    "print()\n",
    "\n",
    "# Filter the code list to include only \"good link\" and \"bad link\" categories\n",
    "list_code_bis = [x for x in list_code if (x == \"good link\" or x == \"bad link\")]\n",
    "\n",
    "# Display statistics for the \"bad link\" category among papers with provided links\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code_bis, \"bad link\")\n",
    "print(f\" - for {(100 * list_code_bis.count('bad link') / len(list_code_bis)):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers for which a link was provided ({list_code.count('bad link')}/{len(list_code_bis)}), the link to the repository is provided but it is empty or wrong.\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 86.67% (95% CI (bootstrap): [78.89%, 93.33%]) of the papers (78/90), at least one of the reviewers said that the code was available.\n",
      "\n",
      "For these 78 papers:\n",
      " - for 47.44% (95% CI (bootstrap): [35.90%, 58.97%]) of the papers (37.0/78), at least one reviewer stated that the code was available and the link was valid.\n",
      " - for 20.51% (95% CI (bootstrap): [12.82%, 30.77%]) of the papers (16.0/78), at least one reviewer stated that the code was available, even if the link led to an error message or an empty repository.\n",
      " - for 32.05% (95% CI (bootstrap): [23.08%, 42.31%]) of the papers (25.0/78), at least one reviewer stated that the code was available, even if no link/code was provided.\n",
      "\n",
      " - for 52.56% (95% CI (bootstrap): [41.03%, 62.85%]) of the papers (41/78), at least one reviewer stated that the code was available, even if the code was actually missing in the published version (no link, broken link, or empty repository)\n",
      "\n",
      "\n",
      "The tables below indicate, for each paper, whether at least one reviewer stated that the \n",
      " code was/will be available (1) or not (0), and whether the link was present and non-empty (good link), \n",
      " present but with an empty repository (empty link), or whether there was no link (no link).\n",
      "\n",
      "+----------------------------------+------------+-------------+-----------+---------+\n",
      "| code availableness (in number)   |   bad link |   good link |   no link |   total |\n",
      "|----------------------------------+------------+-------------+-----------+---------|\n",
      "| no info                          |          2 |           6 |         4 |      12 |\n",
      "| code promised                    |         16 |          37 |        25 |      78 |\n",
      "| total                            |         18 |          43 |        29 |      90 |\n",
      "+----------------------------------+------------+-------------+-----------+---------+\n",
      "+-----------------------------+------------+-------------+-----------+---------+\n",
      "| code availableness (in %)   |   bad link |   good link |   no link |   total |\n",
      "|-----------------------------+------------+-------------+-----------+---------|\n",
      "| no info                     |       2.22 |        6.67 |      4.44 |   13.33 |\n",
      "| code promised               |      17.78 |       41.11 |     27.78 |   86.67 |\n",
      "| total                       |      20    |       47.78 |     32.22 |  100    |\n",
      "+-----------------------------+------------+-------------+-----------+---------+\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Statistics on the rating for the code availibility \n",
    "########################################################################\n",
    "\n",
    "\n",
    "# Define columns for code availability in different reviews\n",
    "list_code_1 = df_rating_1.loc[2:, 5].values.tolist()\n",
    "list_code_2 = df_rating_1.loc[2:, 14].values.tolist()\n",
    "list_code_3 = df_rating_1.loc[2:, 23].values.tolist()\n",
    "\n",
    "# Create a list to store the final code review categories\n",
    "list_code_review = []\n",
    "\n",
    "# Determine code review categories based on code availability in different reviews\n",
    "# (code promised: At least 1 reviewer said the code will be made available)\n",
    "for i in range(len(list_code_1)):\n",
    "    x = list_code_1[i]\n",
    "    if x == '0' and x == list_code_2[i] and x == list_code_3[i]:\n",
    "        list_code_review.append(\"no info\")\n",
    "    else:\n",
    "        list_code_review.append('code promised')\n",
    "\n",
    "# Calculate and display statistics for code availability based on reviews\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code_review, \"code promised\")\n",
    "print(f\"For {(list_code_review.count('code promised')*100/len(list_code_review)):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code_review.count('code promised')}/{len(list_code_review)}), at least one of the reviewers said that the code was available.\")\n",
    "print()\n",
    "\n",
    "# Create a DataFrame to store code availability and review information\n",
    "df_code_reviews = pd.DataFrame(np.zeros((3, 4)), index=[\"no info\", \"code promised\", \"total\"], columns=code_list + [\"total\"])\n",
    "\n",
    "# Further categorize code reviews and update the DataFrame\n",
    "list_code_final = []\n",
    "\n",
    "# Iterate over each paper's code information and respective reviews\n",
    "for i in range(len(list_code)):\n",
    "    # Check if the code link is labeled as \"good link\" and the review indicates \"code promised\"\n",
    "    if list_code[i] == \"good link\" and list_code_review[i] == \"code promised\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"code promised\", \"good link\"] += 1\n",
    "        list_code_final.append(\"code promised good link\")\n",
    "    \n",
    "    # Check if the code link is labeled as \"good link\" but the review has \"no info\"\n",
    "    if list_code[i] == \"good link\" and list_code_review[i] == \"no info\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"no info\", \"good link\"] += 1\n",
    "        list_code_final.append(\"no info good link\")\n",
    "\n",
    "    # Check if the code link is labeled as \"bad link\" and the review indicates \"code promised\"\n",
    "    if list_code[i] == \"bad link\" and list_code_review[i] == \"code promised\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"code promised\", \"bad link\"] += 1\n",
    "        list_code_final.append(\"code promised bad link\")\n",
    "    \n",
    "    # Check if the code link is labeled as \"bad link\" but the review has \"no info\"\n",
    "    if list_code[i] == \"bad link\" and list_code_review[i] == \"no info\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"no info\", \"bad link\"] += 1\n",
    "        list_code_final.append(\"no info bad link\")\n",
    "\n",
    "    # Check if the code link is labeled as \"no link\" and the review indicates \"code promised\"\n",
    "    if list_code[i] == \"no link\" and list_code_review[i] == \"code promised\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"code promised\", \"no link\"] += 1\n",
    "        list_code_final.append(\"code promised no link\")\n",
    "    \n",
    "    # Check if the code link is labeled as \"no link\" but the review has \"no info\"\n",
    "    if list_code[i] == \"no link\" and list_code_review[i] == \"no info\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"no info\", \"no link\"] += 1\n",
    "        list_code_final.append(\"no info no link\")\n",
    "\n",
    "# Update totals in the DataFrame\n",
    "df_code_reviews.loc[\"code promised\", \"total\"] = df_code_reviews.loc[\"code promised\", \"good link\"] + df_code_reviews.loc[\"code promised\", \"bad link\"] + df_code_reviews.loc[\"code promised\", \"no link\"]\n",
    "df_code_reviews.loc[\"no info\", \"total\"] = df_code_reviews.loc[\"no info\", \"good link\"] + df_code_reviews.loc[\"no info\", \"bad link\"] + df_code_reviews.loc[\"no info\", \"no link\"]\n",
    "\n",
    "df_code_reviews.loc[\"total\", \"good link\"] = df_code_reviews.loc[\"code promised\", \"good link\"] + df_code_reviews.loc[\"no info\", \"good link\"] \n",
    "df_code_reviews.loc[\"total\", \"bad link\"] = df_code_reviews.loc[\"code promised\", \"bad link\"] + df_code_reviews.loc[\"no info\", \"bad link\"] \n",
    "df_code_reviews.loc[\"total\", \"no link\"] = df_code_reviews.loc[\"code promised\", \"no link\"] + df_code_reviews.loc[\"no info\", \"no link\"] \n",
    "\n",
    "df_code_reviews.loc[\"total\", \"total\"] = df_code_reviews.loc[\"code promised\", \"total\"] + df_code_reviews.loc[\"no info\", \"total\"]\n",
    "\n",
    "# Calculate statistics for good reviews and bad reviews\n",
    "\n",
    "# Filter out reviews categorized as \"code promised\"\n",
    "good_review_list = [x for x in list_code_final if x.startswith(\"code promised\")]\n",
    "nb_good_reviews = len(good_review_list)\n",
    "\n",
    "# Display the number of papers with at least one reviewer stating that the code is available\n",
    "print(f\"For these {nb_good_reviews} papers:\")\n",
    "\n",
    "# Calculate and display the percentage of papers with \"code promised\" for each sub-category\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(good_review_list, \"code promised good link\")\n",
    "print(f\" - for {(df_code_reviews.loc['code promised', 'good link']*100 / nb_good_reviews):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['code promised', 'good link']}/{nb_good_reviews}), at least one reviewer stated that the code was available and the link was valid.\")\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(good_review_list, \"code promised bad link\")\n",
    "print(f\" - for {(df_code_reviews.loc['code promised', 'bad link']*100 / nb_good_reviews):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['code promised', 'bad link']}/{nb_good_reviews}), at least one reviewer stated that the code was available, even if the link led to an error message or an empty repository.\")\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(good_review_list, \"code promised no link\")\n",
    "print(f\" - for {(df_code_reviews.loc['code promised', 'no link']*100 / nb_good_reviews):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['code promised', 'no link']}/{nb_good_reviews}), at least one reviewer stated that the code was available, even if no link/code was provided.\")\n",
    "print()\n",
    "\n",
    "# Calculate statistics for papers with misleading information about code availability\n",
    "good_reviews_list_bis = [1 if x == \"code promised good link\" else 0 for x in good_review_list]\n",
    "\n",
    "# Display the percentage of papers where reviewers falsely claimed code availability\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(good_reviews_list_bis, 0)\n",
    "print(f\" - for {(good_reviews_list_bis.count(0)*100 / nb_good_reviews):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({good_reviews_list_bis.count(0)}/{nb_good_reviews}), at least one reviewer stated that the code was available, even if the code was actually missing in the published version (no link, broken link, or empty repository)\")\n",
    "print()\n",
    "\n",
    "# Calculate statistics for papers with misleading information about code availability\n",
    "\n",
    "# Filter out reviews categorized as \"no info\"\n",
    "bad_review_list = [x for x in list_code_final if x.startswith(\"no info\")]\n",
    "nb_bad_reviews = len(bad_review_list)\n",
    "\n",
    "# Commented out to avoid displaying an incomplete statement; consider uncommenting as needed\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(bad_review_list, \"no info good link\")\n",
    "# print(f\" - for {(df_code_reviews.loc['no info', 'good link']*100 / nb_bad_reviews):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['no info', 'good link']}/{nb_bad_reviews}), the reviewers said that the code wasn't available even if it was.\")\n",
    "print()\n",
    "\n",
    "# Display information about the tables and the code reviews\n",
    "print(\"The tables below indicate, for each paper, whether at least one reviewer stated that the \\n code was/will be available (1) or not (0), and whether the link was present and non-empty (good link), \\n present but with an empty repository (empty link), or whether there was no link (no link).\")\n",
    "print()\n",
    "\n",
    "# Rename the index for clarity\n",
    "df_code_reviews.index.rename(\"code availableness (in number)\", inplace=True)\n",
    "\n",
    "# Display the table showing the number of papers in each category\n",
    "print(tabulate(df_code_reviews, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "path_code = output_directory / '7-code_number.csv'\n",
    "df_code_reviews.to_csv(path_code, index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Create a DataFrame representing percentages and rename the index for clarity\n",
    "df_code_review_percent = df_code_reviews\n",
    "df_code_review_percent.index.rename(\"code availableness (in %)\", inplace=True)\n",
    "df_code_review_percent = df_code_review_percent * 100 / len(list_code)\n",
    "\n",
    "# Save the DataFrame representing percentages to a CSV file\n",
    "path_code_percent = output_directory / '8-code_percent.csv'\n",
    "df_code_review_percent.to_csv(path_code_percent, index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Display the table showing the percentage of papers in each category\n",
    "print(tabulate(round(df_code_review_percent,2), headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary 'data' to store relevant information\n",
    "data = {}\n",
    "\n",
    "# Store the number of papers in the dictionnary\n",
    "data[\"nb_papers\"] = len(df_rating_1) - 2  # Subtracting 2 to exclude header rows\n",
    "\n",
    "# Calculate the total number of reviews (assuming 3 reviews per paper)\n",
    "data[\"nb_reviews\"] = (len(df_rating_1) - 2) * 3\n",
    "\n",
    "# Store the current date and time using datetime module\n",
    "data[\"date\"] = str(datetime.date.today())  # Store the current date\n",
    "data[\"time\"] = str(datetime.datetime.utcnow())  # Store the current UTC time\n",
    "\n",
    "# Store the path of the CSV file used for ratings\n",
    "data[\"path_rating\"] = path_csv\n",
    "\n",
    "# Convert the 'data' dictionary to a JSON-formatted string with indentation\n",
    "json_data = json.dumps(data, skipkeys=True, indent=4)\n",
    "\n",
    "# Define the path for the output JSON file\n",
    "json_path = output_directory / \"data.json\"\n",
    "\n",
    "# Write the JSON-formatted string to the specified JSON file\n",
    "with open(json_path, \"w\") as f:\n",
    "    f.write(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproducibility-reviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
