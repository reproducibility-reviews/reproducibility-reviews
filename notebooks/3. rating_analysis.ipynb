{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kappa(po, pe):\n",
    "    \"\"\"\n",
    "    Calculate the kappa score\n",
    "    \"\"\"\n",
    "    return (po-pe)/(1-pe)\n",
    "\n",
    "def expected_proportion(matrix: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Overall proportion of agreement expected by chance\n",
    "    \"\"\"\n",
    "    pe = 0\n",
    "    k = len(matrix)-1\n",
    "    for i in range(k):\n",
    "        pe += matrix.loc[i, k] * matrix.loc[k, i]\n",
    "    return pe\n",
    "\n",
    "def observed_proportion(matrix: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Overall proportion of observed agreement \n",
    "    \"\"\"\n",
    "    po = 0\n",
    "    k = len(matrix) - 1\n",
    "    for i in range(k):\n",
    "        po += matrix.loc[i, i]\n",
    "    return po\n",
    "\n",
    "def create_confusion_matrix(list_1: list , list_2: list, list_attributs)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create confusion matrix (in %)\n",
    "    \"\"\"\n",
    "    if not len(list_1)==len(list_2):\n",
    "        print(\"reviwer 1 and 2 may haven't rated the same list of subjects\")\n",
    "\n",
    "    else:\n",
    "        size = len(list_attributs)\n",
    "        matrix = pd.DataFrame(np.zeros((size + 1, size + 1)), index = list_attributs + [\"total\"], columns = list_attributs + [\"total\"])\n",
    "        for k in range(size):\n",
    "            for l in range(size):\n",
    "                att_k = list_attributs[k]\n",
    "                att_l = list_attributs[l]\n",
    "                for i in range(len(list_1)):\n",
    "                    if (list_1[i]== att_k):\n",
    "                        if list_2[i] == att_l :\n",
    "                            matrix.loc[att_k,att_l]+=1\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                att_i = list_attributs[i]\n",
    "                att_j = list_attributs[j]\n",
    "                matrix.loc[\"total\", att_i] += matrix.loc[att_j, att_i]\n",
    "                matrix.loc[att_i, \"total\"] += matrix.loc[att_i, att_j]\n",
    "                matrix.loc[\"total\", \"total\"] += matrix.loc[att_i, att_j]\n",
    "\n",
    "        if len(list_1) == matrix.loc[\"total\", \"total\"]:\n",
    "            matrix = round(matrix* 100/ len(list_1), 2)\n",
    "    return matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_bp(proportion, N):\n",
    "    \"\"\"\n",
    "    Confidence interval (binomial proportion)\n",
    "    \"\"\"\n",
    "    ci_bp_low = (-1.96 * sqrt(proportion*(1-proportion)/N) + proportion) * 100\n",
    "    ci_bp_high = (1.96 * sqrt(proportion*(1-proportion)/N) + proportion) * 100\n",
    "\n",
    "    return ci_bp_low, ci_bp_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_bootstrap(data, val, num_resamples = 1000):\n",
    "    \"\"\"\n",
    "    Confidence interval (bootstrap)\n",
    "    \"\"\"\n",
    "    K = len(data)\n",
    "    outputs = []\n",
    "    for i in range(num_resamples):\n",
    "        Y_resample = random.choices(data, k=K)\n",
    "        out = Y_resample.count(val)\n",
    "        outputs.append(out*100 / K )\n",
    "\n",
    "    return np.percentile(outputs, 2.25), np.percentile(outputs, 97.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa_fleiss_3(data_1, data_2, data_3):\n",
    "    \"\"\"\n",
    "    Boostrap function for cohen kappa score for 3 raters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        mean of the kappa across bootstrap samples\n",
    "    \"\"\"\n",
    "    data_T = np.array([data_1, data_2, data_3]).T\n",
    "    data_fleiss_ = aggregate_raters(data_T)\n",
    "    kappa_fleiss_ = fleiss_kappa(data_fleiss_[0])\n",
    "    return kappa_fleiss_\n",
    "\n",
    "def ci_bootstrap_3(data_1, data_2, data_3, num_resamples = 1000):\n",
    "    \"\"\"\n",
    "    Confidence interval for a 3 raters kappa (bootstrap)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        95% CI lower bound (2.5 centile of the sorted bootstrap distribution)\n",
    "    float\n",
    "        95% CI upper bound (97.5 centile of the sorted bootstrap distribution)\n",
    "    \"\"\"\n",
    "    Y = np.array([data_1, data_2, data_3]).T\n",
    "    list_kappa = []\n",
    "    for i in range(num_resamples):\n",
    "        Y_resample = np.array(random.choices(Y, k=len(Y)))\n",
    "        data_1 = Y_resample[:, 0]\n",
    "        data_2 = Y_resample[:, 1]\n",
    "        data_3 = Y_resample[:, 2]\n",
    "\n",
    "        kappa = kappa_fleiss_3(data_1.astype(str), data_2.astype(str), data_3.astype(str))\n",
    "        list_kappa.append(kappa)\n",
    "\n",
    "    return np.percentile(list_kappa, 2.25), np.percentile(list_kappa, 97.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_0_1= [\n",
    "    \"Models and algorithms\",\n",
    "    \"Datasets\",\n",
    "    \"Code\",\n",
    "    \"Experimental results\",\n",
    "    \"Error bars or statistical significance\",\n",
    "    \"Code is or will be available\"\n",
    "    ]\n",
    "\n",
    "statement_list = [\n",
    "    \"3. (+) statement\",\n",
    "    \"2. (-) statement \",\n",
    "    \"1. (none) statement\",\n",
    "    \"0. Unusable (statement)\",\n",
    "]\n",
    "\n",
    "comments_list = [\n",
    "    \"4. (-/+) comments\",\n",
    "    \"3. (+) comments\",\n",
    "    \"2. (-) comments\",\n",
    "    \"1. (none) comments\",\n",
    "    \"0. Unusable (comments)\",\n",
    "]\n",
    "\n",
    "meta_categories_list = [\n",
    "    \"(+) meta\",\n",
    "    \"(-) meta\",\n",
    "    \"Unusable (meta)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook analyzes the 3 reviews of 90 different papers based on the file ../human_rating/rating_90/rating_90_O.csv\n",
      "Outputs will be saved in ../miccai2023/stats_rating.\n"
     ]
    }
   ],
   "source": [
    "# Enter the path to the tsv file with the rating from the first observer\n",
    "# You can change to analyze the ratings of another observer\n",
    "path_csv = \"../human_rating/rating_90/rating_90_O.csv\"\n",
    "df_rating_1 = pd.read_csv(path_csv, sep = \"\\t\", index_col=False, header= None)\n",
    "\n",
    "print(f\"This notebook analyzes the 3 reviews of {len(df_rating_1)-2} different papers based on the file {path_csv}\")\n",
    "\n",
    "\n",
    "output_directory = Path(f\"../miccai2023/stats_rating\")\n",
    "if not output_directory.is_dir():\n",
    "    os.mkdir(output_directory)\n",
    "print(f\"Outputs will be saved in {output_directory}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For category Models and algorithms, 28.89% of reviewers (78/270) have commented on at least one of the items of the category.\n",
      "confidence intervals (binomial proportion): [23.48%, 34.30%]\n",
      "confidence intervals (bootstrap): [23.51%, 34.08%]\n",
      "\n",
      "For category Datasets, 33.33% of reviewers (90/270) have commented on at least one of the items of the category.\n",
      "confidence intervals (binomial proportion): [27.71%, 38.96%]\n",
      "confidence intervals (bootstrap): [27.78%, 38.89%]\n",
      "\n",
      "For category Code, 46.67% of reviewers (126/270) have commented on at least one of the items of the category.\n",
      "confidence intervals (binomial proportion): [40.72%, 52.62%]\n",
      "confidence intervals (bootstrap): [40.74%, 52.96%]\n",
      "\n",
      "For category Experimental results, 25.56% of reviewers (69/270) have commented on at least one of the items of the category.\n",
      "confidence intervals (binomial proportion): [20.35%, 30.76%]\n",
      "confidence intervals (bootstrap): [20.37%, 30.75%]\n",
      "\n",
      "For category Error bars or statistical significance, 1.85% of reviewers (5/270) have commented on at least one of the items of the category.\n",
      "confidence intervals (binomial proportion): [0.24%, 3.46%]\n",
      "confidence intervals (bootstrap): [0.37%, 3.33%]\n",
      "\n",
      "For category Code is or will be available, 23.33% of reviewers (63/270) have commented on at least one of the items of the category.\n",
      "confidence intervals (binomial proportion): [18.29%, 28.38%]\n",
      "confidence intervals (bootstrap): [18.52%, 28.52%]\n",
      "\n",
      "+----------------------------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews                        |   number |   percent |   ci low |   ci high |\n",
      "|----------------------------------------+----------+-----------+----------+-----------|\n",
      "| Models and algorithms                  |       78 |     28.89 | 23.5102  |  34.0833  |\n",
      "| Datasets                               |       90 |     33.33 | 27.7778  |  38.8889  |\n",
      "| Code                                   |      126 |     46.67 | 40.7407  |  52.963   |\n",
      "| Experimental results                   |       69 |     25.56 | 20.3704  |  30.75    |\n",
      "| Error bars or statistical significance |        5 |      1.85 |  0.37037 |   3.33333 |\n",
      "| Code is or will be available           |       63 |     23.33 | 18.5185  |  28.5185  |\n",
      "+----------------------------------------+----------+-----------+----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Statistics on the rating for the 0/1 categories\n",
    "########################################################################\n",
    "\n",
    "# Create the output dataframe\n",
    "df_category = pd.DataFrame(np.zeros((len(list_0_1),4)), index=list_0_1, columns=[\"number\", \"percent\", \"ci low\", \"ci high\"])\n",
    "\n",
    "for category in range(len(list_0_1)):\n",
    "    all_reviews_1 = []\n",
    "    for i in range(3):\n",
    "        column_id = i*9 + 3 + category\n",
    "        list_review_1 = df_rating_1.loc[2:, column_id].values.tolist()\n",
    "        all_reviews_1 = all_reviews_1 + list_review_1\n",
    "\n",
    "    count_ = all_reviews_1.count(\"1\")\n",
    "    percent_ = round(count_ * 100 / len(all_reviews_1),2)\n",
    "\n",
    "    df_category.loc[list_0_1[category], \"number\"] = count_\n",
    "    df_category.loc[list_0_1[category], \"percent\"] = percent_\n",
    "\n",
    "    print(f\"For category {list_0_1[category]}, {percent_}% of reviewers ({count_}/{len(all_reviews_1)}) have commented on at least one of the items of the category.\")\n",
    "\n",
    "    proportion = count_ / len(all_reviews_1)\n",
    "    ci_bp_low, ci_bp_high = ci_bp(proportion, len(all_reviews_1))\n",
    "    ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(all_reviews_1, '1')\n",
    "\n",
    "    df_category.loc[list_0_1[category], \"ci low\"] = ci_bootstrap_low\n",
    "    df_category.loc[list_0_1[category], \"ci high\"] = ci_bootstrap_high\n",
    "\n",
    "    print(f\"confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "    print(f\"confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "    print()\n",
    "\n",
    "\n",
    "df_category.index.rename(f\"For {len(all_reviews_1)} reviews\", inplace = True)\n",
    "\n",
    "path_category = output_directory / '1-category.csv'\n",
    "df_category.to_csv(path_category, index = True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "print(tabulate(df_category, headers='keys', tablefmt='psql'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for statements (on 270 reviewers):\n",
      "\n",
      "- 48.89% of reviews (132/270) in category 3. (+) statement\n",
      "confidence intervals (binomial proportion): [42.93%, 54.85%]\n",
      "confidence intervals (bootstrap): [43.33%, 54.81%]\n",
      "\n",
      "- 11.85% of reviews (32/270) in category 2. (-) statement \n",
      "confidence intervals (binomial proportion): [8.00%, 15.71%]\n",
      "confidence intervals (bootstrap): [7.78%, 15.93%]\n",
      "\n",
      "- 37.04% of reviews (100/270) in category 1. (none) statement\n",
      "confidence intervals (binomial proportion): [31.28%, 42.80%]\n",
      "confidence intervals (bootstrap): [31.11%, 42.96%]\n",
      "\n",
      "- 2.22% of reviews (6/270) in category 0. Unusable (statement)\n",
      "confidence intervals (binomial proportion): [0.46%, 3.98%]\n",
      "confidence intervals (bootstrap): [0.74%, 4.07%]\n",
      "\n",
      "- 60.74% of reviews (164/270) provided a statement\n",
      "confidence intervals (binomial proportion): [54.92%, 66.57%]\n",
      "confidence intervals (bootstrap): [54.99%, 66.30%]\n",
      "\n",
      "+-------------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews         |   number |   percent |   ci low |   ci high |\n",
      "|-------------------------+----------+-----------+----------+-----------|\n",
      "| 3. (+) statement        |      132 |     48.89 |    43.33 |     54.81 |\n",
      "| 2. (-) statement        |       32 |     11.85 |     7.78 |     15.93 |\n",
      "| 1. (none) statement     |      100 |     37.04 |    31.11 |     42.96 |\n",
      "| 0. Unusable (statement) |        6 |      2.22 |     0.74 |      4.07 |\n",
      "+-------------------------+----------+-----------+----------+-----------+\n",
      "\n",
      "kappa fleiss: -0.051648054755043166\n",
      "confidence intervals (bootstrap): [-0.14, 0.03]\n",
      "\n",
      "Review 1 VS review 2\n",
      "+-------------------------+--------------------+---------------------+-----------------------+---------------------------+---------+\n",
      "|                         |   3. (+) statement |   2. (-) statement  |   1. (none) statement |   0. Unusable (statement) |   total |\n",
      "|-------------------------+--------------------+---------------------+-----------------------+---------------------------+---------|\n",
      "| 3. (+) statement        |              18.89 |               10    |                 18.89 |                      0    |   47.78 |\n",
      "| 2. (-) statement        |               6.67 |                2.22 |                  4.44 |                      0    |   13.33 |\n",
      "| 1. (none) statement     |              20    |                0    |                 16.67 |                      1.11 |   37.78 |\n",
      "| 0. Unusable (statement) |               0    |                1.11 |                  0    |                      0    |    1.11 |\n",
      "| total                   |              45.56 |               13.33 |                 40    |                      1.11 |  100    |\n",
      "+-------------------------+--------------------+---------------------+-----------------------+---------------------------+---------+\n",
      "\n",
      "Review 2 VS review 3\n",
      "+-------------------------+--------------------+---------------------+-----------------------+---------------------------+---------+\n",
      "|                         |   3. (+) statement |   2. (-) statement  |   1. (none) statement |   0. Unusable (statement) |   total |\n",
      "|-------------------------+--------------------+---------------------+-----------------------+---------------------------+---------|\n",
      "| 3. (+) statement        |              25.56 |                4.44 |                 13.33 |                      2.22 |   45.56 |\n",
      "| 2. (-) statement        |               5.56 |                1.11 |                  6.67 |                      0    |   13.33 |\n",
      "| 1. (none) statement     |              21.11 |                3.33 |                 13.33 |                      2.22 |   40    |\n",
      "| 0. Unusable (statement) |               1.11 |                0    |                  0    |                      0    |    1.11 |\n",
      "| total                   |              53.33 |                8.89 |                 33.33 |                      4.44 |  100    |\n",
      "+-------------------------+--------------------+---------------------+-----------------------+---------------------------+---------+\n",
      "\n",
      "Review 1 VS review 3\n",
      "+-------------------------+--------------------+---------------------+-----------------------+---------------------------+---------+\n",
      "|                         |   3. (+) statement |   2. (-) statement  |   1. (none) statement |   0. Unusable (statement) |   total |\n",
      "|-------------------------+--------------------+---------------------+-----------------------+---------------------------+---------|\n",
      "| 3. (+) statement        |              21.11 |                5.56 |                 21.11 |                      0    |   47.78 |\n",
      "| 2. (-) statement        |               5.56 |                1.11 |                  4.44 |                      2.22 |   13.33 |\n",
      "| 1. (none) statement     |              25.56 |                2.22 |                  7.78 |                      2.22 |   37.78 |\n",
      "| 0. Unusable (statement) |               1.11 |                0    |                  0    |                      0    |    1.11 |\n",
      "| total                   |              53.33 |                8.89 |                 33.33 |                      4.44 |  100    |\n",
      "+-------------------------+--------------------+---------------------+-----------------------+---------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Statistics on the rating for the statements category\n",
    "########################################################################\n",
    "\n",
    "# Create the output dataframe\n",
    "df_statement = pd.DataFrame(np.zeros((len(statement_list),4)), index=statement_list, columns=[\"number\", \"percent\", \"ci low\", \"ci high\"])\n",
    "\n",
    "# Extract the statements category for the 3 reviews\n",
    "reviews_statement = []\n",
    "list_statement_1 = df_rating_1.loc[2:, 9].values.tolist()\n",
    "list_statement_2 = df_rating_1.loc[2:, 18].values.tolist()\n",
    "list_statement_3 = df_rating_1.loc[2:, 27].values.tolist()\n",
    "reviews_statement = list_statement_1 + list_statement_2 + list_statement_3\n",
    "\n",
    "print(f\"Statistics for statements (on {len(reviews_statement)} reviewers):\")\n",
    "print()\n",
    "N_statement = len(reviews_statement)\n",
    "\n",
    "for rating in statement_list:\n",
    "    count_ = reviews_statement.count(rating)\n",
    "    percent_ = round(count_ * 100 / N_statement, 2)\n",
    "    df_statement.loc[rating, \"number\"] = count_\n",
    "    df_statement.loc[rating, \"percent\"] = percent_\n",
    "    print(f\"- {percent_}% of reviews ({count_}/{N_statement}) in category {rating}\")\n",
    "\n",
    "    proportion = count_ / len(reviews_statement)\n",
    "    ci_bp_low, ci_bp_high = ci_bp(proportion, len(reviews_statement))\n",
    "    ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(reviews_statement, rating)\n",
    "\n",
    "    df_statement.loc[rating, \"ci low\"] = round(ci_bootstrap_low,2)\n",
    "    df_statement.loc[rating, \"ci high\"] = round(ci_bootstrap_high,2)\n",
    "\n",
    "    print(f\"confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "    print(f\"confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "    print()\n",
    "\n",
    "### percent and ci about reviews which provided a statement\n",
    "new_reviews_statement = []\n",
    "for i in range(N_statement):\n",
    "    if (reviews_statement[i] == \"3. (+) statement\") or (reviews_statement[i] == \"2. (-) statement \"):\n",
    "        new_reviews_statement.append(1)\n",
    "    else :\n",
    "        new_reviews_statement.append(0)\n",
    "\n",
    "new_count_ = new_reviews_statement.count(1)\n",
    "new_percent_ = round(new_count_ * 100 / N_statement, 2)\n",
    "print(f\"- {new_percent_}% of reviews ({new_count_}/{N_statement}) provided a statement\")\n",
    "\n",
    "proportion = new_count_ / N_statement\n",
    "ci_bp_low, ci_bp_high = ci_bp(proportion, N_statement)\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(new_reviews_statement, 1)\n",
    "print(f\"confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "print(f\"confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "print()\n",
    "\n",
    "### Creating distribution of good statement (3 VS 0/1/2/)\n",
    "\n",
    "\n",
    "df_statement.index.rename(f\"For {N_statement} reviews\", inplace = True)\n",
    "print(tabulate(df_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "path_statements = output_directory / '2-statements.csv'\n",
    "df_statement.to_csv(path_statements, index = True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "kappa_fleiss_statement = kappa_fleiss_3(list_statement_1, list_statement_2, list_statement_3)\n",
    "print(f\"kappa fleiss: {kappa_fleiss_statement}\")\n",
    "\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# kappa_sk_statement = cohen_kappa_score(list_statement_1, list_statement_2)\n",
    "# print(f\"kappa sklearn: {kappa_sk_statement}\")\n",
    "\n",
    "ci_low_fleiss_statement, ci_high_fleiss_statement = ci_bootstrap_3(list_statement_1, list_statement_2, list_statement_3)\n",
    "print(f\"confidence intervals (bootstrap): [{ci_low_fleiss_statement:.2f}, {ci_high_fleiss_statement:.2f}]\")\n",
    "print()\n",
    "\n",
    "print(\"Review 1 VS review 2\") \n",
    "m1_statement = create_confusion_matrix(list_statement_1, list_statement_2, statement_list)\n",
    "print(tabulate(m1_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "print(\"Review 2 VS review 3\")\n",
    "m2_statement = create_confusion_matrix(list_statement_2, list_statement_3, statement_list)\n",
    "print(tabulate(m2_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "print(\"Review 1 VS review 3\")\n",
    "m3_statement = create_confusion_matrix(list_statement_1, list_statement_3, statement_list)\n",
    "print(tabulate(m3_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for comments (on 270 reviewers):\n",
      "\n",
      "- 22.96% of reviews (62/270) in category 4. (-/+) comments\n",
      "confidence intervals (binomial proportion): [17.95%, 27.98%]\n",
      "confidence intervals (bootstrap): [18.15%, 28.15%]\n",
      "\n",
      "- 30.74% of reviews (83/270) in category 3. (+) comments\n",
      "confidence intervals (binomial proportion): [25.24%, 36.24%]\n",
      "confidence intervals (bootstrap): [25.19%, 36.30%]\n",
      "\n",
      "- 18.52% of reviews (50/270) in category 2. (-) comments\n",
      "confidence intervals (binomial proportion): [13.89%, 23.15%]\n",
      "confidence intervals (bootstrap): [14.07%, 23.34%]\n",
      "\n",
      "- 22.22% of reviews (60/270) in category 1. (none) comments\n",
      "confidence intervals (binomial proportion): [17.26%, 27.18%]\n",
      "confidence intervals (bootstrap): [17.21%, 27.04%]\n",
      "\n",
      "- 5.56% of reviews (15/270) in category 0. Unusable (comments)\n",
      "confidence intervals (binomial proportion): [2.82%, 8.29%]\n",
      "confidence intervals (bootstrap): [2.96%, 8.89%]\n",
      "\n",
      "- 72.22% of reviews (195/270) provided a comment\n",
      "confidence intervals (binomial proportion): [66.88%, 77.56%]\n",
      "confidence intervals (bootstrap): [66.67%, 77.78%]\n",
      "\n",
      "+------------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews        |   number |   percent |   ci low |   ci high |\n",
      "|------------------------+----------+-----------+----------+-----------|\n",
      "| 4. (-/+) comments      |       62 |     22.96 |    18.15 |     28.15 |\n",
      "| 3. (+) comments        |       83 |     30.74 |    25.19 |     36.3  |\n",
      "| 2. (-) comments        |       50 |     18.52 |    14.07 |     23.34 |\n",
      "| 1. (none) comments     |       60 |     22.22 |    17.21 |     27.04 |\n",
      "| 0. Unusable (comments) |       15 |      5.56 |     2.96 |      8.89 |\n",
      "+------------------------+----------+-----------+----------+-----------+\n",
      "kappa fleiss: 0.0474911357043086\n",
      "confidence intervals (bootstrap): [-0.03%, 0.12%]\n",
      "\n",
      "Review 1 VS review 2\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "|                        |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 4. (-/+) comments      |                4.44 |              7.78 |              4.44 |                 7.78 |                     1.11 |   25.56 |\n",
      "| 3. (+) comments        |                6.67 |              8.89 |              4.44 |                 6.67 |                     1.11 |   27.78 |\n",
      "| 2. (-) comments        |                4.44 |              6.67 |              5.56 |                 4.44 |                     0    |   21.11 |\n",
      "| 1. (none) comments     |                2.22 |              7.78 |              5.56 |                 4.44 |                     2.22 |   22.22 |\n",
      "| 0. Unusable (comments) |                0    |              1.11 |              2.22 |                 0    |                     0    |    3.33 |\n",
      "| total                  |               17.78 |             32.22 |             22.22 |                23.33 |                     4.44 |  100    |\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n",
      "Review 2 VS review 3\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "|                        |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 4. (-/+) comments      |               10    |              2.22 |              1.11 |                 4.44 |                     0    |   17.78 |\n",
      "| 3. (+) comments        |                4.44 |             14.44 |              2.22 |                 6.67 |                     4.44 |   32.22 |\n",
      "| 2. (-) comments        |                5.56 |              5.56 |              3.33 |                 4.44 |                     3.33 |   22.22 |\n",
      "| 1. (none) comments     |                2.22 |             10    |              5.56 |                 4.44 |                     1.11 |   23.33 |\n",
      "| 0. Unusable (comments) |                3.33 |              0    |              0    |                 1.11 |                     0    |    4.44 |\n",
      "| total                  |               25.56 |             32.22 |             12.22 |                21.11 |                     8.89 |  100    |\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n",
      "Review 1 VS review 3\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "|                        |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 4. (-/+) comments      |                4.44 |              7.78 |              3.33 |                 6.67 |                     3.33 |   25.56 |\n",
      "| 3. (+) comments        |                8.89 |             11.11 |              2.22 |                 3.33 |                     2.22 |   27.78 |\n",
      "| 2. (-) comments        |                5.56 |              4.44 |              3.33 |                 5.56 |                     2.22 |   21.11 |\n",
      "| 1. (none) comments     |                6.67 |              6.67 |              3.33 |                 5.56 |                     0    |   22.22 |\n",
      "| 0. Unusable (comments) |                0    |              2.22 |              0    |                 0    |                     1.11 |    3.33 |\n",
      "| total                  |               25.56 |             32.22 |             12.22 |                21.11 |                     8.89 |  100    |\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comments\n",
    "df_comments = pd.DataFrame(np.zeros((len(comments_list),4)), index=comments_list, columns=[\"number\", \"percent\", \"ci low\", \"ci high\"])\n",
    "\n",
    "reviews_comments = []\n",
    "list_comment_1 = df_rating_1.loc[2:, 10].values.tolist()\n",
    "list_comment_2 = df_rating_1.loc[2:, 19].values.tolist()\n",
    "list_comment_3 = df_rating_1.loc[2:, 28].values.tolist()\n",
    "reviews_comments = list_comment_1 + list_comment_2 + list_comment_3\n",
    "\n",
    "print(f\"Statistics for comments (on {len(reviews_comments)} reviewers):\")\n",
    "print()\n",
    "N_comments = len(reviews_comments)\n",
    "\n",
    "for rating in comments_list:\n",
    "    count_ = reviews_comments.count(rating)\n",
    "    percent_ = round(count_ * 100 / N_comments, 2)\n",
    "    df_comments.loc[rating, \"number\"] = count_\n",
    "    df_comments.loc[rating, \"percent\"] = percent_\n",
    "    print(f\"- {percent_}% of reviews ({count_}/{N_comments}) in category {rating}\")\n",
    "\n",
    "    proportion = count_ / N_comments\n",
    "    ci_bp_low, ci_bp_high = ci_bp(proportion, N_comments)\n",
    "    ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(reviews_comments, rating)\n",
    "\n",
    "    df_comments.loc[rating, \"ci low\"] = round(ci_bootstrap_low,2)\n",
    "    df_comments.loc[rating, \"ci high\"] = round(ci_bootstrap_high,2)\n",
    "\n",
    "    print(f\"confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "    print(f\"confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "    print()\n",
    "\n",
    "### percent and ci about reviews which provided a statement\n",
    "new_reviews_comments = []\n",
    "for i in range(N_comments):\n",
    "    if (reviews_comments[i] == \"4. (-/+) comments\") or (reviews_comments[i] == \"3. (+) comments\") or (reviews_comments[i] == \"2. (-) comments\"):\n",
    "        new_reviews_comments.append(1)\n",
    "    else :\n",
    "        new_reviews_comments.append(0)\n",
    "\n",
    "new_count_ = new_reviews_comments.count(1)\n",
    "new_percent_ = round(new_count_ * 100 / N_statement, 2)\n",
    "print(f\"- {new_percent_}% of reviews ({new_count_}/{N_comments}) provided a comment\")\n",
    "\n",
    "proportion = new_count_ / N_comments\n",
    "ci_bp_low, ci_bp_high = ci_bp(proportion, N_comments)\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(new_reviews_comments, 1)\n",
    "print(f\"confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "print(f\"confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "print()\n",
    "\n",
    "\n",
    "df_comments.index.rename(f\"For {N_comments} reviews\", inplace = True)\n",
    "print(tabulate(df_comments, headers='keys', tablefmt='psql'))\n",
    "\n",
    "path_comments = output_directory / '3-comments.csv'\n",
    "df_comments.to_csv(path_comments, index = True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "kappa_fleiss_comment = kappa_fleiss_3(list_comment_1, list_comment_2, list_comment_3)\n",
    "print(f\"kappa fleiss: {kappa_fleiss_comment}\")\n",
    "ci_low_fleiss_comment, ci_high_fleiss_comment = ci_bootstrap_3(list_comment_1, list_comment_2, list_comment_3)\n",
    "print(f\"confidence intervals (bootstrap): [{ci_low_fleiss_comment:.2f}%, {ci_high_fleiss_comment:.2f}%]\")\n",
    "print()\n",
    "print(\"Review 1 VS review 2\")\n",
    "m1_comment = create_confusion_matrix(list_comment_1, list_comment_2, comments_list)\n",
    "print(tabulate(m1_comment, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "print(\"Review 2 VS review 3\")\n",
    "m2_comment = create_confusion_matrix(list_comment_2, list_comment_3, comments_list)\n",
    "print(tabulate(m2_comment, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "print(\"Review 1 VS review 3\")\n",
    "m3_comment =create_confusion_matrix(list_comment_1, list_comment_3, comments_list)\n",
    "print(tabulate(m3_comment, headers='keys', tablefmt='psql'))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of statements VS comments\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "| number                  |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 3. (+) statement        |                  21 |                52 |                 7 |                   52 |                        0 |     132 |\n",
      "| 2. (-) statement        |                   8 |                 0 |                21 |                    3 |                        0 |      32 |\n",
      "| 1. (none) statement     |                  33 |                31 |                22 |                    5 |                        9 |     100 |\n",
      "| 0. Unusable (statement) |                   0 |                 0 |                 0 |                    0 |                        6 |       6 |\n",
      "| total                   |                  62 |                83 |                50 |                   60 |                       15 |     270 |\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n",
      "- 39.39% of reviewers (52/132) made a positive statement but didn't provide a coomment to substantiate their statement.\n",
      "\n",
      "confidence intervals (binomial proportion): [31.06%, 47.73%]\n",
      "confidence intervals (bootstrap): [31.06%, 47.73%]\n",
      "\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "| in %                    |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 3. (+) statement        |                7.78 |             19.26 |              2.59 |                19.26 |                     0    |   48.89 |\n",
      "| 2. (-) statement        |                2.96 |              0    |              7.78 |                 1.11 |                     0    |   11.85 |\n",
      "| 1. (none) statement     |               12.22 |             11.48 |              8.15 |                 1.85 |                     3.33 |   37.04 |\n",
      "| 0. Unusable (statement) |                0    |              0    |              0    |                 0    |                     2.22 |    2.22 |\n",
      "| total                   |               22.96 |             30.74 |             18.52 |                22.22 |                     5.56 |  100    |\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "# statements and comments \n",
    "\n",
    "df_stat_com = pd.DataFrame(np.zeros((len(statement_list)+1,len(comments_list)+1)), index=statement_list+[\"total\"], columns=comments_list+[\"total\"])\n",
    "df_stat_com.index.rename(\"number\", inplace = True)\n",
    "for i in range (len(reviews_comments)):\n",
    "    df_stat_com.loc[reviews_statement[i], reviews_comments[i]] +=1\n",
    "    df_stat_com.loc[\"total\", reviews_comments[i]] +=1\n",
    "    df_stat_com.loc[reviews_statement[i], \"total\"] +=1\n",
    "df_stat_com.loc[\"total\", \"total\"] = len(reviews_comments)\n",
    "\n",
    "print(\"Analysis of statements VS comments\")\n",
    "print(tabulate(df_stat_com, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "reviews_statement_no_comments = []\n",
    "for i in range (len(reviews_comments)):\n",
    "    if reviews_statement[i]==\"3. (+) statement\": \n",
    "        if (reviews_comments[i] == \"1. (none) comments\" or reviews_comments[i] == \"0. (Unusable) comments\" ):\n",
    "            reviews_statement_no_comments.append(1)\n",
    "        else :\n",
    "            reviews_statement_no_comments.append(0)\n",
    "\n",
    "new_count_ = reviews_statement_no_comments.count(1)\n",
    "new_percent_ = round(new_count_ * 100 / len(reviews_statement_no_comments), 2)\n",
    "print(f\"- {new_percent_}% of reviewers ({new_count_}/{len(reviews_statement_no_comments)}) made a positive statement but didn't provide a comment to substantiate their statement.\")\n",
    "print()\n",
    "\n",
    "proportion = new_count_ / len(reviews_statement_no_comments)\n",
    "ci_bp_low, ci_bp_high = ci_bp(proportion, len(reviews_statement_no_comments))\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(reviews_statement_no_comments, 1)\n",
    "print(f\"confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "print(f\"confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "print()\n",
    "\n",
    "path_statements_comments = output_directory / '4-statements_comments.csv'\n",
    "df_stat_com.to_csv(path_statements_comments, index = True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "df_stat_com_percent = df_stat_com\n",
    "df_stat_com_percent.index.rename(\"in %\", inplace = True)\n",
    "df_stat_com_percent = round(df_stat_com*100 /len(reviews_comments), 2)\n",
    "\n",
    "print(tabulate(df_stat_com_percent, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for meta-categories (on 270 reviewers):\n",
      "\n",
      "- 60.37% of reviews (163/270) in category (+) meta\n",
      "confidence intervals (multinomial proportion): [54.54%, 66.20%]\n",
      "confidence intervals (bootstrap): [54.07%, 65.93%]\n",
      "\n",
      "- 32.22% of reviews (87/270) in category (-) meta\n",
      "confidence intervals (multinomial proportion): [26.65%, 37.80%]\n",
      "confidence intervals (bootstrap): [26.47%, 37.41%]\n",
      "\n",
      "- 7.41% of reviews (20/270) in category Unusable (meta)\n",
      "confidence intervals (multinomial proportion): [4.28%, 10.53%]\n",
      "confidence intervals (bootstrap): [4.44%, 10.74%]\n",
      "\n",
      "+-------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews   |   number |   percent |   ci low |   ci high |\n",
      "|-------------------+----------+-----------+----------+-----------|\n",
      "| (+) meta          |      163 |     60.37 |    54.07 |     65.93 |\n",
      "| (-) meta          |       87 |     32.22 |    26.47 |     37.41 |\n",
      "| Unusable (meta)   |       20 |      7.41 |     4.44 |     10.74 |\n",
      "+-------------------+----------+-----------+----------+-----------+\n",
      "kappa fleiss: 0.021688128877534983\n",
      "confidence intervals (bootstrap): [-0.10%, 0.13%]\n",
      "\n",
      "Review 1 VS review 2\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "|                 |   (+) meta |   (-) meta |   Unusable (meta) |   total |\n",
      "|-----------------+------------+------------+-------------------+---------|\n",
      "| (+) meta        |      33.33 |      23.33 |              3.33 |   60    |\n",
      "| (-) meta        |      22.22 |      10    |              1.11 |   33.33 |\n",
      "| Unusable (meta) |       3.33 |       2.22 |              1.11 |    6.67 |\n",
      "| total           |      58.89 |      35.56 |              5.56 |  100    |\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "\n",
      "Review 2 VS review 3\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "|                 |   (+) meta |   (-) meta |   Unusable (meta) |   total |\n",
      "|-----------------+------------+------------+-------------------+---------|\n",
      "| (+) meta        |      40    |      12.22 |              6.67 |   58.89 |\n",
      "| (-) meta        |      18.89 |      13.33 |              3.33 |   35.56 |\n",
      "| Unusable (meta) |       3.33 |       2.22 |              0    |    5.56 |\n",
      "| total           |      62.22 |      27.78 |             10    |  100    |\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "\n",
      "Review 1 VS review 3\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "|                 |   (+) meta |   (-) meta |   Unusable (meta) |   total |\n",
      "|-----------------+------------+------------+-------------------+---------|\n",
      "| (+) meta        |      38.89 |      18.89 |              2.22 |   60    |\n",
      "| (-) meta        |      18.89 |       7.78 |              6.67 |   33.33 |\n",
      "| Unusable (meta) |       4.44 |       1.11 |              1.11 |    6.67 |\n",
      "| total           |      62.22 |      27.78 |             10    |  100    |\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# meta categories\n",
    "df_meta = pd.DataFrame(np.zeros((len(meta_categories_list),4)), index=meta_categories_list, columns=[\"number\", \"percent\", \"ci low\", \"ci high\"])\n",
    "\n",
    "reviews_meta = []\n",
    "list_meta_1 = df_rating_1.loc[2:, 29].values.tolist()\n",
    "list_meta_2 = df_rating_1.loc[2:, 30].values.tolist()\n",
    "list_meta_3 = df_rating_1.loc[2:, 31].values.tolist()\n",
    "\n",
    "reviews_meta = list_meta_1 + list_meta_2 + list_meta_3\n",
    "\n",
    "reviews_meta_python = []\n",
    "for i in range(len(reviews_statement)):\n",
    "    if reviews_statement[i] == \"3. (+) statement\":\n",
    "        reviews_meta_python.append(\"(+) meta\")\n",
    "    elif reviews_statement[i] == \"2. (-) statement \":\n",
    "        reviews_meta_python.append(\"(-) meta\")\n",
    "    elif reviews_comments[i] == \"3. (+) comments\":\n",
    "        reviews_meta_python.append(\"(+) meta\")\n",
    "    elif reviews_comments[i] == \"2. (-) comments\" or reviews_comments[i] ==\"4. (-/+) comments\":\n",
    "        reviews_meta_python.append( \"(-) meta\")\n",
    "    else:\n",
    "        reviews_meta_python.append(\"Unusable (meta)\")\n",
    "\n",
    "if not (reviews_meta==reviews_meta_python):\n",
    "    reviews_meta = reviews_meta_python\n",
    "    print(\"Meta categories calculated values aren't the same as in the provided tsv file.\")\n",
    "\n",
    "\n",
    "print(f\"Statistics for meta-categories (on {len(reviews_meta)} reviewers):\")\n",
    "print()\n",
    "\n",
    "N_meta = len(reviews_meta)\n",
    "for rating in meta_categories_list:\n",
    "    count_ = reviews_meta.count(rating)\n",
    "    percent_ = round(count_ * 100 / N_meta, 2)\n",
    "    df_meta.loc[rating, \"number\"] = count_\n",
    "    df_meta.loc[rating, \"percent\"] = percent_\n",
    "    print(f\"- {percent_}% of reviews ({count_}/{N_meta}) in category {rating}\")\n",
    "\n",
    "    proportion = count_ / N_meta\n",
    "    ci_bp_low, ci_bp_high = ci_bp(proportion, N_meta)\n",
    "    ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(reviews_meta, rating)\n",
    "\n",
    "    df_meta.loc[rating, \"ci low\"] = round(ci_bootstrap_low,2)\n",
    "    df_meta.loc[rating, \"ci high\"] = round(ci_bootstrap_high,2)\n",
    "\n",
    "    print(f\"confidence intervals (multinomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\")\n",
    "    print(f\"confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\")\n",
    "    print()\n",
    "\n",
    "df_meta.index.rename(f\"For {N_meta} reviews\", inplace = True)\n",
    "print(tabulate(df_meta, headers='keys', tablefmt='psql'))\n",
    "\n",
    "path_meta = output_directory / '5-meta.csv'\n",
    "df_meta.to_csv(path_meta, index = True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "kappa_fleiss_meta = kappa_fleiss_3(list_meta_1, list_meta_2, list_meta_3)\n",
    "print(f\"kappa fleiss: {kappa_fleiss_meta}\")\n",
    "ci_low_fleiss_meta, ci_high_fleiss_meta = ci_bootstrap_3(list_meta_1, list_meta_2, list_meta_3)\n",
    "print(f\"confidence intervals (bootstrap): [{ci_low_fleiss_meta:.2f}%, {ci_high_fleiss_meta:.2f}%]\")\n",
    "print()\n",
    "print(\"Review 1 VS review 2\")\n",
    "m1_meta = create_confusion_matrix(list_meta_1, list_meta_2, meta_categories_list)\n",
    "print(tabulate(m1_meta, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "print(\"Review 2 VS review 3\")\n",
    "m2_meta = create_confusion_matrix(list_meta_2, list_meta_3, meta_categories_list)\n",
    "print(tabulate(m2_meta, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "print(\"Review 1 VS review 3\")\n",
    "m3_meta = create_confusion_matrix(list_meta_1, list_meta_3, meta_categories_list)\n",
    "print(tabulate(m3_meta, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+----------+-----------+\n",
      "| kappa fleiss    |   kappa |   ci low |   ci high |\n",
      "|-----------------+---------+----------+-----------|\n",
      "| Statements      |   -0.05 |    -0.14 |      0.03 |\n",
      "| Comments        |    0.05 |    -0.03 |      0.12 |\n",
      "| Meta-categories |    0.02 |    -0.1  |      0.13 |\n",
      "+-----------------+---------+----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# kappa fleiss table \n",
    "\n",
    "df_kappas = pd.DataFrame(np.zeros((3,3)), index=[\"Statements\", \"Comments\", \"Meta-categories\"], columns=[\"kappa\", \"ci low\", \"ci high\"])\n",
    "\n",
    "df_kappas.loc[\"Statements\", \"kappa\"] = kappa_fleiss_statement\n",
    "df_kappas.loc[\"Statements\", \"ci low\"] = ci_low_fleiss_statement\n",
    "df_kappas.loc[\"Statements\", \"ci high\"] = ci_high_fleiss_statement\n",
    "\n",
    "df_kappas.loc[\"Comments\", \"kappa\"] = kappa_fleiss_comment\n",
    "df_kappas.loc[\"Comments\", \"ci low\"] = ci_low_fleiss_comment\n",
    "df_kappas.loc[\"Comments\", \"ci high\"] = ci_high_fleiss_comment\n",
    "\n",
    "df_kappas.loc[\"Meta-categories\", \"kappa\"] = kappa_fleiss_meta\n",
    "df_kappas.loc[\"Meta-categories\", \"ci low\"] = ci_low_fleiss_meta\n",
    "df_kappas.loc[\"Meta-categories\", \"ci high\"] = ci_high_fleiss_meta\n",
    "\n",
    "df_kappas = round(df_kappas,2)\n",
    "df_kappas.index.rename(\"kappa fleiss\", inplace=True)\n",
    "print(tabulate(df_kappas, headers='keys', tablefmt='psql'))\n",
    "\n",
    "path_kappas = output_directory / '6-kappas.csv'\n",
    "df_kappas.to_csv(path_kappas, index = True, sep=\";\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for code (on 90 papers):\n",
      "\n",
      " - for 47.78% (95%CI (bootstrap): [37.78%, 57.78%]) of the papers (43/90), the repository exists and is not empty.\n",
      " - for 20.00% (95%CI (bootstrap): [11.11%, 28.89%]) of the papers (18/90), the link to the repository is provided but it is empty or wrong.\n",
      " - for 32.22% (95%CI (bootstrap): [23.33%, 41.11%]) of the papers (29/90), no link/code was provided.\n",
      "\n",
      " - for 67.78% (95%CI (bootstrap): [57.78%, 76.67%]) of the papers (61/90), an associated repository for the code was provided.\n",
      "\n",
      " - for 29.51% (95%CI (bootstrap): [18.03%, 40.98%]) of the papers for which a link was provided (18/61), the link to the repository is provided but it is empty or wrong.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code\n",
    "column_id = 39\n",
    "code_link_df = df_rating_1.loc[2:, column_id].values.tolist()\n",
    "column_id = 40\n",
    "code_avail_df = df_rating_1.loc[2:, column_id].values.tolist()\n",
    "\n",
    "code_list = [\n",
    "    \"bad link\",\n",
    "    \"good link\",\n",
    "    \"no link\",\n",
    "]\n",
    "\n",
    "print(f\"Statistics for code (on {len(code_link_df)} papers):\")\n",
    "print()\n",
    "\n",
    "list_code = []\n",
    "for i in range(len(code_avail_df)):\n",
    "    if str(code_link_df[i]).startswith(\"http\"):\n",
    "        if code_avail_df[i]==\"1\":\n",
    "            list_code.append(\"good link\")\n",
    "        if code_avail_df[i]==\"0\":\n",
    "            list_code.append(\"bad link\")\n",
    "    \n",
    "    else: \n",
    "        list_code.append(\"no link\")\n",
    "\n",
    "nb_papers= len(list_code)\n",
    "\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code, \"good link\")\n",
    "print(f\" - for {(list_code.count('good link') *100 / nb_papers):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code.count('good link')}/{nb_papers}), the repository exists and is not empty.\")\n",
    "\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code, \"bad link\")\n",
    "print(f\" - for {(list_code.count('bad link') *100 / nb_papers):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code.count('bad link')}/{nb_papers}), the link to the repository is provided but it is empty or wrong.\")\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code, \"no link\")\n",
    "print(f\" - for {(list_code.count('no link')*100 / nb_papers):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code.count('no link')}/{nb_papers}), no link/code was provided.\")\n",
    "print()\n",
    "\n",
    "list_code_binary =  []\n",
    "for i in range(nb_papers):\n",
    "    if list_code[i] == \"good link\" or list_code[i] == \"bad link\"  :\n",
    "        list_code_binary.append(1)\n",
    "    else : \n",
    "        list_code_binary.append(0)\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code_binary, 1)\n",
    "print(f\" - for {(100*list_code_binary.count(1)/len(list_code_binary)):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code_binary.count(1)}/{len(list_code_binary)}), an associated repository for the code was provided.\")\n",
    "print()        \n",
    "\n",
    "list_code_bis = [x for x in list_code if (x==\"good link\" or x==\"bad link\")]\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code_bis, \"bad link\")\n",
    "print(f\" - for {(100*list_code_bis.count('bad link')/len(list_code_bis)):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers for which a link was provided ({list_code.count('bad link')}/{len(list_code_bis)}), the link to the repository is provided but it is empty or wrong.\")\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 86.67% (95%CI (bootstrap): [78.89%, 93.33%]) of the papers (78/90), at least one of the reviewers said that the code was available."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "For these 78 papers:\n",
      " - for 47.44% (95%CI (bootstrap): [36.51%, 58.97%]) of the papers (37.0/78), at least one of the reviewers said that the code was available and it was.\n",
      " - for 20.51% (95%CI (bootstrap): [11.54%, 29.49%]) of the papers (16.0/78), at least one of the reviewers said that the code was available even if the link was leading to an error message or to an empty repository.\n",
      " - for 32.05% (95%CI (bootstrap): [21.79%, 42.31%]) of the papers (25.0/78), at least one of the reviewers said that the code was available even if no link/code was provided.\n",
      "\n",
      " - for 52.56% (95%CI (bootstrap): [41.03%, 64.10%]) of the papers (41/78), at least one of the reviewers said that the code was available even if the code was actually missing in the published version (no link, broken link or empty repository)\n",
      "\n",
      " - for 50.00% (95%CI (bootstrap): [25.00%, 75.00%]) of the papers (6.0/12), the reviewers said that the code wasn't available even if it was.\n",
      "\n",
      "The tables below indicate, for each paper if at least one reviewer said that the \n",
      " code was/will be available (1) or not (0), and whether the link was present and non-empty (good link), \n",
      " present by with empty repository (empty link) or whether there was no link (no link).\n",
      "\n",
      "+----------------------------------+------------+-------------+-----------+---------+\n",
      "| code availableness (in number)   |   bad link |   good link |   no link |   total |\n",
      "|----------------------------------+------------+-------------+-----------+---------|\n",
      "| no info                          |          2 |           6 |         4 |      12 |\n",
      "| code promised                    |         16 |          37 |        25 |      78 |\n",
      "| total                            |         18 |          43 |        29 |      90 |\n",
      "+----------------------------------+------------+-------------+-----------+---------+\n",
      "+-----------------------------+------------+-------------+-----------+----------+\n",
      "| code availableness (in %)   |   bad link |   good link |   no link |    total |\n",
      "|-----------------------------+------------+-------------+-----------+----------|\n",
      "| no info                     |    2.22222 |     6.66667 |   4.44444 |  13.3333 |\n",
      "| code promised               |   17.7778  |    41.1111  |  27.7778  |  86.6667 |\n",
      "| total                       |   20       |    47.7778  |  32.2222  | 100      |\n",
      "+-----------------------------+------------+-------------+-----------+----------+\n"
     ]
    }
   ],
   "source": [
    "# repository and review \n",
    "\n",
    "list_code_1 = df_rating_1.loc[2:, 5].values.tolist()\n",
    "list_code_2 = df_rating_1.loc[2:, 14].values.tolist()\n",
    "list_code_3 = df_rating_1.loc[2:, 23].values.tolist()\n",
    "\n",
    "list_code_review = []\n",
    "for i in range(len(list_code_1)):\n",
    "    x = list_code_1[i]\n",
    "    if x== '0' and x==list_code_2[i] and x==list_code_3[i] :\n",
    "        list_code_review.append(\"no info\")\n",
    "    else :\n",
    "        list_code_review.append('code promised')\n",
    "\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(list_code_review, \"code promised\")\n",
    "print(f\"For {(list_code_review.count('code promised')*100/len(list_code_review)):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code_review.count('code promised')}/{len(list_code_review)}), at least one of the reviewers said that the code was available.\")\n",
    "print()\n",
    "\n",
    "df_code_reviews = pd.DataFrame(np.zeros((3,4)), index=[\"no info\", \"code promised\", \"total\"], columns=code_list + [\"total\"])\n",
    "\n",
    "\n",
    "list_code_final = []\n",
    "for i in range(len(list_code)):\n",
    "    if list_code[i] == \"good link\" and list_code_review[i]==\"code promised\":\n",
    "        df_code_reviews.loc[\"code promised\", \"good link\"]+=1\n",
    "        list_code_final.append(\"code promised good link\")\n",
    "    if list_code[i] == \"good link\" and list_code_review[i]== \"no info\":\n",
    "        df_code_reviews.loc[\"no info\", \"good link\"]+=1\n",
    "        list_code_final.append(\"no info good link\")\n",
    "\n",
    "    if list_code[i] == \"bad link\" and list_code_review[i]==\"code promised\":\n",
    "        df_code_reviews.loc[\"code promised\", \"bad link\"]+=1\n",
    "        list_code_final.append(\"code promised bad link\")\n",
    "    if list_code[i] == \"bad link\" and list_code_review[i]== \"no info\":\n",
    "        df_code_reviews.loc[\"no info\", \"bad link\"]+=1\n",
    "        list_code_final.append(\"no info bad link\")\n",
    "\n",
    "    if list_code[i] == \"no link\" and list_code_review[i]==\"code promised\":\n",
    "        df_code_reviews.loc[\"code promised\", \"no link\"]+=1\n",
    "        list_code_final.append(\"code promised no link\")\n",
    "    if list_code[i] == \"no link\" and list_code_review[i]== \"no info\":\n",
    "        df_code_reviews.loc[\"no info\", \"no link\"]+=1\n",
    "        list_code_final.append(\"no info no link\")\n",
    "\n",
    "df_code_reviews.loc[\"code promised\", \"total\"] = df_code_reviews.loc[\"code promised\", \"good link\"] + df_code_reviews.loc[\"code promised\", \"bad link\"] + df_code_reviews.loc[\"code promised\", \"no link\"]\n",
    "df_code_reviews.loc[\"no info\", \"total\"] = df_code_reviews.loc[\"no info\", \"good link\"] + df_code_reviews.loc[\"no info\", \"bad link\"] + df_code_reviews.loc[\"no info\", \"no link\"]\n",
    "\n",
    "df_code_reviews.loc[\"total\", \"good link\"] = df_code_reviews.loc[\"code promised\", \"good link\"] + df_code_reviews.loc[\"no info\", \"good link\"] \n",
    "df_code_reviews.loc[\"total\", \"bad link\"] = df_code_reviews.loc[\"code promised\", \"bad link\"] + df_code_reviews.loc[\"no info\", \"bad link\"] \n",
    "df_code_reviews.loc[\"total\", \"no link\"] = df_code_reviews.loc[\"code promised\", \"no link\"] + df_code_reviews.loc[\"no info\", \"no link\"] \n",
    "\n",
    "df_code_reviews.loc[\"total\", \"total\"] = df_code_reviews.loc[\"code promised\", \"total\"] + df_code_reviews.loc[\"no info\", \"total\"]\n",
    "\n",
    "good_review_list = [x for x in list_code_final if x.startswith(\"code promised\")]\n",
    "nb_good_reviews = len(good_review_list)\n",
    "\n",
    "print(f\"For these {nb_good_reviews} papers:\")\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(good_review_list, \"code promised good link\")\n",
    "print(f\" - for {(df_code_reviews.loc['code promised', 'good link']*100 / nb_good_reviews):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['code promised', 'good link']}/{nb_good_reviews}), at least one of the reviewers said that the code was available and it was.\")\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(good_review_list, \"code promised bad link\")\n",
    "print(f\" - for {(df_code_reviews.loc['code promised', 'bad link']*100 / nb_good_reviews):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['code promised', 'bad link']}/{nb_good_reviews}), at least one of the reviewers said that the code was available even if the link was leading to an error message or to an empty repository.\")\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(good_review_list, \"code promised no link\")\n",
    "print(f\" - for {(df_code_reviews.loc['code promised', 'no link']*100 / nb_good_reviews):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['code promised', 'no link']}/{nb_good_reviews}), at least one of the reviewers said that the code was available even if no link/code was provided.\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "good_reviews_list_bis = []\n",
    "for i in range(nb_good_reviews):\n",
    "    if good_review_list[i] == \"code promised good link\":\n",
    "        good_reviews_list_bis.append(1)\n",
    "    else :\n",
    "        good_reviews_list_bis.append(0)\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(good_reviews_list_bis, 0)\n",
    "print(f\" - for {(good_reviews_list_bis.count(0)*100 / nb_good_reviews):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({good_reviews_list_bis.count(0)}/{nb_good_reviews}), at least one of the reviewers said that the code was available even if the code was actually missing in the published version (no link, broken link or empty repository)\")\n",
    "print()\n",
    "\n",
    "\n",
    "bad_review_list = [x for x in list_code_final if x.startswith(\"no info\")]\n",
    "nb_bad_reviews = len(bad_review_list)\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = ci_bootstrap(bad_review_list, \"no info good link\")\n",
    "print(f\" - for {(df_code_reviews.loc['no info', 'good link']*100 / nb_bad_reviews):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['no info', 'good link']}/{nb_bad_reviews}), the reviewers said that the code wasn't available even if it was.\")\n",
    "print()\n",
    "print(\"The tables below indicate, for each paper if at least one reviewer said that the \\n code was/will be available (1) or not (0), and whether the link was present and non-empty (good link), \\n present by with empty repository (empty link) or whether there was no link (no link).\")\n",
    "print()\n",
    "\n",
    "df_code_reviews.index.rename(\"code availableness (in number)\", inplace=True)\n",
    "print(tabulate(df_code_reviews, headers='keys', tablefmt='psql'))\n",
    "\n",
    "path_code = output_directory / '7-code_number.csv'\n",
    "df_code_reviews.to_csv(path_code, index = True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "df_code_review_percent = df_code_reviews\n",
    "df_code_review_percent.index.rename(\"code availableness (in %)\", inplace=True)\n",
    "df_code_review_percent = df_code_review_percent*100 /len(list_code)\n",
    "\n",
    "path_code_percent = output_directory / '8-code_percent.csv'\n",
    "df_code_review_percent.to_csv(path_code_percent, index = True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "print(tabulate(df_code_review_percent, headers='keys', tablefmt='psql'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data[\"nb_papers\"] = len(df_rating_1)-2\n",
    "data[\"nb_reviews\"] = (len(df_rating_1)-2)*3\n",
    "data[\"date\"]= str(datetime.date.today())\n",
    "data[\"time\"]=str(datetime.datetime.utcnow())\n",
    "data[\"path_rating\"]= path_csv\n",
    "\n",
    "\n",
    "json_data = json.dumps(data, skipkeys=True, indent=4)\n",
    "json_path =  output_directory/ \"data.json\"\n",
    "with open(json_path,\"w\") as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproducibility-reviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
