{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List representing binary choices (0 or 1) for specific content categories\n",
    "list_0_1 = [\n",
    "    \"Models and algorithms\",\n",
    "    \"Datasets\",\n",
    "    \"Code\",\n",
    "    \"Experimental results\",\n",
    "    \"Error bars or statistical significance\",\n",
    "    \"Code is or will be available\"\n",
    "]\n",
    "\n",
    "# List representing different levels or types of statements\n",
    "statement_list = [\n",
    "    \"3. (+) statement\",\n",
    "    \"2. (-) statement\",\n",
    "    \"1. (none) statement\",\n",
    "    \"0. Unusable (statement)\",\n",
    "]\n",
    "\n",
    "# List representing different levels or types of comments\n",
    "comments_list = [\n",
    "    \"4. (-/+) comments\",\n",
    "    \"3. (+) comments\",\n",
    "    \"2. (-) comments\",\n",
    "    \"1. (none) comments\",\n",
    "    \"0. Unusable (comments)\",\n",
    "]\n",
    "\n",
    "# List representing meta-categories\n",
    "meta_categories_list = [\n",
    "    \"(+) meta\",\n",
    "    \"(-) meta\",\n",
    "    \"Unusable (meta)\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook analyzes the 3 reviews of 90 different papers based on the file ../human_rating/rating_90/rating_90_O.csv\n",
      "Outputs will be saved in ../miccai2023/stats_rating.\n"
     ]
    }
   ],
   "source": [
    "N_REVIEWS = 3\n",
    "\n",
    "# Enter the path to the TSV file with the rating from the first observer\n",
    "# You can change to analyze the ratings of another observer\n",
    "path_csv = Path(\"../human_rating/rating_90/rating_90_O.csv\")\n",
    "df_rating_1 = pd.read_csv(path_csv, sep=\"\\t\", index_col=False, header=None)\n",
    "\n",
    "# Display information about the analysis\n",
    "print(f\"This notebook analyzes the {N_REVIEWS} reviews of {len(df_rating_1) - 2} different papers based on the file {path_csv}\")\n",
    "\n",
    "# Set up the output directory path\n",
    "output_directory = Path(f\"../miccai2023/stats_rating\")\n",
    "\n",
    "# Check if the output directory exists, if not, create it\n",
    "if not output_directory.is_dir():\n",
    "    output_directory.mkdir()\n",
    "\n",
    "# Print the output directory path\n",
    "print(f\"Outputs will be saved in {output_directory}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on the rating for the 0/1 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ci_bp(observed_proportion: float, number_of_observation: int) -> tuple[float, float]:\n",
    "    \"\"\"Return the confidence interval (binomial proportion).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    proportion: (float) The observed proportion.\n",
    "    N: (int) The total number of observations.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float :\n",
    "        The lower bound of the confidence interval.\n",
    "    float :\n",
    "        The upper bound of the confidence interval.\n",
    "    \"\"\"\n",
    "    from math import sqrt\n",
    "    \n",
    "    ratio = sqrt(observed_proportion * (1 - observed_proportion) / number_of_observation)\n",
    "    return (\n",
    "        (-1.96 * ratio + observed_proportion) * 100,\n",
    "        (1.96 * ratio + proportion) * 100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ci_bootstrap(data: list, val: float, num_resamples: int = 1000) -> tuple[float, float]:\n",
    "    \"\"\"Return the confidence interval (bootstrap).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list\n",
    "        The original data.\n",
    "    val : float\n",
    "        The value for which the confidence interval is calculated.\n",
    "    num_resamples : int, optional\n",
    "        The number of bootstrap resamples, by default 1000.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float :\n",
    "        The lower bound of the confidence interval.\n",
    "    float :\n",
    "        The upper bound of the confidence interval.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    # Generate bootstrap samples and calculate the statistic of interest.\n",
    "    for i in range(num_resamples):\n",
    "        Y_resample = random.choices(data, k=len(data))\n",
    "        out = Y_resample.count(val)\n",
    "        outputs.append(out * 100 / len(data))\n",
    "\n",
    "    # Calculate the percentiles to obtain the confidence interval.\n",
    "    return np.percentile(outputs, 2.25), np.percentile(outputs, 97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For category Models and algorithms, 28.89% of reviewers (78/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [23.48%, 34.30%]\n",
      "Confidence intervals (bootstrap): [23.51%, 34.44%]\n",
      "\n",
      "For category Datasets, 33.33% of reviewers (90/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [27.71%, 38.96%]\n",
      "Confidence intervals (bootstrap): [27.78%, 38.89%]\n",
      "\n",
      "For category Code, 46.67% of reviewers (126/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [40.72%, 52.62%]\n",
      "Confidence intervals (bootstrap): [40.74%, 52.59%]\n",
      "\n",
      "For category Experimental results, 25.56% of reviewers (69/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [20.35%, 30.76%]\n",
      "Confidence intervals (bootstrap): [20.00%, 30.75%]\n",
      "\n",
      "For category Error bars or statistical significance, 1.85% of reviewers (5/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [0.24%, 3.46%]\n",
      "Confidence intervals (bootstrap): [0.37%, 3.70%]\n",
      "\n",
      "For category Code is or will be available, 23.33% of reviewers (63/270) have commented on at least one of the items of the category.\n",
      "Confidence intervals (binomial proportion): [18.29%, 28.38%]\n",
      "Confidence intervals (bootstrap): [18.15%, 28.52%]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dataframe to store statistics with zeros\n",
    "df_category = pd.DataFrame(\n",
    "    np.zeros((len(list_0_1), 4)),\n",
    "    index=list_0_1,\n",
    "    columns=[\"number\", \"percent\", \"ci low\", \"ci high\"],\n",
    ")\n",
    "\n",
    "# Iterate over each category and calculate statistics\n",
    "for category_idx, category in enumerate(list_0_1):\n",
    "    # List to store all reviews for the current category from all reviewers\n",
    "    all_reviews_1 = []\n",
    "    \n",
    "    # Iterate over each reviewer (3 in total)\n",
    "    for i in range(N_REVIEWS):\n",
    "        # Extract the ratings for the current category from the corresponding column\n",
    "        column_id = i * 9 + 3 + category_idx\n",
    "        list_review_1 = df_rating_1.loc[2:, column_id].values.tolist()\n",
    "        all_reviews_1 = all_reviews_1 + list_review_1\n",
    "\n",
    "    # Calculate the number of '1' and percentage of '1' for the current category\n",
    "    count_ = all_reviews_1.count(\"1\")\n",
    "    percent_ = round(count_ * 100 / len(all_reviews_1), 2)\n",
    "\n",
    "    # Populate the output dataframe with the calculated statistics\n",
    "    df_category.loc[category, \"number\"] = count_\n",
    "    df_category.loc[category, \"percent\"] = percent_\n",
    "\n",
    "    # Print information about the category and its statistics\n",
    "    print(\n",
    "        f\"For category {category}, {percent_}% of reviewers \"\n",
    "        f\"({count_}/{len(all_reviews_1)}) have commented on at least one of the items of the category.\"\n",
    "    )\n",
    "    # Calculate confidence intervals using binomial proportion and bootstrap methods\n",
    "    proportion = count_ / len(all_reviews_1)\n",
    "    ci_bp_low, ci_bp_high = compute_ci_bp(proportion, len(all_reviews_1))\n",
    "    ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(all_reviews_1, '1')\n",
    "\n",
    "    # Populate the output dataframe with confidence interval values (only bootstrap)\n",
    "    df_category.loc[category, \"ci low\"] = ci_bootstrap_low\n",
    "    df_category.loc[category, \"ci high\"] = ci_bootstrap_high\n",
    "\n",
    "    # Print confidence intervals\n",
    "    print(\n",
    "        f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\\n\"\n",
    "        f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews                        |   number |   percent |   ci low |   ci high |\n",
      "|----------------------------------------+----------+-----------+----------+-----------|\n",
      "| Models and algorithms                  |       78 |     28.89 | 23.5102  |   34.4444 |\n",
      "| Datasets                               |       90 |     33.33 | 27.7778  |   38.8889 |\n",
      "| Code                                   |      126 |     46.67 | 40.7407  |   52.5926 |\n",
      "| Experimental results                   |       69 |     25.56 | 20       |   30.75   |\n",
      "| Error bars or statistical significance |        5 |      1.85 |  0.37037 |    3.7037 |\n",
      "| Code is or will be available           |       63 |     23.33 | 18.1481  |   28.5185 |\n",
      "+----------------------------------------+----------+-----------+----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Rename the index of the dataframe\n",
    "df_category.index.rename(f\"For {len(all_reviews_1)} reviews\", inplace=True)\n",
    "df_category.to_csv(output_directory / \"1-category.csv\", index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Print the dataframe in tabular format\n",
    "print(tabulate(df_category, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on the rating for the statements category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for statements (on 270 reviewers):\n",
      "\n",
      "- 48.89% of reviews (132/270) in category 3. (+) statement\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence intervals (binomial proportion): [42.93%, 54.85%]\n",
      "Confidence intervals (bootstrap): [42.59%, 55.19%]\n",
      "\n",
      "- 11.85% of reviews (32/270) in category 2. (-) statement\n",
      "Confidence intervals (binomial proportion): [8.00%, 15.71%]\n",
      "Confidence intervals (bootstrap): [8.15%, 15.93%]\n",
      "\n",
      "- 37.04% of reviews (100/270) in category 1. (none) statement\n",
      "Confidence intervals (binomial proportion): [31.28%, 42.80%]\n",
      "Confidence intervals (bootstrap): [31.48%, 42.59%]\n",
      "\n",
      "- 2.22% of reviews (6/270) in category 0. Unusable (statement)\n",
      "Confidence intervals (binomial proportion): [0.46%, 3.98%]\n",
      "Confidence intervals (bootstrap): [0.74%, 4.07%]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dataframe to store statistics on statements with zeros.\n",
    "df_statement = pd.DataFrame(\n",
    "    np.zeros((len(statement_list), 4)),\n",
    "    index=statement_list,\n",
    "    columns=[\"number\", \"percent\", \"ci low\", \"ci high\"],\n",
    ")\n",
    "\n",
    "# Extract the statements category for the 3 reviewers\n",
    "reviews_statement = []\n",
    "list_statement_1 = df_rating_1.loc[2:, 9].values.tolist()\n",
    "list_statement_2 = df_rating_1.loc[2:, 18].values.tolist()\n",
    "list_statement_3 = df_rating_1.loc[2:, 27].values.tolist()\n",
    "reviews_statement = list_statement_1 + list_statement_2 + list_statement_3\n",
    "\n",
    "# Display information about the analysis\n",
    "print(f\"Statistics for statements (on {len(reviews_statement)} reviewers):\\n\")\n",
    "\n",
    "# Iterate over each rating level in the statements list and calculate statistics\n",
    "for rating in statement_list:\n",
    "    # Calculate number and percentage of reviews for the current rating level\n",
    "    count_ = reviews_statement.count(rating)\n",
    "    percent_ = round(count_ * 100 / len(reviews_statement), 2)\n",
    "\n",
    "    # Populate the output dataframe with the calculated statistics\n",
    "    df_statement.loc[rating, \"number\"] = count_\n",
    "    df_statement.loc[rating, \"percent\"] = percent_\n",
    "\n",
    "    # Print information about the rating level and its statistics\n",
    "    print(f\"- {percent_}% of reviews ({count_}/{len(reviews_statement)}) in category {rating}\")\n",
    "\n",
    "    # Calculate confidence intervals using binomial proportion and bootstrap methods\n",
    "    proportion = count_ / len(reviews_statement)\n",
    "    ci_bp_low, ci_bp_high = compute_ci_bp(proportion, len(reviews_statement))\n",
    "    ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(reviews_statement, rating)\n",
    "\n",
    "    # Populate the output dataframe with confidence interval values (only bootstrap)\n",
    "    df_statement.loc[rating, \"ci low\"] = round(ci_bootstrap_low, 2)\n",
    "    df_statement.loc[rating, \"ci high\"] = round(ci_bootstrap_high, 2)\n",
    "\n",
    "    # Print confidence intervals\n",
    "    print(\n",
    "        f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\\n\"\n",
    "        f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 48.89% of reviews (132/270) provided a statement\n",
      "Confidence intervals (binomial proportion): [42.93%, 54.85%]\n",
      "Confidence intervals (bootstrap): [42.59%, 54.44%]\n",
      "\n",
      "+-------------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews         |   number |   percent |   ci low |   ci high |\n",
      "|-------------------------+----------+-----------+----------+-----------|\n",
      "| 3. (+) statement        |      132 |     48.89 |    42.59 |     55.19 |\n",
      "| 2. (-) statement        |       32 |     11.85 |     8.15 |     15.93 |\n",
      "| 1. (none) statement     |      100 |     37.04 |    31.48 |     42.59 |\n",
      "| 0. Unusable (statement) |        6 |      2.22 |     0.74 |      4.07 |\n",
      "+-------------------------+----------+-----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage and confidence intervals for reviewers that provided a statement\n",
    "new_reviews_statement = [\n",
    "    1 if (review_statement == \"3. (+) statement\" or review_statement == \"2. (-) statement \")\n",
    "    else 0 for review_statement in reviews_statement\n",
    "]\n",
    "new_count_ = new_reviews_statement.count(1)\n",
    "new_percent_ = round(new_count_ * 100 / len(reviews_statement), 2)\n",
    "\n",
    "# Display information about reviews that provided a statement\n",
    "print(f\"- {new_percent_}% of reviews ({new_count_}/{len(reviews_statement)}) provided a statement\")\n",
    "\n",
    "# Calculate confidence intervals for reviews that provided a statement\n",
    "proportion = new_count_ / len(reviews_statement)\n",
    "ci_bp_low, ci_bp_high = compute_ci_bp(proportion, len(reviews_statement))\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(new_reviews_statement, 1)\n",
    "print(\n",
    "    f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\\n\"\n",
    "    f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\\n\"\n",
    ")\n",
    "# Display statistics dataframe for statements\n",
    "df_statement.index.rename(f\"For {len(reviews_statement)} reviews\", inplace=True)\n",
    "print(tabulate(df_statement, headers='keys', tablefmt='psql'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kappa_fleiss_three_raters(data_1, data_2, data_3) -> float:\n",
    "    \"\"\"Compute Cohen's kappa score for 3 raters (bootstrap).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_1 : array-like\n",
    "        Labels from rater 1.\n",
    "    data_2 : array-like\n",
    "        Labels from rater 2.\n",
    "    data_3 : array-like\n",
    "        Labels from rater 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The mean of the kappa across bootstrap samples.\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "\n",
    "    data_fleiss_ = aggregate_raters(np.array([data_1, data_2, data_3]).T)\n",
    "    return fleiss_kappa(data_fleiss_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ci_bootstrap_three_raters(data_1, data_2, data_3, num_resamples: int = 1000) -> tuple[float, float]:\n",
    "    \"\"\"Compute confidence interval for a 3 raters kappa (bootstrap).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_1 : array-like\n",
    "        Labels from rater 1.\n",
    "    data_2 : array-like\n",
    "        Labels from rater 2.\n",
    "    data_3 : array-like\n",
    "        Labels from rater 3.\n",
    "    num_resamples : int, optional\n",
    "        The number of bootstrap resamples, by default 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float :\n",
    "        95% CI lower bound (2.5 percentile of the sorted bootstrap distribution).\n",
    "    float :\n",
    "        95% CI upper bound (97.5 percentile of the sorted bootstrap distribution).\n",
    "    \"\"\"\n",
    "    Y = np.array([data_1, data_2, data_3]).T\n",
    "    list_kappa = []\n",
    "\n",
    "    # Generate bootstrap samples and calculate the kappa for each sample.\n",
    "    for i in range(num_resamples):\n",
    "        Y_resample = np.array(random.choices(Y, k=len(Y)))\n",
    "        list_kappa.append(\n",
    "            compute_kappa_fleiss_three_raters(\n",
    "                Y_resample[:, 0].astype(str),\n",
    "                Y_resample[:, 1].astype(str),\n",
    "                Y_resample[:, 2].astype(str),\n",
    "            )\n",
    "        )\n",
    "    # Calculate the percentiles to obtain the confidence interval.\n",
    "    return np.percentile(list_kappa, 2.5), np.percentile(list_kappa, 97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(list_1: list, list_2: list, list_attributs: list) -> pd.DataFrame:\n",
    "    \"\"\"Create a confusion matrix in percentage.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_1: List of labels from reviewer 1.\n",
    "    list_2: List of labels from reviewer 2.\n",
    "    list_attributs: List of attribute labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame :\n",
    "        The confusion matrix as a DataFrame (in %).\n",
    "    \"\"\"\n",
    "    if len(list_1) != len(list_2):\n",
    "        raise ValueError(\"Reviewer 1 and 2 may not have rated the same list of subjects.\")\n",
    "    size = len(list_attributs)    \n",
    "    # Initialize the confusion matrix with zeros.\n",
    "    matrix = pd.DataFrame(\n",
    "        np.zeros((size + 1, size + 1)),\n",
    "        index=list_attributs + [\"total\"],\n",
    "        columns=list_attributs + [\"total\"],\n",
    "    )    \n",
    "    # Populate the confusion matrix based on reviewer ratings.\n",
    "    for k, att_k in enumerate(list_attributs):\n",
    "        for l, att_l in enumerate(list_attributs):\n",
    "             for i, elt in enumerate(list_1):\n",
    "                if elt == att_k:\n",
    "                    if list_2[i] == att_l:\n",
    "                        matrix.loc[att_k, att_l] += 1\n",
    "        \n",
    "    # Calculate row and column totals, and total observations.\n",
    "    for i, att_i in enumerate(list_attributs):\n",
    "        for j, att_j in enumerate(list_attributs):\n",
    "            matrix.loc[\"total\", att_i] += matrix.loc[att_j, att_i]\n",
    "            matrix.loc[att_i, \"total\"] += matrix.loc[att_i, att_j]\n",
    "            matrix.loc[\"total\", \"total\"] += matrix.loc[att_i, att_j]\n",
    "\n",
    "    # Convert the matrix to percentages if the number of observations matches the total.\n",
    "    if len(list_1) == matrix.loc[\"total\", \"total\"]:\n",
    "        matrix = round(matrix * 100 / len(list_1), 2)\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa: -0.051648054755043166\n",
      "Confidence intervals (bootstrap): [-0.14, 0.04]\n",
      "\n",
      "Review 1 VS review 2\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "|                         |   3. (+) statement |   2. (-) statement |   1. (none) statement |   0. Unusable (statement) |   total |\n",
      "|-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------|\n",
      "| 3. (+) statement        |              18.89 |              10    |                 18.89 |                      0    |   47.78 |\n",
      "| 2. (-) statement        |               6.67 |               2.22 |                  4.44 |                      0    |   13.33 |\n",
      "| 1. (none) statement     |              20    |               0    |                 16.67 |                      1.11 |   37.78 |\n",
      "| 0. Unusable (statement) |               0    |               1.11 |                  0    |                      0    |    1.11 |\n",
      "| total                   |              45.56 |              13.33 |                 40    |                      1.11 |  100    |\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "\n",
      "Review 2 VS review 3\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "|                         |   3. (+) statement |   2. (-) statement |   1. (none) statement |   0. Unusable (statement) |   total |\n",
      "|-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------|\n",
      "| 3. (+) statement        |              25.56 |               4.44 |                 13.33 |                      2.22 |   45.56 |\n",
      "| 2. (-) statement        |               5.56 |               1.11 |                  6.67 |                      0    |   13.33 |\n",
      "| 1. (none) statement     |              21.11 |               3.33 |                 13.33 |                      2.22 |   40    |\n",
      "| 0. Unusable (statement) |               1.11 |               0    |                  0    |                      0    |    1.11 |\n",
      "| total                   |              53.33 |               8.89 |                 33.33 |                      4.44 |  100    |\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "\n",
      "Review 1 VS review 3\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "|                         |   3. (+) statement |   2. (-) statement |   1. (none) statement |   0. Unusable (statement) |   total |\n",
      "|-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------|\n",
      "| 3. (+) statement        |              21.11 |               5.56 |                 21.11 |                      0    |   47.78 |\n",
      "| 2. (-) statement        |               5.56 |               1.11 |                  4.44 |                      2.22 |   13.33 |\n",
      "| 1. (none) statement     |              25.56 |               2.22 |                  7.78 |                      2.22 |   37.78 |\n",
      "| 0. Unusable (statement) |               1.11 |               0    |                  0    |                      0    |    1.11 |\n",
      "| total                   |              53.33 |               8.89 |                 33.33 |                      4.44 |  100    |\n",
      "+-------------------------+--------------------+--------------------+-----------------------+---------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_statement.to_csv(output_directory / '2-statements.csv', index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Calculate Fleiss' Kappa for the statements\n",
    "kappa_fleiss_statement = compute_kappa_fleiss_three_raters(\n",
    "    list_statement_1,\n",
    "    list_statement_2,\n",
    "    list_statement_3,\n",
    ")\n",
    "print(f\"Fleiss' Kappa: {kappa_fleiss_statement}\")\n",
    "\n",
    "### Sanity check ###\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# kappa_sk_statement = cohen_kappa_score(list_statement_1, list_statement_2)\n",
    "# print(f\"kappa sklearn: {kappa_sk_statement}\")\n",
    "\n",
    "# Calculate confidence intervals for Fleiss' Kappa\n",
    "ci_low_fleiss_statement, ci_high_fleiss_statement = compute_ci_bootstrap_three_raters(\n",
    "    list_statement_1,\n",
    "    list_statement_2,\n",
    "    list_statement_3,\n",
    ")\n",
    "print(f\"Confidence intervals (bootstrap): [{ci_low_fleiss_statement:.2f}, {ci_high_fleiss_statement:.2f}]\\n\")\n",
    "\n",
    "# Display confusion matrices for pairwise comparisons of reviews\n",
    "print(\"Review 1 VS review 2\")\n",
    "m1_statement = create_confusion_matrix(list_statement_1, list_statement_2, statement_list)\n",
    "print(tabulate(m1_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 2 VS review 3\")\n",
    "m2_statement = create_confusion_matrix(list_statement_2, list_statement_3, statement_list)\n",
    "print(tabulate(m2_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 1 VS review 3\")\n",
    "m3_statement = create_confusion_matrix(list_statement_1, list_statement_3, statement_list)\n",
    "print(tabulate(m3_statement, headers='keys', tablefmt='psql'))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on the rating for the comments category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for comments (on 270 reviewers):\n",
      "\n",
      "- 22.96% of reviews (62/270) in category 4. (-/+) comments\n",
      "Confidence intervals (binomial proportion): [17.95%, 27.98%]\n",
      "Confidence intervals (bootstrap): [17.78%, 28.15%]\n",
      "\n",
      "- 30.74% of reviews (83/270) in category 3. (+) comments\n",
      "Confidence intervals (binomial proportion): [25.24%, 36.24%]\n",
      "Confidence intervals (bootstrap): [25.19%, 36.67%]\n",
      "\n",
      "- 18.52% of reviews (50/270) in category 2. (-) comments\n",
      "Confidence intervals (binomial proportion): [13.89%, 23.15%]\n",
      "Confidence intervals (bootstrap): [14.07%, 22.97%]\n",
      "\n",
      "- 22.22% of reviews (60/270) in category 1. (none) comments\n",
      "Confidence intervals (binomial proportion): [17.26%, 27.18%]\n",
      "Confidence intervals (bootstrap): [17.41%, 27.04%]\n",
      "\n",
      "- 5.56% of reviews (15/270) in category 0. Unusable (comments)\n",
      "Confidence intervals (binomial proportion): [2.82%, 8.29%]\n",
      "Confidence intervals (bootstrap): [2.96%, 8.52%]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output dataframe to store statistics on comments with zeros.\n",
    "df_comments = pd.DataFrame(\n",
    "    np.zeros((len(comments_list), 4)),\n",
    "    index=comments_list,\n",
    "    columns=[\"number\", \"percent\", \"ci low\", \"ci high\"],\n",
    ")\n",
    "# Extract the comments category for the 3 reviews\n",
    "reviews_comments = []\n",
    "list_comment_1 = df_rating_1.loc[2:, 10].values.tolist()\n",
    "list_comment_2 = df_rating_1.loc[2:, 19].values.tolist()\n",
    "list_comment_3 = df_rating_1.loc[2:, 28].values.tolist()\n",
    "reviews_comments = list_comment_1 + list_comment_2 + list_comment_3\n",
    "\n",
    "# Display information about the analysis\n",
    "print(f\"Statistics for comments (on {len(reviews_comments)} reviewers):\\n\")\n",
    "N_comments = len(reviews_comments)\n",
    "\n",
    "# Iterate over each rating level in the comments list and calculate statistics\n",
    "for rating in comments_list:\n",
    "    # Calculate number and percentage of reviews for the current rating level\n",
    "    count_ = reviews_comments.count(rating)\n",
    "    percent_ = round(count_ * 100 / N_comments, 2)\n",
    "\n",
    "    # Populate the output dataframe with the calculated statistics\n",
    "    df_comments.loc[rating, \"number\"] = count_\n",
    "    df_comments.loc[rating, \"percent\"] = percent_\n",
    "\n",
    "    # Print information about the rating level and its statistics\n",
    "    print(f\"- {percent_}% of reviews ({count_}/{N_comments}) in category {rating}\")\n",
    "\n",
    "    # Calculate confidence intervals using binomial proportion and bootstrap methods\n",
    "    proportion = count_ / N_comments\n",
    "    ci_bp_low, ci_bp_high = compute_ci_bp(proportion, N_comments)\n",
    "    ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(reviews_comments, rating)\n",
    "\n",
    "    # Populate the output dataframe with confidence interval values\n",
    "    df_comments.loc[rating, \"ci low\"] = round(ci_bootstrap_low, 2)\n",
    "    df_comments.loc[rating, \"ci high\"] = round(ci_bootstrap_high, 2)\n",
    "\n",
    "    # Print confidence intervals\n",
    "    print(\n",
    "        f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\\n\"\n",
    "        f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 72.22% of reviews (195/270) provided a comment\n",
      "Confidence intervals (binomial proportion): [66.88%, 77.56%]\n",
      "Confidence intervals (bootstrap): [67.04%, 77.41%]\n",
      "\n",
      "+------------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews        |   number |   percent |   ci low |   ci high |\n",
      "|------------------------+----------+-----------+----------+-----------|\n",
      "| 4. (-/+) comments      |       62 |     22.96 |    18.15 |     28.15 |\n",
      "| 3. (+) comments        |       83 |     30.74 |    25.19 |     36.67 |\n",
      "| 2. (-) comments        |       50 |     18.52 |    14.07 |     22.97 |\n",
      "| 1. (none) comments     |       60 |     22.22 |    17.41 |     27.41 |\n",
      "| 0. Unusable (comments) |       15 |      5.56 |     2.96 |      8.52 |\n",
      "+------------------------+----------+-----------+----------+-----------+\n",
      "Fleiss' Kappa: 0.0474911357043086\n",
      "Confidence intervals (bootstrap): [-0.03%, 0.12%]\n",
      "\n",
      "Review 1 VS review 2\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "|                        |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 4. (-/+) comments      |                4.44 |              7.78 |              4.44 |                 7.78 |                     1.11 |   25.56 |\n",
      "| 3. (+) comments        |                6.67 |              8.89 |              4.44 |                 6.67 |                     1.11 |   27.78 |\n",
      "| 2. (-) comments        |                4.44 |              6.67 |              5.56 |                 4.44 |                     0    |   21.11 |\n",
      "| 1. (none) comments     |                2.22 |              7.78 |              5.56 |                 4.44 |                     2.22 |   22.22 |\n",
      "| 0. Unusable (comments) |                0    |              1.11 |              2.22 |                 0    |                     0    |    3.33 |\n",
      "| total                  |               17.78 |             32.22 |             22.22 |                23.33 |                     4.44 |  100    |\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n",
      "Review 2 VS review 3\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "|                        |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 4. (-/+) comments      |               10    |              2.22 |              1.11 |                 4.44 |                     0    |   17.78 |\n",
      "| 3. (+) comments        |                4.44 |             14.44 |              2.22 |                 6.67 |                     4.44 |   32.22 |\n",
      "| 2. (-) comments        |                5.56 |              5.56 |              3.33 |                 4.44 |                     3.33 |   22.22 |\n",
      "| 1. (none) comments     |                2.22 |             10    |              5.56 |                 4.44 |                     1.11 |   23.33 |\n",
      "| 0. Unusable (comments) |                3.33 |              0    |              0    |                 1.11 |                     0    |    4.44 |\n",
      "| total                  |               25.56 |             32.22 |             12.22 |                21.11 |                     8.89 |  100    |\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n",
      "Review 1 VS review 3\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "|                        |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 4. (-/+) comments      |                4.44 |              7.78 |              3.33 |                 6.67 |                     3.33 |   25.56 |\n",
      "| 3. (+) comments        |                8.89 |             11.11 |              2.22 |                 3.33 |                     2.22 |   27.78 |\n",
      "| 2. (-) comments        |                5.56 |              4.44 |              3.33 |                 5.56 |                     2.22 |   21.11 |\n",
      "| 1. (none) comments     |                6.67 |              6.67 |              3.33 |                 5.56 |                     0    |   22.22 |\n",
      "| 0. Unusable (comments) |                0    |              2.22 |              0    |                 0    |                     1.11 |    3.33 |\n",
      "| total                  |               25.56 |             32.22 |             12.22 |                21.11 |                     8.89 |  100    |\n",
      "+------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage and confidence intervals for reviews that provided a comment\n",
    "new_reviews_comments = [\n",
    "    1 if review_comment in (\"4. (-/+) comments\", \"3. (+) comments\", \"2. (-) comments\")\n",
    "    else 0 for review_comment in reviews_comments\n",
    "]\n",
    "new_count_ = new_reviews_comments.count(1)\n",
    "new_percent_ = round(new_count_ * 100 / N_comments, 2)\n",
    "\n",
    "# Display information about reviews that provided a comment\n",
    "print(f\"- {new_percent_}% of reviews ({new_count_}/{N_comments}) provided a comment\")\n",
    "\n",
    "# Calculate confidence intervals for reviews that provided a comment\n",
    "proportion = new_count_ / N_comments\n",
    "ci_bp_low, ci_bp_high = compute_ci_bp(proportion, N_comments)\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(new_reviews_comments, 1)\n",
    "print(\n",
    "    f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\\n\"\n",
    "    f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\\n\"\n",
    ")\n",
    "\n",
    "# Save values needed to extract latex data\n",
    "comments_latex = [ new_percent_, new_count_, N_comments, ci_bootstrap_low, ci_bootstrap_high]\n",
    "\n",
    "# Display statistics dataframe for comments\n",
    "df_comments.index.rename(f\"For {N_comments} reviews\", inplace=True)\n",
    "print(tabulate(df_comments, headers='keys', tablefmt='psql'))\n",
    "\n",
    "df_comments.to_csv(output_directory / '3-comments.csv', index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Calculate Fleiss' Kappa for the comments\n",
    "kappa_fleiss_comment = compute_kappa_fleiss_three_raters(\n",
    "    list_comment_1,\n",
    "    list_comment_2,\n",
    "    list_comment_3,\n",
    ")\n",
    "print(f\"Fleiss' Kappa: {kappa_fleiss_comment}\")\n",
    "\n",
    "# Calculate confidence intervals for Fleiss' Kappa\n",
    "ci_low_fleiss_comment, ci_high_fleiss_comment = compute_ci_bootstrap_three_raters(\n",
    "    list_comment_1,\n",
    "    list_comment_2,\n",
    "    list_comment_3,\n",
    ")\n",
    "print(f\"Confidence intervals (bootstrap): [{ci_low_fleiss_comment:.2f}%, {ci_high_fleiss_comment:.2f}%]\\n\")\n",
    "\n",
    "# Display confusion matrices for pairwise comparisons of reviews\n",
    "print(\"Review 1 VS review 2\")\n",
    "m1_comment = create_confusion_matrix(list_comment_1, list_comment_2, comments_list)\n",
    "print(tabulate(m1_comment, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 2 VS review 3\")\n",
    "m2_comment = create_confusion_matrix(list_comment_2, list_comment_3, comments_list)\n",
    "print(tabulate(m2_comment, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 1 VS review 3\")\n",
    "m3_comment = create_confusion_matrix(list_comment_1, list_comment_3, comments_list)\n",
    "print(tabulate(m3_comment, headers='keys', tablefmt='psql'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of statement category VS comment category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of statements VS comments\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "| number                  |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 3. (+) statement        |                  21 |                52 |                 7 |                   52 |                        0 |     132 |\n",
      "| 2. (-) statement        |                   8 |                 0 |                21 |                    3 |                        0 |      32 |\n",
      "| 1. (none) statement     |                  33 |                31 |                22 |                    5 |                        9 |     100 |\n",
      "| 0. Unusable (statement) |                   0 |                 0 |                 0 |                    0 |                        6 |       6 |\n",
      "| total                   |                  62 |                83 |                50 |                   60 |                       15 |     270 |\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "\n",
      "39.39% of reviewers (52/132) made a positive statement but didn't provide a comment to substantiate their statement.\n",
      "Confidence intervals (binomial proportion): [31.06%, 47.73%]\n",
      "Confidence intervals (bootstrap): [31.82%, 46.99%]\n",
      "\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n",
      "| in %                    |   4. (-/+) comments |   3. (+) comments |   2. (-) comments |   1. (none) comments |   0. Unusable (comments) |   total |\n",
      "|-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------|\n",
      "| 3. (+) statement        |                7.78 |             19.26 |              2.59 |                19.26 |                     0    |   48.89 |\n",
      "| 2. (-) statement        |                2.96 |              0    |              7.78 |                 1.11 |                     0    |   11.85 |\n",
      "| 1. (none) statement     |               12.22 |             11.48 |              8.15 |                 1.85 |                     3.33 |   37.04 |\n",
      "| 0. Unusable (statement) |                0    |              0    |              0    |                 0    |                     2.22 |    2.22 |\n",
      "| total                   |               22.96 |             30.74 |             18.52 |                22.22 |                     5.56 |  100    |\n",
      "+-------------------------+---------------------+-------------------+-------------------+----------------------+--------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Initialize with zeros a DataFrame to store the cross-tabulation of statements and comments\n",
    "df_stat_com = pd.DataFrame(\n",
    "    np.zeros((len(statement_list) + 1, len(comments_list) + 1)),\n",
    "    index=statement_list + [\"total\"],\n",
    "    columns=comments_list + [\"total\"],\n",
    ")\n",
    "df_stat_com.index.rename(\"number\", inplace=True)\n",
    "\n",
    "# Populate the cross-tabulation DataFrame based on the reviews' statements and comments\n",
    "for i, review_comment in enumerate(reviews_comments):\n",
    "    df_stat_com.loc[reviews_statement[i], review_comment] += 1\n",
    "    df_stat_com.loc[\"total\", review_comment] += 1\n",
    "    df_stat_com.loc[reviews_statement[i], \"total\"] += 1\n",
    "\n",
    "# Set the total count for the total row and column\n",
    "df_stat_com.loc[\"total\", \"total\"] = len(reviews_comments)\n",
    "\n",
    "# Display the cross-tabulation of statements and comments\n",
    "print(\"Analysis of statements VS comments\")\n",
    "print(tabulate(df_stat_com, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "# Identify reviewers who made a positive statement but didn't provide a comment\n",
    "reviews_statement_no_comments = []\n",
    "for i, review_comment in enumerate(reviews_comments):\n",
    "    if reviews_statement[i] == \"3. (+) statement\":\n",
    "        reviews_statement_no_comments.append(\n",
    "            1 if review_comment in (\"1. (none) comments\", \"0. (Unusable) comments\") else 0\n",
    "        )\n",
    "# Calculate percentage and confidence intervals for reviewers \n",
    "# who made a positive statement but didn't provide a comment\n",
    "new_count_ = reviews_statement_no_comments.count(1)\n",
    "new_percent_ = round(new_count_ * 100 / len(reviews_statement_no_comments), 2)\n",
    "print(\n",
    "    f\"{new_percent_}% of reviewers ({new_count_}/{len(reviews_statement_no_comments)}) \"\n",
    "    \"made a positive statement but didn't provide a comment to substantiate their statement.\"\n",
    ")\n",
    "\n",
    "proportion = new_count_ / len(reviews_statement_no_comments)\n",
    "ci_bp_low, ci_bp_high = compute_ci_bp(proportion, len(reviews_statement_no_comments))\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(reviews_statement_no_comments, 1)\n",
    "print(\n",
    "    f\"Confidence intervals (binomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\\n\"\n",
    "    f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\\n\"\n",
    ")\n",
    "\n",
    "df_stat_com.to_csv(output_directory / '4-statements_comments.csv', index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Create a new DataFrame to store the percentage representation of statements and comments\n",
    "df_stat_com_percent = df_stat_com\n",
    "df_stat_com_percent.index.rename(\"in %\", inplace=True)\n",
    "df_stat_com_percent = round(df_stat_com * 100 / len(reviews_comments), 2)\n",
    "\n",
    "# Display the percentage representation of statements and comments\n",
    "print(tabulate(df_stat_com_percent, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on the rating for the meta category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta categories calculated values aren't the same as in the provided tsv file.\n",
      "Statistics for meta-categories (on 270 reviewers):\n",
      "\n",
      "- 60.37% of reviews (163/270) in category (+) meta\n",
      "Confidence intervals (multinomial proportion): [54.54%, 66.20%]\n",
      "Confidence intervals (bootstrap): [54.07%, 66.30%]\n",
      "\n",
      "- 31.11% of reviews (84/270) in category (-) meta\n",
      "Confidence intervals (multinomial proportion): [25.59%, 36.63%]\n",
      "Confidence intervals (bootstrap): [25.36%, 36.67%]\n",
      "\n",
      "- 8.52% of reviews (23/270) in category Unusable (meta)\n",
      "Confidence intervals (multinomial proportion): [5.19%, 11.85%]\n",
      "Confidence intervals (bootstrap): [5.19%, 11.85%]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize with zeros a DataFrame to store the statistics on the rating for the meta category\n",
    "df_meta = pd.DataFrame(\n",
    "    np.zeros((len(meta_categories_list), 4)),\n",
    "    index=meta_categories_list,\n",
    "    columns=[\"number\", \"percent\", \"ci low\", \"ci high\"],\n",
    ")\n",
    "# Combine the ratings for the meta category from the three reviews\n",
    "reviews_meta = []\n",
    "list_meta_1 = df_rating_1.loc[2:, 29].values.tolist()\n",
    "list_meta_2 = df_rating_1.loc[2:, 30].values.tolist()\n",
    "list_meta_3 = df_rating_1.loc[2:, 31].values.tolist()\n",
    "reviews_meta = list_meta_1 + list_meta_2 + list_meta_3\n",
    "\n",
    "# Convert reviews_meta to match provided categories for consistency\n",
    "reviews_meta_python = []\n",
    "for i, review_statement in enumerate(reviews_statement):\n",
    "    if review_statement == \"3. (+) statement\":\n",
    "        reviews_meta_python.append(\"(+) meta\")\n",
    "    elif review_statement == \"2. (-) statement \":\n",
    "        reviews_meta_python.append(\"(-) meta\")\n",
    "    elif reviews_comments[i] == \"3. (+) comments\":\n",
    "        reviews_meta_python.append(\"(+) meta\")\n",
    "    elif reviews_comments[i] in (\"2. (-) comments\", \"4. (-/+) comments\"):\n",
    "        reviews_meta_python.append(\"(-) meta\")\n",
    "    else:\n",
    "        reviews_meta_python.append(\"Unusable (meta)\")\n",
    "\n",
    "# Check and update reviews_meta if necessary\n",
    "if reviews_meta != reviews_meta_python:\n",
    "    reviews_meta = reviews_meta_python\n",
    "    print(\"Meta categories calculated values aren't the same as in the provided tsv file.\")\n",
    "\n",
    "print(f\"Statistics for meta-categories (on {len(reviews_meta)} reviewers):\\n\")\n",
    "\n",
    "# Calculate and display statistics for the meta category\n",
    "N_meta = len(reviews_meta)\n",
    "for rating in meta_categories_list:\n",
    "    count_ = reviews_meta.count(rating)\n",
    "    percent_ = round(count_ * 100 / N_meta, 2)\n",
    "    df_meta.loc[rating, \"number\"] = count_\n",
    "    df_meta.loc[rating, \"percent\"] = percent_\n",
    "    print(f\"- {percent_}% of reviews ({count_}/{N_meta}) in category {rating}\")\n",
    "\n",
    "    proportion = count_ / N_meta\n",
    "    ci_bp_low, ci_bp_high = compute_ci_bp(proportion, N_meta)\n",
    "    ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(reviews_meta, rating)\n",
    "\n",
    "    df_meta.loc[rating, \"ci low\"] = round(ci_bootstrap_low, 2)\n",
    "    df_meta.loc[rating, \"ci high\"] = round(ci_bootstrap_high, 2)\n",
    "\n",
    "    print(\n",
    "        f\"Confidence intervals (multinomial proportion): [{ci_bp_low:.2f}%, {ci_bp_high:.2f}%]\\n\"\n",
    "        f\"Confidence intervals (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-----------+----------+-----------+\n",
      "| For 270 reviews   |   number |   percent |   ci low |   ci high |\n",
      "|-------------------+----------+-----------+----------+-----------|\n",
      "| (+) meta          |      163 |     60.37 |    54.07 |     66.3  |\n",
      "| (-) meta          |       84 |     31.11 |    25.36 |     36.67 |\n",
      "| Unusable (meta)   |       23 |      8.52 |     5.19 |     11.85 |\n",
      "+-------------------+----------+-----------+----------+-----------+\n",
      "kappa fleiss: 0.021688128877534983\n",
      "Confidence intervals (bootstrap): [-0.08%, 0.12%]\n",
      "\n",
      "Review 1 VS review 2\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "|                 |   (+) meta |   (-) meta |   Unusable (meta) |   total |\n",
      "|-----------------+------------+------------+-------------------+---------|\n",
      "| (+) meta        |      33.33 |      23.33 |              3.33 |   60    |\n",
      "| (-) meta        |      22.22 |      10    |              1.11 |   33.33 |\n",
      "| Unusable (meta) |       3.33 |       2.22 |              1.11 |    6.67 |\n",
      "| total           |      58.89 |      35.56 |              5.56 |  100    |\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "\n",
      "Review 2 VS review 3\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "|                 |   (+) meta |   (-) meta |   Unusable (meta) |   total |\n",
      "|-----------------+------------+------------+-------------------+---------|\n",
      "| (+) meta        |      40    |      12.22 |              6.67 |   58.89 |\n",
      "| (-) meta        |      18.89 |      13.33 |              3.33 |   35.56 |\n",
      "| Unusable (meta) |       3.33 |       2.22 |              0    |    5.56 |\n",
      "| total           |      62.22 |      27.78 |             10    |  100    |\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "\n",
      "Review 1 VS review 3\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "|                 |   (+) meta |   (-) meta |   Unusable (meta) |   total |\n",
      "|-----------------+------------+------------+-------------------+---------|\n",
      "| (+) meta        |      38.89 |      18.89 |              2.22 |   60    |\n",
      "| (-) meta        |      18.89 |       7.78 |              6.67 |   33.33 |\n",
      "| Unusable (meta) |       4.44 |       1.11 |              1.11 |    6.67 |\n",
      "| total           |      62.22 |      27.78 |             10    |  100    |\n",
      "+-----------------+------------+------------+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the statistics DataFrame to a CSV file\n",
    "df_meta.index.rename(f\"For {N_meta} reviews\", inplace=True)\n",
    "print(tabulate(df_meta, headers='keys', tablefmt='psql'))\n",
    "df_meta.to_csv(output_directory / '5-meta.csv', index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Calculate Fleiss' Kappa for the meta category\n",
    "kappa_fleiss_meta = compute_kappa_fleiss_three_raters(\n",
    "    list_meta_1,\n",
    "    list_meta_2,\n",
    "    list_meta_3,\n",
    ")\n",
    "print(f\"kappa fleiss: {kappa_fleiss_meta}\")\n",
    "\n",
    "# Calculate confidence intervals for Fleiss' Kappa\n",
    "ci_low_fleiss_meta, ci_high_fleiss_meta = compute_ci_bootstrap_three_raters(\n",
    "    list_meta_1,\n",
    "    list_meta_2,\n",
    "    list_meta_3,\n",
    ")\n",
    "print(f\"Confidence intervals (bootstrap): [{ci_low_fleiss_meta:.2f}%, {ci_high_fleiss_meta:.2f}%]\\n\")\n",
    "\n",
    "# Display confusion matrices for pairwise comparisons of reviews\n",
    "print(\"Review 1 VS review 2\")\n",
    "m1_meta = create_confusion_matrix(list_meta_1, list_meta_2, meta_categories_list)\n",
    "print(tabulate(m1_meta, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 2 VS review 3\")\n",
    "m2_meta = create_confusion_matrix(list_meta_2, list_meta_3, meta_categories_list)\n",
    "print(tabulate(m2_meta, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "print(\"Review 1 VS review 3\")\n",
    "m3_meta = create_confusion_matrix(list_meta_1, list_meta_3, meta_categories_list)\n",
    "print(tabulate(m3_meta, headers='keys', tablefmt='psql'))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating table of kappa values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+----------+-----------+\n",
      "| kappa fleiss    |   kappa |   ci low |   ci high |\n",
      "|-----------------+---------+----------+-----------|\n",
      "| Statements      |   -0.05 |    -0.14 |      0.04 |\n",
      "| Comments        |    0.05 |    -0.03 |      0.12 |\n",
      "| Meta-categories |    0.02 |    -0.08 |      0.12 |\n",
      "+-----------------+---------+----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store kappa Fleiss values and confidence intervals for different categories\n",
    "df_kappas = pd.DataFrame(\n",
    "    np.zeros((3, 3)),\n",
    "    index=[\"Statements\", \"Comments\", \"Meta-categories\"],\n",
    "    columns=[\"kappa\", \"ci low\", \"ci high\"],\n",
    ")\n",
    "# Populate the DataFrame with kappa Fleiss values and confidence intervals for the statements category\n",
    "df_kappas.loc[\"Statements\", \"kappa\"] = kappa_fleiss_statement\n",
    "df_kappas.loc[\"Statements\", \"ci low\"] = ci_low_fleiss_statement\n",
    "df_kappas.loc[\"Statements\", \"ci high\"] = ci_high_fleiss_statement\n",
    "\n",
    "# Populate the DataFrame with kappa Fleiss values and confidence intervals for the comments category\n",
    "df_kappas.loc[\"Comments\", \"kappa\"] = kappa_fleiss_comment\n",
    "df_kappas.loc[\"Comments\", \"ci low\"] = ci_low_fleiss_comment\n",
    "df_kappas.loc[\"Comments\", \"ci high\"] = ci_high_fleiss_comment\n",
    "\n",
    "# Populate the DataFrame with kappa Fleiss values and confidence intervals for the meta-categories\n",
    "df_kappas.loc[\"Meta-categories\", \"kappa\"] = kappa_fleiss_meta\n",
    "df_kappas.loc[\"Meta-categories\", \"ci low\"] = ci_low_fleiss_meta\n",
    "df_kappas.loc[\"Meta-categories\", \"ci high\"] = ci_high_fleiss_meta\n",
    "\n",
    "# Round the values in the DataFrame for better presentation\n",
    "df_kappas = round(df_kappas, 2)\n",
    "\n",
    "# Rename the index for clarity\n",
    "df_kappas.index.rename(\"kappa fleiss\", inplace=True)\n",
    "\n",
    "# Display the kappa Fleiss values and confidence intervals in tabular format\n",
    "print(tabulate(df_kappas, headers='keys', tablefmt='psql'))\n",
    "\n",
    "df_kappas.to_csv(output_directory / '6-kappas.csv', index=True, sep=\";\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on the rating for the code category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for code (on 90 papers):\n",
      "\n",
      " - for 47.78% (95% CI (bootstrap): [37.78%, 58.89%]) of the papers (43/90), the repository exists and is not empty.\n",
      " - for 20.00% (95% CI (bootstrap): [12.22%, 27.78%]) of the papers (18/90), the link to the repository is provided but it is empty or wrong.\n",
      " - for 32.22% (95% CI (bootstrap): [23.33%, 42.22%]) of the papers (29/90), no link/code was provided.\n",
      "\n",
      " - for 67.78% (95% CI (bootstrap): [57.78%, 76.67%]) of the papers (61/90), an associated repository for the code was provided.\n",
      "\n",
      " - for 29.51% (95% CI (bootstrap): [19.67%, 40.98%]) of the papers for which a link was provided (18/61), the link to the repository is provided but it is empty or wrong.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define column indices for code-related information\n",
    "column_id_link = 38\n",
    "code_link_df = df_rating_1.loc[2:, column_id_link].values.tolist()\n",
    "\n",
    "column_id_avail = 39\n",
    "code_avail_df = df_rating_1.loc[2:, column_id_avail].values.tolist()\n",
    "\n",
    "# Define code categories\n",
    "code_list = [\n",
    "    \"bad link\",\n",
    "    \"good link\",\n",
    "    \"no link\",\n",
    "]\n",
    "\n",
    "# Display statistics for code availability on papers\n",
    "print(f\"Statistics for code (on {len(code_link_df)} papers):\\n\")\n",
    "\n",
    "# Create a list to store code categories for each paper\n",
    "list_code = []\n",
    "\n",
    "# Determine code categories based on code links and availability\n",
    "for i in range(len(code_avail_df)):\n",
    "    if str(code_link_df[i]).startswith(\"http\"):\n",
    "        if code_avail_df[i] == \"1\":\n",
    "            list_code.append(\"good link\")\n",
    "        if code_avail_df[i] == \"0\":\n",
    "            list_code.append(\"bad link\")\n",
    "    else:\n",
    "        list_code.append(\"no link\")\n",
    "\n",
    "# Calculate the number of papers\n",
    "nb_papers = len(list_code)\n",
    "\n",
    "# Display statistics for each code category\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(list_code, \"good link\")\n",
    "print(\n",
    "    f\" - for {(list_code.count('good link') * 100 / nb_papers):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code.count('good link')}/{nb_papers}), the repository exists and is not empty.\"\n",
    ")\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(list_code, \"bad link\")\n",
    "print(\n",
    "    f\" - for {(list_code.count('bad link') * 100 / nb_papers):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code.count('bad link')}/{nb_papers}), the link to the repository is provided but it is empty or wrong.\"\n",
    ")\n",
    "\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(list_code, \"no link\")\n",
    "print(\n",
    "    f\" - for {(list_code.count('no link') * 100 / nb_papers):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code.count('no link')}/{nb_papers}), no link/code was provided.\\n\"\n",
    ")\n",
    "\n",
    "# Create a binary list to represent the presence or absence of code links\n",
    "list_code_binary = [1 if x in (\"good link\", \"bad link\") else 0 for x in list_code]\n",
    "\n",
    "# Display statistics for the presence of code links\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(list_code_binary, 1)\n",
    "print(\n",
    "    f\" - for {(100 * list_code_binary.count(1) / len(list_code_binary)):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code_binary.count(1)}/{len(list_code_binary)}), an associated repository for the code was provided.\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "# Filter the code list to include only \"good link\" and \"bad link\" categories\n",
    "list_code_bis = [x for x in list_code if x in (\"good link\", \"bad link\")]\n",
    "\n",
    "# Display statistics for the \"bad link\" category among papers with provided links\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(list_code_bis, \"bad link\")\n",
    "print(\n",
    "    f\" - for {(100 * list_code_bis.count('bad link') / len(list_code_bis)):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers for which a link was provided ({list_code.count('bad link')}/{len(list_code_bis)}), the link to the repository is provided but it is empty or wrong.\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on the rating for the code availibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 86.67% (95% CI (bootstrap): [80.00%, 93.33%]) of the papers (78/90), at least one of the reviewers said that the code was available.\n",
      "\n",
      "For these 78 papers:\n",
      " - for 47.44% (95% CI (bootstrap): [35.90%, 57.72%]) of the papers (37.0/78), at least one reviewer stated that the code was available and the link was valid.\n",
      " - for 20.51% (95% CI (bootstrap): [11.54%, 29.49%]) of the papers (16.0/78), at least one reviewer stated that the code was available, even if the link led to an error message or an empty repository.\n",
      " - for 32.05% (95% CI (bootstrap): [23.08%, 42.31%]) of the papers (25.0/78), at least one reviewer stated that the code was available, even if no link/code was provided.\n",
      "\n",
      " - for 52.56% (95% CI (bootstrap): [40.36%, 64.10%]) of the papers (41/78), at least one reviewer stated that the code was available, even if the code was actually missing in the published version (no link, broken link, or empty repository)\n",
      "\n",
      "The tables below indicate, for each paper, whether at least one reviewer stated that the \n",
      "code was/will be available (1) or not (0), and whether the link was present and non-empty (good link), \n",
      "present but with an empty repository (empty link), or whether there was no link (no link).\n",
      "\n",
      "+----------------------------------+------------+-------------+-----------+---------+\n",
      "| code availableness (in number)   |   bad link |   good link |   no link |   total |\n",
      "|----------------------------------+------------+-------------+-----------+---------|\n",
      "| no info                          |          2 |           6 |         4 |      12 |\n",
      "| code promised                    |         16 |          37 |        25 |      78 |\n",
      "| total                            |         18 |          43 |        29 |      90 |\n",
      "+----------------------------------+------------+-------------+-----------+---------+\n",
      "+-----------------------------+------------+-------------+-----------+---------+\n",
      "| code availableness (in %)   |   bad link |   good link |   no link |   total |\n",
      "|-----------------------------+------------+-------------+-----------+---------|\n",
      "| no info                     |       2.22 |        6.67 |      4.44 |   13.33 |\n",
      "| code promised               |      17.78 |       41.11 |     27.78 |   86.67 |\n",
      "| total                       |      20    |       47.78 |     32.22 |  100    |\n",
      "+-----------------------------+------------+-------------+-----------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Define columns for code availability in different reviews\n",
    "list_code_1 = df_rating_1.loc[2:, 5].values.tolist()\n",
    "list_code_2 = df_rating_1.loc[2:, 14].values.tolist()\n",
    "list_code_3 = df_rating_1.loc[2:, 23].values.tolist()\n",
    "\n",
    "# Create a list to store the final code review categories\n",
    "list_code_review = []\n",
    "\n",
    "# Determine code review categories based on code availability in different reviews\n",
    "# (code promised: At least 1 reviewer said the code will be made available)\n",
    "for i in range(len(list_code_1)):\n",
    "    x = list_code_1[i]\n",
    "    if x == '0' and x == list_code_2[i] and x == list_code_3[i]:\n",
    "        list_code_review.append(\"no info\")\n",
    "    else:\n",
    "        list_code_review.append('code promised')\n",
    "\n",
    "# Calculate and display statistics for code availability based on reviews\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(list_code_review, \"code promised\")\n",
    "print(\n",
    "    f\"For {(list_code_review.count('code promised')*100/len(list_code_review)):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({list_code_review.count('code promised')}/{len(list_code_review)}), at least one of the reviewers said that the code was available.\\n\"\n",
    ")\n",
    "\n",
    "# Create a DataFrame to store code availability and review information\n",
    "df_code_reviews = pd.DataFrame(\n",
    "    np.zeros((3, 4)),\n",
    "    index=[\"no info\", \"code promised\", \"total\"],\n",
    "    columns=code_list + [\"total\"],\n",
    ")\n",
    "\n",
    "# Further categorize code reviews and update the DataFrame\n",
    "list_code_final = []\n",
    "\n",
    "# Iterate over each paper's code information and respective reviews\n",
    "for code, code_review in zip(list_code, list_code_review):\n",
    "    # Check if the code link is labeled as \"good link\" and the review indicates \"code promised\"\n",
    "    if code == \"good link\" and code_review == \"code promised\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"code promised\", \"good link\"] += 1\n",
    "        list_code_final.append(\"code promised good link\")\n",
    "    \n",
    "    # Check if the code link is labeled as \"good link\" but the review has \"no info\"\n",
    "    if code == \"good link\" and code_review == \"no info\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"no info\", \"good link\"] += 1\n",
    "        list_code_final.append(\"no info good link\")\n",
    "\n",
    "    # Check if the code link is labeled as \"bad link\" and the review indicates \"code promised\"\n",
    "    if code == \"bad link\" and code_review == \"code promised\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"code promised\", \"bad link\"] += 1\n",
    "        list_code_final.append(\"code promised bad link\")\n",
    "    \n",
    "    # Check if the code link is labeled as \"bad link\" but the review has \"no info\"\n",
    "    if code == \"bad link\" and code_review == \"no info\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"no info\", \"bad link\"] += 1\n",
    "        list_code_final.append(\"no info bad link\")\n",
    "\n",
    "    # Check if the code link is labeled as \"no link\" and the review indicates \"code promised\"\n",
    "    if code == \"no link\" and code_review == \"code promised\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"code promised\", \"no link\"] += 1\n",
    "        list_code_final.append(\"code promised no link\")\n",
    "    \n",
    "    # Check if the code link is labeled as \"no link\" but the review has \"no info\"\n",
    "    if code == \"no link\" and code_review == \"no info\":\n",
    "        # Update the DataFrame and append the categorization to the list\n",
    "        df_code_reviews.loc[\"no info\", \"no link\"] += 1\n",
    "        list_code_final.append(\"no info no link\")\n",
    "\n",
    "# Update totals in the DataFrame\n",
    "df_code_reviews.loc[\"code promised\", \"total\"] = (\n",
    "    df_code_reviews.loc[\"code promised\", \"good link\"] +\n",
    "    df_code_reviews.loc[\"code promised\", \"bad link\"] +\n",
    "    df_code_reviews.loc[\"code promised\", \"no link\"]\n",
    ")\n",
    "df_code_reviews.loc[\"no info\", \"total\"] = (\n",
    "    df_code_reviews.loc[\"no info\", \"good link\"] +\n",
    "    df_code_reviews.loc[\"no info\", \"bad link\"] +\n",
    "    df_code_reviews.loc[\"no info\", \"no link\"]\n",
    ")\n",
    "df_code_reviews.loc[\"total\", \"good link\"] = (\n",
    "    df_code_reviews.loc[\"code promised\", \"good link\"] +\n",
    "    df_code_reviews.loc[\"no info\", \"good link\"]\n",
    ")\n",
    "df_code_reviews.loc[\"total\", \"bad link\"] = (\n",
    "    df_code_reviews.loc[\"code promised\", \"bad link\"] +\n",
    "    df_code_reviews.loc[\"no info\", \"bad link\"]\n",
    ")\n",
    "df_code_reviews.loc[\"total\", \"no link\"] = (\n",
    "    df_code_reviews.loc[\"code promised\", \"no link\"] +\n",
    "    df_code_reviews.loc[\"no info\", \"no link\"]\n",
    ")\n",
    "df_code_reviews.loc[\"total\", \"total\"] = (\n",
    "    df_code_reviews.loc[\"code promised\", \"total\"] +\n",
    "    df_code_reviews.loc[\"no info\", \"total\"]\n",
    ")\n",
    "\n",
    "# Calculate statistics for good reviews and bad reviews\n",
    "# Filter out reviews categorized as \"code promised\"\n",
    "good_review_list = [x for x in list_code_final if x.startswith(\"code promised\")]\n",
    "nb_good_reviews = len(good_review_list)\n",
    "\n",
    "# Display the number of papers with at least one reviewer stating that the code is available\n",
    "print(f\"For these {nb_good_reviews} papers:\")\n",
    "\n",
    "# Calculate and display the percentage of papers with \"code promised\" for each sub-category\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(good_review_list, \"code promised good link\")\n",
    "print(\n",
    "    f\" - for {(df_code_reviews.loc['code promised', 'good link']*100 / nb_good_reviews):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['code promised', 'good link']}/{nb_good_reviews}), at least one reviewer stated that the code was available and the link was valid.\"\n",
    ")\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(good_review_list, \"code promised bad link\")\n",
    "print(\n",
    "    f\" - for {(df_code_reviews.loc['code promised', 'bad link']*100 / nb_good_reviews):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['code promised', 'bad link']}/{nb_good_reviews}), at least one reviewer stated that the code was available, even if the link led to an error message or an empty repository.\"\n",
    ")\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(good_review_list, \"code promised no link\")\n",
    "print(\n",
    "    f\" - for {(df_code_reviews.loc['code promised', 'no link']*100 / nb_good_reviews):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['code promised', 'no link']}/{nb_good_reviews}), at least one reviewer stated that the code was available, even if no link/code was provided.\\n\"\n",
    ")\n",
    "\n",
    "# Calculate statistics for papers with misleading information about code availability\n",
    "good_reviews_list_bis = [1 if x == \"code promised good link\" else 0 for x in good_review_list]\n",
    "\n",
    "# Display the percentage of papers where reviewers falsely claimed code availability\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(good_reviews_list_bis, 0)\n",
    "print(\n",
    "    f\" - for {(good_reviews_list_bis.count(0)*100 / nb_good_reviews):.2f}% (95% CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({good_reviews_list_bis.count(0)}/{nb_good_reviews}), at least one reviewer stated that the code was available, even if the code was actually missing in the published version (no link, broken link, or empty repository)\\n\"\n",
    ")\n",
    "\n",
    "# Calculate statistics for papers with misleading information about code availability\n",
    "# Filter out reviews categorized as \"no info\"\n",
    "bad_review_list = [x for x in list_code_final if x.startswith(\"no info\")]\n",
    "nb_bad_reviews = len(bad_review_list)\n",
    "\n",
    "# Commented out to avoid displaying an incomplete statement; consider uncommenting as needed\n",
    "ci_bootstrap_low, ci_bootstrap_high = compute_ci_bootstrap(bad_review_list, \"no info good link\")\n",
    "# print(f\" - for {(df_code_reviews.loc['no info', 'good link']*100 / nb_bad_reviews):.2f}% (95%CI (bootstrap): [{ci_bootstrap_low:.2f}%, {ci_bootstrap_high:.2f}%]) of the papers ({df_code_reviews.loc['no info', 'good link']}/{nb_bad_reviews}), the reviewers said that the code wasn't available even if it was.\")\n",
    "\n",
    "# Display information about the tables and the code reviews\n",
    "print(\n",
    "    \"The tables below indicate, for each paper, whether at least one reviewer stated that the \\n\"\n",
    "    \"code was/will be available (1) or not (0), and whether the link was present and non-empty (good link), \\n\"\n",
    "    \"present but with an empty repository (empty link), or whether there was no link (no link).\\n\"\n",
    ")\n",
    "# Rename the index for clarity\n",
    "df_code_reviews.index.rename(\"code availableness (in number)\", inplace=True)\n",
    "\n",
    "# Display the table showing the number of papers in each category\n",
    "print(tabulate(df_code_reviews, headers='keys', tablefmt='psql'))\n",
    "\n",
    "df_code_reviews.to_csv(output_directory / '7-code_number.csv', index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Create a DataFrame representing percentages and rename the index for clarity\n",
    "df_code_review_percent = df_code_reviews\n",
    "df_code_review_percent.index.rename(\"code availableness (in %)\", inplace=True)\n",
    "df_code_review_percent = df_code_review_percent * 100 / len(list_code)\n",
    "\n",
    "df_code_review_percent.to_csv(output_directory / '8-code_percent.csv', index=True, sep=\";\", encoding='utf-8')\n",
    "\n",
    "# Display the table showing the percentage of papers in each category\n",
    "print(tabulate(round(df_code_review_percent,2), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary 'data' to store relevant information\n",
    "data = {}\n",
    "\n",
    "# Store the number of papers in the dictionnary\n",
    "data[\"nb_papers\"] = len(df_rating_1) - 2  # Subtracting 2 to exclude header rows\n",
    "\n",
    "# Calculate the total number of reviews (assuming 3 reviews per paper)\n",
    "data[\"nb_reviews\"] = (len(df_rating_1) - 2) * 3\n",
    "\n",
    "# Store the current date and time using datetime module\n",
    "data[\"date\"] = str(datetime.date.today())  # Store the current date\n",
    "data[\"time\"] = str(datetime.datetime.utcnow())  # Store the current UTC time\n",
    "\n",
    "# Store the path of the CSV file used for ratings\n",
    "data[\"path_rating\"] = str(path_csv)\n",
    "\n",
    "# Convert the 'data' dictionary to a JSON-formatted string with indentation\n",
    "json_data = json.dumps(data, skipkeys=True, indent=4)\n",
    "\n",
    "with open(output_directory / \"data.json\", \"w\") as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote tex file ../miccai2023/stats_rating/../latex/paragraph_3.tex\n"
     ]
    }
   ],
   "source": [
    "# Generate Latex Paragraph \n",
    "latex_directory = Path(output_directory) / \"..\" / \"latex\"\n",
    "if not latex_directory.is_dir():\n",
    "    os.mkdir(latex_directory)\n",
    "\n",
    "\n",
    "tex_file_=latex_directory / 'paragraph_3.tex'\n",
    "with open(tex_file_, 'w') as f_:\n",
    "\n",
    "    df_cat_bis = df_category\n",
    "\n",
    "    max_df = pd.DataFrame(df_cat_bis.sort_values('percent')[-1:])\n",
    "    max_cat = max_df.index[0]\n",
    "\n",
    "    print(f\"The checklist category that was most often commented upon was '{max_cat}' (${max_df.loc[max_cat]['percent']:.0f}\\\\%$ of reviews $({max_df.loc[max_cat]['number']:.2f}/{nb_papers})$, $95\\\\% \\\\text{{CI}} [{max_df.loc[max_cat]['ci low']:.0f}\\\\%, {max_df.loc[max_cat]['ci high']:.0f}\\\\%]$).\", file=f_)\n",
    "    \n",
    "    min_df = df_cat_bis.sort_values('percent')[:1]\n",
    "    min_cat = min_df.index[0]\n",
    "\n",
    "    print(f\"The lowest frequency was found for the '{min_cat}' category (${min_df.loc[min_cat]['percent']:.0f}\\\\%$ of reviews $({min_df.loc[min_cat]['number']:.2f}/{nb_papers})$, $95\\\\% \\\\text{{CI}} [{min_df.loc[min_cat]['ci low']:.0f}\\\\%, {min_df.loc[min_cat]['ci high']:.0f}\\\\%]$).\", file=f_)\n",
    "    \n",
    "    print(f\"Around {df_category.loc['Error bars or statistical significance']['percent']:.0f}\\\\% of reviews commented upon Error bars and/or statistical significance.\", file=f_)\n",
    "    print(\"\", file=f_)\n",
    "\n",
    "    print(f\"${statement_latex[0]}\\\\%$ of reviews provided a statement ({statement_latex[1]}/{statement_latex[2]}, $95\\\\% \\\\text{{CI }}$ $[{statement_latex[3]:.0f}\\\\%, {statement_latex[4]:.0f}\\\\%]$) and \", file=f_)\n",
    "    print(f\"${comments_latex[0]}\\\\%$ came with a comments ({comments_latex[1]}/{comments_latex[2]}, $95\\\\% \\\\text{{CI }}$ $[{comments_latex[3]:.0f}\\\\%, {comments_latex[4]:.0f}\\\\%]$)\\\\footnote{{'Unusable' statements and comments are not taken into account.}}. \", file=f_)\n",
    "    print(f\"Of note, ${stat_com_latex[0]}\\\\%$ of reviewers which had made a positive statement regarding the reproducibility (indicating that they found that the reproducibility of the paper was overall satisfactory) provided no comments to substantiate their statement ({stat_com_latex[1]}/{stat_com_latex[2]}, $95\\\\% \\\\text{{CI }}$ $[{stat_com_latex[3]:.0f}\\\\%, {stat_com_latex[4]:.0f}\\\\%]$).\", file=f_)\n",
    "    print(\"\", file=f_)\n",
    "\n",
    "    print(f\"Importantly, there was no agreement between reviewers with respective Fleiss'$\\kappa$ values of ${df_kappas.loc['Statements']['kappa']}$ ($95\\\\% \\\\text{{CI }} [{df_kappas.loc['Statements']['ci low']:.0f}\\\\%, {df_kappas.loc['Statements']['ci high']:.0f}\\\\%]$) for statement \", file=f_)\n",
    "    print(f\"and ${df_kappas.loc['Meta-categories']['kappa']:.0f}$ ($95\\\\% \\\\text{{CI }} [{df_kappas.loc['Meta-categories']['ci low']:.0f}\\\\%, {df_kappas.loc['Meta-categories']['ci high']:.0f}\\\\%]$) for meta-category.\", file=f_)\n",
    "    print(\"\", file=f_)\n",
    "\n",
    "    print(f\"For {code_avail_list[0]:.0f}\\\\% of papers, at least one of the reviewers said that the code was or will be available ({code_avail_list[1]}/{code_avail_list[2]}, $95\\\\%\\\\text{{CI }} [{code_avail_list[3]:.0f}\\\\%, {code_avail_list[4]:.0f}\\\\%]$). \", file=f_)\n",
    "    print(f\"However, for {code_avail_false_list[0]:.0f}\\\\% of these,  the code was actually missing in the published version (no link, broken link or empty repository) ({code_avail_false_list[1]}/{code_avail_false_list[2]}, $95\\\\%\\\\text{{CI }} [{code_avail_false_list[3]:.0f}\\\\%, {code_avail_false_list[4]:.0f}\\\\%]$). \", file=f_)\n",
    "    print(\"\", file=f_)\n",
    "    \n",
    "    print(f\"Finally, {code_link_list[0]:.0f}\\\\% of published papers provided an associated repository for the code ({code_link_list[1]}/{code_link_list[2]}, $95\\\\%\\\\text{{CI }} [{code_link_list[3]:.0f}\\\\%, {code_link_list[4]:.0f}\\\\%]$). \", file=f_)\n",
    "    print(f\"However, for {code_link_binary_list[0]:.0f}\\\\% of these, the link was broken or the repository was empty ({code_link_binary_list[1]}/{code_link_binary_list[2]}, $95\\\\%\\\\text{{CI }} [{code_link_binary_list[3]:.0f}\\\\%, {code_link_binary_list[4]:.0f}\\\\%]$). \", file=f_)\n",
    "\n",
    "\n",
    "print(f\"Wrote tex file {tex_file_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
