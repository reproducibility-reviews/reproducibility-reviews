{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import random\n",
    "from pathlib import Path\n",
    "import os\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_cqk(y_true, y_pred, quad=False, num_resamples = 999):\n",
    "    \"\"\"\n",
    "    Boostrap function for cohen kappa score \n",
    "    \"\"\"\n",
    "    Y = np.array([y_true, y_pred]).T\n",
    "\n",
    "    weighted_kappas = []\n",
    "    for i in range(num_resamples):\n",
    "        Y_resample = np.array(random.choices(Y, k=len(Y)))\n",
    "        y_true_resample = Y_resample[:, 0]\n",
    "        y_pred_resample = Y_resample[:, 1]\n",
    "        if quad==False:\n",
    "            weighted_kappa = cohen_kappa_score(y_true_resample.astype(str), y_pred_resample.astype(str))\n",
    "        else: \n",
    "            weighted_kappa = cohen_kappa_score(y_true_resample.astype(str), y_pred_resample.astype(str), weights='quadratic')\n",
    "        weighted_kappas.append(weighted_kappa)\n",
    "\n",
    "    return np.mean(weighted_kappas), np.std(weighted_kappas), np.percentile(weighted_kappas, 2.25), np.percentile(weighted_kappas, 97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(list_1: list , list_2: list)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create confusion matrix \n",
    "    \"\"\"\n",
    "    \n",
    "    if not len(list_1)==len(list_2):\n",
    "        print(\"reviwer 1 and 2 may haven't rated the same list of subjects\")\n",
    "\n",
    "    else:\n",
    "        list_attributs = []\n",
    "        for i in list_1:\n",
    "            if i not in list_attributs:\n",
    "                list_attributs.append(i)\n",
    "        for i in list_2:\n",
    "            if i not in list_attributs:\n",
    "                list_attributs.append(i)\n",
    "\n",
    "\n",
    "        size = len(list_attributs)\n",
    "        matrix = pd.DataFrame(np.zeros((size + 1, size + 1)))\n",
    "        for k in range(size):\n",
    "            for l in range(size):\n",
    "                att_1 = list_attributs[k]\n",
    "                att_2 = list_attributs[l]\n",
    "                for i in range(len(list_1)):\n",
    "                    if (list_1[i]== att_1):\n",
    "                        if list_2[i] == att_2 :\n",
    "                                matrix.loc[k,l]+=1\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                matrix.loc[size, i] += matrix.loc[j, i]\n",
    "                matrix.loc[i, size] += matrix.loc[i, j]\n",
    "        for i in range(size):      \n",
    "            matrix.loc[size, size] += matrix.loc[i, size]\n",
    "        matrix = matrix / len(list_1)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_proportion(matrix: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculate the overall proportion of agreement expected by chance\n",
    "    \"\"\"\n",
    "    pe = 0\n",
    "    k = len(matrix)-1\n",
    "    for i in range(k):\n",
    "        pe += matrix.loc[i, k] * matrix.loc[k, i]\n",
    "    return pe\n",
    "\n",
    "def observed_proportion(matrix: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculate the overall proportion of observed agreement.\n",
    "    \"\"\"\n",
    "    po = 0\n",
    "    k = len(matrix) - 1\n",
    "    for i in range(k):\n",
    "        po += matrix.loc[i, i]\n",
    "    return po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sd_cohen(po, pe):\n",
    "    \"\"\"\n",
    "    Cohen standard deviation.\n",
    "    \"\"\"\n",
    "    sd_= sqrt((po*(1-po))/((1-pe)*(1-pe)))\n",
    "    return sd_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa(po, pe):\n",
    "    \"\"\"\n",
    "    Calculate the kappa cohen score.\n",
    "    \"\"\"\n",
    "    return (po-pe)/(1-pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stat(df_final, category, method, kappa_, low_, high_, se_):\n",
    "    df_final.loc[category, (\"kappa score\", method)]=kappa_\n",
    "    df_final.loc[category, (\"ci low\", method)]=low_\n",
    "    df_final.loc[category, (\"ci high\", method)]=high_\n",
    "    df_final.loc[category, (\"se\", method)]=se_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Enter the path to the tsv file with the rating from the first reviwer\n",
    "path_tsv = \"../human_rating/rating_90/rating_90_O.tsv\"\n",
    "\n",
    "df_rating_1 = pd.read_csv(path_tsv, sep = \"\\t\", index_col=False, header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the tsv file with the rating from the second reviwer\n",
    "path_tsv = \"../human_rating/rating_90/rating_90_E.tsv\"\n",
    "\n",
    "df_rating_2 = pd.read_csv(path_tsv, sep = \"\\t\", index_col=False, header= None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of categories you want to make statistics for\n",
    "list_categories = [\n",
    "        \"Models and algorithms\",\n",
    "        \"Datasets\",\n",
    "        \"Code\",\n",
    "        \"Experimental results\",\n",
    "        \"Error bars or statistical significance\",\n",
    "        \"Code is or will be available\",\n",
    "        \"Statement\",\n",
    "        \"Comments\",\n",
    "    ]\n",
    "list_methods = [\"bootstrap\", \"cohen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the DataFrame \n",
    "\n",
    "list_stats = [\"kappa score\", \"ci low\", \"ci high\", \"se\"]\n",
    "\n",
    "index_line = pd.Index(list_categories + [\"Meta-categories\", \"Agreement\", \"Repo provided\"])\n",
    "index_column = pd.MultiIndex.from_product( [list_stats, list_methods], names=[\"stat\", \"method\"])\n",
    "\n",
    "df_final = pd.DataFrame(index=index_line, columns=index_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'Models and algorithms' item (over 270 reviews):\n",
      "Cohen's kappa = 0.7544080604534007\n",
      "standard error (bootstrap) = 0.04572129537387089\n",
      "CI bootstrap = [0.6642971219193222, 0.8415432666133558]\n",
      "**************************************************\n",
      "For 'Datasets' item (over 270 reviews):\n",
      "Cohen's kappa = 0.9085872576177285\n",
      "standard error (bootstrap) = 0.026294218817813443\n",
      "CI bootstrap = [0.8542383379271602, 0.9572242534659395]\n",
      "**************************************************\n",
      "For 'Code' item (over 270 reviews):\n",
      "Cohen's kappa = 0.9107142857142856\n",
      "standard error (bootstrap) = 0.02452274286617275\n",
      "CI bootstrap = [0.865600669681564, 0.9558122545118058]\n",
      "**************************************************\n",
      "For 'Experimental results' item (over 270 reviews):\n",
      "Cohen's kappa = 0.8637248539909151\n",
      "standard error (bootstrap) = 0.03485545968200329\n",
      "CI bootstrap = [0.7927693548507789, 0.9287536234528341]\n",
      "**************************************************\n",
      "For 'Error bars or statistical significance' item (over 270 reviews):\n",
      "Cohen's kappa = 1.0\n",
      "standard error (bootstrap) = 0.03485545968200329\n",
      "CI bootstrap = [0.7927693548507789, 0.9287536234528341]\n",
      "**************************************************\n",
      "For 'Code is or will be available' item (over 270 reviews):\n",
      "Cohen's kappa = 0.8688536840532057\n",
      "standard error (bootstrap) = 0.034667163360676524\n",
      "CI bootstrap = [0.7914701834293301, 0.926873308885752]\n",
      "**************************************************\n",
      "For 'Statement' item (over 270 reviews):\n",
      "Cohen's kappa = 0.736981934112646\n",
      "standard error (bootstrap) = 0.03386679541819226\n",
      "CI bootstrap = [0.669080409811223, 0.8043872338492989]\n",
      "**************************************************\n",
      "For 'Comments' item (over 270 reviews):\n",
      "Cohen's kappa = 0.8155936590100292\n",
      "standard error (bootstrap) = 0.028045212100042648\n",
      "CI bootstrap = [0.7582488810527164, 0.8680459393564599]\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for category in range(len(list_categories)):\n",
    "    all_reviews_1 = []\n",
    "    all_reviews_2 = []\n",
    "    for i in range(3):\n",
    "        column_id = i*9 + 3 + category\n",
    "        \n",
    "        list_review_1 = df_rating_1.loc[2:, column_id].values.tolist()\n",
    "        list_review_2 = df_rating_2.loc[2:, column_id].values.tolist()\n",
    "\n",
    "        all_reviews_1 = all_reviews_1 + list_review_1\n",
    "        all_reviews_2 = all_reviews_2 + list_review_2\n",
    "\n",
    "    N = len(all_reviews_1)\n",
    "    \n",
    "    if list_categories[category] != \"Error bars or statistical significance\":\n",
    "        kappa_btp, se_btp, low_btp, high_btp = bootstrap_cqk(y_true=all_reviews_1, y_pred=all_reviews_2)\n",
    "        write_stat(df_final, list_categories[category], \"bootstrap\", kappa_btp, low_btp, high_btp, se_btp)\n",
    "        \n",
    "    confusion_matrix = create_confusion_matrix(list_1=all_reviews_1, list_2=all_reviews_2)\n",
    "    po_ = observed_proportion(confusion_matrix)\n",
    "    pe_ = expected_proportion(confusion_matrix)\n",
    "    kappa_ = kappa(po_, pe_)\n",
    "\n",
    "    kappa_sklearn = cohen_kappa_score(all_reviews_1, all_reviews_2)\n",
    "    df_final.loc[list_categories[category], (\"kappa score\", \"sklearn\")]=kappa_sklearn\n",
    "\n",
    "    data = [all_reviews_1, all_reviews_2]\n",
    "    data_T = np.array(data).T\n",
    "    data_fleiss_ = aggregate_raters(data_T)\n",
    "    kappa_fleiss_ = fleiss_kappa(data_fleiss_[0])\n",
    "    df_final.loc[list_categories[category], (\"kappa score\", \"fleiss\")]=kappa_fleiss_\n",
    "        \n",
    "    sd_cohen_ = sd_cohen(po_, pe_)\n",
    "    se_cohen = sd_cohen_ / sqrt(N)\n",
    "    write_stat(df_final, list_categories[category], \"cohen\", kappa_, -1.96 * se_cohen + kappa_, 1.96 * se_cohen + kappa_, se_cohen )\n",
    "\n",
    "\n",
    "    print(f\"For \\'{df_rating_1.loc[1, column_id]}\\' item (over {N} reviews):\")\n",
    " \n",
    "    print(f\"Cohen's kappa = {kappa_}\")\n",
    "    ######### For sanity check\n",
    "    # print(f\"kappa cohen sklearn = {kappa_sklearn}\")\n",
    "    # print(f\"kappa cohen bootstrap = {kappa_btp}\")\n",
    "    # print(f\"kappa fleiss statsmodels = {kappa_fleiss_}\")\n",
    "\n",
    "    print(f\"standard error (bootstrap) = {se_btp}\")\n",
    "    ######### For sanity check\n",
    "    # print(f\"standard error (cohen) = {sd_cohen_ / sqrt(N)}\")\n",
    "\n",
    "    print(f\"CI bootstrap = [{low_btp}, {high_btp}]\")\n",
    "    ######### For sanity check\n",
    "    low_parametric_cohen=-1.96 * se_cohen + kappa_\n",
    "    high_parametric_cohen=1.96 * se_cohen + kappa_\n",
    "    #print(f\"CI parametric from Cohen's SE = [{low_parametric_cohen}, {high_parametric_cohen}]\")\n",
    "    print(\"**************************************************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'Meta-category' item (over 270 reviews):\n",
      "Cohen's kappa = 0.8014027898179528\n",
      "standard error (bootstrap) = 0.03513093822996074\n",
      "CI bootstrap = [0.7293335962912879, 0.8690400826049199]\n"
     ]
    }
   ],
   "source": [
    "# Meta-categories\n",
    "\n",
    "list_meta_1 = []\n",
    "list_meta_2 = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    column_id = i + 29\n",
    "    \n",
    "    list_review_1 = df_rating_1.loc[2:, column_id].values.tolist()\n",
    "    list_review_2 = df_rating_2.loc[2:, column_id].values.tolist()\n",
    "\n",
    "    list_meta_1 = list_meta_1 + list_review_1\n",
    "    list_meta_2 = list_meta_2 + list_review_2\n",
    "\n",
    "\n",
    "test = list_meta_1.count(\"Unusable (meta)\")\n",
    "test2 = list_meta_2.count(\"Unusable (meta)\")\n",
    "\n",
    "N = len(list_meta_1)\n",
    "if list_categories[category] != \"Error bars or statistical significance\":\n",
    "    kappa_btp, se_btp, low_btp, high_btp = bootstrap_cqk(y_true=list_meta_1, y_pred=list_meta_2)\n",
    "    write_stat(df_final, \"Meta-categories\", \"bootstrap\", kappa_btp, low_btp, high_btp, se_btp)\n",
    "        \n",
    "confusion_matrix = create_confusion_matrix(list_1=list_meta_1, list_2=list_meta_2)\n",
    "po_ = observed_proportion(confusion_matrix)\n",
    "pe_ = expected_proportion(confusion_matrix)\n",
    "kappa_ = kappa(po_, pe_)\n",
    "\n",
    "kappa_sklearn = cohen_kappa_score(list_meta_1, list_meta_2)\n",
    "df_final.loc[\"Meta-categories\", (\"kappa score\", \"sklearn\")]=kappa_sklearn\n",
    "\n",
    "data = [list_meta_1, list_meta_2]\n",
    "data_T = np.array(data).T\n",
    "data_fleiss_ = aggregate_raters(data_T)\n",
    "kappa_fleiss_ = fleiss_kappa(data_fleiss_[0])\n",
    "df_final.loc[\"Meta-categories\", (\"kappa score\", \"fleiss\")]=kappa_fleiss_\n",
    "\n",
    "sd_cohen_ = sd_cohen(po_, pe_)\n",
    "se_cohen = sd_cohen_ / sqrt(N)\n",
    "write_stat(df_final, \"Meta-categories\", \"cohen\", kappa_, -1.96 * se_cohen + kappa_, 1.96 * se_cohen + kappa_, se_cohen )\n",
    "\n",
    "print(f\"For \\'Meta-category\\' item (over {N} reviews):\")\n",
    "# For sanity check\n",
    "# print(f\"We can count {test} reviews unusable for the first rater and {test2} reviews unusable for the second.\")\n",
    "\n",
    "print(f\"Cohen's kappa = {kappa_}\")\n",
    "######### For sanity check\n",
    "# print(f\"kappa cohen sklearn = {kappa_sklearn}\")\n",
    "# print(f\"kappa cohen bootstrap = {kappa_btp}\")\n",
    "# print(f\"kappa fleiss statsmodels = {kappa_fleiss_}\")\n",
    "\n",
    "print(f\"standard error (bootstrap) = {se_btp}\")\n",
    "######### For sanity check\n",
    "#print(f\"standard error (cohen) = {sd_cohen_ / sqrt(N)}\")\n",
    "\n",
    "print(f\"CI bootstrap = [{low_btp}, {high_btp}]\")\n",
    "######### For sanity check\n",
    "# low_parametric_cohen=-1.96 * se_cohen + kappa_\n",
    "# high_parametric_cohen=1.96 * se_cohen + kappa_\n",
    "# print(f\"CI parametric from Cohen's SE = [{low_parametric_cohen}, {high_parametric_cohen}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Repo provided and not empty review :\n",
      "Number of reviews = 90\n",
      "kappa cohen bootstrap = 1.0\n",
      "ci bootstrap = [1.0, 1.0]\n",
      "standard error (bootstrap) = 0.0\n"
     ]
    }
   ],
   "source": [
    "# add repo provided review\n",
    "\n",
    "list_repo_1 = df_rating_1.loc[2:, 40].values.tolist()\n",
    "list_repo_2 = df_rating_2.loc[2:, 40].values.tolist()\n",
    "N = len(list_repo_1)\n",
    "kappa_btp, se_btp, low_btp, high_btp = bootstrap_cqk(y_true=list_repo_1, y_pred=list_repo_2)\n",
    "write_stat(df_final, \"Repo provided\", \"bootstrap\", kappa_btp, low_btp, high_btp, se_btp)\n",
    "\n",
    "confusion_matrix = create_confusion_matrix(list_1=list_repo_1, list_2=list_repo_2)\n",
    "po_ = observed_proportion(confusion_matrix)\n",
    "pe_ = expected_proportion(confusion_matrix)\n",
    "kappa_ = kappa(po_, pe_)\n",
    "\n",
    "kappa_sklearn = cohen_kappa_score(list_repo_1, list_repo_2)\n",
    "df_final.loc[\"Repo provided\", (\"kappa score\", \"sklearn\")]=kappa_sklearn\n",
    "\n",
    "data = [list_repo_1, list_repo_2]\n",
    "data_T = np.array(data).T\n",
    "data_fleiss_ = aggregate_raters(data_T)\n",
    "kappa_fleiss_ = fleiss_kappa(data_fleiss_[0])\n",
    "df_final.loc[\"Repo provided\", (\"kappa score\", \"fleiss\")]=kappa_fleiss_\n",
    "\n",
    "sd_cohen_ = sd_cohen(po_, pe_)\n",
    "se_cohen = sd_cohen_ / sqrt(N)\n",
    "write_stat(df_final, \"Repo provided\", \"cohen\", kappa_, -1.96 * se_cohen + kappa_, 1.96 * se_cohen + kappa_, se_cohen)\n",
    "\n",
    "print(f\"For {df_rating_1.loc[1, 40]} review :\")\n",
    "print(f\"Number of reviews = {N}\")\n",
    "# print(f\"kappa fleiss statsmodels = {kappa_fleiss_}\")\n",
    "# print(f\"kappa cohen sklearn = {kappa_sklearn}\")\n",
    "# print(f\"kappa cohen = {kappa_}\")\n",
    "print(f\"kappa cohen bootstrap = {kappa_btp}\")\n",
    "print(f\"ci bootstrap = [{low_btp}, {high_btp}]\")\n",
    "print(f\"standard error (bootstrap) = {se_btp}\")\n",
    "# print(f\"standard error (cohen) = {sd_cohen_ / sqrt(N)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final df to csv file \n",
    "output_directory = Path(f\"../stats_inter_rater\")\n",
    "if not output_directory.is_dir():\n",
    "    os.mkdir(output_directory)\n",
    "path_inter_rater_stats = output_directory / 'inter_rater_stats.csv'\n",
    "df_final.to_csv(path_inter_rater_stats, index = True, sep=\";\", encoding='utf-8')\n",
    "df_final.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------------------------+------------------------+---------------------------+-----------------------+--------------------------------+----------------------------+-----------------------------+------------------------------+-----------------------+-------------------+\n",
      "|                                        |   ('ci high', 'bootstrap') |   ('ci high', 'cohen') |   ('ci low', 'bootstrap') |   ('ci low', 'cohen') |   ('kappa score', 'bootstrap') |   ('kappa score', 'cohen') |   ('kappa score', 'fleiss') |   ('kappa score', 'sklearn') |   ('se', 'bootstrap') |   ('se', 'cohen') |\n",
      "|----------------------------------------+----------------------------+------------------------+---------------------------+-----------------------+--------------------------------+----------------------------+-----------------------------+------------------------------+-----------------------+-------------------|\n",
      "| Models and algorithms                  |                   0.842829 |               0.84415  |                  0.66081  |              0.664666 |                       0.755479 |                   0.754408 |                    0.753788 |                     0.754408 |             0.0456111 |         0.0457868 |\n",
      "| Datasets                               |                   0.957743 |               0.961497 |                  0.852072 |              0.855678 |                       0.908762 |                   0.908587 |                    0.908586 |                     0.908587 |             0.0269979 |         0.0269947 |\n",
      "| Code                                   |                   0.961505 |               0.960097 |                  0.857154 |              0.861332 |                       0.910509 |                   0.910714 |                    0.910714 |                     0.910714 |             0.025458  |         0.0251953 |\n",
      "| Experimental results                   |                   0.928743 |               0.933235 |                  0.788092 |              0.794215 |                       0.864118 |                   0.863725 |                    0.863725 |                     0.863725 |             0.0356988 |         0.0354642 |\n",
      "| Error bars or statistical significance |                 nan        |               1        |                nan        |              1        |                     nan        |                   1        |                    1        |                     1        |           nan         |         0         |\n",
      "| Code is or will be available           |                   0.926506 |               0.938408 |                  0.786409 |              0.799299 |                       0.864947 |                   0.868854 |                    0.866796 |                     0.866798 |             0.0352654 |         0.035487  |\n",
      "| Statement                              |                   0.80406  |               0.808085 |                  0.660894 |              0.665879 |                       0.734367 |                   0.736982 |                    0.736822 |                     0.736982 |             0.0354606 |         0.036277  |\n",
      "| Comments                               |                   0.864736 |               0.869944 |                  0.75373  |              0.761243 |                       0.814645 |                   0.815594 |                    0.815579 |                     0.815594 |             0.0271263 |         0.0277298 |\n",
      "| Meta-categories                        |                   0.870961 |               0.871046 |                  0.728005 |              0.73176  |                       0.80057  |                   0.801403 |                    0.801385 |                     0.801403 |             0.0357517 |         0.035532  |\n",
      "| Agreement                              |                   0.794598 |               0.796079 |                  0.446021 |              0.469976 |                       0.631341 |                   0.633028 |                    0.632137 |                     0.633028 |             0.0847643 |         0.0831894 |\n",
      "| Repo provided                          |                   1        |               1        |                  1        |              1        |                       1        |                   1        |                    1        |                     1        |             0         |         0         |\n",
      "+----------------------------------------+----------------------------+------------------------+---------------------------+-----------------------+--------------------------------+----------------------------+-----------------------------+------------------------------+-----------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(df_final, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex output\n",
    "file1 = open('../latex/inter_raters_analysis.tex', 'w')\n",
    "file1.write(\"\\documentclass{article}\\n\\n\")\n",
    "file1.write(\"\\\\usepackage{float}\\n\\n\")\n",
    "file1.write(\"\\\\title{Inter raters analysis}\\n\\n\")\n",
    "file1.write(\"\\\\begin{document}\\n\\n\")\n",
    "file1.write(\"\\maketitle\\n\\n\")\n",
    "\n",
    "# categories\n",
    "file1.write(\"\\section{Kappa table} \\n\\n\")\n",
    "file1.write(\"\\\\begin{table}[H]\\n\\n\")\n",
    "file1.write(\"\\centering\\n\\n\")\n",
    "file1.write(tabulate(df_final, headers='keys', tablefmt='latex'))\n",
    "file1.write(\"\\caption{Different method to calculate the kappa scores with confidence intervals and standard errors}\\n\\n\")\n",
    "file1.write(\"\\end{table}\\n\\n\")\n",
    "file1.write(\"\\n\\n\")\n",
    "\n",
    "file1.write(\"\\end{document}\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproducibility-reviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
