{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "import urllib.request\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_review_text = {\n",
    "    \"contribution\" : \"Please describe the contribution of the paper\",\n",
    "    \"strenghts\" : \"Please list the main strengths of the paper\",\n",
    "    \"weakness\" : \"Please list the main weaknesses of the paper\",\n",
    "    \"clarity\" : \"Please rate the clarity and organization of this paper\",\n",
    "    \"reproducibility\" : \"Please comment on the reproducibility of the paper\",\n",
    "    \"detailed\" : \"Please provide detailed and constructive comments for the authors\",\n",
    "    \"rate\" : \"Rate the paper on a scale of 1-8, 8 being the strongest\",\n",
    "    \"justifictation\" : \"Please justify your recommendation.\",\n",
    "    \"number of paper\": \"Number of papers in your stack\",\n",
    "    \"ranking\" : \"What is the ranking of this paper in your review stack?\",\n",
    "    \"confidence\" : \"Reviewer confidence\",\n",
    "    \"rate rebuttal\" : \"[Post rebuttal] After reading the authorâ€™s rebuttal, state your overall opinion of the paper if it has been changed\",\n",
    "    \"justification rebuttal\" : \"[Post rebuttal] Please justify your decision\",\n",
    "}\n",
    "\n",
    "list_categories_str = [ \"contribution\", \"strenghts\", \"weakness\", \"reproducibility\", \"detailed\", \"justifictation\" ]\n",
    "list_categories_scores = [\"clarity\", \"rate\", \"confidence\", \"rate rebuttal\"]\n",
    "\n",
    "columns_reviews = [\"id\", \"category\", \"title\" ,\"review 1\" ,\"review 2\" , \"review 3\", ]\n",
    "columns_statistics = [\"id\", \"category\", \"title\" , \"words1\", \"words2\", \"words3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accepted_paper_list(year: str = \"2023\"):\n",
    "    \"\"\"\n",
    "    Get the list of all html files from the chosen year\n",
    "    \"\"\"\n",
    "\n",
    "    miccai_website_path = \"https://conferences.miccai.org\"\n",
    "    path_online_list = miccai_website_path + f\"/{year}/papers/\"\n",
    "\n",
    "    reponse = urllib.request.urlopen(path_online_list)\n",
    "    contenu_web = reponse.read().decode('UTF-8')\n",
    "    soup = BeautifulSoup(contenu_web, \"html.parser\")\n",
    "\n",
    "    all = soup.find_all('a')\n",
    "    paper_list = [(miccai_website_path + link.get('href')) for link in all if link.get('href').endswith('html')]\n",
    "\n",
    "    return paper_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews(paper, df_reviews, df_stats, df_scores, year=\"2023\",  list_categories= \"reproducibility\"):\n",
    "    \"\"\"\n",
    "    Extract the 3 first reviews from a given paper webpage\n",
    "    \"\"\"\n",
    "    \n",
    "    # open html webpage and extract with BeautifulSoup\n",
    "    reponse = urllib.request.urlopen(paper)\n",
    "    contenu_web = reponse.read().decode('UTF-8')\n",
    "    soup = BeautifulSoup(contenu_web, \"html.parser\")\n",
    "\n",
    "    if year == \"2023\" :\n",
    "        paper_title = soup.find(\"title\").get_text().rstrip(\"MICCAI 2023 - Accepted Papers, Reviews, Author Feedback\").rstrip(' |')\n",
    "    elif year == \"2022\" :\n",
    "        paper_title = soup.find(\"title\").get_text().rstrip(\"MICCAI 2022 - Accepted Papers and Reviews\").rstrip(' |')\n",
    "    paper_id = Path(paper).name[:13]\n",
    "\n",
    "    try : \n",
    "        code_link = soup.find(lambda tag: tag.name == \"a\" and \"https://git\" in tag.text)\n",
    "        code_link = code_link.get_text()\n",
    "        code_link = code_link.replace(\"\\n\",\" \")\n",
    "    except:\n",
    "        code_link = \"N/A\"\n",
    "        pass\n",
    "    \n",
    "    df_reviews.loc[(paper_id, unidecode(paper_title)), (\"code link\", \"code link\")]=code_link\n",
    "    \n",
    "    for category in list_categories: \n",
    "        text = list_review_text[category]\n",
    "        repro_reviews_paragraph = soup.find_all(lambda tag: tag.name == \"li\" and text in tag.text)\n",
    "        repro_exact_text = soup.find(lambda tag: tag.name == \"strong\" and text in tag.text).get_text()\n",
    "        \n",
    "        i=0\n",
    "        for review in repro_reviews_paragraph[:3]:\n",
    "            i +=1\n",
    "            tmp_review = unidecode(review.get_text().strip(repro_exact_text))\n",
    "            tmp_review = tmp_review.strip(\"\\n\")\n",
    "            tmp_review = tmp_review.replace(\"\\n          \\n\",\" \")\n",
    "            tmp_review = tmp_review.replace(\"\\t\", \" \")\n",
    "            tmp_review = tmp_review.replace(\"\\n\\n\\n\\n\",\" \")\n",
    "            tmp_review = tmp_review.replace(\"\\n\\n\\n\",\" \")\n",
    "            tmp_review = tmp_review.replace(\"\\n\\n\",\" \")\n",
    "            tmp_review = tmp_review.replace(\"\\n\",\" \")\n",
    "            tmp_review = tmp_review.replace(\"\\t\", \" \")\n",
    "\n",
    "            if category in list_categories_str:\n",
    "                df_reviews.loc[(paper_id, unidecode(paper_title)), (category, f\"review {i}\")]=tmp_review\n",
    "                df_stats.loc[(paper_id, unidecode(paper_title)), (category, f\"review {i}\")]=len(str(tmp_review).split())\n",
    "            elif category in list_categories_scores:\n",
    "                df_scores.loc[(paper_id, unidecode(paper_title)), (category, f\"review {i}\")]=tmp_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_paragraph(paper_list, year= \"2023\"):\n",
    "    \"\"\"\n",
    "    Extract the 3 first reviews of all paper from the given list.\n",
    "    \n",
    "    Return 3 DatFrame:\n",
    "        - df_reviews: DataFrame containing the 3 first reviews of all papers\n",
    "        - df_stats: DataFrame containing the number of words for each review of df_reviews\n",
    "        - df_scores: DataFrame containing the scores given by the 3 first reviewers of all papers.\n",
    "    \"\"\"\n",
    "    iterables_str = [list_categories_str, [\"review 1\", \"review 2\", \"review 3\"]]\n",
    "    iterables_score = [list_categories_scores, [\"review 1\", \"review 2\", \"review 3\"]]\n",
    "\n",
    "    index_line_str = pd.MultiIndex.from_product(iterables_str, names=[\"category\", \"review\"])\n",
    "    index_line_score = pd.MultiIndex.from_product(iterables_score, names=[\"category\", \"review\"])\n",
    "    index_column = pd.MultiIndex.from_product( [[], []], names=[\"id\", \"title\"])\n",
    "\n",
    "    df_reviews = pd.DataFrame(index = index_column, columns=index_line_str)\n",
    "    df_stats = pd.DataFrame(index = index_column, columns=index_line_str)\n",
    "    df_scores = pd.DataFrame(index = index_column, columns=index_line_score)\n",
    "\n",
    "    for paper in paper_list:\n",
    "        list_categories = list_categories_str + list_categories_scores\n",
    "        extract_reviews(paper, df_reviews, df_stats, df_scores, year, list_categories)\n",
    "\n",
    "    return df_reviews, df_stats, df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repro_copy_paste(df_all_reviews, output_directory= \"../results\", threshold:int  = 10 ):\n",
    "    \"\"\"\n",
    "    Find reviewers that have copy/paste the reproducibility review in another category.\n",
    "    \n",
    "    \"\"\"\n",
    "    from copy import copy\n",
    "    df_all_reviews_wo_copy_paste = copy(df_all_reviews)\n",
    "    df_bad_reviews = pd.DataFrame(columns=columns_reviews)\n",
    "    df_bad_reviews.set_index([\"id\", \"category\"], inplace= True)\n",
    "    \n",
    "    for id, id_df in df_all_reviews.groupby(level=0):\n",
    "        for _, title in id_df.index.values:\n",
    "            for category in list_categories_str:\n",
    "                if category != \"reproducibility\" :\n",
    "                    for i in range(1,3):\n",
    "                        repro = id_df.loc[(id,title), (\"reproducibility\", f\"review {i}\")]\n",
    "                        cate = id_df.loc[(id, title), (category, f\"review {i}\")]\n",
    "                        if len(str(repro)) > threshold : \n",
    "                            if str(repro) in str(cate):\n",
    "                                df_bad_reviews.loc[(id, title), (category, f\"review {i}\")] = id_df.loc[(id, title), (category, f\"review {i}\")]\n",
    "                                try :\n",
    "                                    df_all_reviews_wo_copy_paste.drop((id, title), inplace=True)\n",
    "                                except:\n",
    "                                    pass\n",
    "                                \n",
    "    df_all_reviews_wo_copy_paste.to_csv(os.path.join(output_directory ,f'reviews_wo_copy_paste_{threshold}.csv'), index = True, sep=\"\\t\", encoding='utf-8')\n",
    "    df_bad_reviews.to_csv(os.path.join(output_directory ,f'reviews_copy_paste_{threshold}.csv'), index = True, sep=\"\\t\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_checklist(df_all_reviews, output_directory= \"../results\", category = \"reproducibility\"):\n",
    "    \"\"\"\n",
    "    Find reviewers that have mentionned the word 'cheklist' in the reproducibility review.\n",
    "\n",
    "    \"\"\"\n",
    "    df_checklist  = pd.DataFrame(columns=columns_reviews)\n",
    "    df_checklist.set_index([\"id\", \"category\"], inplace= True)\n",
    "    for id, id_df in df_all_reviews.groupby(level=0):\n",
    "        for _, title in id_df.index.values:\n",
    "            for i in range(1,4):\n",
    "                review = str(df_all_reviews.loc[(id, title), (category, f\"review {i}\")])\n",
    "\n",
    "                if (\"check-list\" in review) or (\"checklist\" in review) or (\"check list\" in review):\n",
    "                    df_checklist.loc[(id, title), (category, f\"review {i}\")] = df_all_reviews.loc[(id, title), (category, f\"review {i}\")]\n",
    "\n",
    "    df_checklist.to_csv(os.path.join(output_directory ,f'{category}_checklist_reviews.csv'), index = True, sep=\"\\t\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rating_excel(df_all_reviews, output_directory=\"../results\"):\n",
    "    \"\"\"\n",
    "    Save the excel file with the reproducibility reviews to create the rating file\n",
    "    \"\"\"\n",
    "    df_repro_excel = df_all_reviews.loc[:, (\"reproducibility\")]\n",
    "    df_repro_excel.to_excel(os.path.join('../rating' ,f'reviews_reproducibility_{year_}.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_ = \"2023\"\n",
    "paper_list = get_accepted_paper_list(year=year_)\n",
    "output_directory = Path(f\"../miccai{year_}\")\n",
    "\n",
    "if not output_directory.is_dir():\n",
    "    os.mkdir(output_directory)\n",
    "path_all_reviews = output_directory / 'reviews.csv'\n",
    "path_all_stats = output_directory / 'count_words.csv'\n",
    "path_all_scores = output_directory / 'scores.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extraction takes about 7 min  \n",
    "if (not path_all_reviews.is_file()) or (not path_all_stats.is_file()):\n",
    "    print(f\"Extract reviews and count word for year {year_}\")\n",
    "    df_all_reviews, df_all_stats, df_all_scores = extract_paragraph(paper_list, year_)\n",
    "    df_all_scores.to_csv(path_all_scores, index = True, sep=\"\\t\", encoding='utf-8')\n",
    "    df_all_reviews.to_csv(path_all_reviews, index = True, sep=\"\\t\", encoding='utf-8')\n",
    "    df_all_stats.to_csv(path_all_stats, index = True, sep=\"\\t\", encoding='utf-8')\n",
    "\n",
    "else:\n",
    "    print(f\"Import tsv from {output_directory}\")\n",
    "    df_all_reviews = pd.read_csv(path_all_reviews, sep= \"\\t\",  header=[0, 1], index_col=[0,1], skip_blank_lines=True)\n",
    "    df_all_stats = pd.read_csv(path_all_stats, sep= \"\\t\",  header=[0, 1], index_col=[0,1], skip_blank_lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_repro_copy_paste(df_all_reviews=df_all_reviews, output_directory=output_directory)\n",
    "\n",
    "count_checklist(df_all_reviews=df_all_reviews, output_directory=output_directory, category=\"reproducibility\")\n",
    "\n",
    "create_rating_excel(df_all_reviews= df_all_reviews, output_directory= output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproducibility-reviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
