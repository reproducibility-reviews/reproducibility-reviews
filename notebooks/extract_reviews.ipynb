{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #Beautiful Soup is a library that makes it easy to scrape information from web pages\n",
    "import os\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "import urllib.request #Functions for opening URLs\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_review_text = {\n",
    "    \"contribution\" : \"Please describe the contribution of the paper\",\n",
    "    \"strengths\" : \"Please list the main strengths of the paper\",\n",
    "    \"weakness\" : \"Please list the main weaknesses of the paper\",\n",
    "    \"clarity\" : \"Please rate the clarity and organization of this paper\",\n",
    "    \"reproducibility\" : \"Please comment on the reproducibility of the paper\",\n",
    "    \"detailed\" : \"Please provide detailed and constructive comments for the authors\",\n",
    "    \"rate\" : \"Rate the paper on a scale of 1-8, 8 being the strongest\",\n",
    "    \"justification\" : \"Please justify your recommendation.\",\n",
    "    \"number of paper\": \"Number of papers in your stack\",\n",
    "    \"ranking\" : \"What is the ranking of this paper in your review stack?\",\n",
    "    \"confidence\" : \"Reviewer confidence\",\n",
    "    \"rate rebuttal\" : \"[Post rebuttal] After reading the authorâ€™s rebuttal, state your overall opinion of the paper if it has been changed\",\n",
    "    \"justification rebuttal\" : \"[Post rebuttal] Please justify your decision\",\n",
    "}\n",
    "\n",
    "list_categories_str = [ \"contribution\", \"strengths\", \"weakness\", \"reproducibility\", \"detailed\", \"justification\" ]\n",
    "list_categories_scores = [\"clarity\", \"rate\", \"confidence\", \"rate rebuttal\"]\n",
    "\n",
    "columns_reviews = [\"id\", \"category\", \"title\" ,\"review 1\" ,\"review 2\" , \"review 3\", ]\n",
    "columns_statistics = [\"id\", \"category\", \"title\" , \"words1\", \"words2\", \"words3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accepted_paper_list(year: str = \"2023\"):\n",
    "    \"\"\"\n",
    "    Get the list of all html files from the chosen year\n",
    "    \"\"\"\n",
    "\n",
    "    miccai_website_path = \"https://conferences.miccai.org\"\n",
    "    path_online_list = miccai_website_path + f\"/{year}/papers/\"\n",
    "\n",
    "    reponse = urllib.request.urlopen(path_online_list)\n",
    "    contenu_web = reponse.read().decode('UTF-8')\n",
    "    soup = BeautifulSoup(contenu_web, \"html.parser\")\n",
    "\n",
    "    all = soup.find_all('a')\n",
    "    paper_list = [(miccai_website_path + link.get('href')) for link in all if link.get('href').endswith('html')]\n",
    "\n",
    "    return paper_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews(paper, df_reviews, df_stats, df_scores, year=\"2023\",  list_categories= \"reproducibility\"):\n",
    "    \"\"\"\n",
    "    Extract the 3 first reviews from a given paper webpage\n",
    "    \"\"\"\n",
    "    \n",
    "    # open html webpage and extract with BeautifulSoup\n",
    "    reponse = urllib.request.urlopen(paper)\n",
    "    contenu_web = reponse.read().decode('UTF-8')\n",
    "    soup = BeautifulSoup(contenu_web, \"html.parser\")\n",
    "\n",
    "    if year == \"2023\" :\n",
    "        paper_title = soup.find(\"title\").get_text().rstrip(\"MICCAI 2023 - Accepted Papers, Reviews, Author Feedback\").rstrip(' |')\n",
    "    elif year == \"2022\" :\n",
    "        paper_title = soup.find(\"title\").get_text().rstrip(\"MICCAI 2022 - Accepted Papers and Reviews\").rstrip(' |')\n",
    "    paper_id = Path(paper).name[:13]\n",
    "\n",
    "    try : \n",
    "        code_link = soup.find(lambda tag: tag.name == \"a\" and \"https://git\" in tag.text)\n",
    "        code_link = code_link.get_text()\n",
    "        code_link = code_link.replace(\"\\n\",\" \")\n",
    "    except:\n",
    "        code_link = \"N/A\"\n",
    "        pass\n",
    "    \n",
    "    df_reviews.loc[(paper_id, unidecode(paper_title)), (\"code link\", \"code link\")]=code_link\n",
    "    \n",
    "    for category in list_categories: \n",
    "        text = list_review_text[category]\n",
    "        repro_reviews_paragraph = soup.find_all(lambda tag: tag.name == \"li\" and text in tag.text)\n",
    "        repro_exact_text = soup.find(lambda tag: tag.name == \"strong\" and text in tag.text).get_text()\n",
    "        \n",
    "        i=0\n",
    "        for review in repro_reviews_paragraph[:3]:\n",
    "            i +=1\n",
    "            tmp_review = unidecode(review.get_text().strip(repro_exact_text))\n",
    "            tmp_review = tmp_review.strip(\"\\n\")\n",
    "            tmp_review = tmp_review.replace(\"\\n          \\n\",\" \")\n",
    "            tmp_review = tmp_review.replace(\"\\t\", \" \")\n",
    "            tmp_review = tmp_review.replace(\"\\n\\n\\n\\n\",\" \")\n",
    "            tmp_review = tmp_review.replace(\"\\n\\n\\n\",\" \")\n",
    "            tmp_review = tmp_review.replace(\"\\n\\n\",\" \")\n",
    "            tmp_review = tmp_review.replace(\"\\n\",\" \")\n",
    "            tmp_review = tmp_review.replace(\"\\t\", \" \")\n",
    "\n",
    "            if category in list_categories_str:\n",
    "                df_reviews.loc[(paper_id, unidecode(paper_title)), (category, f\"review {i}\")]=tmp_review\n",
    "                df_stats.loc[(paper_id, unidecode(paper_title)), (category, f\"review {i}\")]=len(str(tmp_review).split())\n",
    "            elif category in list_categories_scores:\n",
    "                df_scores.loc[(paper_id, unidecode(paper_title)), (category, f\"review {i}\")]=tmp_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_paragraph(paper_list, year= \"2023\"):\n",
    "    \"\"\"\n",
    "    Extract the 3 first reviews of all paper from the given list.\n",
    "    \n",
    "    Return 3 DatFrame:\n",
    "        - df_reviews: DataFrame containing the 3 first reviews of all papers\n",
    "        - df_stats: DataFrame containing the number of words for each review of df_reviews\n",
    "        - df_scores: DataFrame containing the scores given by the 3 first reviewers of all papers.\n",
    "    \"\"\"\n",
    "    iterables_str = [list_categories_str, [\"review 1\", \"review 2\", \"review 3\"]]\n",
    "    iterables_score = [list_categories_scores, [\"review 1\", \"review 2\", \"review 3\"]]\n",
    "\n",
    "    index_line_str = pd.MultiIndex.from_product(iterables_str, names=[\"category\", \"review\"])\n",
    "    index_line_score = pd.MultiIndex.from_product(iterables_score, names=[\"category\", \"review\"])\n",
    "    index_column = pd.MultiIndex.from_product( [[], []], names=[\"id\", \"title\"])\n",
    "\n",
    "    df_reviews = pd.DataFrame(index = index_column, columns=index_line_str)\n",
    "    df_stats = pd.DataFrame(index = index_column, columns=index_line_str)\n",
    "    df_scores = pd.DataFrame(index = index_column, columns=index_line_score)\n",
    "\n",
    "    for i, paper in enumerate(paper_list):\n",
    "        print(f\"Processing paper {i + 1}/{len(paper_list)}\", end='\\r', flush=True)\n",
    "        list_categories = list_categories_str + list_categories_scores\n",
    "        extract_reviews(paper, df_reviews, df_stats, df_scores, year, list_categories)\n",
    "\n",
    "    return df_reviews, df_stats, df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repro_copy_paste(df_all_reviews, output_directory= \"../results\", threshold:int  = 10 ):\n",
    "    \"\"\"\n",
    "    Find reviewers that have copy/paste the reproducibility review in another category.\n",
    "    \n",
    "    \"\"\"\n",
    "    from copy import copy\n",
    "    df_all_reviews_wo_copy_paste = copy(df_all_reviews)\n",
    "    df_bad_reviews = pd.DataFrame(columns=columns_reviews)\n",
    "    df_bad_reviews.set_index([\"id\", \"category\"], inplace= True)\n",
    "    \n",
    "    for id, id_df in df_all_reviews.groupby(level=0):\n",
    "        for _, title in id_df.index.values:\n",
    "            for category in list_categories_str:\n",
    "                if category != \"reproducibility\" :\n",
    "                    for i in range(1,3):\n",
    "                        repro = id_df.loc[(id,title), (\"reproducibility\", f\"review {i}\")]\n",
    "                        cate = id_df.loc[(id, title), (category, f\"review {i}\")]\n",
    "                        if len(str(repro)) > threshold : \n",
    "                            if str(repro) in str(cate):\n",
    "                                df_bad_reviews.loc[(id, title), (category, f\"review {i}\")] = id_df.loc[(id, title), (category, f\"review {i}\")]\n",
    "                                try :\n",
    "                                    df_all_reviews_wo_copy_paste.drop((id, title), inplace=True)\n",
    "                                except:\n",
    "                                    pass\n",
    "                                \n",
    "    df_all_reviews_wo_copy_paste.to_csv(os.path.join(output_directory ,f'reviews_wo_copy_paste_{threshold}.csv'), index = True, sep=\"\\t\", encoding='utf-8')\n",
    "    df_bad_reviews.to_csv(os.path.join(output_directory ,f'reviews_copy_paste_{threshold}.csv'), index = True, sep=\"\\t\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_checklist(df_all_reviews, output_directory= \"../results\", category = \"reproducibility\"):\n",
    "    \"\"\"\n",
    "    Find reviewers that have mentionned the word 'cheklist' in the reproducibility review.\n",
    "\n",
    "    \"\"\"\n",
    "    df_checklist  = pd.DataFrame(columns=columns_reviews)\n",
    "    df_checklist.set_index([\"id\", \"category\"], inplace= True)\n",
    "    for id, id_df in df_all_reviews.groupby(level=0):\n",
    "        for _, title in id_df.index.values:\n",
    "            for i in range(1,4):\n",
    "                review = str(df_all_reviews.loc[(id, title), (category, f\"review {i}\")])\n",
    "\n",
    "                if (\"check-list\" in review) or (\"checklist\" in review) or (\"check list\" in review):\n",
    "                    df_checklist.loc[(id, title), (category, f\"review {i}\")] = df_all_reviews.loc[(id, title), (category, f\"review {i}\")]\n",
    "\n",
    "    df_checklist.to_csv(os.path.join(output_directory ,f'{category}_checklist_reviews.csv'), index = True, sep=\"\\t\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rating_excel(df_all_reviews, output_directory=\"../results\"):\n",
    "    \"\"\"\n",
    "    Save the excel file with the reproducibility reviews to create the rating file\n",
    "    \"\"\"\n",
    "    df_repro_excel = df_all_reviews.loc[:, (\"reproducibility\")]\n",
    "    df_repro_excel.to_excel(os.path.join('../rating' ,f'reviews_reproducibility_{year_}.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract reviews and count word for year 2023\n",
      "Processing paper 730/730\r"
     ]
    }
   ],
   "source": [
    "# Note extraction takes 5-10 minutes\n",
    "\n",
    "# Default year is 2023\n",
    "# To change to another year, please modify the variable below\n",
    "year_ = \"2023\"\n",
    "\n",
    "# Get the list of HTML pages for the different papers\n",
    "paper_list = get_accepted_paper_list(year=year_)\n",
    "\n",
    "# Set output directories and files for the extraction\n",
    "output_directory = Path(f\"../miccai{year_}\")\n",
    "if not output_directory.is_dir():\n",
    "    os.mkdir(output_directory)\n",
    "path_all_reviews = output_directory / 'reviews.csv'\n",
    "path_all_stats = output_directory / 'count_words.csv'\n",
    "path_all_scores = output_directory / 'scores.csv'\n",
    "\n",
    "# Skip the extraction if the files already exist\n",
    "# If you want to rerun the extraction, remove the directory \"miccaiYYYY\" where YYYY is the year  \n",
    "if (not path_all_reviews.is_file()) or (not path_all_stats.is_file()) or (not path_all_scores.is_file()):\n",
    "    print(f\"Extract reviews and count word for year {year_}\")\n",
    "    df_all_reviews, df_all_stats, df_all_scores = extract_paragraph(paper_list, year_)\n",
    "    df_all_scores.to_csv(path_all_scores, index = True, sep=\"\\t\", encoding='utf-8')\n",
    "    df_all_reviews.to_csv(path_all_reviews, index = True, sep=\"\\t\", encoding='utf-8')\n",
    "    df_all_stats.to_csv(path_all_stats, index = True, sep=\"\\t\", encoding='utf-8')\n",
    "\n",
    "else:\n",
    "    print(f\"Files already exist\")\n",
    "    print(f\"Skipping extraction and importing existing csv from {output_directory}\")\n",
    "    df_all_reviews = pd.read_csv(path_all_reviews, sep= \"\\t\",  header=[0, 1], index_col=[0,1], skip_blank_lines=True)\n",
    "    df_all_stats = pd.read_csv(path_all_stats, sep= \"\\t\",  header=[0, 1], index_col=[0,1], skip_blank_lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify reproducibility reviews which contain copy/paste from other parts (need to have more than 10 consecutive words in common)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rf/9f5s04x100n1rl5c_b92rsh8000kc6/T/ipykernel_16499/1210693690.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'The code is not provided. The method is built upon the training segmentation label.' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_bad_reviews.loc[(id, title), (category, f\"review {i}\")] = id_df.loc[(id, title), (category, f\"review {i}\")]\n",
      "/var/folders/rf/9f5s04x100n1rl5c_b92rsh8000kc6/T/ipykernel_16499/1210693690.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Insufficient Dataset Description: The authors have not provided an adequate description of the dataset utilized in the study, which may hinder the reader's understanding of the context and the applicability of the proposed method. Furthermore, the lack of information regarding the preprocessing steps implemented in the research could adversely affect the reproducibility of the method, thereby limiting its potential adoption by other researchers. Disorganized Introduction Section: The Introduction section of the paper appears to be lacking in organization and clarity, making it difficult for the reader to grasp the importance and motivation behind the proposed method. A well-structured Introduction that clearly outlines the research problem, its significance, and the authors' approach to addressing it is crucial for setting the context and engaging the readers. Inadequate Description of Previous Methods: While the paper compares the proposed method with earlier approaches in the field, the authors have not provided sufficient information about these previous methods. A brief but informative overview of the earlier approaches would have been valuable in helping the reader understand the limitations of existing methods and the reasons behind the development of the proposed method. This additional context would further emphasize the novelty and potential benefits of the authors' work. Addressing these weaknesses in the paper would greatly enhance its overall quality and increase its potential to make a meaningful contribution to the existing body of literature in the field' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_bad_reviews.loc[(id, title), (category, f\"review {i}\")] = id_df.loc[(id, title), (category, f\"review {i}\")]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count the number of reviews that mention the checklist\n",
      "Create excel files for human rating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rf/9f5s04x100n1rl5c_b92rsh8000kc6/T/ipykernel_16499/4058375330.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Reproducibility should be possible, as training and evaluation code is provided (based on the checklist).' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_checklist.loc[(id, title), (category, f\"review {i}\")] = df_all_reviews.loc[(id, title), (category, f\"review {i}\")]\n"
     ]
    }
   ],
   "source": [
    "print(\"Identify reproducibility reviews which contain copy/paste from other parts (need to have more than 10 consecutive words in common)\")\n",
    "get_repro_copy_paste(df_all_reviews=df_all_reviews, output_directory=output_directory)\n",
    "\n",
    "print(\"Count the number of reviews that mention the checklist\")\n",
    "count_checklist(df_all_reviews=df_all_reviews, output_directory=output_directory, category=\"reproducibility\")\n",
    "\n",
    "print(\"Create excel files for human rating\")\n",
    "create_rating_excel(df_all_reviews= df_all_reviews, output_directory= output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproducibility-reviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
