id	title	review1	review2	review3
001	3D CVT-GAN: A 3D Convolutional Vision Transformer-GAN for PET Reconstruction	"This paper extends the 2D CVT to 3D CVT, which is useful and helpful for 3D data.
This work builds a 3D CVT-GAN for reconstructing SPET images from LPET images, and the experimental results are satisfactory."	"The method is clear and makes sense.
The results include comparison with multiple state-of-the-art low-dose PET synthesis methods.
The method was evaluated on real low-dose PET instead of simulated low-dose PET."	"Ablation study is provided to evaluate the effectiveness of each proposed modules, including patch-based discriminator, 3D CVT blocks, 3D TCVT blocks and convolutional embedding and projection.
Comparisons with state-of-the-art methods show the superiority of proposed method.
This paper is clearly written and easy to follow."
002	3D Global Fourier Network for Alzheimer's Disease Diagnosis using Structural MRI	"Using Fourier networks for AD diagnosis is novel.
The method outperforms a large number of competing methods.
The authors present an interesting ablation study."	"-Used public datasets like ADNI
-Compare with state-of the art"	Method is described clear with good experimental results.
003	4D-OR: Semantic Scene Graphs for OR Domain Modeling	"A new 4D-OR dataset is built and will be released, which will benefit the community.

The idea of using semantic scene graph for holistic OR understanding is significant, which has the potential to make an impact.

The paper achieves scene graph generation by assembling several state-of-the-art computer vision methods into a reasonable and effective pipeline."	"The paper is clear and well-written. The methodology is clearly explained, and its explanation makes for most of the content of the paper. The proposed method appears to be reproducible thanks to all the details provided and that is a good thing.
This paper can contribute to future context-aware systems with an automatic and holistic understanding of the activities happening in the OR. A rich dataset is introduced, which can be used by the community for developing and evaluating similar approaches and go one step closer towards a smart OR. Indeed, the presented dataset is complex and is challenging to obtain. Synchronizing and calibrating six RGB-D cameras, with all the post-processing needed, is not an easy task. The dataset also provides several kinds of annotations. The quantitative results provided will represent a baseline for future papers.
I also find this paper interesting because MICCAI has already seen similar works but rather dealing with images coming from minimally invasive surgeries (such as laparoscopic videos or robot-assisted surgeries).  Yet this paper deals with recordings from a conventional orthopedic procedure from ceiling cameras. This is promising because today around 90% of total knee replacement surgeries are still performed using conventional instrumentation (no navigation, cameras, or robot present). Hence, this paper shows that conventional approaches can also benefit from smart context-aware systems in the near future."	"Focused on a problem of holistic scene understand in the OR that can benefit many applications
Generated a novel dataset with annotation
Making the dataset publicly available
Achieving high performance on detecting roles and relationship"
004	A Comprehensive Study of Modern Architectures and Regularization Approaches on CheXpert5000	The paper is a solid set of experiments on using modern architectures on relatively small datasets and evaluating performance. The discussion of the findings are thought provoking and interesting. It provides good guidance for fertilizing future work.	"The paper brings a new class of models to the attention of the medical imaging community. Results can be easily applied by other researchers
Transfer learning from ImageNet is still the standard practice in the medical domain, especially when dataset size is small, and thus the results are relevant
Experiments are comprehensive and provide practical pointers e.g., related to the optimal batch size"	"The experiments are thorough - they are well designed and thoroughly executed. It well backs the papers claim and contribution.
The topic and experiments are relevant - the network architectures (BiT, ViT) that the authors experiment with are probably relevant to the readers interest."
005	A Deep-Discrete Learning Framework for Spherical Surface Registration	The paper proposes a neural nets-based spherical registration. The underlying theory is based on existing spherical registration [22,23] and MoNet architecture [9]. Although theoretical contributions seem weak in this work, the authors integrated existing approaches into a single framework. The proposed method was validated on a part of the HCP dataset (N~1.1k) with other spherical registration methods. The results show comparable performance (especially to Spherical Demons) while reducing computing time.	The proposed method uses different architecture choices compared to the closest existing work, S3Reg, that simplify the approach, eliminating the need to average multiple solutions. The overall design of the approach makes sense for the registration problem at hand. The method is very clearly explained. The evaluation is excellent, using the very large Human Connectome Project dataset, and comparing to several conventional methods and S3Reg under different parameter settings. The comparison considers both quality of matching and distortion, making it more thorough.	The authors address a weakness of a prior learning-based approach, i.e. lacking equivariance of filters, by incorporating a suitable solution from another paper. The authors' design is creative and well tailored to the problem at hand. Furthermore, the authors provide sensible explanations about the components of their method and present evaluations providing insight into different dimensions of their results, e.g. looking at distributions of strain etc..
006	A Geometry-Constrainted Deformable Attention Network for Aortic Segmentation	"The main strengths of this work are :

Considering the shape of the aorta in the segmentation process, and then by extent, the fact that the segmentation must be anatomically plausible
Validation on a database with different diseases
Evaluation of the method according to the part of the thoracic aorta (ascending, arch and descending)
Good results"	"The work proposed a novel pipeline for the automatic segmentation of the aortic lumen. 
The authors show that this pipeline outperforms previous works on both healthy and diseased aortas. It is of potential interest to the community given the limited amount of work on image analysis of chronic aortic syndromes [1,2].
[1] Fleischmann, Dominik, et al. ""Imaging and Surveillance of Chronic Aortic Dissection: A Scientific Statement From the American Heart Association."" Circulation: Cardiovascular Imaging 15.3 (2022): e000075.
[2] Pepe, Antonio, et al. ""Detection, segmentation, simulation and visualization of aortic dissections: A review."" Medical image analysis 65 (2020): 101773."	Strong evalutation: The proposed method is applied to the aorta segmentation and  diameter measurement. The paper gives a reasonable detailed comparison with other methods which shows the performance of the proposed method.
007	A Hybrid Propagation Network for Interactive Volumetric Image Segmentation	"The approach leverages a slice propogation network to propogate information from use scribbles on one slice to adjacent ones using memory modules. A volume propogation network is used to perform volumetric segmentation and generate features for the memory modules. This is an interesting approach that is novel to my knowledge and is broadly applicable.
The approach is tested on segmentation of multiple organs and compared to multiple methods. Quantitative results are impressive. The method appears to generalize well to a variety of applications."	"The interactive segmentation of medical images is an important but under-studied problem.
The proposed method improves performance over existing interactive segmentation methods on multiple datasets.
The paper is well written and relatively easy to follow."	"This paper addresses a relevant (yet not particularly researched) problem, namely interactive segmentation. This is particularly important nowadays to help clinician annotate images more efficiently.
The method is compared on several datasets and to several baseline approaches."
008	A Learnable Variational Model for Joint Multimodal MRI Reconstruction and Synthesis	"(1) The proposed joint MRI reconstruction and synthesis comes with theoretical analysis.
(2) A bilevel optimization is used for parameter updating.
(3) Experimental results, especially some visual results zoomed in on tumor regions, shows its potential utility and value in practice."	"This paper delivers an solid work on jointly reconstruct undersampled MRI images and perform the image synthesis, the paper is well written and include a thorough analysis and metric comparison. The method is also well described, In general, a very solid work.
In terms of both quantitative metric, as well as the visual image quality, the proposed method provide superior results compared to other methods, also, including the results in the regions of pathologies (Fig 2) delivers more diagnostic value of the paper."	In this paper, the convergence of multi contrast joint reconstruction and generation learnable algorithm is guaranteed by controlling the super parameters, and the idea of meta learning is used to optimize the super parameters to obtain the balance of multiple regular terms.
009	A Medical Semantic-Assisted Transformer for Radiographic Report Generation	"1.The paper injects bilinear-pooling into the self-attention to capture the 2nd or even higher-order interactions of the input fine-grained visual features.
2.To record the historical information, the paper extents the set of keys and values with additional ""memory-slots"" to encode and collect the features from all the previous processes.The paper utilized ReLU instead of softmax unit to prune out all negative scores of low query-key relevance, automatically ensuring the sparse property of the attention weight."	"1.Memory-augmented Sparse Attention module combines the memory mechanism and squeeze-excitation operation to capture the higher-order interactions.
2.CLIP is used to extract features of the image, which is not used in this task before.

the performance of this method is good."	"The motivation for using higher order interaction for extracting fine-grained detail in x-ray images for report generation was well justified and well verified through the experimentation. Coupled with sparse attention, was able to improve the efficiency.
The proposed MSA module having memory slots with sparse attention was able to perform significantly better than vanilla self-attention.
The medical concepts from RadGraph enhance the performances by providing semantic information.
Thorough comparison with state of the art  and ablation with various components introduced in the paper"
010	A Multi-task Network with Weight Decay Skip Connection Training for Anomaly Detection in Retinal Fundus Images	"Exploration of HOG feature prediction for medical image reconstruction is indeed interesting and novel.

The proposed method achieved the SOTA results on the dataset."	"a)   Different from the previous reconstruction-based approaches which are built upon auto-encoder architecture without skip connection, this paper proposes a novel WDMT-Net with an auxiliary HOG prediction task that adapts U-shape network to anomaly detection task.
b)   A weight decay training strategy and an auxiliary HOG prediction task are respectively designed to suppress the identity mapping problem and make full use of the shared commonalities of normal fundus images.		
c)   Experimental results demonstrate that the proposed method outperforms other state-of-the-art anomaly detection methods.
d)  The detailed description of the model and experiment in this paper is accurate and clear. The writing of this paper is coherent and easy to understand."	"1.This paper comes up with two questions and do validation experiments : whether the skip connection can be helpful for improving the anomaly detection performance?whether the HOG prediction task can serve the image reconstruction (main task) as auxiliary and assist the anomaly detection?
2.This paper's method demonstrates its effectiveness for detecting abnormal regions in retinal fundus images."
011	A New Dataset and A Baseline Model for Breast Lesion Detection in Ultrasound Videos	"The dataset and its annotations would be of value to many investigators.
The detection algorithm performs well in cased when the lesion is known to be in the video."	The method is novel and well justified and presented in details. The data set is nicely gathered and annotated by experts. The experiments are well done and the results are valuable. The authors offer their data and their code to the scientific community.	"Releasing of the data upon acceptance
Use of transformers for lesion detection"
012	A Novel Deep Learning System for Breast Lesion Risk Stratification in Ultrasound Images	"Adding BI-RADS as an additional task to the pathology is novel, to the best of my knowledge, as well as the consistency loss.
In the presented results the proposed architecture has superior performance compared to other architectures."	Very easy to understand, reasonable model design. Great datasets. Comparisons and ablations are fairly thorough. Results show substantial improvements on many metrics	The paper is well written and has good experimental validation of claims. The proposed approach shows good improvements over other baselines and can have broader applicability to other domains. Abalation study showing the gains from the proposed loss functions and student-teacher method is provided. CAM analysis shows the intended benefits of the loss functions are observed.
013	A Novel Fusion Network for Morphological Analysis of Common Iliac Artery	"The application is novel.
Morphological analysis is a sound idea.
It is good to see that the authors attempted to use the ablative analysis to back up the claims regarding the proposed network modules."	"Clear description: The structure diagram and formula are clearly described, and the method part is clearly organized.
Clear motivation: Fluent writing and clear clinical meaning."	"The paper designs an interesting way that combines CNN and Swin Transformer for the ends of the common iliac artery and the edge pixels segmentation.
The authors propose a morphological analysis algorithm to obtain anatomical information on the common iliac arteries (the minimum inner diameter, access diameter, and tortuosity)."
014	A Novel Knowledge Keeper Network for 7T-Free But 7T-Guided Brain Tissue Segmentation	1) Clear presentation and well written manuscript	This work presents a knowledge keeper network to extract 7T-like representations from 3T image, without paired-7T images during training.	The method is novel and effective. They propose a novel knowledge keeper network (KKN) to extract 7T-like representations from a 3T image that can further guide tissue segmentation to take advantage of the contrast information of 7T without 7T images.
015	A Penalty Approach for Normalizing Feature Distributions to Build Confounder-Free Models	Learning representations that are free of confounding factors is an important aspect for a wide range of tasks in medicine and beyond. The evaluation is extensive and illustrates the proposed scheme is less affected by smaller batch sizes than the original approach.	This paper slightly improved from MDN to learnable and trainable version, to better perform the regression and handle the difficulty of large batch size.	"Compared to conventional MDN, the beta in proposed PMDN is learnable and  is not confined by the batch size.
The figure 1 is very clear and is helpful to understand the overview of this paper.
The writing and organization of this paper is good and easy to follow."
016	A Projection-Based K-space Transformer Network for Undersampled Radial MRI Reconstruction with Limited Training Subjects	The network seems to perform well. Using the raw k-space data to predict missing samples is a really interesting approach and the application of  Transformers in this context seems very relevant.	The main strength of this paper is the application of the transformer network in predicting the skipped radial spokes. The radial spokes were acquired sequentially which makes the transformer network a good fit.	The idea of treating the radial acquisition lines as a sequence is novel. It allows the authors to use the transformer network for this problem which is not obvious.
017	A Robust Volumetric Transformer for Accurate 3D Tumor Segmentation	"1) The idea of designing a 3D pure transformer for medical image segmentation is novel, given that 3D transformer is not easy to train and requires careful design like the parallel cross-attention and self-attention.
2) The effectiveness of the proposed method is demonstrated on a large MRI dataset with better performance than all the other pure CNN baselines and CNN+transformer baselines.
3) The paper well-written and structured, the figures help a lot on illustrate the ideas."	"1) VT-UNet has very less number of parameters and computational complexity when compared to the other recent works while getting better performance.
2) The concept of introducing parallel cross-attention and self-attention in the expansive path to create a bridge between queries from the decoder and keys & values from the encoder is good.
3) The proposed method is purely transformer based and improves upon the previous works and shows clear distinction when compared to them.
4) The paper is neatly organized and clear to understand."	"The high performance comparing with other methods is the key strength of this paper, and the model size is also excellent.
The shared projection of the queries and independently computes cross and self-attention is an interesting contribution."
018	A Self-Guided Framework for Radiology Report Generation	"(1) The writing of the paper is very standardized and logically clear, and it is easy to read.
(2) Figures and tables are very clear and detailed explanations are given.
(3) The experimental part is adequate with detailed analysis."	"*	Unsupervised clustering acts as knowledge extraction from domain-specific knowledge source i.e, radiology reports.
*	The reuse of report-embedding extracted from sentence-bert in report generator for supervised cosine similarity loss is interesting."	The paper is written methodically and provides step by step description of the various stages of model development and demonstrates validation by help of visual representations ( Fig 3, heat maps) which allows easy co-relation between observing visual features and corresponding text generated.
019	A Sense of Direction in Biomedical Neural Networks	The two strengths of the paper are the novelty and relevance of the approach as well as the experimental evaluation which is thorough.	"it improves an already well performing state of the art method
a comprehensive evaluation has been done on public datasets which highlights improvements and limitations of the method"	"This work points out that MASC [8] sometimes is unstable and proposes to solve it by calibrated response shaping and a phase-offset rotational error (PoRE).

This paper combines the convolution operations with the orientation information, like using Gabor filters. The proposed model has about 1% parameters to U-Net and shows comparable performance.

Experiment datasets contain two retinal fundus image datasets and one histology image dataset. The proposed G-MASC shows comparable performance on DRIVE, and works better on MoNuSeg, comparing to MASC.

PoRE design is reasonable to regularise the filters to keep local relationships, which is also verified in the ablation study."
020	A Spatiotemporal Model for Precise and Efficient Fully-automatic 3D Motion Correction in OCT	"The paper provides a good introduction, and a good explanation of the differences between the proposed method and the competing ones.
The proposed method requires a different protocol for scanning, with a single mapping, which takes less time, so it potentially leads to less errors caused by saccadic movement or by wandering eye from the patients, as well as less discomfort.
The proposed method is 5 times faster than the fastest method it was compared against
The proposed method supposedly provides a dramatic improvement over competing methods on registration accuracy."	"The authors proposed a novel strategy to correct OCT volumetric distortion.
The authors made experiments based on patients to prove the effectiveness.
The authors proposed the first metric quantification of errors in OCT motion correction."	using non-rigid registration compare to rigid-registration, using regularization term , using a-scan and B-scan information , motion compensation throughout fast microsaccadic eye movements.
021	A Transformer-Based Iterative Reconstruction Model for Sparse-View CT Reconstruction	This paper introduced a novel unfolded iterative reconstruction model, which combined convolution and transformer branches to simultaneously extract local and non-local regularization terms.	"a. The motivation to introduce transformer is clearly described.
b. A new module called iteration transmission is proposed to connect the iterations to improve the deep feature extraction and structure preservation.
c. The results look promising."	"1 design an iteration block to simultaneously learn the local and nonlocal regularizer. 
2 IT model is proposed to build the communications between different iterations."
022	AANet: Artery-Aware Network for Pulmonary Embolism Detection in CTPA Images	A novel artery-aware framework for pulmonary embolism detection is proposed.  A loss function even-dice loss is introduced and balances the artery / PE loss. The experiment with public data and various settings is persuasive.	The experiment is of great significance for the PE diseases, and the technical method is reliable. In this paper, an artery-aware network (AANet) to segment PE in CTPA image that fully utilizes artery context is proposed. The method has certain novelty in application.	Authors put forward a way to introduce attention in the segmentation networks, together with a loss function (Even-Dice Loss) which could work even if there is no foreground in the sampled batch.
023	Accelerated pseudo 3D dynamic speech MR imaging at 3T using unsupervised deep variational manifold learning	"The motivation to pursue unsupervised learning is well founded given that it is challenging to collect a ""gold standard"" dataset in such acquisitions.
The use of preparing a ""pseudo-3D"" seems practical and exploits k-t space rather than either a 2D only or 3D only approach"	The proposed approach does not need large-scale fully sampled Pseudo 3D dynamic speech MRI for supervised training but reconstructs the image time series only from the measured under-sampled (k-t) data	"(1) The authors explored the speech MRI which to my knowledge is less intensively studied in fast MRI research, yet it is a meaningful task with challenges.
(2) The proposed unsupervised learning spares the need for fully sampled training references.
(3) The paper is well organized and presented with good image quality."
024	Accurate and Explainable Image-based Prediction Using a Lightweight Generative Model	The main strengths of the paper are its originality (new derivation of an algorithm). The fact that it is not a deep learning based strategy is quite refreshing (and even brave). Another advantage is the existence of only hyperparameter that needs to be tuned and/or experimentally set.	"The main strength is conceptual.  The broad trend is toward ever-more-complex computational machines for this type of task, without considering the disadvantages.  The conceptual trap, for computer scientists, is that cheap and simple alternatives like the proposed one are not ""novel,"" but novel doesn't necessarily mean better in any and all ways.
The attempt to compare the simple method against linear/nonlinear generative/discriminative alternatives is also a strength, with some limitations.  This appears to be a good-faith effort to replicate prior work."	The method proposes a more tractable and lightweight generative model which is linear, and admits closed-form solutions for the weight matrix (common with most linear models). The method performs very well for smaller datasets, but this could also be attributed to model capacity (which is not directly explored in the paper). The paper addresses the problem with deep learning methods early on in the paper, regarding issues with smaller training datasets, difficulty in model interpretation, and extensive tuning  required to make the method work, which also can lead to brittle performance.
025	Accurate and Robust Lesion RECIST Diameter Prediction and Segmentation with Transformers	"New decoder path for RECIST diameter prediciton in DeepLesion : keypoint regression via transformer.
Novel consistency losses.
The ablation studies are thorough and informative.
SOTA performance.
Thorough comparisons to other methods."	Although not the first to propose this, the submission addresses an interesting combination of CNNs and Transformer networks with a similarly interesting application in a clear radiological environment and with a straightforward practical use. The manuscript contains a variety of descriptive figures, which facilitates a better understanding of the authors' arguments.	"a transformer-based network (Meaformer, Measurement Transformer)
Two consistency losses are introduced to explicitly establish the relationship between these tasks."
026	Accurate Corresponding Fiber Tract Segmentation via FiberGeoMap Learner	"The two main advantages of this paper are as follows:

A new method of fiber information description is proposed. This method, which is based on spherical coordinates, computes local and global information separately and combines two kinds of information together as a whole sent to the subsequent deep learning model.
The transformer module is used to resolve the fiber segmentation problem with FiberGeoMap as input for the transformer."	This is a nicely designed method and shows a good result.	"A novel geometric descriptor for fiber tracts capturing global and local information.
A novel Transformer and self attention based segmentation framework.
Extensive validation, including ablation experiments.
Evaluation using 205 HCP subjects and comparison with state of the art approaches, where proposed method significantly outperforms state of the art methods, namely, Tract-Seg and WMA.
Application of the proposed tract segmentation method to clinical setting (Autism versus controls).
The concepts, results, are well illustrated.
Code and video for tracts shared via GitHub."
027	ACT: Semi-supervised Domain-adaptive Medical Image Segmentation with Asymmetric Co-Training	"The problem formulation of semi-supervised domain adaptation (SSDA) is highly relevant for medical imaging
The proposed asymmetric co-training approach provides a framework for making use of both UDA and SSL
The empirical results demonstrate ACT outperforms the baseline UDA and SSL models"	The idea of asymmetric co-training is interesting and novel. Rather than describe each example using two different sets of features that provide complementary information about the instance, this paper decouples the source data and the target data into two sets which are then fed into an SSL module and a UDA module to achieve the co-training.	"The idea is novel and works well. It is reasonable to generate pseudo labels for each other and boost each other for SSDA.

The methodology is easy to follow. Gradual co-training is suitable and helpful for asymmetric co-training.

The experiments are well-designed, which demonstrates the effectiveness of ACT. Ablation studies and sensitivity analysis can help further evaluate the feasibility of decoupling labels to SSL and UDA for SSDA."
028	Adaptation of Surgical Activity Recognition Models Across Operating Rooms	"The proposed pseudo label sampling is somewhat helpful;
experimental results are good;
presentation is clear and well-organized."	This paper presents several strengths, the state-of-the-art is complete, the method is well explained, the validation compare to state-of-the-art methods and an ablation study is done	"generated a big dataset
proposed a model for domain adaptation
well written"
029	Adapting the Mean Teacher for keypoint-based lung registration under geometric domain shifts	"The paper is well written and easy to follow.
Adapting the mean-teacher consistency for registration is interesting.
The method is simple and shows effectiveness in exhale-to-inhale lung registration."	"The method introduced in this paper propose a new method using Mean Teacher for registration adapation. The method is novel, simple and obtained very good results on two public datasets.
The author proposed adaptation of the Mean Teacher framework to work in the context of registration problem."	"The proposed method is based on the mean teacher framework alongside domain adaptation, overcoming two main drawbacks of deep learning, including the assumption of i.i.d. between source and target domain data and the need for massive training data.
Domain adaptation for registration is not many compared with UDA for segmentation and classification"
030	Adaptive 3D Localization of 2D Freehand Ultrasound Brain Images	"The algorithm is able to localize the plane in the head of a fetus
The analysis is sound"	"The method for adaptation of previuosly trained CNN is a novel contribution.
Testing was performed in an adequate set of 3D volumes (17) not used for training, as well as testing in 7 video sequences of free hand 2d ultrasound with more than 1000 image frames (planes) in total"	"The method requires limited number of frames to be manually annotated which is good. Unsupervised fashion of the method alow the technique to adapt to 3 different datasets from different US machines.
Authors claimed that the overall displacement of a video in the 3D anatomical atlas is equal to the displacement from the first image to the last in that video.
Authors claimed that compare to the baseline methods they fine tuned their method to produce more accurate localization accuracy."
031	AdaTriplet: Adaptive Gradient Triplet Loss with Automatic Margin Learning for Forensic Medical Image Matching	"The proposed method was mathematically proved in detail and the main concept of the target problem and resolving ideas were clearly descripted and visualized.
The proposed method was effective on the selected datasets throught reasonable experiments, and make significant improvement with minor modifications."	"The writing is very good. The problem is clear, the existing method is analyzed, and the proposed method is well motivated. The figures in the manuscript help a lot in understanding the work.
Both theoretic analysis and the experimental results are presented in the manuscript.
Alation studies shows the effectiveness of the proposed method."	The paper is very well written and structured, with the proposed methods themselves being well motivated. The performance of Adaptriplet + Autogmargin is quite convincing (see Section 5 for some issues with this particular aspect.).
032	Addressing Class Imbalance in Semi-supervised Image Segmentation: A Study on Cardiac MRI	"The ablation study demonstrated the value of RCS, fuzzy fusion, and DTS, when added to the baseline model. 
The proposed model was evaluated on two different datasets.
Performance is not very sensitive to the values of hyperparameters beta and lambda."	The main strength of the paper is its novelty in algorithm formulation. The proposed training scheme includes several novel elements such as category-wise confidence scores, fuzzy adaptive fusion, class-wise resampling, and dynamic training stabilization.	"(1) The application of cardic MRI segmentation, the semi-supervised algorithm and the proposed training strategy are tightly matched.
(2) Most of the formulas are written clearly and detailed.
(3) Experiments are fully conducted on hyperparameters, ablation studies, and method comparison.
(4)Two public datasets are utilized to demonstrate generalizability."
033	Adversarial Consistency for Single Domain Generalization in Medical Image Segmentation	This paper is nicely organized and easy to follow. The authors have done a good survey and analyzed the limitations of existing methods. The proposed adversarial synthesizing method with the guidance of mutual information regularization is relatively new in DG. The algorithm is clearly presented. Both quantitative and visualization results are reported to verify the effectiveness of the proposed method.	The concept of the adversarial domain synthesizer is intriguing and novel.	"1.The method is novel. This paper designs an adversarial domain synthesizer with a mutual information regularization, which can reduce the negative effects of adversarial learning and achieve high generalization performance.
2.An interesting use of contrastive loss. Using the patch-level contrastive loss as a surrogate for mutual information estimator, which can reduce computational cost and achieve similar results."
034	Adversarially Robust Prototypical Few-shot Segmentation with Neural-ODEs	The topic of adversarial robustness is an interesting and relevant topic to the computer vision as well as the medical community, thus the motivation for the work is solid.	"Novelty: the adversarial attacks on few-shot segmentation (FSS) with deep neural networks and their defense mechanisms have not yet been explored. Clearly there is a need for such robust models in clinical setting.
Literature review: systematic and complete reviews on neural ODE, FSL, Adversarial robustness
Experiments: extensive experiments using three benchmark data sets across multiple segmentation models and attacks methods."	"The authors perfroms extensive experiments comparing with different baseline methods, the evaluation results show that the proposed method outperforms baseline methods.
The idea of using neural ODE for prototypical few-shot segmentation is interesting.
The writing quality is good."
035	Agent with Tangent-based Formulation and Anatomical Perception for Standard Plane Localization in 3D Ultrasound	"Strength:

The paper is very well written
The idea of using a tangent point to uniquely represent a SP is pretty nifty as the search space is reduced to the surface of the sphere of a given radius.
The paper clearly formulates the problem as a Reinforcement Learning Problem by clarifying the state and action space and reward function
The figures are clear and well-produced.
The supplementary training video is quite cool!"	The formulation of the SP localization is essential for optimizing the RL framework. This work proposes a new formulation for SP localization in RL. The proposed formulation is unrestricted by directional cosines coupling with less action space than the previous ones (6 < 8). The reward function affect the optimal searching policy with the action. Considering the abnormal data, the reward function encourage the agent to perceive anatomical information.	"A novel way to frame the problem of localisation with a novel tangent-based formulation and a novel anatomical landmark-based reward; combining an auxiliary task with RL problems is also fairly uncommon and thus has some novelty
Sufficient details are provided in order for the paper to be reproducible
Ablation studies and experiments comparing different methods are useful and insightful"
036	Aggregative Self-Supervised Feature Learning from Limited Medical Images	The proposed method is novel and effective. The authors conducted extensive experiments to verify the effectiveness of the two proposed strategies. The manuscript is well organized, clear and easy to follow.	"Their multi-task aggregative SSL (MT-ASSL) uses linear centered kernel alignment (LCKA) to align the feature representation of two neural networks to look interested and novelty.
Self-Aggregative SSL makes sense and is able to apply to other settings.
In general, Reviewer thinks that the novelty of the method in this paper is good enough."	"This paper is well-motivated. SSL needs a large amount of samples to train, and collecting medical images is expensive. Achieving good performance of SSL by using limited data is necessary.
The idea of aggregating multiple SSL tasks to improve the representation learning is interesting.
The writing is clear."
037	An Accurate Unsupervised Liver Lesion Detection Method Using Pseudo-Lesions	"The proposed lesion simulation strategy is novel, simple, and apparently very useful. It should not be difficult to adopt for other tasks.
The paper is clear and the ablation study is fairly convincing.
The method is compared against multiple anomaly localization methods on two similar datasets."	"-An ablation study is performed to evaluate the contribution of the different loss terms.
-Comparison with state-of-the art method is performed

Use of the gradient magnitude similarity deviation (GMSD) in both the consistency loss term and for the computation of the reconstruction error index."	The key strength of the paper is the clever application of unsupervised learning/unpaired image translation techniques to lesion identification. The approach can also be extended to other region identification tasks in medical imaging, beyond lesions. The method is compared to several popular anomaly detection frameworks, and a detailed ablation study of various components of the system is presented.
038	An adaptive network with extragradient for diffusion MRI-based microstructure estimation	"The introduction of extragradient is not new per se, but it is innovative in the context of estimating microstructure from dMRI.
The paper is very well written, easy to follow.
Statistical tests are sufficient."	"-The experimentation and results are well presented and adequatly compared to other learning-based methods.
-The in vivo datasets used have different diffusion acquisition protocols and were acquired at 3T and 7T, supporting the generability of the findings.
-The manuscript is well written."	"The topic is interesting and clinically significant.
A series of experiments (ablation study, the performance comparison against several previous methods) demonstrated the superiority of the proposed method.
The adaptive mechanism of iterative units selection seems effective and provides an efficient training strategy."
039	An Advanced Deep Learning Framework for Video-based Diagnosis of ASD	The collected dataset is valuabel for the ML community.	The paper has a sound experimental setup and strong evaluation. Another major contribution of the paper is the dataset, which will be made publicly available.	"The paper is well organized
It collected a dataset for ASD detection, and claims that dataset will be released.
A new pipeline is proposed for detection. It exploits openface features and introduces HRC attention."
040	An End-to-End Combinatorial Optimization Method for R-band Chromosome Recognition with Grouping Guided Attention	The problem analysis is done well. Then, the method is designed and described in great detail. The proposed DAM and GFIM modules address the problem very well. GFIM enhances the feature aggregation between similar chromosome samples. DAM enhances the recognition of chromosomes with numerical abnormalities.	"*	This paper studied an interesting and important imaging computing problem for chromosome identification in karyotyping. The application is relatively unique, in comparison with typical image computing problems studied in MICCAI.
*	The proposed end-to-end method is innovative.
*	The empirical study yielded improved prediction performance compared with competing methods."	"The paper is generally well written and concise. The figures and table are mostly self-contained, meaning that they can be understood in isolation, without the context of the surrounding text. The authors are clearly well versed in the technicalities of both the biological side, and the technical side concerning deep learning, this is both a strength and a weakness of the manuscript.
The authors show promising results on a decently sized dataset. The authors compare with reasonable baseline methods and do an ablation study of their proposed approach. The performance is good and generally convincing that the method could indeed be better than what is compared to."
041	An Inclusive Task-Aware Framework for Radiology Report Generation	"Interesting idea to solve the problem structure wise instead of as a whole inspiring from how a real doctor would do the job.
Using one head for each structure in a multi-head attention network is also a meaningful proposal.
Auto balance mask loss is a useful idea."	"1, the structure-aware idea makes great sense. It can help improve the coverage of the generated report on a very large scale. In the real world, many anatomical components of integral reports are omitted simply because no issue is found. This causes a great volume of context missing for training a model. In this paper, the structure-aware idea is realized by combining the task-distillation module and specialized decoders. Shedding light on retaining all anatomical components is the main contribution of this paper.
2, as discussed above, context is omitted intentionally in the real world. To counterattack, the authors propose to randomly attach the normal descriptions (from other reports), this is a big augment for the training
3, moreover, the imbalance of abnormality parts of reports also causes troubles. As a remedy, the paper proposes the Auto-Balance Masks Loss for better training.
4, comprehensive experiments both confirm the superiority of the whole solution as well as the necessity of each technical component"	novel task-aware framework is proposed where various information from the dataset is extracted and group the descriptions into several anatomical-structure-specific aspects instead of generating the overall report at once
042	An Optimal Control Problem for Elastic Registration and Force Estimation in Augmented Surgery	"The proposed method attempts to compute physically (biomechanically) plausible deformation field and surface force distribution.
The error measures used (Euclidean distance between the actual positions of selected points and the positions predicted through registration) has a clear geometric interpretation and appears to be clinically relevant (accurate information about target position is crucial in surgery)
The manuscript structure is very clear."	"the problematic is well stated
the optimization problem and adjoint solving are sound and clearly formulated
introducing ""admissible controls"" is very relevant, to restrict the location and magnitude of possible load forces
the force estimation study is clearly a plus; this part may actually be more significant than the registration result itself"	The paper is appropriately written. The structure of the article is properly placed.
043	Analyzing and Improving Low Dose CT Denoising Network via HU Level Slicing	"This is a very good idea that solves a complex problem with a simple add-on to denoising strategies.

The results are very good and have been validated with different networks and different datasets."	"Novelty: The novelty of the work lies in the use of HU level slicing on CNN networks.
The method shows a good performance (in terms of PSNR, SSIM and RSMEI) when combined with some state-of-the-art methods."	The main strengths of the paper is that they bring up the intensity resolution issue in LDCT denoising. In particular, most deep neural network uses min/max normalization for preprocessing of the input image, the relatively large dynamic range needs to be adapted for the LDCT denoising network. The proposed method is validated on multiple public dataset.
044	Analyzing Brain Structural Connectivity as Continuous Random Functions	"The exposition is good, the method is well-motivated and laid out, and the writing is clear (up to where the math lost me around theorem 1, but that is usual for me). So the paper is a pleasure to read. 
The approach is creative and compelling, one of those papers that make you smile and say ""wow, that's neat"". 
The removal of the atlas constraint is valuable."	"Compared to the exiting methods, this work extends the classical discrete representation to continuous space and develops mathematics schemes to solve the computation task. Experimental results prove the advantage of this new method in group-wise inference from SC data as well as in localizing group differences to brain regions and connectivity patterns on the cortical surface.
Overall, this paper contributes a novel method to the field of brain functional connectivity analysis."	"1). In this work, the authors comprehensively employ real analysis and functional analysis to prove the brain structural connectivity as a continuous function.
2). This paper is written well."
045	Anatomy-Guided Weakly-Supervised Abnormality Localization in Chest X-rays	"The topic of adapting positive-unlabeled learning to chest x-rays is interesting, probably making the contributions useful for medical communities.
The results appear strong (although some comparisons are missing).
The paper is well-written."	"The paper is overall well-prepared and easy to follow
The authors explicit model the anatomical mentions in the report for the localization and classification purpose
Two large-scale datasets are utilized to demonstrate the effectiveness of the proposed AGX module"	"The authors incorporated anatomy mentions into Weakly-Supervised Abnormality Localization in Chest X-rays through an anatomy-guided attention (AGA) module.
Positive Unlabeled (PU) learning was used to alleviate the noise of in CXR reports."
046	Anomaly-aware multiple instance learning for rare anemia disorder classification	"This paper aims to address a very important and meaningful problem.
The idea and the overflow of the proposed framework is clear."	"The paper is mostly well-written and clear.
The method achieves good performance on the authors' private dataset.
Most of the aspects are described in sufficient detail to enable the reproduction of results.
The anomaly-aware GMM modeling using the negative bag is novel, and provides good potential impact in real-world clinical applications."	"+The idea to model the distribution of negative instances by using Bayesian Gaussian mixture models is interesting and in-depth. As traditional MIL is capability of finding the positive samples, how to alleviate its omission error rate is always an important topic. Hence, I believe the idea in this work can have impact on the MIL community, vision community, explainable community and the medical imaging community.
+The discussion of the proposed method, especially on the behavior of the anomaly score is in depth and solid.
+This paper is well written and easy to follow."
047	Assessing the Performance of Automated Prediction and Ranking of Patient Age from Chest X-rays Against Clinicians	"1.The authors demonstrate a GAN-based 'explainable AI'solution to visualise age-relevant features identified by the model, comparing with those identified by the radiologists based on their clinical experience. This paper is relatively experimental on demonstrating the effectiveness of each components of proposed method. 
2.The author use GAN-generated synthetic chest X-rays conditioned on patient age to intuitively visualise age-relevant features via simulated age progression."	"An impressive large dataset is used in this work.
I found the ablation study and the comparison with radiologists (used to validate the proposed work) quite interesting.
The use of the predictive model to visualize semantic features is quite relevant and this solution can be used to discover new potential biomarkers."	The study is very interested. Well written organised. They deliver and answer their hypothesis questions. There is a novel idea of the network and how to combine GAN with regression models to predict the age of a patient from X-ray.
048	Asymmetry Disentanglement Network for Interpretable Acute Ischemic Stroke Infarct Segmentation in Non-Contrast CT Scans	"The main premise of the work, developing a method for leveraging asymmetry to detect pathology, is a very good one. It could potentially be useful for the detection not just of stroke, but others as well. And developing such methods could be useful to enhance the strong general-purpose learning-based models (networks) commonly used nowadays.

The method is well thought, well-designed, and well implemented. For this, I identify 2 components: 1) the regularizer for learning to predict a pathology-asymmetry is intuitive and nicely-designed for the purpose. 2) The framework for combining image X, all-asymmetries map A, and pathology-asymmetries map P, to get a get a synthetic image (asymmetry compensated X_comp) where the non-pathology-asymmetries are (pseudo-)removed (X_comp = X+A-P) is a well-designed one for the purpose.

The method gives a secondary output, the asymmetry-compensated image, where only the pathology-asymmetries should be visible, not the non-pathology ones. This is the image that is given to the segmentation network (primary output being the segmentation). This image makes the segmentation model more interpretable by humans. (shows why the segmenter predicts what it does). I find this a very nice advantage.

The results seem ok, outperforming 2 standard general-purpose segmentation models, the 3D CNN DeepMedic and the 3D (Res)Unet, and some stroke-specific segmentation models [9,18].

I liked that the authors re-implemented and adapted some of the previous methods [9,18] to make the comparison fair (e.g. [9] from 2D to 3D). Makes me more confident that they put some effort to make good baselines.

The paper is very well written and explains the method clearly. It was a pleasant read."	"an asymmetry disentanglement network based on domain knowledge to provide extra supervision.
improved numbers by comparing with existing methods."	"Overall a nice paper to read some aspects that were nice to see:

Tissue type aware regularisation term
Different asymmetry maps to try and seperate/disentangle pathologies - like this concept, so not focusing on one aspect but potentially have the ability to highlight a few pathologies as one tries to make the model more explainable
Nice detail in their methodology and explanation of the parts of the network"
049	Atlas-based Semantic Segmentation of Prostate Zones	"The idea of integrating the spatial probabilistic prior into an atlas to help the segmentation framework is interesting and novel.
The writing and organization is clear, making the whole process easy to understand."	In general, this is a well organized and clearly written paper. I like the incorporation of a probabilistic atlas to provide semantic context.	This work integrates two segmentation approaches to perform two-zone prostate segmentation. Novelty lies in allowing the user to adjust each method's influence to improve segmentation by adjusting a hyperparameter in real-time.
050	Atlas-powered deep learning (ADL) - application to diffusion weighted MRI	"extensive comparison with competing methods
according to their resuls, the proposed method is faster and more accurate than existing ones;"	This paper proposes to learn from an atlas in addition to the diffusion images to evaluate on a new set of data microstructure scalar parameters. This approach seems novel to me and results are of interest.	"*	Paper contributes with a novel approach to leverage atlas-based derived information with dMRI signal for the estimation of FA/OD scalars. To my knowledge, such idea and approach are both novel.
*	Authors use dHCP data for atlas-construction (230) and have a ""pure"" testing set of 70 subjects through different ages (31 to 45 weeks).
*	Comparison with existing approaches and statistical significance of the results"
051	Attention mechanisms for physiological signal deep learning: which attention should we take?	"The paper seeks to compare the performance of several self-attention mechanisms in CNN architectures in 1D physiological (mostly ECG) signals. While extensive experimentation has been done in the computer vision literature regarding such architectures, the benefits and drawbacks are less well established for 1D signals. As a researcher in EEG and ECG I have personally searched the literature for papers in the physiological signal domain addressing similar architecture design related questions and found a dearth of resources. I believe that work presented here addresses questions that may be common in the 1D physiological signal domain that there are currently few resources for.
The applications in clinical/medical practice are generally well motivated. 1D signal monitoring is commonplace in many clinical settings and the work presented here could be of relevance to researchers working in a variety of application areas.
While the paper does not propose new methods or architectures, the way it evaluates and compares existing methods is intuitive and well thought out. The experimental procedure is well described, results are presented in an interpretable way and discussed understandably in ways that might be informative for other researchers in the field.
The paper is clear and free of misspellings and other errors."	The manuscript was written clearly and organised well.	"The problem studied in this paper is important and needs to be solved in ECG
Extensive case studies"
052	Attentional Generative Multimodal Network for Neonatal Postoperative Pain Estimation	This paper is well written, the target application is excellent and it combines multiple modalities in the analysis. The architecture design seems appropriate for the task of combining multiple modalities and fusing them in a lower-dimensional latent space.	Thorough evaluations: Authors evaluate the proposed method by using many types of scores and conducting ablation experiments. These results show the efficacy of the proposed approaches in the paper.	"1)	This paper handles the problems of missing modalities by reconstructing them using a generative model. 
2)	It is novel to use a transformer-based attentional model to generate final pain label and its intensity."
053	Attention-enhanced Disentangled Representation Learning for Unsupervised Domain Adaptation in Cardiac Segmentation	"Novel channel-wise disentangled representation learning was presented as opposed to dual-path disentanglement.
An attention bias for adversarial learning was proposed to emphasize task-relevant domain invariant features"	"1.The paper is well-motivated, well-written, and easy to understand.
2.The topic of unsupervised domain adaptation and application to cross-modality is highly important in clinical practice. 
3.The proposed method is a combination of disentangled representation learning and attention mechanism. Both are hot topics with a lot of literature and both are interpretable. Such a combination has limited novelty, but the paper demonstrates its effectiveness in unsupervised segmentation of medical images."	"The problem of cross-modality segmentation is important and interesting. The proposed HSIC  and attention bias modules are proven useful.
Fig.1 is clear and helps to understand.
The paper is well written and nicely organized."
054	Attentive Symmetric Autoencoder for Brain MRI Segmentation	"1) Paper is clearly organized and neatly written.
2) Masked Pre-training for medical segmentation is novel and makes sense as well.
3) Attentive reconstruction loss and symmetric position encoding help use some key properties of medical data to do the pre-training.
4) Experiments show a decent improvement in performance."	"The paper has clear motivation for its novel ARloss (add importance to informative patch reconstruction) and SPE (induce anatomical symmetric prior to positional encoding).
The proposed model/methods are evaluated on multiple benchmarks and different metrics (Dice & HD95), and achieve sota performance compared with other sota transformer-based models and SSL methods.
The attentive reconstructed loss takes importance score for each patch using 3DD VHOG, which is reasonable and easy to implement.
Ablation studies demonstrate the effectiveness of SPE and ARloss separately.
The 3D brain MRI is aligned to a template anatomical space during pretraining so that the left-right symmetric could be guaranteed."	"Considering that MAE needs a lot of data, it is difficult to apply it to medical images. The high performance of this paper may be the main strength.
Symmetric Position Encoding is an interesting work."
055	Autofocusing+: Noise-Resilient Motion Correction in Magnetic Resonance Imaging	The main strength of this paper is around formulation of the optimization by including k-space trajectory estimates.	"The proposed method does not require motion detection or estimation to perform motion correction;
The proposed methods was compared with several other motion correction methods using four image quality metrics; 
-The images obtained with the proposed method look good even in the presence of severe motion;
-The source code is provided;"	Iterative-based motion correction using the concept of autofocusing with an automatic update of translation, rotation and scaling parameters. Combination of optimization-based refinement of motion parameters (translation, rotation) and an image-derived scaling prior extracted by a trainable UNet to prevent artifact inpainting or unrealistic restorations.
056	AutoGAN-Synthesizer: Neural Architecture Search for Cross-Modality MRI Synthesis	"The proposed model can  search for a remarkable and light-weight architecture with 6.31 Mb parameters by occupying 12 GPU hours.
Prior knowledge is introduced into AutoGAN the  for MRI synthesis."	"1) Authors propose lightweight but effective model for cross-modality MRI synthesis.
2) They provide comprehensive experiments to verify the advantage of their method.
3) They propose several loss functions and present the visualized results, which is convicing."	"The direction of investigating neural architecture search for cross-modality MRI Synthes is interesting.
The experiments are comprehensive.
Code will be made publicly available."
057	AutoLaparo: A New Dataset of Integrated Multi-tasks for Image-guided Surgical Automation in Laparoscopic Hysterectomy	There is a bad need for more publicly available data sets for applications such as automation in surgery. The main strength in this paper is that it aims at filling this gap by providing a data set from real surgeries.	"This dataset is collected from real surgeries in hospital.

The single dataset works for three tasks: workflow recognition, laparoscope motion prediction, and scene segmentation.

SOTA models are evaluated on the dataset to present the benchmark references."	"The paper is well-written, its structure is clear and easy for readers to follow. The topic of this paper is closely relevant to MICCAI interests, in particular focusing on fostering the CAI research field.

This paper aims at presenting a newly annotated laparoscopic video dataset focusing on three important sub-tasks towards surgical automation. The details of the dataset are provided and it does seem straightforward to use this dataset upon its release.

Benchmarking examples are demonstrated. Several state-of-the-art approaches have been tested on the dataset, and this further proves the usability of the dataset."
058	Automated Classification of General Movements in Infants Using Two-stream Spatiotemporal Fusion Network	"The motivation is reasonable and interesting.
The paper is well-written
The GM classification data set was collected and labeled."	"The proposed preprocessing networks, while not technically novel, are an effective way to normalize against background, pose and scale.

Authors leverage existing work on two-stream spatio-temporal architectures which seems particularly well suited for GM classification

authors release the code for comparison. One major difficulty of comparing automating GMA methods is that the data (recordings of infants) are often ""private"". The release of code will allow the community to compare on other cohorts."	Detailed ablation study to demonstrate the effectiveness of the proposed components including the two stream design and the preprocessing network.
059	Automatic Detection of Steatosis in Ultrasound Images with Comparative Visual Labeling	"This is the first time CVL is applied to diagnostic labeling of medical images.
It provides a reliable way of generating labels for medical diagnostic tasks, which are often subjective and difficult to obtain.
The authors show that deep learning models trained with these labels achieve similar performance to histopathology labels.
The paper is well-written with nice, illustrative figures.
There are sufficient experiments to support the findings."	"Authors addressed an important problem related to the fatty liver disease diagnosis. Sometimes the reference labels for the fatty liver disease diagnosis are not available. In this case, radiologist assess the US images to provide the labels. An approach to the robust image labeling would be therefore very useful.

Authors used the RankNet algorithm in an interesting and novel way. Authors compared the proposed approach with the conventional method.

3 annotators participated in the study. Table 1 suggests that the proposed method improved the quality of the labels to some extend.

good reproducibility. Authors plan to release the codes and the dataset."	"The paper is well-organized and easy to follow. 
The authors have presented an innovative idea of using RankNets for their specific application of improving the label quality in Steatosis detection, which can be extended to any other usage of biomedical images for disease detection."
060	Automatic identification of segmentation errors for radiotherapy using geometric learning	X	The major strength of the work is the novelty of the hybrid CNN-GNN for contouring error prediction. The method does not require secondary training of alternative models as related ensemble approaches or statistical model information for local error predictions, and differently to classification approaches only finding failed contours, the method offers with the node-wise classification richer information regarding potentially erroneous parts of the segmentation.  Also, the training time for a new organ of only 10 minutes is very interesting for a potential practical application as an additional QA tool for both manual and automated contours.	Topic is relatively fresh. Lots of paper talk about how to delineate targets, while limited number of them think about error control.
061	Automatic Segmentation of Hip Osteophytes in DXA Scans using U-Nets	The original idea of the paper is the automatic segmentation of osteophytes on the hip from DXA scans using neural networks.	"Osteophytes are one of the most distinct signs of osteoarthritis and they are included in different OA grading schemes (for hip, knee, hand, etc). Their clinical picture and overall etiology are not well understood. Since this research direction is covered in the literature very sparsely, this work provides new evidence on feasibility of automatic osteophyte detection and quantification. Subsequently, the work and the developed method open opportunities for further epidemiological studies, at least with the UK BioBank data. These are the primary contribution of this work.
The methodology applied in the study is principled at all steps (dataset creation, annotation, data standardization, model training, analysis) and is well shaped to approach the related clinical quesiton.
Large sample size.
The article is very well structured and written in a clear language. The graphical materials are informative and sufficient."	"Novel application: automatic segmentation of osteophytes from DXA scan is new and if successful could open of new avenues for screening population for a risk of total hip arthroplasty (THA).

Testing the method on UKBB dataset with 41,160 left hip DXA scans is a strength. The sesisitivity for detection of osteophytes was excellent >95% but the specificity was fair (>70%). The dice metric was also fair ~0.65."
062	Automating Blastocyst Formation and Quality Prediction in Time-Lapse Imaging with Adaptive Key Frame Selection	The paper is clearly written. The frame selection mechanism is interesting and can be potentially useful in other relevant MICCAI topics (e. g. surgical workflow segmentation / action recognition).	"Novel method about key frame selection for improving the automatic blastocyst formation.
Promising results on the in-house dataset are achieved."	"The proposed framework is novel. It addresses two issues in existing methods: input videos need to be manually annotated; redundant and irrelevant information in TLM videos can overwhelm the informative ones.

Extensive experiments on a large-size dataset were conducted, which includes comparison with state-of-the-art methods and ablation studies, to systematically evaluate the proposed method.

The manuscript writing is very good and clear."
063	Automation of clinical measurements on radiographs of children's hips	"The proposed method relies on automatically detecting anatomical landmarks, which are then used to determine the radiographic measurements. This generates a system which I believe has a great potential for easy adoptability by clinicians, due to its ability to be explainable.
Furthermore, the authors tested and validated the proposed method extensively on an independent dataset with multiple manual measurements."	"Significant clinical feasibility for monitoring DDH and achieves SOTA for at least one of the measures, namely RMP.
The approach is tested on a challenging dataset which includes cases of severe disease. Furthermore, the method is tested on a replication dataset to indicate performance in the wild.
The authors describe a reasonable effort to establish ground truth dataset with multiple clinician landmark annotations and they also report on the agreement of the landmarking."	"This study is of clinical value.
This article takes into account the reproducibility of manual measurement in the evaluation process."
064	BabyNet: Residual Transformer Module for Birth Weight Prediction on Fetal Ultrasound Video	"An end-to-end birth weight estimation method based directly on fetal ultrasound video scans.
The BabyNet is trained and validated with data acquired one day prior to delivery.
The experiment results are shown to be competitive compared to SOTA on 225 2D fetal scans from 75 pregnant women."	BabyNet efficiently bridges CNNs and transformers for end-to-end estimations of fetal weights from US videos. It avoids the high computational complexity of pure transformers and also allows local and global feature learning.	"The paper addresses an interesting problem to estimate birth weight of the fetus from ultrasound videos.

Experimental results show that the proposed method outperforms state-of-the-art
methods and is comparable human experts. Combining human and AI outperforms individual methods.

The paper is well-written and organized."
065	Bayesian dense inverse searching algorithm for real-time stereo matching in minimally invasive surgery	A very nice paper, nicely developed and presented methods, well evaluated and discussed.	"The technical novelty of this paper is adequate. Combining Bayesian model into Dense Inverse Searching provides the confidence of identifying textureless and non-Lambertian surfaces, and this is particularly useful for dealing with specular highlights in surgical videos.
The proposed approach presents good performance on both synthetic and in vivo datasets and has been compared to both classic feature matching and deep learning approaches. It is worth noting that the approach runs in real-time 25Hz on 360x288 images.
Given current trend of using deep learning for depth estimation, this reviewer is delighted to see the practical approach proposed in this paper. Although DL-based approaches present outstanding performance in MIS data, these approaches however have not yet addressed their generalizability issues. Researchers are currently experiencing poor performance when using the trained networks to process unseen data."	The main strength of the paper is a rather complete experimental work (synthetic and real data) and comparison with different approaches.
066	Bayesian Pseudo Labels: Expectation Maximization for Robust and Efficient Semi-Supervised Segmentation	"The idea if optimizing the threshold parameter during training is really interesting.  Since the threshold parameter is the output of the network, with this method, different pseudo labels can have different threshold value to be used in the next iteration. This also eliminates the hurdle of manual optimization of the hyper parameter,
This approach can be used for computing the segmentation uncertainty  and is also shown to be robust against adversarial attack.
The experiments and results are extensive."	This work proposed a new formulation of pseudo-labelling as an Expecation-Maximization (EM) algorithm for clear statistical interpretation. And the authors further introduces a probabilistic extension of SegPL using variational inference, which learns a dynamic threshold during the training. The two formulations are novelty and may provide some new insights in the future.	The paper is well written, the method is novel and it is empirically shown that the method is effective. The link between EM and pseudo-labeling is interesting. The method is compared to different consistency-based baselines and yields better results. Moreover, SegPL is robust towards distribution-shift and adversarial attacks. The paper addresses an important problem, as expert annotations are especially costly in medical imaging.
067	Benchmarking the Robustness of Deep Neural Networks to Common Corruptions in Digital Pathology	"The experimentation is extensive, and the conclusion from the experiments are mostly useful. It's interesting to see that the error on the corrupted validation set is a better prediction of generalization. This suggests that the corruption being propose gets the image closer to real test set.
The paper is relatively easy to follow."	"This paper explores an important topic, robustness problem of CNNs, which is significant in the real-world deployment;
The design of corruption types are close to reality;
The experimental results shows poor robustness of modern CNNs is valuable. Another interesting phenomenon is that DNNs have been constantly improved over the past decade, but their classification performance on corrupted pathology images is slightly changed."	The idea of the paper is intriguing. It is well-known that model confidence is not a good predictor of probability, especially given out-of-distribution pertubations. I like the idea to run a standard suite of tests on models to evaluate which of them are more robust and/or show reliable confidence estimates.
068	BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis	"This research shows the feasibility of performing V&L analysis and disease diagnosis on small medical datasets without labels.
Various comparative experimental analysis shows the effectiveness of the proposed method."	"The paper is well written and easy to follow.
Dataset and training procedure are well presented.
The effectiveness of the choices made is demonstrated by testing different feature extractors and different transformer backbones."	"BERTHop implements PixelHop++ for unsupervised visual feature learning for medical images. This helps specifically when labeled data is not available which makes it a perfect use case for medical tasks.
The paper shows detailed disease-wise labels and compared the results with two baselines. The improvement in AUC is significant. Also, the comparison of different transformer backbones is shown.
The argument for replacing BUTD as it fails to detect certain medical abnormalities is supported with convincing results in Table 1."
069	Bi-directional Encoding for Explicit Centerline Segmentation by Fully-Convolutional Networks	The centerline based n-connected points to cover the segmentation seems interesting.	"Although there are already many works that also use connections of key points for different tasks (e.g. CurveNet for point cloud processing, deepsnake for semantic segmentation), the proposed centerline encoding in this work is somewhat novel. Also, the bi-directional design is also interesting and sound.

The emprical experiments and comparisons seem satisfactory. Qualitative results are also meaningful."	"The authors present an interesting encoding approach to improve centerline segmentation which utilizes a point-based encoding of the centerline.
The authors provide results on three different data sets (synthetic, semi-synthetic, CLIP)
The authors compare their results to multiple recent methods for centerline segmentation."
070	BiometryNet: Landmark-based Fetal Biometry Estimation from Standard Ultrasound Planes	"(1) The author proposed an end-to-end landmark regression framework BiometryNet for fetal biometry estimation, which only used simple landmark annotations for training. It reduced the time for manual labelling and high inter-and intra-operator variabilities. 
(2) The Dynamic Orientation Determination mechanism was further introduced to determine measurement-wise orientation and provide consistent landmark class for various measurements."	In my opinion the original contribution is significant and the extensive validation in fetal ultrasound biometry tasks provides enough evidence to support the possible clinical application of the methods.	"The idea of this paper is simple but effective.
The results are strong where the proposed method outperforms other methods and ablation studies"
071	BMD-GAN: Bone mineral density estimation using x-ray image decomposition into projections of bone-segmented quantitative computed tomography using hierarchical learning	"The main idea of the paper is to estimate BMD using QCT and plain X-ray images widely available and more accessible.
Unlike previous methods on BMD estimation from X-ray images, the proposed method uses information in the training phase from QCT."	"Novel methods for applied that make use of related data in a different representation.  Specifically the authors use a hierarchical learning approach, which allows them to take advantage of available quantitative CT data.  The algorithm and the training approach allow the algorithm to greatly improve performance.  The investigation presents a novel way to use the QCT data, it is used as a way to measure ground truth BMD, but also for training a GAN for image translation from x-ray to a synthetic DRR that is useful or BMD assessment.
The article is well written
The clinical need is well established
The authors create a dataset, create a novel algorithm, investigate different training regimens and then demonstrate impressive performance.  There is lots of novel and interesting work here"	"The proposed hierarchical framework was novel to learn a Digital Reconstructed Radiograph (DRR) from X-rays, and then estimate BMD from the corresponding DRR generated using a generative adversarial network (GAN).

Extensive validation using different backbone architecture was performed.

The paper is very well written and I enjoyed reading through it."
072	Boundary-Enhanced Self-Supervised Learning for Brain Structure Segmentation	"The motivation is clear and convincing. How to enhance the boundary segmentation result using self-supervised learning is a promising direction in medical image analysis.

The idea of employing the distance transform map (DTM) based on supervoxels to emphasize the the edges and boundaries sounds reasonable to me. Also, applying self-supervised learning to predict DTMs is novel.

Learning the registration from each volume to the mean volume is an interesting way to incorporate the semantic information, where I suppose the mean volume incorporates the semantics of the whole dataset."	"The proposed pretext tasks are straightforward.
The pretext task of regressing unsigned distance maps defined by supervoxels seems novel."	This paper proposes a new self-supervision method that consists of supervoxel segmentation and image registration as proxy tasks to enhance boundary segmentation for the main task. The paper is well written and easy to follow.
073	BoxPolyp: Boost Generalized Polyp Segmentation using Extra Coarse Bounding Box Annotations	"The amount of data present in recent datasets (such as LDPolypVideo) is needed for robust translatability of polyp detection models, but has the problem that the labels are ""softer"" and contain noise. The paper focuses achieving state-of-the-art results (usually obtained on smaller, curated datasets) on these larger and noisier datasets.
The authors employ well thought techniques that are easy to implement and can be applied to a variety of situations.
The experiments show the benefits of the proposed improvements in a consistent, detailed and thorough way.
The methods are implemented using open datasets. Particularly, the results are evaluated on 5 available datasets showing increased results when compared to the counterpart networks on all of them.
The proposed architecture is compared to 9 state-of-the-art networks, and implemented on top of 2 of them. The authors provide additional ablation studies on 2 datasets.
Qualitative examples are also provided, showing the benefits of their proposals."	The paper is well-written and organzied. The experimental results and analysis are sufficient.	"A simple technique to leverage the dataset with bounding boxes
The proposition is well ablated"
074	Brain-Aware Replacements for Supervised Contrastive Learning in Detection of Alzheimer's Disease	"The paper is well organized and it presents the methodology very clearly. It is addressing a significant problem without any unrealistic claims.
The authors have formulated the problem and the study's hypothesis is clear. The proposed method is an incremental improvement on the literature, which is sufficient for publication.
The experimental setup is designed to validate the hypothesis of the paper, with sufficient ablation study."	"The paper is well written.
The BAR and BAM augmentations are novel: BAR is a new version of CutMix which takes benefit from the anatomic properties of the brain while BAM is a new version of Cutout."	"It is an interesting idea to produce a great variety of realistic-looking synthetic but not simply mix up some image patches in ""CutMix"". ""CutMix"" has been proved to be effective in natural images. But, in the medical image field, we pay more attention to Interpretability. It is important to input the cases matching the anatomy structure so ""CutMix"" strategy may not be suitable for the medical images.  Meanwhile, they train a supervised contrastive loss with
the soft labels and synthetic images, leading to very powerful representation learning."
075	Breaking with Fixed Set Pathology Recognition through Report-Guided Contrastive Training	"The paper is extremely well written. The explanation of the problem and proposed solution is precise, yet well motivated, and detailed enough.

Evaluation is performed on large-scale datasets and extensive investigation has been performed on various factors impacting model performance, such as prompt engineering, ablations on loss components and model heads. The experimental design is thorough, which is a big plus for potential translational applications. Extensive and relevant baseline comparisons have been provided"	"This work presents a novel technique for integrating radiology reports into model training for different disease detection in chest X-ray. The authors propose a  method for adapting the well known contrastive language and image pretraining for recognition of natural images to more complex text such as radiology reports.
The analysis provided and results is clear and well defined."	"The proposed approach is well-motivated and novel for medical images.
The experiments and analyses are very extensive."
076	Building Brains: Subvolume Recombination for Data Augmentation in Large Vessel Occlusion Detection	"interesting idea and novel method for this application.
good evaluation"	"*	An interesting way of augmenting the brain data
*	Comprehensive experiments: five fold cross validation on three models, each with ablation study"	"The presented method is a simple yet effective and clinically relevant solution to solve the problem.
The ROC AUC is significantly improved with respect to the compared method.
The paper is very well written and structured."
077	CACTUSS: Common Anatomical CT-US Space for US examinations	"Clearly written, well explained, and good figures make the concept easy to understand.
Novel IR methodology using conv. ray tracing instead of simple edge detection
Clinically acceptable results on volunteer data"	The use of unpaired image-to-image translation network is interesting for this application.  It demonstrates the feasibility of using ultrasound for AAA diagnosis.	Accurate domain adaptation of deep learning models between CT and US modality holds considerable value. CT-based models are more plentiful, well curated, and reproducible. US can be performed in any setting (office, emergency room, OR), requires less capital and can be leveraged by robotic interventions to provide real-time guidance. The approach of using an intermediate representation space that can leverage CT-based labels for US applications is novel to this reviewer. Importantly, the accuracy results for a specific clinical task-aorta measuring-is reported as better than if a model built only with US imaging were used.
078	Calibrating Label Distribution for Class-Imbalanced Barely-Supervised Knee Segmentation	"Novel methods for semi-supervised learning within a cross pseudo supervision framework are proposed and applied to a knee segmentation task
o	Specific methods include
	A weighted loss that puts more weight on volumes that have fewer volumes.  This favours the smaller classes, which is particularly important for the task of segmenting cartilage
	Training patch selection that is dependent on the classes present that again is designed to favour improving the segmentation task
	Patch selection based on the class distribution in the z direction
o	The observation that these features of the data and problem can be exploited is novel and clever.  It is useful to a broad audience because these aspects could be useful in other image analysis tasks
ablation studies are considered to examine the effect of the 3 different strategies to improve performance
comparison with state-of-the-art methods is presented
the authors demonstrate significant improvements particularly in the cartilage segmentation tasks"	I think the proposed method is an effective extension of the baseline CPS. The proposed strategies to calibrate the distribution of labels could work well for knee bone and cartilage segmentation. Especially for the knee cartilages, even under the few-sample condition, the proposed modules could obtain relatively high results for the FC and TC in a semi-supervised framework. From an engineering point of view, this is an effective work.	This is a well written manuscript focused on a common problem of class imbalance that often occurs in multi-class segmentation processes. The study provides equally novel solution based on a model centric strategy of combining weights to distribute class imbalance, probabilities for image cropping, and sampling supervision for uncertainty arising due to unlabeled data. The experiments demonstrate the clinical utility of the approach on a publicly available dataset with a strong evaluation of network predictions and using an ablation study.
079	Calibration of Medical Imaging Classification Systems with Weight Scaling	"The proposed calibration technique is well described and formulated.  The calibration can be potentially applied to any network and classification dataset.
Multiple networks, and datasets are used for the validation. The validation is overall fair and reliable. Performing the validation on three public datasets makes the obtained results stronger.
Results seem to show a clear benefit of this calibration method with respect to others existing works
The paper is clearly written and easy to follow"	The idea is interesting for a calibration method but the approach has been utilised before, similar to a paper released last year: https://arxiv.org/pdf/2108.00106.pdf, which is my only concern re novelty. However, the premise of not altering the accuracy of confident samples is different/not given as guaranteed in papers as the paper indicates.	The motivation of the paper is sound. Models being calibrated is a property that is important, especially in the medical field. The paper uses a number of different architectures and datasets to showcase their experiments, which is a plus.
080	Camera Adaptation for Fundus-Image-Based CVD Risk Estimation	"The constuction of the dataset is important for research on the camera adaption. 
The proposed scheme consider the camera adapation problem from a novel view."	The proposed cross-laterality feature alignment pre-training scheme is realized by minimizing the CVD risk difference between left and right fundus photos, hoping to extract common features in left and right fundus photos. And the self-attention camera adaptor modul is realized by minimizing the predction value between fundus photos from two equipments. This research show potential application value in disease prevention.	In this paper, domain adaptive technology is used to increase the accuracy of CVD risk prediction from images collected by low-quality portable fundus camera, which is of great significance in clinical application. Moreover, experiments in this paper are abundant.
081	Capturing Shape Information with Multi-Scale Topological Loss Terms for 3D Reconstruction	The paper concisely explains topological data analysis and persistent homology in a clear way, and makes the reader aware that not only is this loss function more suitable for reconstruction, but it can be implemented in pre-existing modeling architectures due to its desirable properties.  TDA methods are also stable under noise perturbations, which is useful for image data.	The topological loss, formulated as the Wasserstein distance between persistence diagrams plus the total persistence, is well justified. That it is also differentiable makes it especially valuable. This is a potentially significant advance for this field that provides a general mechanism for the inclusion of topological information which has been neglected by the field.	"To my best knowledge, the proposed topology-aware loss is novel. As discussed in related works, the idea of topology-aware loss functions has been explored for image segmentation tasks, but the application of the 3D reconstruction from 2D images is novel. Besides, the method is supported by solid mathematical analysis, including the error bounds in loss calculation.
This submission is generally well-organized, with informative illustrations. Although the method section is a bit mathematically heavy, it's easy to follow with intuitive explanations."
082	Carbon Footprint of Selecting and Training Deep Learning Models for Medical Image Analysis	Timely and important topic. Presenting the carbon footprint of DL models in medical image analysis in terms of distance travelled by car is an excellent way to convey the results.	"The paper originally addresses an extremely important concern for the community and the general global population, from the point of view of the medical image analysis (MIA) community. This is very interesting because it is not a topic frequently discussed within the medical community, despite its relevance. It presents and compares multiple methods that can be used to measure energy consumption.
The manuscript is well written and structured, and experiments correctly corroborate the authors' hypotheses, showing that training using large 3D/4D images means a larger energy consumption."	The experiment results are provided.
083	CaRTS: Causality-driven Robot Tool Segmentation from Vision and Kinematics Data	The idea of using a 3D model tracking to provide a segmentation mask is not really new, it is a different approach from what people commonly try and the authors correctly identify that it could provide some benefits in challenging cases where pure image based methods break.	"1) The paper explores a model that goes beyond the standard paradigm for robot instrument segmentation. Removing the direct causal link between the image and the segmentation mask is hypothesized to improve performance when unseen image-space conditions are encounted (ex low brightness, smoke etc). This is supported by the experimental results of the paper, as the proposed model is tested on several unseen image-domains with varying conditions. It outperforms a standard U-Net baseline and a method that also leverages kinematic parameters combined with Convolutional network.
2) The proposed model links various parameters of the robotic platform (camera, tool semantics, kinematics). Thus it constitutes a flexible framework that can be used to estimate missing parameters via gradient descent, given all involved operations are differentiable. This is leveraged to iteratively refine the measurements of the kinematic parameters using gradient descent while also resulting in improved segmentation performance across domains."	"The proposed framework, which combines image information and kinematics, is interesting though not novel as existing works have already explored this framework
The proposed algorithm seems to obtain high segmentation performance, including under different settings such as low brightness, bleeding, smoke,
background change, and simulated smoke
The chosen dataset, and metrics are adequate
The paper is well presented and easy to read"
084	CASHformer: Cognition Aware SHape Transformer for Longitudinal Analysis	Using large pre-trained Transformers as the universal computing engine and finetune it in the small  downstream tasks is an interesting research topic, which might helpful to deal with the limited data problem in the medical field.	"This paper effectively incorporates the transformer model into its framework to solve the low-resource data issues with detailed experimental discussion.
CASHformer designed cognitive decline aware loss for the longitudinal analysis."	"Overall clarity: the context, goal, contributions are clearly described and the article seems well written to me. 
Clinically aware: the effort to anchor clinical relevance and medical expertise throughout the introduction, methods and evaluation is highly appreciated.
Generalizable methodology and contributions: although it may seem contradictory with the previous comment, the approach presented seem to be easily transposed to the analysis of other longitudinal data (for different pathologies or clinical need) using any encoding/decoding network (relevant to the task) and the same training strategy of the pre-trained transformer backbone, aswell as some task specific loss / embeddings."
085	Censor-aware Semi-supervised Learning for Survival Time Prediction from Medical Images	"*The paper is very well written and it is easy to follow.
*The authors proposed a pseudo labelling approach to leverage the use of censored data, which seems to be novel and very useful.

The paper shows a good ablation study of the proposed model as well as a good comparison to other methods.
The paper claims to achieve SOTA in both datasets used."	"*	The proposed solution is straightforward, comparatively simple, and can be combined with other technical approaches. 
*	The proposed solution seems to be superior to existing solutions. 
*	The problem that is addressed in this paper is under-investigated."	"The introduced ELR loss and censor-aware ranking loss shows promissing results and could be adopted in related tasks.

Rich ablative studies are conducted and show detailed performance impacts of th e proposed modules."
086	CephalFormer: Incorporating Global Structure Constraint into Visual Features for General Cephalometric Landmark Detection	"The method is carefully designed and significantly outperforms the state-of-the-art methods.

the use of local group attention and global group reduction attention is an efficient way to capture the long-range dependency and alleviate computational burden at the same time."	"*	The submitted contents are related to the application of neural networks in the field of anatomical landmark detection in 2D/3D medical images, which is highly relevant to the MICCAI audience.
*	Experimental results support the claims made in the paper.
*	The paper is well-organized and well-written."	"(1) The authors proposed a general Transformer-based framework that naturally handles
both 2D and 3D scenarios for the landmark detection. 
(2) The authors studied and innovatively proposed a way to represent visual features and landmarks into a coherent feature space to explicitly incorporate the global structure constraint for accurate cephalometric landmark detection.
(3) The method in this paper outperforms the state-of-the-art methods on two public cephalometric landmark detection benchmarks and a real-patient dataset."
087	Cerebral Microbleeds Detection Using a 3D Feature Fused Region Proposal Network with Hard Sample Prototype Learning	"1) Introduces a 3D single-stage deep convolutional neural network for automatic detection of cerebral microbleeds, which can be time-consuming and subject to error in clinical practice.
2) Includes comparison of the proposed method with 2 approaches without addition of the customized learning components
3) Overall results appear promising"	"*	The authors combine several known techniques in a sensible manner and show that their method is outperforming simpler baselines.
*	The results may indicate a preferable performance compared to the cited state of the art.
*	The authors performed quantitative as well as extensive qualitative evaluations employing the visualization of feature maps and probability maps."	"Paper merges u-net with object detection architectures to detect and classify all in one step (avoiding the usual detection + false positive reduction step).
Paper uses feature fusion model to incorporate contextual information-
A hard sample prototype learning module is introduce to gauge the false positives location and use this information in the metric to reduce the number of false positives."
088	CFDA: Collaborative Feature Disentanglement and Augmentation for Pulmonary Airway Tree Modeling of COVID-19 CTs	Authors propose novel method to introduce structural information from healthy lungs' images to noisy damaged by COVID-19 lungs. The pipeline improves airway tree segmentation quality compared to multiple baseline methods.	"1) It is interesting to exploit information from both clean and noisy CT scans, and deal with the domain difference problem of the airway segmentation for these two kinds of CT scans. 
2) The disentangle technique is novel and reasonable."	"It is an interesting task to consider generalization to noisy domain datasets.
Comparison methods are rich to demonstrate the improvements.
The total framework is very clear with Feature Disentanglement and Augmentation."
089	Characterization of brain activity patterns across states of consciousness based on variational auto-encoders	The authors further associated the encoded information with different brain states	This work provides an excellent framework to instill interpretability and exploitability of the latent space, which unveil the biological insights on the states of consciousness. In this model, receptive field analysis leverages the regions to perturb for inflecting trajectories and perhaps restoring wakefulness. The VAE framework for Visualizing and Interpreting the ENcoded Trajectories (VAE-VIENT) is then used to describe the latent space dynamic.	"Writing is generally concise and clear.
The topic is of interest to the sub-field."
090	CheXRelNet: An Anatomy-Aware Model for Tracking Longitudinal Relationships between Chest X-Rays	The proposed model utilizes both local and global anatomical information to output accurate localized comparisons between two sequential chest X-rays examinations. The authors came up with the graph construction to capture correlations between anatomical regions from a pair of chest X-rays. The proposed model outperforms baselines.	"Clinical relevance: The sequential monitoring of pathological findings in CXR can potentially help patient follow-up. This topic has limited research before.
Global-local relation consideration: It is promising if the prediction from the neural network can leverage more local information since the pathology is usually localized in specific regions. The inter/intra-image relation proposed in the paper can provide complementary information for the global decision.
The proposed CheXRelNet is based on the graph neural network that can merge information from different regions and from past to current."	The study is nicely explained and formulated.
091	ChrSNet: Chromosome Straightening using Self-attention Guided Networks	"The motivation is well-stated. 
The prior work is well and succinctly covered (I do not have expertise to assess if it is complete).
The loss function is well-described and thoughtfully incorporates domain-specific metrics.
The clarity of the paper is good."	"Novelty: This study creates mappings between straight and curved chromosomes for
chromosome straightening for the first time.
Experimental evaluation: well conducted and presented. Much appreciated the comparison."	the beauty of this paper is about formulating an important biological application into a pixel-to-pixel prediction problem, solved by a simple but effective learning paradigm.
092	CIRDataset: A large-scale Dataset for Clinically-Interpretable lung nodule Radiomics and malignancy prediction	"Novel idea for lung nodule malignancy classification
Special focus on challenging vertex-wise spiculation and lobulation classification
Derived masks and annotations will be made publicly available"	I like the idea of the presented approach: very clean solution and includes explainable features for radiologists. Plus: the application of lung nodule analysis is clinically very relevant.	The annotated spiculations will be shared publicly. The method is simple and makes good use of the existing Voxel2Mesh method with a good design (multi-class Voxel2Mesh and malignancy prediction). Mesh classification and final malignancy prediction results are reported, using only mesh features vs mesh + deep (encoder) features
093	Class Impression for Data-free Incremental Learning	"A.	The authors suggest to initialize the neural network with the average batch value of the input. The proposed scheme is an interesting attempt that is distinct from the existing deep inversion method. Through a comparative study, the paper demonstrates that the initialization contributes to the classification accuracy
B.	The performance of a neural network greatly depends on the scaling of multiple loss functions. The presented automatic loss weighting method mitigates the imbalance problem of multiple losses. 
C.	The authors conduct extensive comparison experiments with diverse incremental learning methods. The proposed class impression (CL) method outperforms existing methods including LUCIR, ABM, and CLBM. The ablation study is presented and demonstrates the efficacy of using multiple loss functions."	"The authors apply data-free rehearsal-based class incremental learning to the medical image analysis task. The implementation seems interesting.

This paper leverages three additional loss terms, which are specifically designed for medical image analysis, to address the catastrophic forgetting problem. One of them, named margin loss, is the first time to be applied to data-free class incremental learning.

Large improvements have been made on a datasets, which demonstrates the effectiveness on this task."	"The authors propose novel 1) cosine normalized cross-entropy loss for imbalance issue, 2) margin loss to encourage robust decision boundary, and 3) intra- domain contrastive loss to alleviate domain shift, which empowers Class Impression in addressing the catastrophic forgetting problem.
- They conduct extensive comparison experiments and ablation analysis on the echocardiogram view classification task to demonstrate the efficacy.
Class Impression out-performs the SOTA methods in data-free class incremental learning with an improbable gap of 31.34% accuracy in the final task and get comparable results with the SOTA data-saving rehearsal-based methods."
094	Classification-aided High-quality PET Image Synthesis via Bidirectional Contrastive GAN with Shared Information Maximization	"The paper is well-written and well-organized.
The motivation of the method is very clear and well-explained.
The method is relatively novel."	"The idea to use shared semantic content and structure information between LPET and SPET in training is novel.
Extensive evaluation with comparison with the state-of-the-art methods."	"The paper is well organized, and the motivation behind low dose PET noise reduction is well justified.
The work introduced a novel end-to-end bidirectional contrastive GAN (BiC-GAN), including a master network and an auxiliary network, for intra-domain reconstruction and inter-domain synthesis tasks.
The authors proposed a domain alignment module to maximize the maximum mutual information between the two domains.
The work achieves better results compared with the state-of-the-art methods quantitatively and visually."
095	Clinical-realistic Annotation for Histopathology Images with Probabilistic Semi-supervision: A Worst-case Study	The proposed architecture dealing with both a rough polygon containing positive samples and just an estimation of the tumour/tissue ratio is very original and could be useful in clinical routine	"This paper proposed new annotation strategy that may be insightful for clinical annotation.
Designed semi-supervised learning method proved its effectiveness on Camelyon 16 under worst-case setting."	"Well-organized and well-motivated ideas. This paper starts by posing domain-specific limitations and challenges in the pathology image annotation process and derives its motivation and idea along with the text. I can easily follow the main idea and find it solid.

The proposed probabilistic weak-supervision training method is novel, to me. Using the sorted prediction scores to match the expected labels is a clever way to exploit the ration information. Although it does strongly rely on good stage-1 training (in Table 2, ""skip"" stage-1 fails), the proposed probabilistic framework can improve the upstream model's performance on the downstream task of interest, which is acceptable to me."
096	CLTS-GAN: Color-Lighting-Texture-Specular Reflection Augmentation for Colonoscopy	"impressive augmentation results that create realistic looking colonoscopy images, generated by using a image to image translation framework that can transfer textures from real colonoscopy images to synthetic ones created by 3D modelling.
the authors present a clear clinical task and 2 routes for use in training and in improving segmentation methods
well thought out unsupervised method making use of a lot of useful concepts for applying textures and lighting to colonoscopy images
adversarial loss
cyclic loss
identity loss

novel architecture allow lighting and texture disentanglement"	"Control of features for data augmentation using the proposed approach generating good results
Evaluation of performance on other models by introducing augmentations resulting from this work showing improved results
Code will be available upon publication"	The authors present a sophisticated and flexible framework for manipulating colonoscopy data. The proposed framework allows a user to gain control over the relevant image capture settings after acquiring the videos and map from one image to many other appearances. Not only the data augmentation but also the training application has great potential.
097	Collaborative Quantization Embeddings for Intra-Subject Prostate MR Image Registration	"This paper is well-written and easy to follow.
The network architecture design showed enough technical novelty.
The motivation is clearly stated in the introduction section."	"The paper is very well-written (relating to language variety, broad content organization, level of detail of explanation and reasoning).
The author's approach is innovative, well-motivated, well-documented and thoroughly validated. As the approach is complex, the authors provide an ablation over method components allowing the reader insight into how different components work together and influence performance.
The method out-performs other approaches for this task."	"The authors attempt to address a quite challenging but important topic to address the potential overfitting problem for image registration.

The idea of using collaborative and hierarchical quantization methods to reduce overparameterization is quite interesting and the formulation seems to be quite novel."
098	Combining mixed-format labels for AI-based pathology detection pipeline in a large-scale knee MRI study	"External validation of the developed method
Conceptually right direction - adding positional information is naturally a way to ensure that the network learns from relevant spots"	"While the proposed method is essentially a two-step localization-classification pipeline with multi-task supervision, it is meticulously designed and evaluated by the authors. Consequently, the study provides a range of insights into the value of integrating the diverse annotations, performance of automatic defect localization, performance of automatic defect grading, and value of multi-institutional (multi-view, multi-protocol) MRI data. Overall, the study presents a very strong clinically-relevant evaluation.
While the multi-institutional data is one of the core assets behind the study yet it is private, the authors make a focused effort to describe the dataset in detail, including the protocol- and the defect-related details.
The article is written in an excellent way considering all the parts - problem formulation, structure, data description and preprocessing, method description, experiment design, statistical analysis, interpretation of the results, conclusions, valuable supplemental materials. Excellent graphical materials."	The main strength is the ablation study of the various training methods and the comparison with inter-reader agreement.
099	Combining multiple atlases to estimate data-driven mappings between functional connectomes using optimal transport	The proposed algorithm is novel. An all-way optimal transport algorithm was proposed based on single-source one. The information integration ability of the proposed algorithm was well demonstrated by comparison with single-source one.	The paper is very well written. It addresses an interesting problem, for which only one solution seems to have been proposed so far. The solution is a natural extension of the single atlas to target algorithm. The evaluation is comprehensive and shows that the proposed multi-atlas strategy predicts the true connectome much better than single-atlas. Particularly impressive are the IQ prediction results because they show that synthetic connectomes generated using multiple atlases are just as good at predicting IQ as the true connectomes.	"1) The paper is well written and easy to follow
2) Using optimal transport for multiple source atlases is interesting 
3) Results show clear improvement in correlation values with target ground truth
4) Provided details on parameter sensitivity is worth noting"
100	Computer-aided Tuberculosis Diagnosis with Attribute Reasoning Assistance	4.(1) The proposed dataset provides attribute information which can help model detect TB areas in a weakly-supervised style. This dataset may receive well focus in the future research if provided publicly. (2) The proposed multi-scale feature interaction module effectively leverages the attribute feature to conduct self-attention and cross-attention, resulting a better performance. Such method is useful for the weakly-supervised framework, and have promising potential for wide-spread application.	It presents the TBX-Att dataset for attribute-assisted X-ray diagnosis for TB. It proposes a method to fuse the attribute information and TB information, including the feature pyramid network, the attribute classifier and the feature interaction module. It faces many difficulties to collect the dataset of attribute-based TB X-rays, and it combines the TBX11K dataset to construct a totally new attribute-based TB dataset.	Majority of existing TB CXR datasets contain only disease identifying labels (TB, healthy, sick/no TB). However, there are many other clinical features that may be of interest to clinicians during diagnosis. To address this, the paper presents a TB CXR dataset with attributes (e.g., fibrotic streaks, pulmonary cavitation etc.) to facilitate computational analysis and reasoning about different TB properties.
101	Conditional Generative Data Augmentation for Clinical Audio Datasets	"The paper presents a new direction. 
Overall, well organized and well presented. 
The flow is easy to follow."	"Introducing a new audio dataset recording the sound of surgical action
Propose to enlarge the dataset with GAN"	"The authors present a novel method for augmenting audio datasets in medical applications.
The authors show improved performance over existing techniques
The analysis of audio signals is a potentially rich source of insight in medicine that is not well researched."
102	Conditional VAEs for confound removal and normative modelling of neurodegenerative diseases	"Simple idea with reasonable validation.
Interesting finding in Figure 4 that the pattern detected seems consistent with known neurodegenerative patterns associated with AD."	The paper tackles an important problem of normative modeling + confounder removal.	variational autoencoder is a better model compared to autoencoder in terms of parameterizing your data.  I am happy that the authors used this model. However, I am a bit unsure of the main contribution of the paper. Why authors directly started talking about Deviation metrics in page 4 without linking it to Eq. 2? Maybe I am missing something but It would be great to explain Pinaya's method .
103	Consistency-based Semi-supervised Evidential Active Learning for Diagnostic Radiograph Classification	"A Consistency-based Semi-supervised Evidential Active Learning framework (CSEAL) is presented, where two major components are involved: evidential-based semi-supervised learning, and evidential-based active learning.

In the low-range labelling regime of the average test AUROC, the best performing CSEAL method eNoT+AU outperforms two baselines ToD+CoD [10] and VAT+Aug Var [7]."	"The authors propose a novel combination of SSL + AL that can be applied to a variety of SSL methods.
The new method obtains better performance than strong baselines like COD + TOD and VAT + AugVar.
The improvements are especially good for rare classes which are harder."	"The paper improves the classification performance in the existence of low number of annotated data and abundant unannotated data.
The application is indeed appealing in the biomedical domain where the expert annotations are rare and expensive.
The way the CDSEAL semi-supervised learning is formulated. In addition, authors have a good grasp of the current state of the art.
The paper is well structure and the stream of thought is clear.
The selected low-range labeling regime is realistic and well done."
104	Consistency-preserving Visual Question Answering in Medical Imaging	"*	The paper is well-written and easy to follow. 
*	The idea to enforce consistency, by letting the user ask questions about a specific region in the image (by providing a mask) is interesting.
*	The strength of the paper lies in learning from special dataset that provides presence or segmentation labels of hard-exudates.
*	This paper is a good example of extending a deep learning model to incorporate domain specific constraints. Though the extended VQA is trained using a special supervised dataset, the training is still compatible with standard dataset without any consistency information."	Solid experimental results on improving both model accuracy and consistency in the diabetic macular edema staging experiment.	"Problem addressed in this paper is intresting and an important.
The model outperforms a baseline on one dataset"
105	Context-Aware Transformers For Spinal Cancer Detection and Radiological Grading	"This study considers context from multiple sequences and neighboring vertebrae for for spinal cancer detection and radiological grading, which is interesting.

This study demonstrates the potential of obtaining supervision from free-text radiological reports."	"The paper focuses on clinically relevant task and does that in the technically appealing context, that of using transformers, and within weak supervision making it of interest for the medical imaging community overall. The proposed evaluation is sufficiently broad to allow for comprehension and judgement.
     Moreover, the paper is nice to read as it is quite clear and well exposed, so the reading flows. The provided illustrations contribute to the understanding of the paper."	"The paper proposes to use transformer layers and attention mechanism to fuse features from multiple MR slices, series and vertebrae, which is intuitive and effective. The use of labels extracted from reports is also economical.
Comprehensive experiments are done on muliple spinal tasks."
106	Context-aware Voxel-wise Contrastive Learning for Label Efficient Multi-organ Segmentation	"- This work aims to solve the partial label multi organ segmentation, which is an important problem in medical image segmentation.
- The contrastive learning loss is applied for unlabeled voxels to enhance the learned features."	"1) The performance of the proposed method demonstrates superior performance than previous state-of-the-art loss functions [12], [21] in the task of partially labeled segmentation.
2) The motivation to learn the unlabeled information is good."	"The motivation (utilizing partially labeled datasets) is practical.
The idea of ""context-aware"" seems interesting. The authors would like the same voxels but from different patches (context) to be the postive pairs."
107	ConTrans: Improving Transformer with Convolutional Attention for Medical Image Segmentation	"This paper is well-written, understandable, and obtains impressive results.
The paper is insightful. It analyzes the inherent shortcomings of CNN and Transformer and comes up with a well-designed hybrid network to inherit their merits.
DAB (Depthwise Attention Block) looks promising. This could not only be applied to medical image segmentation but also other CV-related tasks."	"++ This method achieves promising results on three common medical segmentation tasks, including polyp segmentation, skin lesion segmentation, pneumonia lesion segmentation and cell segmentation).
++ This paper has good clarification and organization."	"The authors explore and exploit the most advanced progress of vision transformer (Swin Transformer, Cross-attention) in medical segmentation task;

Evaluation on multiple datasets and achieve state-of-the-art performance."
108	ContraReg: Contrastive Learning of Multi-modality Unsupervised Deformable Image Registration	The use of an embedded feature-based contrast comparison is a novel idea, and the presented results suggest strong performance for the proposed approach over existing methods. In addition, the paper was well written, and does a fantastic job covering relevant work.	"The author deals with the hard problem of multi modality registration and proposed an approach based on contrastive learning.
They compared with different classic multimodality losses and obtained better results."	"New approach. The novelty of the approach lies in the use of contrastive representation learning to measure the similarity of images with different modalities. The approach is novel in that it does not build on common geometric image similarity measures such as NCC or MI, nor does it explicitly learn a metric. It provides a very interesting and fully data-driven alternative for multimodal registration.

The presentation is clear and sound with a balanced high technical level.  The motivation is clear, with a detailed list of works cited (>20 references).

Strong evaluation and comparison. The evaluation compares several variants of the approach using state-of-the-art methods, including hyperparameter optimization, to provide a fair and realistic picture of the comparison.

The results are good and slightly superior to the compared methods for the presented expalele. This is very interesting as it strongly suggests that such data-driven methods could be a quite attractive and effective approach for multimodal registration."
109	Contrast-free Liver Tumor Detection using Ternary Knowledge Transferred Teacher-student Deep Reinforcement Learning	"Paper has good and strong evaluation dataset - 352 patients with data from two MR scanners which helps to prove that the technique proposed has strong test value.
The formulation of the technique is simple but good enough to be understood in layman term ; Ts-DRL provides knowledge set that is <A,R,F>  - action, reward, and feature from the DRL's agents of teacher network to guide the student network learning.This ternary knowledges also inform the student network what to do,and innovatively embeds
F to teach the student the reason and purpose behind the A,R.
The novelty of this method is the why to do of the ternary knowledge framework (A,R,F) .Thus, it improves the effectiveness of the teacher-student DRL framework and the accuracy of detection. It also  possesses a novel progressive hierarchy transferring strategy (P-strategy) to strengthen the transfer of ternary knowledge."	The topci of this paper is interesting. The methodology used in this work is well described.	"The method is well motivated to use a P-strategy to stale the training process which is better than other DRL strategy including DQN, DPG, DDPG, etc.
The extensive experimental results show that the proposed methods can detect tumor better than previous baseline models."
110	Contrastive Functional Connectivity Graph Learning for Population-based fMRI Classification	The paper proposes a method to encode functional connectome features by using contrastive learning to obtain embeddings that are then used as inputs to graph convolutional networks for disease classification. As brain imaging datasets are scarce, attempts to overcome overfitting problems are needed.	This is a novel application of contrastive learning on the FC graph data. The AUC improvement looks pretty good.	"Overall I think the idea of using contrastive learning on functional connectivity graph and Dynamic Graph Classification on Population is novel.
The authors compare against a wide range of baseline methods and conducts statistical tests."
111	Contrastive learning for echocardiographic view integration	"Well-written; clear story-line, and reliable results.
Rigorous experiments with ablations studis which independently assess the impact of each component and idea.
To the extent of my knowledge, the ideas around intra-subject contrastive loss and inter-subject contrastive loss are novel.
Experiments are conducted on public datasets and source code will be released, hence, a more prominant impact is expected."	"This paper is well-written and easy to follow. The figure is illustrative.
The idea of contrastive learning makes sense especially considering the physical characteristic of ED/ES in the two views of A2C/A4C.
The ablation experiments are good to illustrate the effectiveness of each proposed loss function."	"The authors propose a novel method that uses a volume contrastive network for 2D information fusion. The network itself is not novel but the application is. 
Furthermore, the authors propose using intra and inter subject constrastive losses by maximixing/minimizing positive/negative distances between pairs, which shows a deep understanding of the problem and a novel method to improve the solution.
The evaluation is very detailed, with ablation studies showing the contribution of each of the features added to the base architecture and statistical analysis shoing the statistical significance of the improvement."
112	Contrastive Masked Transformers for Forecasting Renal Transplant Function	According to my knowledge, this study is among the first that propose a novel, robust, and clinically relevant framework for forecasting serum creatinine directly from imaging data. This study proposes a novel transformer based architecture tailored to deal with missing data for the challenging task of serum creatinine prediction 2 years posttransplantation using imaging modalities. First, they show the significant use of contrastive learning schemes for this task. Their trained representations outperform common transfer learning and contrastive approaches. Then, a transformer encoder architecture enables to input the sequential features data per follow-up in order to forecast the renal transplant function, including a custom method to handle missing data. Their strategy performs better than other commonly used data imputation techniques. Those promising results encourage the use of medical imaging through time to assist clinical practice for fast and robust monitoring of kidney transplants.	I think this is a new novel study for forecasting serum creatinine directly from imaging data.They proposed two contrastive learning schemes to explore meaningful data representations. They showed the significant use of contrastive learning schemes for this task. They used the transformers encoder  to input the sequential features data per follow-up to forecast the renal transplant function, including a custom method to handle missing data.	"*	Interesting research problem
*	Up-to-date reference list
*	The method outperforms related works"
113	Contrastive Re-localization and History Distillation in Federated CMR Segmentation	"Working on the distribution shift problem in federated learning is important.
The introduction of CRL and MD modules to the solution combines novelty with a realistic problem.
Results show substantial improvements compared with standard methods."	"1.Clarity in problem introduction and motivation: The problem statement regarding heterogeneous datasets and bias in FL is explained well and the motivation is quite clear. The figures are clear and help in understanding the problem.
2.Novelty of the method: The proposed method using momentum distillation is quite novel and the use of cross-attention transformer for reducing representation bias in this application seems interesting (though attention-based algorithm have been attempted for fairer client selection recently in Chen et al., 2021, ArXiv).
3.Works on cross sequence and validation on multiple datasets: The method is shown to work on cine-CMR and DE-CMR sequences obtained from different scanners/centres and dataset size is also different from each other.
4.Results are shown  to work, not only on heterogeneous scenario but also on homogeneous scenario (within cine-CMR sequence), indicating the adaptability of the model."	Comparison with other federated learning strategies and ablation studies are conducted.
114	Contrastive Transformer-based Multiple Instance Learning for Weakly Supervised Polyp Frame Detection	"The idea is novel, with new proposed hard/easy example mining based on the task.
The illustration is clear.
The experiments are robust and the results are promissing."	The paper deals with one of the challenging problems in colonoscopy, detecting abnormality, especially the video snippets with flat or small polyps. A dataset including normal, abnoram(polyps) is collected from publicly available data.	The authors combine multiple methods in the literature as their method for Polyp Frame Detection. This combination does have its advantage and outperforms many SOTA methods. From this aspect, the system is well-designed and has some novelty.
115	Coronary R-CNN: Vessel-wise Method for Coronary Artery Lesion Detection and Analysis in Coronary CT Angiography	"Main Strengths are:

Well written and explained
Good and convincing diagrams
Comparison with existing methods.
Experiments
Large dataset"	The main strengths of this paper include introducing Faster R-CNN framework for lesion detection. Then a multi-task network is employed for plaque classification and stenosis. In the plaque classification branch, two FC layers are used to determine the presence of calcified and non-calcified plaque respectively. Experiments have been conducted using a large clinical dataset consisting of 1031 CCTA images.	The whole curved planar reformation (CPR) volume along the coronary artery centerline is used for the coronary plaques analysis.  This is an application innovation
116	CorticalFlow++: Boosting Cortical Surface Reconstruction Accuracy, Regularity, and Interoperability	This is a technical submission addressing a fundamental but important problem in brain morphometric analysis, cortical reconstruction. The major novelty lies in the improvement of pipeline and practical application scenario. The proposed work competes with several latest main-stream methods, and shows a strong performance gain.	"Accurately located the weaknesses of the cortical flow method and improved these weaknesses correspondingly.
The paper organization and writing is quite clear, which makes the paper easy to follow."	"The proposed method extends [15]. The authors improves each component in [15] for better cortical surface reconstruction.

The RK4 ODE solver was used for accurate estimation of the solution to the flow ODE. It is well-known that RK4 can offer a more accurate solution than the Euler forward method.

The union of training volumes was used as an initial template. This approach may better capture deep sulci by placing the initial vertices close to the cortical tissue.

Pial reconstruction was done by employing the estimated white surface rather than a convex hull template. This idea has been widely adapted in the classic surface reconstruction pipelines and generally offers better CSF/GM boundaries."
117	CRISP - Reliable Uncertainty Estimation for Medical Image Segmentation	"The task tackled by the paper is highly relevant to the community especially for clinical deployments of deep learning methods. It is very important to have anatomical bias in the uncertainty maps to increase the interpretability of the confidence of the neural networks.
The paper is well written and easy to follow.
The evaluations are very rigorous with an evaluation metric that is proposed by the authors that i believe is very suitable for the task at hand.
The qualitative results provided are very impressive an dpromising.
Usually uncertainty estimation methods tend to boil down to edge detection as discussed in the paper and the method presented seems it goes fir the first time beyond being an edge detector."	"The authors leveraged contrastive learning for joint image-segmentation embedding, which leads to better calibration of predicted confidence and true probability.
While the formulation has drawbacks, the idea to have an uncertainty estimator based on an anatomically feasible shape prior has merit."	"The idea of mapping images and segmentations to closer in the latent space and exploiting this information for uncertainty estimation is a quite interesting idea.

The proposed method is evaluated on multiple dataset and show improvement compared to 3 existing methods."
118	CS2: A Controllable and Simultaneous Synthesizer of Images and Annotations with Minimal Human Intervention	"It is important to explore means to reduce the cost of medical image annotation. The presented method, CS2, is an promising approach. It utilizes 30 labeled images for data synthesize while its baseline counterparts require 1000 labeled images.

The presented method is technically sound. Its key components are clearly explained and figures are provided to understand the method.

This paper presents good experiments. The proposed method and three popular baseline approaches are compared on both in-house and public datasets. Promising quantitative and qualitative results are reported with detailed discussions."	The key strength of the paper is the clever idea of incorporating HU value maps into an image generation network for CTs. By adding controlled manipulation into the more traditional V2I network, the resulting approach combines the best of both V2I and M2I methods.	"Novel idea to use less human-labeled data to generate more synthetic images.
Comprehensive literature review of existing synthetic image generation methods."
119	Curvature-enhanced Implicit Function Network for High-quality Tooth Model Generation from CBCT Images	Obtains a solution for producing quality tooth reconstructions from CBCT images without the need for the intra-oral scan and image registration to obtain an adequate accuracy.	"The idea of using both modalities is very interesting. Also, implicit function networks are very popular for 3D shape reconstruction and this method is a new example of using IFN for medical data.  It is applicable to several practical medical reconstruction problems.
The comparison of the method with other methods (especially HGMNet) is very useful for showing the effectiveness of using intro-oral data. I think the ablation study shows the effectiveness of the curvature enhancement and surface reconstruction.
The figures provide useful information about the method. The curvature enhancement with a separate branch is an original approach."	its potential applicability in clinical practice
120	DA-Net: Dual Branch Transformer and Adaptive Strip Upsampling for Retinal Vessels Segmentation	"1) Methodology: They propose a novel architecture that fuses regional and global information using transformers. To the best of my knowledge, it is the first application and intergration of a transformer module in a encoder-decoder like architecture. Related work that is inspired from U-net and Transformers is the PCAT-Unet model presented by Danny Chen et al. [Ref1] for the retinal vessel segmentation. For the decoding part, they replace the standard square kernel with oriented line detectors that take into account context along the length of the vessels.    
2) Reproducibility: The authors provide the necessary tools to the MICCAI community to be able to reproduce the experiments and results. They provide the code implementation with the necessary dependencies, the evaluation of their method, the dataset that was used in the study. Also the previous are supplemented with the trained weights of the proposed model so the community can replicate exactly the algorithm.
[Ref1]: Danny Chen et al. ""PCAT-Unet: UNet-like network fused convolution and transformer for retinal vessel segmentation"", PLOS one, 2022"	The paper provides a new way of how to combine patch-wise and image-wise segmentation approaches in a single network for vessel segmentation, with the use of dual transformer, which makes the paper interesting.  Also, adaptive strip upsampling block seems to suit well for the segmentation of vessels, which are elongated structures.	Overall, it is well written and well organized. The idea for tackling small vessels in a patch way is very straightforward, yet the mechanism to combine patch and non-patch is interesting. Additionally, this method seems to obtain decent experimental results. With their codes promised to be released. I have no doubt about the methodology part of the paper.
121	D'ARTAGNAN: Counterfactual Video Generation	"well written
interesting problem of generating counterfactual image generation
evaluation on two datasets"	"Practical strategy for the absence of true labels missing for synthetic data. They defined  3 rules that will allow them to broadcast their true labels to the generated videos. Key point here is they want to make counterfactual videos that are visually indistinguishable.
Two public datasets used MorphoMNIST and EchoNet databases.
They are open to releasing their code.
Proposed technique seems to be noval.
Claiming that this is the first time this approach has been explored for medical image analysis."	"The authors propose a novel model.
The experimental results look promising."
122	Data-Driven Deep Supervision for Skin Lesion Classification	"Overall the paperis well writen and the presentation is satisfactory.
The lack of object level feedback in classification problems is an important problem to tackle."	"The idea is novel, particularly in the area of skin lesion classification.
The study is performed on multiple datasets and performance gains are reported on all the datasets"	"The method can provide accurate lesion localizations through activation mapping. 
The obtained quantitative results are competitive or better than baseline methods."
123	Data-driven Multi-Modal Partial Medical Image Preregistration by Template Space Patch Mapping	"Strong experimental results
Large dataset with gold standard labels
Good comparison with baseline methods"	"*	Comparison to both standard initialization techniques using traditional registration methods and to deep-learning methods is rigorous.
*	The proposed method outperforms the comparison method.
*	Evaluation on moving images with partial field of views (FOVs) stratified by FOV size is good (Fig. 4).
*	Cross-validation is rigorous for evaluation.
*	Ablation experiments demonstrate the importance of removing outliers (using RANSAC) in the inference results."	"Alternative deep learning methods typically assume that data images the same whole region, that they are roughly aligned already or even that data has the same size or scale. This initialization step, however, performs well without requiring any of those.
The proposed method represent a potentially very interesting addition as initialization for a variety of multimodal registration methods.
The experiments section is quite good. It's very detailed, covers a good range of experiments and enough competing methods"
124	DDPNet: A novel dual-domain parallel network for low-dose CT reconstruction	A novel dual-domain network, which is parallelly designed and not cascaded as the previous work.	"The paper is written clearly, and the motivation is well justified.
The proposed method utilizes both image and sinogram domain information through an IIF mechanism to reconstruct high-quality CT images from LDCT images. The cumulative error can be suppressed by parallel optimization between sinogram and image domains streams."	"The authors propose a dual-domain parallel solution with interactive information flow to fuse the dual-domain features and eliminate the accumulation error.
The unified fusion block use multi-head attention to better fuse dual-domain features.
Quantitative results and visual comparisons show the superior performance of DDPNet."
125	Decoding Task Sub-type States with Group Deep Bidirectional Recurrent Neural Network	"The authors propose Group Deep Bidirectional Recurrent Neural Network that decoding the functional brain for group-wise tasks is novel.
The proposed Multiple-scale Random Fragment Strategy and the multi-task interaction layer for decoding functional brain states are innovative."	"1.The proposed bidirectional GRU-based group-wise brain functional state classification method is innovative.
2.The proposed multi-task interaction strategy for mining temporal-task-wise context information is novel.
3.The experimental results show that the proposed method has good classification performance."	"In the manuscript, the authors proposed a novel group-wise Bidirectional Recurrent Neural Network for analysis of the brain function sub-type states.
It is innovative that the authors implement the classification task of different subtypes of brain networks using a single model."
126	Decoupling Predictions in Distributed Learning for Multi-Center Left Atrial MRI Segmentation	"The paper addresses a very relevant and difficult problem, namely combining global and local optima in a federated learning setting.
The methodology is novel, sound and interesting.
The experimental set-up is (mostly) well-devised and the results are convincing.
The paper is generally well-written and easy to follow."	"Good clinical feasibility for distributed learning to handle the learning-based analysis method with privacy-sensitive data.
Good results (outperform competing methods) in DICE score metrics across global and local tasks."	
127	Deep filter bank regression for super-resolution of anisotropic MR brain images	This paper is novel in the way that the problem is modelled from a Digital Signal Processing (DSP) perspective instead of traditional Deep Learning model design. Authors have compared their method to traditional upsampling methods (i.e. b-spline) as well as a SOTA deep learning method (SMORE) and have shown an improvement in performance.	This is a good paper, both well written and well structured, with a novel methodology and solid validation. I am not very familiar with perfect reconstruction filter banks, but I get the idea of the paper, and the results are promising and convincing. A method that can super-resolve high-quality SR of thick-sliced hospital MRIs - without requiring training data - is valuable, and is what is presented in this work.	"(1)	This paper proposed a novel formwork which is supported by theory. 
(2)	Experiments verify the effectiveness of the proposed method."
128	Deep Geometric Supervision Improves Spatial Generalization in Orthopedic Surgery Planning	The proposed formulation is novel and improved the point detection accuracy measured as median error from 2.29 mm [95% CI=1.84 to 2.82] to 1.58 mm [95% CI =1.15 to 2.09].	"Appropriate statistical analysis
Novel method seems to improve results significantly
Validated on two different datasets"	Novel method: This is an extension from presumably the authors' previous work where the planning target was calculated from the optimization of so-called proxy objective without optimizing planning target itself. In the current study, the optimization for planning target and proxy objective are jointed performed, achieving significantly improved planning target accuracy. The proxy object was also improved to accommodate joint optimization.
129	Deep is a Luxury We Don't Have	The proposed HCT is a convolutional transformer for high resolution inputs. With linear attention approximation, HCT seems to improve over GMIC, a benchmark for high resolution mammography.	this work adopts the latest transformer technique Performer (Transformer architectures which can estimate regular full-rank-attention Transformers with provable accuracy, but using only linear space and time complexity, without relying on any priors such as sparsity or low-rankness), and demonstrates the feasibility of applying the Performer on the large-scale medical input.	"The problem studied in this paper is important and needs to be solved in Medical Imaging
Extensive case studies"
130	Deep Laparoscopic Stereo Matching with Transformers	"The paper presents a deep-learning-based method to solve the stereo matching problem involving laparoscopic images. An existing framework (reference [4]) is modified to achieve superior performance for laparoscopic applications. The authors main contributions are the following:

Use of Transformer networks in place of Convolutional NN in cost-aggregation. The authors justify this architectural change in terms of loss landscape, learning trajectory and accuracy

The proposed architecture is compared to the state-of-the-art using publicly available datasets"	The idea of visualizing the loss landscape to demonstrate the differences among various architectures is interesting, though the way to represent the results could be further improved.	"Extensive experiments;
Combining feature extraction using a transformer and matching using a CNN."
131	Deep Learning based Modality-Independent Intracranial Aneurysm Detection	"well-written paper
interesting approach to use surface models and pointNet
good evaluation"	"The main strengths of the manuscript are:

modality-independent method for aneurysm detection, which achieves very good results on both, CTA and MRA datasets in a study with 500 datasets, and outperforms the state-of-the-art
well-written, concise manuscript which is easy to read"	Generalization of machine learning models can be difficult, and moderns trained on a specific dataset may not actually work well in practice. This work has addressed these issues atleast in part by showing that their deep learning method for detecting intracranial aneurysms performs on part or better than manual segmentation, and changes in imaging modality do not particularly affect the performance of their method.
132	Deep Learning-based Facial Appearance Simulation Driven by Surgically Planned Craniomaxillofacial Bony Movement	"The paper solves a new clinical problem using a pointnet,  Allowing for quicker and easier computation than labour intensive FEA and without relying on surgical expertise.
The authors compile a dataset of pre and post op imaging of facial reconstruction patients that is used to train and evaluate the model
The authors present a novel architecture that uses PointNet derviced features, point to point correspondence with convolutional layers to learn displacements to apply to pre-operative geometries
Limited data, but still good performance
The article is well written
The methods presented use a different formulation, relying on points that is less researched than voxel based methods."	"The whole manuscript was well prepared and clearly written, the contributions in both technical and clinical perspective were well demonstrated. 
The proposed method took both bony and facial surface points to be considered, it is more convincing for real clinical application.
The experimental results showed good achievements and efficiency of the proposed method compared with the SOTA FEM-based method."	"This paper proposes an innovative approach to address the problem of transferring correspondences between shapes and/or point sets, which is a well-known and open problem not only for the specific application considered in this paper. I believe this work can have a quite broad impact on all those applications that require correspondence mapping between different point sets.
In addition to the novelty of the methodology, I congratulate the authors for the clarity and the thoroughness of the paper. The methodology is clearly described with plenty of details. Figures are well-done, self-explanatory and provide complementary and essential information to the text. The conducted evaluation is complete and convincing. It assesses the performance of the method in comparison with alternative approaches both quantitatively and qualitatively, includes statistical analysis and an ablation study. Obtained results are thoroughly discussed. Limitations of the method are mentioned, as well as possible future directions."
133	Deep learning-based Head and Neck Radiotherapy Planning Dose Prediction via Beam-wise Dose Decomposition	"The newly introduced strategy to include the beam directions as prior knowledge makes intuitive sense. It is elegantly implemented in form of the beam masks, which can be efficiently calculated and processed.

The proposed method has been extensively compared to seven relevant baseline methods. Additionally, ablation experiments were conducted to quantify the benefit of the newly introduced components. All benchmarking experiments were based on the publicly available OpenKBP dataset.

The manuscript is clearly structured and nicely illustrated, making it easy to understand the main ideas and conducted experiments."	"This paper proposes a novel deep-learning based dose prediction method, which generates beam mask to represent an irradiation boundary as a prior knowledge.
This paper evaluates the estimation accuracy using a grand challenge dataset and showed the proposed method outperformed the state-of-the-art methods."	"The general idea of ""disassembling-then-assembling"" strategy to consider the dose prediction task seems interesting.

The proposed architecture looks workable to this specific task."
134	Deep Motion Network for Freehand 3D Ultrasound Reconstruction	"Clear usage of IMU for the first time in this literature
MoNet for reconstruction of image sequences
Combining ResNet and LSTM for using temporal information in 3D reconstruction
Use of 6DOF for reconstruction"	Presentation of the methodology is very precise, sound and clear. State of the art and problems of approaches from related work are precisely delineated. So it seems, the paper perfectly addresses the need / missing link of the given solutions. The visualizations (cf. Fig. 5) are very nice, useful and impressive.	"The paper addresses a relevant and challenging problem, namely the use of IMU acceleration data for 3D ultrasound reconstruction, which has not been done before.
The method outperforms several baselines, and an ablation study is performed to investigate the effect of the two contributions.
The references and figures are adequate and generally well-made."
135	Deep Multimodal Guidance for Medical Image Classification	The paper trained a guidance model to learn the latent representation from inferior modality to superior modality, and the classification performances slightly improved in two different tasks.	The authors present a method with ample novelty and clinical relevance. The experimental design is well motivated and described such that other researchers should be able to reproduce the results. The proposed method is benchmarked against sound baselines and findings supported by multiple well-justified metrics on two datasets centered on two different tasks.	"The main strength is the importance of the problem setting, which is very widespread in medicine (i.e., the desire to use inferior modalities to do jobs that are well performed by superior modalities).
Another strength is the evaluation, which very carefully teases out what exactly is added to task performance by superior data, inferior data that has been transformed towards superior data, and raw inferior data.  This evaluation is done on two entirely different medical data classification domains- another strength.
Clarity of writing is an additional strength.  It is difficult to get confused about how this method works or why it might be thought to work."
136	Deep Regression with Spatial-Frequency Feature Coupling and Image Synthesis for Robot-Assisted Endomicroscopy	X	"The paper is well-writen and well-organized.
The first approach to tackle the pCLE probe and tissue surface with regression. The performance outperformed other methods.
Dataset construction is helpful to the community and further experiments."	"This is the first application for pCLE probe and tissue surface distance estimation.
The authors proposed the SFFC-Net utilized both the image and frequency domain information.
The authors proposed feedback training to boost the network training, with augmented data
The results looks promising."
137	Deep Reinforcement Learning for Detection of Inner Ear Abnormal Anatomy in Computed Tomography	"Clarity in the exposition and detailed explanation of the problem and state of the art.
Great validation with manual annotations, scans with congenital abnormalities (123) and normal anatomies (300).
Results show good detection performance."	"Their proposed method is training uniquely on normative data for landmark location making it easy to adapt for other anatomies and also circumventing the need to represent the anomalies, nor have for that matter have balanced data of normal vs. abnormals. This is significant for the medical imaging case where such data are difficult to obtain.
Both abnormality measures are relatively straightforward to implement and easy to interpret. The first is a typical analysis in geometric morphometry-based anomaly detection. The second method, uses the variability in Q-values for landmark detection with the hypothesis being that normal configuration would result in a uniform distribution while abnormal configurations of landmarks would have a more varied distribution.
The authors provide tests on both synthetic and real data with compelling results for both despite a significant drop in the performance in the real dataset.
This seems to be the first work of its kind and presents a possible solution to a non trivial problem of anomaly detection in the inner ear."	"The idea of combining (or simply separately using) the PCA shape distance and the Q-value history distribution to detect the abnormality is novel.
The way to generate a synthetic set is also interesting.
The paper is well-written."
138	Deep Reinforcement Learning for Small Bowel Path Tracking using Different Types of Annotations	the method appears to be performing well. to the best of my knowledge this is a novel application of RL for this problem set	"The manuscript is well-organised and information is easy to find within the respective sections
Sufficient details have been provided in order for the work to be reproducible
The problem being solved is well-motivated and properly justified using previous work"	"It is the first DRL based method to track small bowel path, and the idea of enabling the framework to train on different types of annotations is interesting.
A customized reward calculation algorithm that incoorperate the wll detection and geodesic distance transform.
Comparison to a wide variaty of other methods (graph-based, DRL-based, and supervised learning-based methods)"
139	Deep treatment response assessment and prediction of colorectal cancer liver metastases	"treatment response prediction can help in patient stratification for a given treatment.
Ablation study to establish contribution of each component"	"Clinically relevant problem
Well-written
Proposed completely automatic system can avoid the variability caused by manual segmentation"	Applied deep learning model on longitudinal data to predict chemotherapy response.
140	DeepCRC: Colorectum and Colorectal Cancer Segmentation in CT Scans via Deep Colorectal Coordinate Transform	"Novel approach to segment CRS: the surrogate task proposed helps the model to better identify the organ and improves the results. This solution tackles a problem inherent to the task (organ with a long shape that is hard to distinguish) in a simple and effective way.

Complete experimental validation: the model starts from nnUNet and performs two major modifications: adding self-attention layers at each stage and adding the surrogate regression task to guide segmentation. Both modifications are evaluated independently and together to show their effect in colorectum and tumor segmentation.

Results reach human performance: the method obtains similar metrics to the human annotators.

Complete related work: the paper correctly places itself with respect to the literature."	"Generalisable extension of a Unet like architecture for the colon. Nice adaption of a standard segmentation approach to specific characteristics of a certain problem. In this case the length of the colon.
Appears to be a novel deep learning approach to the problem
Good comparison to the literature in table 1 that provides a clear reference and differences in the datasets
Evaluation - Good comparison to nnUNet and the impact of both proposed extensions as well as a range of performance metrics including detection rate and DSC in Table 2. This provides clear justification of the impact of the additions."	"The motivation of the paper is solid and clear;
The task of the paper is interesting and important;
The solution of the algorithm is novel;
The experimental results to some extent validate the effectiveness of the algorithm."
141	Deep-learning Based T1 and T2 Quantification from Undersampled Magnetic Resonance Fingerprinting Data to Track Tracer Kinetics in Small Laboratory Animals	"The proposed deep learning based MRF method uses a sliding-window averaging to extract spatial features and combine the use of map loss and recon loss.
The results show a 4-fold acceleration and faithful T1 mapping both before and after Mn2+ injection."	"Significance: There is a lack of computational methods development for small animals and this paper fills a gap. It convincingly shows that DL-based MRF can be applied to Mouse data and saves acquisition time by allowing a higher undersampling factor.
Validation: The impact of the different components of the network is correctly evaluated in an ablation study.
Writing: The paper is well written and very easy to follow."	"Overall, it is a well written manuscript with supporting validation.
The application of the modules with sliding-window and U-Net for MRF reconstruction is appealing.
The proposed framework has been well explained.
The method achieved an on par precision compared to the baseline method.
The ablation study is sound and validates the improvement of each component in the proposed pipeline.
The proposed work tackles the clinical need for robust MRF reconstruction from undersampled data."
142	DeepMIF: Deep learning based cell profiling for multispectral immunofluorescence images with graphical user interface	"A deep learning based framework is proposed for the cell detection and phenotyping for M-IF analysis.
A GUI is developed for the M-IF visualization."	Building accessible computation tools is essential for better biomedical research. DeepMIF enables effective cell phenotype identification in M-IF images. It also shows great accessibility with a GUI and generalizability to different panels.	The paper is well written, offer a standalone GUI capable of analysing multispectral data (up to 25 channels) and provided a very high output, higher than Resnet, Inception and other architectures. The improvement over VGG is marginal but still it is better, which is good, and at the levels they are working, would be difficult to have a higher improvement.
143	DeepPyramid: Enabling Pyramid View and Deformable Pyramid Reception for Semantic Segmentation in Cataract Surgery Videos	The paper is well written and clear in general. The use of deformable convolutions gives the model the ability to learn geometric distortions that are common in cataract surgery. The additional blocks appear to improve performance.	The main strengths of this paper are two-fold: 1) it designs a varying-angle surrounding view to extract features for each pixel. 2) It  extracts shape-wise features, which is very useful for segmentation of complex objects.	"The structure and the text of the paper is good while a clear, and
The paper contributes to the body of knowledge,"
144	DeepRecon: Joint 2D Cardiac Segmentation and 3D Volume Reconstruction via A Structure-Specific Generative Method	The idea of reconstructing 3D images and segmentations from an optimized latent embedding, as well as transfering longitudinal information, is interesting and novel. Using the generator of a GAN for decoding the latent embeddings gives a rich model for synthesizing images. The validation is thorough and shows good results on the experiments performed.	"The motivation of this work looks interesting and useful, i.e., joint 2D cardiac segmentation and 3D volume reconstruction are fundamental to building statistical cardiac anatomy models and understanding functional mechanisms from motion patterns.

The datasets used for evaluation look very large."	"Authors show the path that clinicians need to obtain a complete analysis preview of the heart.  And get to obtain graphic volume flow. 
Although it is a known problem, they propose a different solution. 
The solution shows the workflow necessary to obtain a final product for clinicians. so it could have a immediate application."
145	Deformer: Towards Displacement Field Learning for Unsupervised Medical Image Registration	"This method proposed a multi-scale structure with multi-head attention to capturing the long-range dependencies between the high-level embeddings. The results in tables 2 and 3 demonstrate that the proposed Deformer block outperforms the existing Transformer and CNN blocks by a significant margin.
Strong evaluation. This paper comprehensively evaluates the registration accuracy, diffeomorphic properties and smoothness of the deformation field of the proposed method.
The paper provides a sufficient ablation study to justify the hyperparameters choice and architectural design of the proposed DMR model.
The writing is clear and easy to follow."	The paper is clear to read.	The ablation experiments and comparison with other models show Deformer module really works. It successfully improve performances in registration area.
146	Degradation-invariant Enhancement of Fundus Images via Pyramid Constraint Network	"the paper written and explained well.
the contributions are clear.
the experimental results contain well methods, data and metrics
the method sounds reasonable"	The organization of this paper is good and clearly describes the pipeline of the task. The structure of PCE-Net is technically sound. As shown in table 2, the proposed method outperforms the existing method by a margin in terms of restoration, segmentation, and diagnosis.	The main idea of the work is to form SeqLCs (image sequences) and LPF (Laplacian pyramid features) from degraded images. The PCE-Net is to learn a degradation invariant model. The manuscript proposed a novel loss function to train the PCE-Net.
147	Delving into Local Features for Open-Set Domain Adaptation in Fundus Image Analysis	"overall the paper is clearly written and well organized.
it has a clear clinical application
it has a good comparison study with existing arts."	"1.This paper investigates the OSDA problem in the medical imaging scenario, specically for fundus disease recognition.

A novel method is proposed to perform positive transfer more precisely while avoiding negative transfer across domains, through delving into local features.
The  proposed method achieves state-of-the-art performance compared to previous methods."	"This manuscript investigates a somehow overlooked problem in UDA for medical images: open-set domain adaptation.

The design of informative region selection makes sense considering that lesions in these datasets are often localized. It is shown to dramatically boost the performance of the baseline DCC.

The proposed method is tested on two pairs of datasets, and is shown to outperform baseline OSDA methods."
148	Denoising for Relaxing: Unsupervised Domain Adaptive Fundus Image Segmentation without Source Data	"The authors present an interesting problem to solve for domain adaptation.
The paper is well-written and enjoyable to read.
Problem is well-formulated and extensive results effectively demonstrate the effectiveness."	"S1: The contribution of uncertainty-rectified label soft correction is novel, where author estimate class-conditional label error map through the confident joint matrix and obtain uncertainty map through Monte Carlo dropout. Then, both estimated label error map and uncertainty map are utilized to correct pseudo labels.
S2: Although the proposed method aims to solve SFDA problem, it can benefit many self-training based methods to alleviate the noisy pseudo label issues. Moreover, it can also be applied to unsupervised domain adaptation and semi-supervised learning tasks. Hence, the proposed method is of great application value."	"Unsupervised domain adaptation in cases where the source domain is not available is of great interest in clinical applications. The motivation of this work is clear and well described in the introduction. Related work is very well embedded throughout the paper.
The evaluation of the method and the comparison to other methods is extensive and clear."
149	Denoising of 3D MR images using a voxel-wise hybrid residual MLP-CNN model to improve small lesion diagnostic confidence	"Novelty:  Authors present a deep learning method based on a voxel-wise hybrid residual MLP-CNN model

Radiologist confirmation: two experienced radiologists confirmed that the proposed method outperforms other methods in terms of recovery of small lesions and overall image denoising quality."	"The paper has a very good structure.
The method improve image quality while restoring the details of small lesions in the  image."	"The paper is well organized and has presented enough figures and tables to support authors' ideas.
A reader study is conducted to evaluate super-resolution results and show the possibility of the using the proposed method in real-world applications."
150	DentalPointNet: Landmark Localization on High-Resolution 3D Digital Dental Models	"The coarse-to-fine strategy presented in the paper where landmark point detection is handled as an object detection problem with RPN is quite interesting.  The method is end-to-end which allows making better detection.
The experiments including variant-1 and variant 2 are useful for showing the effectiveness of the proposed balanced focal loss and curvature-constraint.
I think the results of Table 1 and Table 2 should be given with the whole dataset to show the overall performance of both normal and partially edentulous patients. Also, the number of missing teeth in the dataset should be given."	"The paper is well-organized.
The improvement seems to be promising.
The proposed is application-oriented and could be helpful for clinical use."	"Introduction of a new loss function to train the region proposal network.
Results of the proposed method were compared with two other methods using 5-fold cross validation.
The assessment of method on missing tooth/teeth was conducted using separated anatomical regions.
Results have shown significant improvement compared to the other compared methods.
The number of figures and tables are appropriate; the figures are well illustrative."
151	DeSD: Self-Supervised Learning with Deep Self-Distillation for 3D Medical Image Segmentation	The idea of cross-scale comparison sounds interesting.	"Simple idea. The core idea is to introduce deep supervision to the DINO approach. This idea is simple and easy to implement. This makes the message from this paper clear and facilitates the adaptation of this idea.

Good experiments. The paper conducted a series of experiments to demonstrate its effectiveness. I particularly like the comparison with two variants of DeSD (FC-DeSD and para-DeSD) which shows that the authors have some critical thinking in introducing deep supervision to DINO."	"This manuscript is well-written and easy to follow.
DeSD showed promising results compared with 3 SSL methods.
The ablation study of different deep self-distillation variants is interesting and insightful."
152	DeStripe: A Self2Self Spatio-Spectral Graph Neural Network with Unfolded Hessian for Stripe Artifact Removal in Light-sheet Microscopy	"The motivation (problem to be solved and why) is compelling.
The blending of optimization in both spatial and spectral domains is ingenious, and leverages the specifics of the use-case.
The proposed method appears to give better results than the baselines used (though there is little visible difference in the output images). Uncertainty measures are provided."	The paper proposes a novel extension of existing works by applying a graph neural network as a model in Fourier space together with the Bregman algorithm to optimize an energy formulation. The paper is well written, and it is compared with a wide range of existing techniques. The method appears to perform as state-of-the-art	The paper introduces a novel method to solve the stripe artifact removal which is an important problem in light-sheet microscopy. The results are very convincing.
153	Detecting Aortic Valve Pathology from the 3-Chamber Cine Cardiac MRI View	The presented method is very interesting and relies on a simple, yet obviously powerful, machine learning approach. The authors describe a multi-step network to first detect features of potential aortic valve pathologies and then to classify them. The paper is well written, easy to understand and the methodology is explained properly. I would specifically like to point out the importance of explainability in AI, which the authors have addressed with their multi-level approach.	Disease classification and the combination of machine learning and explainability are generally interesting to the MICCAI community. The evaluation is done on a reasonably sized training and testing sets.	"Novelty: the proposed approach presents novel aspects, both in terms of application (first attempt to classify aortic valve abnormalities from a single standard CMR view) and methodology (an ingenious multi-stage hybrid [deep/machine learning] strategy that mimics clinicians reasoning and provides an explainable framework).
Explainability: a key aspect for clinical practice integration, which is here accounted for with a tractable machine learning classifier (RF).
Applicability: the proposed curve-based heatmap regression (followed by a ridge detection method) seems generic and sufficiently interesting to a panoply of clinical applications."
154	DEUE: Delta Ensemble Uncertainty Estimation for a More Robust Estimation of Ejection Fraction	"well written and motivated
novel use (as far as I can tell) of Delta Method with model ensembles for uncertainty estimation
use of public dataset EchoNet-Dynamic
comparison of ResNet-18 and its use for Ensemble of Methods (EM)  and Deep Bayesian Neural Networks, and a single deterministic deep regression model (DDR)"	"The benefits of this approach over prior work are relative computation tractability especially at inference time since only one pass of inference is required and there is no special architecture required of the Deep Learning network.
The exposition is very clear. The approach is one others could easily adopt and evaluate."	"The main strength of this paper is that it proposes a memory/time-efficient estimation of epistemic uncertainty with a single feed-forward pass through the network.  The method was based on the Taylor's expansion of the expected squared error. The model parameter and the covariance matrix were determined by multiple feed forward propagation. Then during test time, on one forward computation is required to obtain the uncertainty.
The method can identify samples with poor quality."
155	DGMIL: Distribution Guided Multiple Instance Learning for Whole Slide Image Classification	"This paper models the multi-instance problem from the perspective of the data distribution of pathological slides, which doesn't need to design complex discriminative networks.
This paper is well-written and logically clear.
This paper achieves a new SOTA on the CAMELYON16 dataset, verifying the effectiveness and superiority of the method."	"The paper is well-organized and easy to follow. The motivation and method are clearly demonstrated.
The experiment is basically complete. The proposed method achieves performance gain on Camelyon16."	"+The proposed cluster-conditioned feature distribution modeling method and a pseudo label-based iterative feature space refinement strategy is interesting and can be beneficial to the community on better utilizing the MIL for medical images.

The paper is well organized and easy to follow.
The performance improvement against the state-of-the-art is significance on CAMELYON16 dataset."
156	Did You Get What You Paid For? Rethinking Annotation Cost of Deep Learning Based Computer Aided Detection in Chest Radiographs	"The findings are useful for the community to improve accuracy with minimum annotation cost.
The study is conducted on a large dataset with manual labels and comprehensive results are reported. The quantity, quality, and granularity of annotations are analyzed for both classification and segmentation.
I enjoy reading the paper. It is clearly written."	"The paper extensively analyze (two tasks, four different kinds of annotations, dozens of different settings) the effects of different annotations for chest X-ray analysis with interesting findings, which is a practical evaluation.
All models are run three times with mean and std reported. I quite appreciate this point that makes the results quite convincing."	"The paper addresses one of the most important aspects of training deep learning models in the medical domain: how to properly budget for the cost of annotation
The paper investigates not only the issues of noisy labels, but also the added benefit of providing lesion-level annotations. Previous studies in literature, such as the mammography Dream challenge, stressed that  training from image-level labels alone results in lower performance. The present paper, however, explores the topic in a more quantitative and systematic fashion
The paper is overall well written and the experiments comprehensive"
157	Diffusion Deformable Model for 4D Temporal Medical Image Generation	"generated realistic deformed images along the continuous trajectory in a 4D cardiac MRI generation;
proposed a diffusion deformable model for 4D medical image generation, which employs the denoising diffusion model to estimate the latent code;
by simply scaling the latent code, the proposed model provides non-rigid continuous deformation of the source image toward the target."	"The method utilizes a diffusion deformable model adapted from the denoising diffusion probabilistic model and can learn the spatial deformation along a geodesic path. As I know, this is the first time to use the denoising diffusion probabilistic model in this 4D data generation with a trick of deformation module.
The experimental results on ACDC dataset verified that the performance of the proposed DDM outperforms the registration based method. These experiments covered most parts for evaluation of the registration performance."	"The proposal of a diffusion probabilistic model for deformable image generation is a very interesting idea.
The experiments show that the proposed method provides an interpolation that may be plausible between the diastolic and systolic phases of the cardiac cycle."
158	Diffusion Models for Medical Anomaly Detection	"The paper is mostly well-written and clear.
The method achieves good performance for anomaly segmentation.
Most of the aspects are described in sufficient detail to enable the reproduction of results.
Denoising Diffusion Implicit Models seems a good adaptation to anomaly detection in medical images"	The key strength of the paper is the idea to use diffusion processes in medical image denoising. In this case, denoising is treated as an image synthesis problem (generate a healthy image), where diffusion models have shown to preserve more details and generate higher-quality images as compared to GANs, which are traditionally used in this domain. In addition, the experimental validation of the paper is thorough and demonstrates well the capabilities of the proposed method.	"Great and novel Idea! (I personally feel like this idea was overdue already, I was thinking about trying that for some years now as well)
Experiments on multiple datasets.
Nice analysis of the effect of the hyperparameters of the method."
159	Digestive Organ Recognition in Video Capsule Endoscopy based on Temporal Segmentation Network	The main strength of this paper is to propose a method that can possible to longitudinally segment VCE images.  Whole video can be segmented by the proposed method.	"The paper is well motivated. Anatomical transition annotation for VCE is a much needed technology to help cut down on what type of lesions and typical locations should be looked for.

There are very few other works published for this specific problem, so there might be a publication justification from this point of view.

The ablations are appreciated."	"The clinical motivation is very well set, and the application use case is very clear.
The utilised dataset is very large, it would certainly have impact if released.
The inclusion of segmental metrics in the validation is well apreciated. The exclusive focus on frame-based metrics has been a longstanding issue in surgical temporal segmentation literature, and the study of other temporal event metrics is needed in the field."
160	Discrepancy and Gradient-guided Multi-Modal Knowledge Distillation for Pathological Glioma Grading	"1, The proposed problem is clinically relevant, where one data modality is present and another is missing.
2, The problem is clearly motivated and formulated, and each component is well explained.
3, The proposed methods properly addressed the challenges of missing modality in testing time."	"The multimodal framework is highly novel and includes recent advances in computer vision in a comprehensive manner.

The results clearly show that the use of genomic information in the multimodal approaches outperform the unimodal unimodal pathology approaches.

The proposed DC- Distill is more effective at transferring the knowledge than state-of-the-art knowledge distillation methods.

While the model has many components, each one with its own technical properties and rationale, the authors explained it clearly and with the necessary formal support.

The paper is very well written."	The main strength goes to the novel idea of transferring multi-modal knowledge to unimodal model via knowledge distillation. After training, the performance of the learned unimodal model can be very close to that of the pathology-genomic model and only require histopathological images as inputs. Besides, authors also propose discrepancy-induced contrastive distillation and the gradient-guided knowledge refinement to improve the performance of knowledge distillation.
161	Discrepancy-based Active Learning for Weakly Supervised Bleeding Segmentation in Wireless Capsule Endoscopy Images	"It is important to explore means to reduce the cost of medical image annotation. The presented method, DEAL, is an promising approach. It can use only 10% label budget to achieve comparable performance to fully supervised method.

The presented method is technically sound. Its key components are clearly explained with clear formulations.

This paper presents good experiments with promising performance and informative ablation study. The proposed method and eight baseline approaches are compared on a public datasets. Promising quantitative results are reported in comparison with the baseline approaches."	"The paper proposes a new activate learning framework which selects pseudo labels according to the proposed CAMPUS criterion considering model divergence and CAM divergence.
The proposed way to measure the divergence based on different threshold values is simple and efficient. The quality of the generated annotations is a critical problem in weakly supervised learning. The proposed method considers both the model divergence and CAM divergence."	"A novel active learning pipeline (DEAL) that borrows idea from CAMs and pseudo labels and a carefully designed label selection criterion that fits the pipeline ;
CAM maps and decoder with multiple heads/predictions to tackle the noisy predictions cause by the weakly supervision;"
162	Disentangle then Calibrate: Selective Treasure Sharing for Generalized Rare Disease Diagnosis	"Network design is novel
Comparison with other existing methods
Performing Ablation study
The paper is well written"	"Clear and easy to read, with good clinical motivation.
The method is well described, interesting and properly motivated.
Comparison with six recent approaches."	The major strength of the paper is the formulation of the classification task into a few shot learning task. The concept of splitting feature maps into shared and specific features based on the gradient agreement addresses the feature disentanglement in an elegant way by circumventing the interpretability issue. From an empiric point of view, the reported numbers show the superiority of the introduced methods compared to the state of the art.
163	DisQ: Disentangling Quantitative MRI Mapping of the Heart	"(1) The proposed contrast-anatomy disentanglement framework suit well for cardiac qMRI problems as this paper promoted. Cardiac MRIs often has different object motions and contrasts across sequences, causing difficulties of quantitative mapping. Thus a disentangled representation of contrast and anatomy can help unify the baseline images, as demonstrated in experiments using T1 mapping.
(2) The writing of this paper is very good and easy to follow.
(3) Both qualitative results for disentanglement and quantitative results for baseline comparison and ablation studies showed that the proposed method is promising."	"Overall, it is a well written manuscript with supporting validation.
The application of disentangled representation for straight unsupervised registration in T1-weighted images is appealing.
The proposed framework has been well explained.
The method achieved an improved precision compared to the vanilla Voxelmorph.
The ablation study is sound and validates the improvement of each component in the proposed pipeline.
The proposed work tackles the clinical need for robust qMRI with a different, useful approach (disentanglement framework) contributing to already existing deep learning-based methods for motion correction in T1 mapping."	"A novel formulation of cardiac qMRI image disentanglement
A novel network architecture for cardiac qMRI"
164	Distilling Knowledge from Topological Representations for Pathological Complete Response Prediction	"The fusion of topology and the student/teacher network makes for 
compelling reading and the improvement in performance appears to be
considerable."	"Using topological features for breast cancer imaging is novel and can have a big impact. I really think this is a very good research direction and is underexplored.
The key advantage of the proposed method is the possibility to use topological information without computation at inference stage. TopoTxR can be very expensive as it not only computes persistence diagrams, but also computes representation cycles. I think this is a quite nice motivation and should be better stressed and supported empirically.
Empirical results reasonably demonstrated the performance gain. But I have some issues with the baselines. Will explain below."	"1 - The main strength of the paper is the incorporation of the topological features with a CNN model to outperform the state-of-the-art results in the literature. This is the first time a medical imaging study incorporates both CNN features and topological features. 
2 - Authors exhaustively report the results based on the state-of-the-art as a benchmark and they did use different strategies for knowledge-based distillation as an ablation study."
165	Domain Adaptive Mitochondria Segmentation via Enforcing Inter-Section Consistency	"The exploration of  inter-section consistency for this task stands for its novelty;
The work presents an extensive experimental section.
The paper is clear and well written."	"The authors evaluated their method on multiple datasets and compare with an extensive set of methods that exceed methods developed for this task
The authors show that their method outperforms existing methods
The paper is written clearly
The authors include ablation studies"	"The design of inter-section consistency leverages intra-domain information, which is intuitive and effective. Although enforcing the prediction consistency in general is a common idea for 3D image segmentation, it seems has not been leveraged for UDA of 3D images yet.
Both the extensive experiments on four datasets as well as the ablation experiment seem solid and convincing."
166	Domain Adaptive Nuclei Instance Segmentation and Classification via Category-aware Feature Alignment and Pseudo-labelling	"It is a simple but effective way to use the class-aware feature alignment for domain adaptation to handle different types of nuclei, because the appearance and distributions among different nuclei are large.
The ablation studies clearly present the effectivenss of the proposed methods."	"The approach is well-motivated. Although class-aware domain adaptation has been done in the machine learning communities, it is claimed to be the first time for nuclei instance segmentation and classification.
Empirical results and ablation studies show that the proposed approach outperforms other baselines."	"This paper proposed a category-aware prototype pseudo-labelling architecture
for unsupervised domain adaptive nuclear instance segmentation and
classification"
167	Domain Specific Convolution and High Frequency Reconstruction based Unsupervised Domain Adaptation for Medical Image Segmentation	"The paper is well-written and easy to follow.
The two core components are novel.
The comparison study and ablations study are somewhat thorough. The idea of DSC with a domain-specific controller to characterise domain-specific convolutional block is interesting and effective. The advantage  with such a dynamic convolution kernel design compared to shared convolution kernel with different sets of domain specific batch normalisation layers have been discussed and validated in the experiments."	"Paper is very well written and easy to follow.
The usage of resnet-18 to get the encoding of the input image for domain specifc controller is interesting.
The additional branch to compensate for the differences in the low frequency data is an apprecibale solution (more like multi-task learning).
The design of experiments is reasonable and the results are also promising."	"The design of HFR is based on the assumption that the style information is embedded in low-frequency components and structural information is embedded in high-frequency components. Therefore, the authors propose the HFR to filter out the low-frequency components where most style information locates and hence preserve the structure information for UDA, which is interesting.
The authors conduct extensive comparative experiments with eight methods, including baseline, data-level, feature-level and decision-level, to evaluate the performance of their method, which is a plus.
Fig.1 is clear and helps to understand and this paper is well-written and nicely organized."
168	Domain-Adaptive 3D Medical Image Synthesis: An Efficient Unsupervised Approach	The idea of considering 3D volume as the stacked 2D slices and applying them in a mini-batch instead of different channels is very interesting. In this way, the model size can be dramatically reduced compared to 3D based model.	"Novelty: Does not try to transform the inputs from one domain to the other, but directly trains the network on both domains.
Significance: Unsupervised and easy to implement, and can potentially be used on a number of tasks (e.g. semi-supervised training on datasets where only a small proportion of the data is paired)"	"The authors suggest a novel problem formulation that potentially enhances the development of DA and domain generalization methods.

The motivation, structure, experimental setup, and analysis (including the study of different factors) are properly detailed, creating a complete picture of the problem and approach to solve it."
169	Domain-Prior-Induced Structural MRI Adaptation for Clinical Progression Prediction of Subjective Cognitive Decline	"This work tries to solve a vital small-sample problem in medicine by means of domain adaptation.
The paper is well organized, making their contribution clear."	"(1) Feature adaptation is important for transfer learning, which is the study of this paper.
(2) The paper is well organized, and the idea is easy to understand.
(3) The performance is improved by the proposed method."	"Very well organized
Technically thorough
Great experiment design - appreciate the authors investigating different source dataset; performing ablation studies and hyperparameter analysis and benchmarking with other methods
Strong evaluation of results
Neat figures"
170	DOMINO: Domain-aware Model Calibration in Medical Image Segmentation	"This is a novel approach to tuning deep learning algorithms that can help increase deep-learning model accuracy.

Very well organized paper that was very detailed, enough to where the methods could be reproduced.

This method could be used across multiple deep-learning models, even outside of segmentation. DOMINO appears to be useful across multiple deep-learning algorithm domains.

The paper also displays a good understanding of the problem paired with a novel solution.

The authors were able to demonstrate the validity of the DOMINO framework through extensive quantitative testing measures."	"The paper is very well written, very elegant, well structured
Experiments are convincing
Motivation is quite clear"	
171	Double-Uncertainty Guided Spatial and Temporal Consistency Regularization Weighting for Learning-based Abdominal Registration	"novel formulation of dynamic regularization weighting, exploiting temporal information across the training steps
reported the state-of-the-art registration results for the 10 abdominal CT-MRI pairs
well written and clearly organized manuscript"	This work exploited the self-ensembling teacher model with the transformation and appearance uncertainty, avoiding grid searching for the optimal fixed regularization weight in the deep registration model.	The authors do effectively describe the method, which is able to produce uncertainty maps in the image registration process.  Adaptive weighting allows images which are more difficult to register to receive more attention in subsequent steps of the iterative algorithm.  Method outperforms other image registration methods in various metrics.
172	DRGen: Domain Generalization in Diabetic Retinopathy Classification	"The experimental design is sound (leave one dataset out for testing), the method is explained well and the paper is clear. The hyperparameters are reasonably well adjusted.
Honest results showing heterogeneous improvement across dataset."	The proposed method is easy to implement.	"The paper is clear and well structured. The description in the implementation details is helpful to understand the precise settings of the experiments.
The manuscript addresses a precise problem and evaluate the method with appropriate comparison to baselines and the closest method, Fishr. It is the first time that this method has been applied on the chosen dataset."
173	DS3-Net: Difficulty-perceived Common-to-T1ce Semi-Supervised Multimodal MRI Synthesis Network	"There are two major strengths in this work:

Multi-modal MRI synthesis is able to make full use of multimodal information for more accurate MRI synthesis, which therefore improves the performance over the traditional single-modal MRI synthesis.
The paper is well organized and easy to follow."	They proposed a novel difficulty-perceived semi-supervised multimodal MRI synthesis pipeline to generate the difficult-to-obtain modality T1ce from three common easy-to-obtain MRI modalities including T1, T2, and FLAIR. Difficulty-perceived maps are adopted to guide the synthesization process of important regions, and dual-level distillation enables the model to train a well-performimg network with limited paired data.	"The strengths of the paper are summarized as follows:
1) The authors introduce a semi-supervised framework to make full use of unpaired multimodal MRI data for T1ce generation based on the easy-to-acquire modalities, which demonstrates efficiency to save the cost of the paired data significantly.
2) The authors designs a specific attentional mechanism to relax the generation process so that the model focused on the important area from both pixel-wise and patch-wise."
174	DSP-Net: Deeply-Supervised Pseudo-Siamese Network for Dynamic Angiographic Image Matching	"The proposed DSP-Net processes X-ray fluoroscopic and angiographic images parallelly, achieving state-of-the-art performance on their medical image
datasets.
The designed PSAD block successfully distinguishes nuanced frames by learning the representative features and efficiently overcomes the noisy background, showing great generality to images from different sequences."	"The method proposed in this paper is novel: Use the transmissing information and the compensating details to connect the two inputs, extract the significant features, and improve the accuracy;
The comparative experiments of the methods proposed in this paper are sufficient: there are many similar methods compared, and the comparative results are more detailed."	"The dataset is constructed, in which the performance is competitive compared to other methods.
The depiction is clear with loss.
Well written and well oeganized."
175	DSR: Direct Simultaneous Registration for Multiple 3D Images	The simultaneous registration approach is expressed as a bundle-adjustment problem that allows for a Gauss-Newton solver for least-squares problems to be utilized. It's mathematical properties are thoroughly explained. This is an innovative idea that could be of interest to other researchers.	"The paper is easy to follow
Clinically very valuable
Methodology has all essential mathematical details"	"Well Written
Well Structured
mathematically well-founded
Rigorous evaluation
Code available if the paper is accepted"
176	Dual-Branch Squeeze-Fusion-Excitation Module for Cross-Modality Registration of Cardiac SPECT and CT	"1) Comprehensive evaluation but limited to artificial deformations.
2) The proposed method improves the performance for this rigid SPECT/CT registration task.
3) The paper is well written."	"The proposed method claims to propose a completely novel attention module for early feature fusion between two different medical imaging modalities before registering them using a deep multilayered module. DuSFE module is takes two inputs from a parallel convolutional backbone catering to each modality. This layer then fuses and recalibrates the features into two stages - channel-wise squeeze-fusion-excitation (cSFE) followed by spatial squeeze-fusion-excitation (sSFE). This construction offers a potentially novel way of fusing multimodal features across spatial as well as channel dimensions. 
Model performance was validated in an appropriately sized cohort of 450 individuals and the proposed scheme was compared with four different iterative and deep learning-based image registration methods."	"This paper is well-organized, clearly written, and easy to follow.
The novelty of increasing cross-modal registration accuracy by squeezing-fusing-excitating both the channel and spatial dimensions are intuitive and interesting.
The main motivation is well-supported by strong experimental evaluations."
177	Dual-Distribution Discrepancy for Anomaly Detection in Chest X-Rays	"This is the first work to include data with unlabeled abnormal and normal images.
A dual-distribution method is proposed to learn the inter-and intro- discrepancy between the two reconstructed images: from the network trained with unlabeled image datasets and normal image datasets.
The proposed method achieves state-of-the-art results demonstrating the effectiveness of involving abnormal data in uncertainty training."	"This paper can use unlabeled data and labeled data for anomaly detection, which will greatly improve the efficiency of anomaly detection, and is also very consistent with the actual situation of clinical application data.
The theoretical formula expression is also relatively clear, and the comparison experiment and ablation experiment both demonstrate the effectiveness of the method."	"The paper is mostly well-written and clear.
The method achieves good performance for anomaly detection in chest x-rays.
Most of the aspects are described in sufficient detail to enable the reproduction of results.
Authors claim this is the first time that utilizes unlabeled images to improve the performance of anomaly detection."
178	Dual-graph Learning Convolutional Networks for Interpretable Alzheimer's Disease Diagnosis	This paper makes a clear description of the dGLCN, which is a novel method to fuse the dual graphs from different group participants. The paper makes a detailed ablation analysis that make the method valid.	Problem is being posed in the context of dual representation learning. Graphs are being constructed at both the subjects and features level.	While the idea of accounting for noise in the labelling of subjects and brain ROI measurements is not new (see for example Adeli et al PAMI 2020 https://ieeexplore.ieee.org/document/8653343), doing so within a deep learning framework is intriguing. The authors nicely develop and carefully explain the model. The experiments are thorough especially for a conference paper. They consist of t-tests performed on the accuracy scores derived from repeated cross-validation applied to several classical machine learning approaches and more advanced deep learning models, and contain an ablation and parameter sensitivity study. Also the selection of ROI measures based on multiple trials is nice.
179	Dual-HINet: Dual Hierarchical Integration Network of Multigraphs for Connectional Brain Template Learning	Node-level embeddings and hierarchical module-level embeddings are fused to generate multigraph representations.	The motivations for constructing brain multigraph in a hierarchical way are sound, and the methodology introduced in this paper is valid, and with sufficient novelty. Experiments also show the validity of the proposed method.	It is very challenging to simultaneously learn the node-level and hierarchical cluster-level integrations to produce the  subject-specific CBT.
180	DuDoCAF: Dual-Domain Cross-Attention Fusion with Recurrent Transformer for Fast Multi-contrast MR Imaging	"Manuscript is well organized and easy to follow.
Motivation is clear and persuasive.
Methods are well formulated and presented.
Experiments are comprehensive and informative. The proposed method is compared to various baselines and is evaluated on different sampling strategies and accelerating ratios."	"1) The cross-attention fusion mechanism fuses the features extracted from two contrast images in a bidirectional way to harness complementary information of these two contrasts.
2) The residual-reconstruction transformer to model the long-range dependencies based on the fused feature maps in both domains to counteract aliasing artifacts and faithfully reconstruct the target images.
3) The recurrent dual-domain learning makes the reconstruction results more interpretative."	"The paper is well organized and has presented enough figures and tables to support authors' ideas.
It is novel of the proposed dual domain network."
181	Dynamic Bank Learning for Semi-supervised Federated Image Diagnosis with Class Imbalance	"The idea is relatively novel.
The overflow of the proposed method is clear.
This paper is well written.
The results of the proposed are very good."	"This work aims to address the class imbalance in the semi-supervised FL, which is an interesting task. Moreover, they consider the server with a small amount of labeled data and all clients only have unlabeled data, which is a relatively new setting in medical imaging.
Significant performance improvements.
The work is well written."	"The idea of using bank learning as a proxy task on clients is novel and interesting.
The performance improvement is effective compared with other methods."
182	EchoCoTr: Estimation of the Left Ventricular Ejection Fraction from Spatiotemporal Echocardiography	"Relevant architecture overcoming the limitations of two types of state-of-the-art methods
Use of a known and publicly available large dataset
Extensive evaluation against state-of-the-art methods and architectural choices"	"There is a novel formulation in the use of transformers to obtain ejection fraction of the heart's left ventricle. 
Authors compare their new proposal with known ones and in all give quantittative results, comparing each other and demonstrate the advantages of using transformers. 
They clarify the clinical background importance."	"The results of the paper outperform the state-of-the-art approach, which was using CNNs. The architecture used here, while not new, uses a combination of transformer and convolutional blocks. It beats the existing transformer-based approaches by a large margin.
The results are supported by a solid ablation study and compared to the relevant literature. The network architecture used by the author had never been tested for this specific task before."
183	EchoGNN: Explainable Ejection Fraction Estimation with Graph Neural Networks	"I found the paper to be strong and clinically relevant. Methodology, experiments and size of datasets are sound and sufficient.
Particularly enjoyable is the apparent simplicity of the method, at least from an architectural point-of-view. In a way, the more difficult aspects of the methodology are hidden in plain sight, facilitating clear objective functions and measures. I think the combination of tools is very clever, and yields simple and effective results.
- The paper is well written and organised. The used statistical methods are simple as a first cut, and also well presented. Supplementary material is helpful."	"This work is novel in its formulation of the GNN, and using it to generate weights for each frame of the echo video. The adjacency matrix is used for the graph convolution. These frame weights seem to align well with the cardiac cycle, in situations where the videos are of good quality. They don't seem to align well, when the video quality isn't good. So, these weights can be used to guide a clinical user when to trust the result and when not to.

Another advantage is the flexibility this model provides where a single video can be used or multiple if necessary.

They test their algorithm on a nice standard set (EchoNet), which makes it easy for comparison.

The model is also pretty light-weight, making it practically usable in POCUS settings and other resource constrained settings."	"The authors succeed in highlighting three advantages over competing models: 1) EchoGNN produces explainable indicators as to why a model fails or succeeded, which is why the authors claim that their model can indicate whether human intervention is required; 2) the framework does not rely on accurate ground truth ED and ES labels; 3) the model has a lower number of parameters to reduce computational time. 
They achieved this by implementing a Graph Neural Network, which they claim was the first time such a network was applied to echo cines in the context of EF estimation.
Quantitative results appear convincing in terms of MAE, R2 and F1.
The paper is well written, and each component explained with detail. The supplementary material and the illustrations are helpful to the reader."
184	Edge-oriented Point-cloud Transformer for 3D Intracranial Aneurysm Segmentation	"The strengths of the paper:
1: The authors present a novel method for intracranial aneurysm segmentation by edge-oriented processes. These processes include edge point classification by point-based transformer, edge point refinement by graph convolution network and hard sample mining around target boundary.
2: The authors evaluate the method on a public dataset compared to previously reported results. Effectiveness of proposed components are also studied as well.
3: The paper is well organized and the presentation of the paper is great."	The proposed aneurysm segmentation framework is new and the motivation of each part is reasonable. Better performance on aneurysm segmentation is achieved than baselines. Evaluation is performed on public dataset. The paper is well organized and easy to follow.	"The paper proposed a three-stage paradigm to achieve 3D Intra Segmentation with clearer edge boundary.

The proposed method outperforms current SOTA by a considerable margin.

The paper is well-written with meaningful figures."
185	Effective Opportunistic Esophageal Cancer Screening using Noncontrast CT Imaging	"They present a deep learning method to detect and classify esophageal tumors from noncontrast CT, a novel, non-invasive, low-cost, ready-to-distribute, and highly accurate tool, for screening esophageal cancer.
They proposed the position-sensitive full-attention layer to better use the positional information and long-range dependencies in 3D noncontrast CT, which could improve the performance over a strong baseline nnUNet model.
Compared with doctors' reading of noncontrast CT, they automated method
shows substantially higher accuracy in both detection and classification.
Compared with established state-of-the-art esophageal cancer screening methods, e.g., blood testing [11] and endoscopy AI system [14], they screening tool has comparable performance and is even more sensitive for early-stage cancer and benign tumor."	"The large dataset from 4 institutions is an important strength.
The manuscript is well-written and well-organized."	"The main strengths of the paper:
(1) One novel effective opportunistic esophageal cancer screening model. The position-sensitive full-attention layer could improve the nnUNet performance. 
(2) Very detailed experiments and discussions.  A. The authors implemented the two-class classification and three-class classification experiments respectively (see Table 1). B. The detailed experiments comparison with other algorithms and readers (see Fig.3, Table2, and Table 3).
(3) The strong evaluation (see Table 1-3 and Fig.3).
(4) The big dataset and strong annotation would ensure the study's quality."
186	Efficient Bayesian Uncertainty Estimation for nnU-Net	"Comprehensive literature review;
Novel with utilization of network checkpoints at various training epochs;
Comprehensive evaluations;"	The main strength of this paper is that it fills a gap in DL community by providing an uncertainty estimation method for the nnU-net architecture.	"The paper is well-organized and easy to follow.
The idea is neat and it can have border impact once code is available, as it is integrated into the popular nnU-Net framework.
The improvement in the ECE metric is significant, although the gain in the segmentation performance is relatively marginal compared to Deep Ensemble."
187	Efficient Biomedical Instance Segmentation via Knowledge Distillation	"1.Clear explanations. The authors present their ideas clearly, making the paper easy to follow
2.Thorough experiments. The authors compare the proposed method with several typical segmentation models."	"Novel idea to enforce both instance-graph consistency and pixel affinity consistency
evaluation on difficult datasets clearly shows the method superiority
the paper is very well written and illustrated"	The ideas of instance graph and pixel affinity distillation is novel, since it explores a different aspect of knowledge distillation where high-level representations of feature maps are used to transfer knowledge from teacher model to student model.
188	Efficient population based hyperparameter scheduling for medical image segmentation	the method to use multiple checkpoints, and retraining models to populate the configuration space for  TPE appears to be a novel application for hyperparameter optimization	the claimed reduction of computation cost to 3%-10% of original PBT is impressive	The paper uses an existing technique to solve a practical hyperparameter tuning problem. There is potential value to applying it in many other applications and accelerating the development of new deep learning models in the future.
189	Electron Microscope Image Registration using Laplacian Sharpening Transformer U-Net	"interesting use of Laplacian sharpening of skip connections
interesting use of Transformer-based Swin-UNet for capturing more long-range semantic information with the Transformer modules.
comparison to SOTA (designed for different purposes though)"	"Integration of an adequate filter (Laplacian sharpening) for the nature of the images to analyse in the skip connections.
The authors introduce the idea of fine tuning the results by processing the output result with the trained architecture (cascade processing)
The authors benchmark their proposal with existing state of the art methods."	"Clear motivation and approach integrating three orthogonal ideas from related work.

Ablation study demonstrating improvements due to each architectural choice."
190	Embedding Gradient-based Optimization in Image Registration Networks	"The main strenghts of the paper is the original way to combine iterative registration and deep learning based registration.

The proposed formulation have better performance on out of domain distribution or with a decrease of the training dataset  than competing methods."	"The authors propose a method to combine deep-learning and conventional image registration to further improve the results obtained by the DL-Reg
The experiments show promising results.
The paper is well written.
A reasonable selection of metrics was made to evaluate the quality of registration (Dice, HD, detJ, std(detJ), runtime
the authors perform further evaluations on data efficieny and domain robustness."	The method presented by the authors is motivated by classical image registration techniques. In the work, they extend conventional deep learning  ased image registration methods with an update step motivated from image dissimilarity. This approach appears promising. The methodological foundations of image registration are explained in detail, thus motivating the newly added step. The method section takes enough space for motivating the individual building blocks. Another point worth highlighting is the use of clinical data to validate the new method. 2D and 3D data representative of current clinical issues (cardio and neuro) are used. These data are not only used to show the own strengths, but a comparison with current methods (classical and AI) is performed. Another strength is the experiments on data efficiency and domain robustness.
191	Embedding Human Brain Function via Transformer	The work provides an approach on representing regularity and variability of human brain function in a  latent space.	A good implementation of introducing cutting-edge computer vision and natural language processing technology to medical image analysis. This submission provides an option of analyzing medical time series data via transformer.	"The paper is well written, easy to follow and the method and task are well motivated.
The method is simple and sound.
The results demonstrate the benefit of the proposed approach over a simple auto-encoder, for a limited computational cost increase."
192	End-to-End cell recognition by point annotation	1 The proposed methdod achieves competitive results on PD-L1 IHC stained images of tumor tissue.	"This paper is easy to follow and the cost function is explained in detail.
Then contribution is sufficient. It deploys the pyramidal features aggregation and the cost function integrate the detection and regression and classification loss.
The experiments are sufficient and clearly shows the improvements."	"The authors proposed a novel multi-stage cell recognition method, using the point labels. The framework consists of several key improvements, Pyramidal Feature Aggregation, Multi-task Learning and Proposal Matching.
Experiments suggest the proposed method can provide better performance."
193	End-to-End Evidential-Efficient Net for Radiomics Analysis of Brain MRI to Predict Oncogene Expression and Overall Survival	The manuscript has multiple strengths: (1) tackling a clinically meaningful problem that can potentially alter management of glioblastoma patients; (2) a novel formulation and application of the EDL model to fuse high-dimensional features from multiparametric MRI scans; and (3) superior performance of the model compared to other state-of-the-art.	"(1) The idea of this paper is easy to understand.
(2) The end-to-end evidence-efficient net is proposed to simultaneously classify the methylation status of MGMT and predict OS."	The proposed method to integrate the uncertainty to the final prediction score is the main strength of this paper. This method was well developed and described. It was tested on comprehensive datasets and the results were well analyzed. External comparison against several advanced models were done that show the superiority of the model.
194	End-to-end Learning for Image-based Detection of Molecular Alterations in Digital Pathology	The authors have indeed identified an important challenge for digital pathology tasks, identifying which areas in an image are important for classification. In addition, they use the EfficentNet model a backbone model that has significantly less parameters than other comparable models.	Interesting results using k-siamese networks	Proposing a variant of Siamese CNN to make a decision based on k samples instead of two samples which is generally done by a normal Siamese network.
195	End-to-end Multi-Slice-to-Volume Concurrent Registration and Multimodal Generation	Very well written paper, thorough introduction of related work & own contribution, method description, detailed and systematic evaluation on a large data set.	Problem important in medical practice	"Novel end-to-end approach for adversarial method coupled with registration, similar adversarial methods were previously used as an intermediate step to generate synthetic data.
The large difference in texture resolution between the two datasets used demonstrates the potential for generalization of the method.
The parameterization of the basic methods was optimized for fair comparison."
196	End-to-End Segmentation of Medical Images via Patch-wise Polygons Prediction	"*	Using neural renderers in a segmentation task is novel.
*	The method is evaluated on several challenging benchmark datasets and achieves top performance."	"1.This paper adopt a neural renderer to translate the polygons to binary raster-graphics masks for optimization purposes of current activte contour methods.
2.The method achieves considerable results on both medical image datasets and a non-medical dataset."	"The proposed method for medical image segmentation is novel in the way that it is not directly output pixel value segmentation but a geometry representation instead. 
To make this formulation trainable, the author use neural renderer to convert the representation into pixel map where cross entropy and dice loss can be applied."
197	Enforcing connectivity of 3D linear structures using their 2D projections	"Interesting, novel approach to ensure connectivity in elongated structure segmentation
Smart way of incorporating a recent, successful 2D region separation loss in 3D segmentation
Good validation showing convincing improvements compared  to logical baselines as well as to previous methods proposed to improve topological correctness"	"effective translation of technology from 2D satellite image analysis (with its focus on connectivity for street network analysis) to 3D medical image analysis
elegant solution to prevent gaps in the segmentation of linear structures"	"The authors have done a detailed evaluation of three datasets and achieved an improved topology-aware score over existing topology-aware loss functions.
The method can offer 3D segmentation from 2D annotation."
198	Enhancing model generalization for substantia nigra segmentation using a test-time normalization-based method	The authors proposed a novel way to use test-time normalization. An affine transformation and histogram matching are used to normalize the input query. 84 cases were used for training, 52 for testing, and 20 for validation.	"This paper is extremely detailed in writing every step taken to create the model, run the model, and even the values for each hyper-parameter used and tuned. This makes the methods highly reproducible. Although the model was trained on in-house data, which is not accessible to others outside the lab, anyone trying to reproduce the method could use the 2 open-source databases of images the paper mentions, to train and try out the model.

This is a novel approach to getting accurate segmentations of the substantia nigra without using an atlas or without using imaging such as a neuromelanin scan. T2w, as mentioned by the authors, is not typically an imaging modality used for this kind of segmentation, however, this is an image that is typically acquired, clinically, next to the T1, and therefore is more readily available in open-source datasets.

This definitely has clinical relevance, as being able to segment the substantia nigra and potentially perform some quantitative metrics such as size or any other relevant clinical feature metrics can be of great value.

For the most part, every step of the pipeline is explained really well. The reasoning behind including steps, such as histogram matching, is also explained really well in the 'Discussion' section."	"A novel TTN method based on spatial and intensity attributes for accurate SN segmentation and better model generalization.
Prior atlas-based likelihood estimation to examine the segmentation output on unlabeled datasets.
Fair comparison of the proposed work against the research being done in this application."
199	Ensembled Prediction of Rheumatic Heart Disease from Ungated Doppler Echocardiography Acquired in Low-Resource Settings	"I like the focus of the work on the low resource setting, which is an issue that is often overlooked in the research literature.
The paper is generally well written and easy to understand.
The authors have put together a pipeline that seems to be robust and performs similarly to human experts."	"The paper is very well written.
The clinical motivation to use ungated Doppler to diagnose RHD in low-resource settings is compelling and significant.
The deep learning stragegy is logically motivated.
Evaluation is on a relatively large point-of-care dataset.
Performance of automated RHD diagnosis is on par with expert clinical assessment."	The problem is relatively new, interesting, and has not received much attention, but it would have great potential and impact.  There are few works on automatic RHD diagnosis with CDE; the most related one is [Ref. 19] in the paper. This study focuses on CDE by hand-held ultrasound devices, which are low priced and easy to deploy in low- and middle-income countries. This work is very practical and can benefit people, especially children, who live in low-income conditions. Our community probably would pay more attention to this kind of study.
200	Estimating Model Performance under Domain Shifts with Class-Specific Confidence Scores	The description of the method is clear.	"Performance estimation on new, unlabeled data is a highly relevant problem for implementing trained machine learning models into clinical routine. The miscalibration of overconfident classifiers is another problem on its own. The authors tackle the first problem by solving the latter, which is an interesting approach. Existing methods are extended by class-wise confidence calibration, which helps to improve performance estimation.
The proposed method is extensively evaluated on different classification and segmentation datasets with introduced domain shift. The authors clearly show the benefit of global vs. class-specific calibration in Tab. 1."	"The evaluation is very thorough and for multiple use cases (classification and segmentation). The data corpus includes many publicly available datasets.

The results show a clear improvement after taking advantage of the proposed modification.

The paper follows a clear structure and maintains good writing quality. The authors clearly state how their method is different from existing ones and the math is rigorous. Figure 2 also provides a nice summary. Only very limited prior knowledge on the topic is required to understand the paper. The authors also explain how they adapt their methods to image segmentation."
201	Evidence fusion with contextual discounting for multi-modality medical image segmentation	The paper estimates the importance of each input (different MRI modality), without treating them equal (common practice), which is to help with the final accuracy.	"The authors proposes a multi-modal deep learning and DST based framework or brain tumor segmentation.
They investigated the contribution of each module component in their framework.
Quantitative and qualitative evaluation was provided."	The paper designs an evidential segmentation module based on Dempster-Shafer theory and an evidence discounting mechanism take into account the ability of each modality.
202	Evolutionary Multi-objective Architecture Search Framework: Application to COVID-19 3D CT Classification	"The author proposes a new objective which can be optimized during training, namely potential.
By mutating and cross-overing operations, the author balances the exploitation and exploration during weight training step.
Numeric experiment shows the effectiveness of the method."	"The use of ""potential"" for evulation-based neural architecture search seems interesting and novel, at least in the context of medical image classification.
The paper is well-written and interesting. The application is relevant to the medical imaging community."	"This paper tackle an important problem as NAS instability is a big issue for neural architecture search.
The experiments show a improvement over three public COVID-19 3D datasets."
203	Explainable Contrastive Multiview Graph Representation of Brain, Mind, and Behavior	A lot of fancy features in the model: dynamic, heterogeneous, explainable, causal model...	In general, this paper is comprehensive and technical sound that will surely inspire future research along similar lines. The main message is brought across fully supported by the presented results.	the fusion manner of multimodal imaging in the paper is novel, effective and interpretable, which shows great potential and extensibility in many related clinical tasks.
204	Explaining Chest X-ray Pathologies in Natural Language	"The paper proposes an interesting extension to the MIMIC CXR dataset and a general method for producing such extensions. 
Both numerical and clinician evaluations are performed."	"- a new dataset is presented and will be useful for community
- presented an approach to provide NLEs for multi-label classification
- evaluation is validated by a clinician."	"The paper is interesting. It proposed to fully capture how evidence in a scan relates to a diagnosis. Specifically, the predictive model aims to detect lung conditions and explain their reasoning in natural language.
The new dataset MIMIC-NLE (38,000 high-quality NLEs from the over 200,000 radiology reports) can be served as an important resource that provides chest x-rays with diagnoses and evidence labels and NLEs for the diagnoses.
The paper proposes the first general approach to provide NLEs for multi-label classification, that encourages new research on  NLE for chest X-ray interpretation."
205	Exploring Smoothness and Class-Separation for Semi-supervised Medical Image Segmentation	"The paper is very well organized.
The motivation and ideas of the two losses are clear and straightforward.
The proposed methods are helpful as verified in the experiments."	"I found this paper well-written and easy to follow. Especially, it is good to use a toy exemplar data to help readers understand their two key insights and motivations.
The combination of VAT-based strong perturbation with class separation is well linked to their two insights.
The experiments are well designed with rigorous ablation study.
The method will not introduce obvious computational complexity."	"Two different datasets are used for evaluation.
The proposed method has been compared to five other semi-supervised segmentation methods."
206	Extended Electrophysiological Source Imaging with Spatial Graph Filters	The strength of this paper is to project the problem in a subspace with lower frequency, and ask for temporal and spatial regularisation, that is feasible thanks to the representation of the problem with graphs.	The method proposed is novel and the  results presented are very convincing for the need of the method. The rational - starting point of the method used makes absolute sense and overall is a well written- well structured paper.	In general, this paper is technically sound and the topic is interesting.
207	FairPrune: Achieving Fairness Through Pruning for Dermatological Disease Diagnosis	"This is a new way of debiasing a model that is conceivably more stable and efficient than the adversarial strategies. It does not require re-training the model.

The results are relatively comprehensive on two large datasets."	"The paper is well-written and easy to follow.
The method is intuitive and has clear motivation.
Bias in machine learning datasets is a critical issue, thus there is wide clinical applicability for the approach, specially since it has the additional benefit of smaller models after pruning.
The related work section gives a good overview and taxonomy of the existing methods for the task of overcoming dataset bias.
There were many comparative baselines from different de-biasing method categories."	"As far as I know, the proposed idea of using pruning to improve fairness is novel
The paper is well-written and easy to follow
Experiments are extensive and include analysis of the effects of key hyperparameters"
208	Fast Automatic Liver Tumor Radiofrequency Ablation Planning via Learned Physics Model	"Combining biophysical models and machine learning is a recent and developing area of research and the authors have made a good work in connection to planning of RFA
Predictions were accurate and matching closely those using spherical models while taking into account patient-specific data
Inference time similar to those of spherical models"	"(1) This work focused on an important challenge on the automatic planning of RFA, i.e., how to estimate ablation zone quickly during planning with considering biophysical effects.
(2) The authors proposed a noval method to enable fast, biophysics-based RFA planning. The authors considered the simulaiton as an ""operator"" and they used an operator learning approach. This is a new formulation for heat transfer simulaiton, which is interesting for MICCAI community, especially for computer assisted thermal ablation.
(3) The results of the proposed method were constent with the simulation using finite difference solver, which showed that the proposed method has the potential for fast estimation of theraml ablation."	The work is well justified and solid, with thorough evaluation. The authors address an important and interesting problem in the domain of treatment planning. The approach, which is much faster, has potential to significantly improve planning for RFA and treatment efficacy. .
209	Fast FF-to-FFPE Whole Slide Image Translation via Laplacian Pyramid and Contrastive Learning	"The paper is well written and it is easy to follow.
The method is clearly explained
The idea of using Laplacian Pyramids even though already used in natural images, has not been exploited in Digital Pathology.
*Good ablation study"	"The motivation for the work looks interesting. Collecting FFPE takes tremendous time when comparing it with acquiring FF.
The work focused on providing a framework with efficient computation resource usage, i.e., training time and memory usage."	The paper is generally well written, with a clear rationale and proposes a methodology that revisits the oldie-but-goodie technique of the Laplacian Pyramid. The methodology allows the use of larger patches (from 512x to 1024x and 2048X) which indicates a more compact use of memory. The processing is also much quicker than alternatives.
210	Fast Spherical Mapping of Cortical Surface Meshes using Deep Unsupervised Learning	A spherical mapping is key in many surface-based analysis for cortical surface registration, parcellation, etc. In this paper, a fast spherical mapping was proposed that significantly reduces the computing time over the classic approach such as FreeSurfer. The approach is non-supervised, which is also an advantage of the proposed method.	"Efficiency: proposed framework runs fast.
Clear writing: the paper is well written."	In this paper, the authors proposed a novel framework based on Spherical U-Net for spherical mapping of cortical surface meshes. Compared with FreeSurfer, which is the most popular tools for brain images, the proposed method have fewer distortions and achieve a speedup for more than 200 folds.
211	Fast Unsupervised Brain Anomaly Detection and Segmentation with Diffusion Models	"The method using latent DDPM for unsupervised medical image analysis is new as there are limited works in this field.
The proposed method is simple and seems reasonable.
The proposed methods are evaluated on four public MRI and CT datasets. The experiment results show an improvement for some cases in an efficient way.
The organization of the paper is also good."	"The proposed pipeline is methodologically sound and very suited to the application. It is interesting that the introduction of DDPM significantly improves the performance of VAE-based methods.
The authors performed evaluations on three different synthetic and real datasets, which is comprehensive. The detailed supplementary material and the nice video add to the thoroughness of the paper.
The evaluation of the inference time demonstrates its clinical feasibility.
This paper is well-written and well-organized."	"The authors propose a clever solution to segment anomalies in an unsupervised manner combining two state-of-the-art techniques for image synthesis. The idea of compressing the original image into a latent space and then correcting that representation by making it closer to the previously learned healthy distribution is an interesting one.
The model is tested with different public datasets with different types of anomalies (lesions) ranging from small lesions to tumors. Furthermore, execution times for a time critical approach are also provide to further validate the proposed method."
212	Feature Re-calibration based Multiple Instance Learning for Whole Slide Image Classification	"The paper is well written and clearly states the objectives of the work.
The idea is simple but effective."	"The problem, idea and proposed solution are clear. Specifically, the application of feature re-calibration for producing balanced bags is interesting.
The organization of the paper is good."	The study objective is interesting. The authors used multiple instance learning for image classification and to solve ground truth labeling issues. The authors worked on the benchmark datasets. The authors reported that their approach outperforms the existing methods on CM16 and COLON-MSI datasets in terms of accuracy and AUC. The density plots between normal vs tumor and MSS vs MSI seem significant.  The authors checked the performance of their algorithm by varying some loss functions.
213	Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer's disease detection	"The paper is well-written
Hyptheses are clearly stated and tested
Findings show no sex-dependency"	Analysis by gender in the classification of subjects with AD/HC, pMCI/sMCI.	"The problematic is important as it has been shown in other contexts that sex differences can bias classifiers and many works focus on Alzheimer's disease computer-aided diagnosis/prognosis.
The experimental setup seems sound and well designed to answer the proposed question.
The results seem solid and well explained.
The paper is clear and easy to follow."
214	Federated Medical Image Analysis with Virtual Sample Synthesis	"The main strengths are summarized as follows:

Easy to follow.
VAT introduced to federated learning for data synthesis is interesting.
Comprehensive comparison experiments."	"(1) The paper is well written and easy to follow.
(2) The idea is novel. It is simple but effective. The synthesis of local and global samples can be done locally thus does not introduce extra communication cost.
(3) The evaluation is good to prove the effectiveness of the method."	"This paper aims to tackle the important problem of data heterogeneity in federated learning.
The idea of using the local model and the global model to synthesize virtual training samples is novel and interesting.
The motivation for improving the client-side training by using the virtual samples is well demonstrated.
The paper is well organized and the writing logic is clear.
The method is validated on multiple datasets and achieves large performance improvement on the Camelyon dataset."
215	Federated Stain Normalization for Computational Pathology	"The proposed method only includes 1x1 convolutions, which appears to be well-suited to the task of stain normalization. This is an interesting adaptation of more generic architectures to this problem, with benefits of fewer parameters to be shared. The Many to one to Many formulation of the GAN seems to be a novel approach that offers benefits over other approaches that do not scale as efficiently with more stain varieties.
The displayed results certainly seem to be compelling when compared to simpler FedAvgM approaches."	this work introduced a GAN-based architecture for staining style transfer, and combining Federated learning for across laboratory training in a privacy-preserving manner	"The idea to apply federal learning paradigm to computational pathology can really be of great practical importance. In this regard, the authors offered solution for the major obstacle: how to solve problem created by different privacy-protected staining-styles protocols in laboratories supposed to cooperate in creating large datasets necessary for deep networks training.
The main novelty is architecture of BottleGAN following Many-One-Many paradigm.  That allows staining style transfers between clients using only two generators and two discriminators. That is in a strong contrast with the existing solutions such as Stain-GAN and Star-GAN-based. For K clients, they respectively require K and K^2 generator-discriminator pairs. Regarding generator architecture, it is based on 1x1 CNN without pooling and skip connections. Since there is no long-distance correlation modeling between the pixels, the architecture is independent on the size of the input image. Two discriminators have different roles. First one to decide whether an image is destained or reference stained, and second one on a particular staining style.
The main strength of proposed concept is capability to implement federated learning paradigm in computational pathology by solving problem where different laboratories (clients) have their private (non-shareable) staining styles."
216	FedHarmony: Unlearning Scanner Bias with Distributed Data	"The paper is readable and the main themes readily understood. Also, the topic is current and interesting. Privacy-preserving data integration from images is helped by this approach in terms of unlearning scanner bias.
The testing performed on the ABIDE public dataset is reasonable, making use of the the T1 MR structural datasets. The 5-fold cross validation performed is appropriate and useful results are reported in the Tables.
Using age prediction from T1 MRI as the task, the mean absolute error (MAE) shows incremental improvement in accuracy over alternative strategies (e.g. FedProx or FedAvg) in both the fully supervised and semi-supervised cases, but the key new result is that the new approach (FedHarmony) reduces the ability to identify the scanner site where the individual data were acquired to close to random chance.
The PCA diagram in Figure 3 helps to further illustrate that FedHarmony moves to limit the ability to identify different scanner sites."	"Very timely work as federated learning is a key enabler of large scale medical imaging studies.
Simple method with high practical value.
Results are promising in the example shown."	"The paper is clearly written.
Experiments are thorough. MR images from four sites are used in evaluation, and ablation studies are conducted."
217	Few-shot Generation of Personalized Neural Surrogates for Cardiac Simulation via Bayesian Meta-Learning	"The proposed learning framework is new as it learns the process of learning a personalized neural surrogate from a small number of available data of a subject.
The proposed method is evaluated in synthetic and real-data experiments"	The paper targets cardiac simulation, an important problem in electrophysiology, and sophisticatedly designs advanced machine learning algorithms, which perform better than the baselines.	The meta learning framework demonstrate better adaptation performance when the support set is small.
218	Few-shot Medical Image Segmentation Regularized with Self-reference and Contrastive Learning	The main idea of this paper is clear and easy to understand. Authors properly incorporate contrastive learning techniques into existing few-shot segmentation method and successfully improve performance. And they show relevant quantitative and qualititative results.	The main strength of the paper is the use of contrastive learning in order to generate more discriminative prototypes. Also, they use this technique simultaneously with other techniques such as novel self-reference loss, and recently proposed ones such as local prototyping and self-supervision. The use of contrastive learning paired with prototypes for segmentation seems to be a fully novel idea that yielded consistently better results than baselines.	"The proposed methods are simple and effective on the two tested datasets.
The self-supervision method is simple and straightforward as it can be easily applied to any other datasets and network architectures.
The paper is well written overall."
219	FFCNet: Fourier Transform-Based Frequency Learning and Complex Convolutional Network for Colon Disease Classification	"-A complex network is applied to colonoscopy images for classification, which suppose to deal with brightness/speculation in images. 
-Images are sliced so that local information can be obtained for better classification through the network."	"The motivation of utilising frequency learning for colon diseases classification is well stated and interesting.

The patching before DFT may alleviates the lack of local features in frequency learning and generates smaller numerical distribution in frequency domain, which may improve training stability.

They carry out extensive experiments to justify the improvement of the proposed method over baselines and the contributions of critical designs."	"Overall the approach is rather interesting from a technical novelty point of view. It is exciting to see a method pushing into other areas beyond just CNNs and Transformers, even if the performance isn't particularly spectacular (similar to some simple CNNs).

The experiments and ablations are thorough and can be helpful in understanding this fairly novelty approach when trying to apply similar techniques to other domains."
220	Fine-grained Correlation Loss for Regression	"1,This paper proposed two novel correlation losses, which are crucial for various image regression tasks.

The presentation is acceptable and the readers can follow this work easily."	"* The study is well-motivated, and the manuscript is well-written.
* The method and experiments are explained clearly.
* The idea of using PLC as the loss function and making it robust to outliers, as well as providing a smoother cost function by introducing the Coarse-to-Fine optimization strategy seems interesting."	"The organization of the paper is very good.
Technical novelty:
a.	In the first part, the regression branch, the authors use PLC between prediction and target, mean, variance as loss for normal samples. This idea is straightforward since the PLCC is an evaluation metric for regression tasks, but using L2 loss for outliers can avoid misleading, which is a simple and effective idea.
b.	In the second part, the similarity rank branch, the authors combine contrastive learning methods and ranking order constraints to give a coarse-to-fine learning strategy.  This strategy forces the features also in ranking order as the prediction. Instead of positive and negative sampling in classification, the authors use the ratio of regression label as supervision information, and use the difference of the ratio as an adaptive margin.
The visualization in the supplementary explains how the method works intuitively."
221	Flat-aware Cross-stage Distilled Framework for Imbalanced Medical Image Classification	"Data imbalance is an important problem in medical image analysis.
The proposed method is reasonable and novel.
The paper is well written.
The proposed method is evaluated on two public imbalanced datasets.
The comparison experiments are comprehensive."	"The proposed methods are well motivated and constrcuted
Good performance on two large datasets with well-designed experiments / ablations."	"Good clarity and formulations.
The proposed FLM technique is interesting and obtains significant improvments through the ablation study results.
The proposed methods consist several main components, which can be well plugged into many other state-of-the-art methods with further improvments on the performance.
Extensive experiments on two public datasets. The comparison study covers most of popular methods in long-tailed learning and imbalanced classification benchmarks."
222	Flexible Sampling for Long-tailed Skin Lesion Classification	"The paper is well written and the ideas are clearly presented
The curriculum idea in sample selection overall makes sense in general
Authors support their idea with extensive experimental results"	"the representation and orgnization of the article are nice, figures are clear.
the topic of learning from long-tailed distribution is hot and important. Long-tailed data is a common problem in medical imaging.
authors provide a novel way toward long-tailed distribution learning. It establishs an anchor set based on balanced representation learned from SSL. This anchor set is key for the method to outperform the others. Such a sub-set helps to fairly evaluate the difficulty/uncertainty of the samples, and thus facilitate the learning from imbalanced data.
the experiments comparing with SOTA methods are comprehensive."	Overall, the paper is well written, the experiments are easy to follow, and the results are presented clearly and concisely. The paper is technically sound, and all the equations reflect the key elements to understanding the proposed method. The comparative study is well executed and contains adequate baselines to compare thoroughly with the state-of-the-art.
223	fMRI Neurofeedback Learning Patterns are Predictive of Personal and Clinical Traits	This writing is easy to understand and the organization is good.	"This has novelty and the research is creative
The application to mental disorders is no too far away, since the amygdala is a clear structure for fear/anxiety related symptoms.
Neurofeedback is a strong candidate for self learning"	The way of predicting data in Amygdala from non-Amygdala regions and using the prediction error as one of the traits predictor is novel and interesting
224	Free Lunch for Surgical Video Understanding by Distilling Self-Supervisions	"Well-organized and well written
The idea of using knowledge from larger dataset to improve task solving where the dataset is small is relevant in general and especially for surgery videos, where the annotation is particularly time-consuming and definitively require expertise.
The underlying assumption (""using the same backbone and self-supervised learning method, the model trained with ImageNet data can yield a comparable performance for surgical phase recognition with that trained with surgical video data"") is tested and verified numerically.
There is no new component, but the combination is new and its application as well.
The strategy of semantic-preservation is experimentally verified by the ablation study and makes intuitively sense.
The experimental section is well furnished: 2 datasets and several appropriate metrics."	"This is a well-written paper with clear motivation, description of methods and experimental validation on publicly available datasets.
The paper proposes a novel training technique to leverage large-scale publicly available datasets to enhance performance in surgical video segmentation tasks. The method is well described and compared with other SOTA approaches.
Experimental validation and ablation studies are reasonable and reproducible on publicly available datasets."	"The paper presents the first study using the state-of-the-art self-supervised approaches in the surgical domain.
The proposed two-stage self-supervised training approach provides improved results."
225	Frequency-Aware Inverse-Consistent Deep Learning for OCT-Angiogram Super-Resolution	"The novelty is clear by integrate spatial and frequency domain information in the GAN.
This paper has several Architecture and illustration figures to enhance readability"	"The paper proposes an unpaired OCTA image enhancement framework to enhance 6x6-mm image quality by learning high-frequency information from 3x3-mm images.
The paper constructs super-resolution networks to enhance OCTA image quality from the perspective of frequency domain decomposition."	It is interesting that this work decomposes and processes the data and thus optimize the network from the perspective of frequency domain.
226	From Images to Probabilistic Anatomical Shapes: A Deep Variational Bottleneck Approach	The main strength of this study lies on the novelty of the proposed methodology, which relaxes the linear dependence assumption in existing PCA-based methods. Better calibrated aleatoric uncertainty quantification was achieved without comprising the shape modeling quality. This study is an advance in statistical shape modeling (SSM) and has a great potential to be used as a research tool for SSM analysis.	"The proposed framework is novel and the difference to the related works are also clearly explained.
The validation experiments are well designed."	"(1) Thorough explanations for proposed vs previous methods
(2) Good shape-predictive performance and uncertainty estimation of the proposed method
(3) Simple architecture / Loss (Conv/MLP and VAE ELBO loss with a \beta term for KL divergence)"
227	FSE Compensated Motion Correction for MRI Using Data Driven Methods	"Motion corrupted FSE images were simulated by accounting for MRI acquisition, which improves the realistic representation of training data.
The proposed approach was compared with the models trained by naive motion corrupted FSE image, showing its superiorities."	"Well-structured
Clearly motivated
Neat figures"	"The paper pointed out a critical problem in existing motion simulation methods in MRI, and proposed a reasonable way to solve it. The motivation is clear and sound.
The idea of taking into account the effects of FSE when simulating motion is insightful and interesting. The proposed method is simple yet effective, achieving  superior performance for motion correction compared to conventional method."
228	Fusing Modalities by Multiplexed Graph Neural Networks for Outcome Prediction in Tuberculosis	This paper is well written and contains clear descriptions, explanations, and illustrations throughout. The use of multiplexed graph neural networks for multi-modal fusion appears to be novel, and the rationale for its use is intuitive and sound. The clinical task, data types, and sample size are appropriate for testing multi-modal fusion for classification. The results demonstrate that the proposed framework was consistently the best performer across the 5 different outcomes.	"Demonstration of the method was done on a complex dataset which is ""truly"" multimodal, with 5 modalities: CT/Genomic/Regimen/Demographic/Clinical data. It would be great if authors, along with their method (which apparently will be open-sourced), also published their pre-processing pipeline which extracts latent representations from the individual models (e.g. genomic vector representation from genomic sequence raw data). This in itself is a complex task wihch requires domain knowledge from several experts. It would also short-cut the entry of new teams into this dataset and multi-omics fusion. If the data was already present in tabular form, and pre-processing only constituted in modality-wise d-AEs, please ignore this suggestion.
Authors propose to use Multiplexed-GNNs as a novel approach for latent fusion method. As far as I understand, its strength comes from the capability of the model to find salient correspondence across sub-dimensional feature spaces of the input modalities. Multiplexed-GNNs are theoretically well founded, a foundational book is cited in the paper for further study.
Strong baseline analysis, comparing 7 latent fusion methods. Two methods serve as ablation study - one model replacing  Multiplex-GNN with Relational-GCN, the other removing the latent encoder.
Statistical robustness of results by comparing AU-ROC values by a DeLong test and reporting p-values.
Convincing results on the Tuberculosis dataset, with consistent performance of Multiplex-GNN on all 5 classes (and weighted avg)."	"-A large number of baseline models (including one using a monoplex graph representation)  are considered and experimented on
-The proposed model shows statistically significant improvements over the baseline models for the majority of the comparisons
-Dataset is relatively large with 5 types of clinically relevant data for patients"
229	FUSSNet: Fusing Two Sources of Uncertainty for Semi-Supervised Medical Image Segmentation	"I like the main idea of using both aleatoric and epistemic uncertainty in the semi-supervised learning framework
The comparative validation and ablation study are generally good (but see concerns below)"	"The evaluation is detailed on two different datasets showing slight improvement over previous methods, which has clinical relevance.
The novelty of this paper is limited, as explained below. However, the ablation regarding PL and CR is interesting and can be helpful to other student-teacher unsupervised learning settings."	This paper addresses uncertainty at various levels, which contributes to an important trend that emerged over recent years in the MICCAI community. The way uncertainty is exploited here in the context of anatomical segmentation appears meaningful to allow learning useful features from both labeled and unlabeled data, in particular in challenging regions of the image (organ borders, noisy regions, imaging artifacts, etc.). In the future, this framework may even be worth extending to potentially include an active learning component to allow for a dynamic increase of meaningful labeled data to further boost its performance.
230	GaitForeMer: Self-Supervised Pre-Training of Transformers via Human Motion Forecasting for Few-Shot Gait Impairment Severity Estimation	This paper proposed a novel method. It is the first one to used motion data from normal people to pretrain the model and then fineturn on the skeleton-based motor impairment estimation task, which can well solve the problem of small sample size. With a strong and reasonable motivation, they designed a reasonable and feasible transformer-based model and achieved remarkable results. I think it deserves to be promoted in this field.	"1) The author presents an original idea of self-supervised learning of a given model by predicting the latter half of the video.
2) Detailed experimental results are presented (e.g., comparing various existing methods, showing results while changing the fine-tuning strategy, and showing performance changes as the amount of training data changes)."	the use of pretraining has enhanced the performance
231	GazeRadar: A Gaze and Radiomics-guided Disease Localization Framework	"Combining radiomics and gaze information.
Ablation study of the contribution of each component"	"1, The proposed problem is clinically relevant, as model explanation is an important task.
2, The proposed method is extensively evaluated on several benchmarks, demonstrating its effecitveness.
3, The problem is clearly motivated and formulated, and each component is well explained.
4, The proposed methods properly addressed the gaze difference problems of the ragiologists."	The authors came up with a novel loss function to transfer the joint radiomics-visual knowledge from the teacher block to the student block. The authors claim that the proposed work is the first work that incorporates radiomics and radiologists' search patterns into a decision-making pipeline. The authors provide ablation study for their GAF-RAF strategies.
232	Geometric Constraints for Self-supervised Monocular Depth Estimation on Laparoscopic Images with Dual-task Consistency	"This paper is overall well-written. The flow of the paper is easy for readers to follow. The Introduction section has included a good review of the literature.
The technical contribution of this paper is adequate, given the inclusion of scene coordinates and consistency-based weighting mask.
A good comparison study was provided by authors and several state-of-the-art approaches have been added into the comparison. The results have shown the proposed framework demonstrated better performance."	"The monocular depth estimation is treated slightly different from previous approaches, which enhances the results.
The system can be applied to real data relatively easily, since no ground truth is required for training (only a camera calibration matrix) and it works on monocular data, which is easy to acquire
Evaluation on real data
A thorough comparison against many other methods is performed, as well as an ablation study."	"Writing is clear and easy to follow.
Adding scene coordinate prediction task as an auxiliary is a novel idea for monocular depth estimation.
Averaging the forward/backward poses in training seems to be a useful trick to boost the performance a bit.
The performances were compared to the state-of-the-art in general depth estimation areas and in the medical domains, which makes the merit of this work more convincing."
233	Gigapixel Whole-Slide Images Classification using Locally Supervised Learning	"The idea is novel in pathology and seems applicable; however, comparisons are not comprehensive. The main strengths of the paper:
1- Feeding WSI to the network is beneficial as it preserves spatial information. However, 5X is not what pathologists look at in many cases. 
2- Recunstractiong a part of WSI is a good idea to overcome the size difficulties; however, ten patches 128x128 seems intuitive without further investigations. 
3- Apply Experiments in 3 public datasets is a good strategy."	"Given the memory bottleneck for WSI representation learning, the idea of using the locally supervised learning scheme is interesting and reasonable.
The motivations and solutions are clear."	The entire whole slide images can be trained on GPU. they evaluated their method on three public datasets and achieved satisfactory results. This work is interesting.
234	Global Multi-modal 2D/3D Registration via Local Descriptors Learning	"the method is concise and well described
it is adaptable to different image dimension and modality
no prior segmentation nor pose is needed, although this information could be taken into account if available.
the results are very interesting, especially with a far initial pose
nice mitigation of the US images FOV"	"The paper is very nicely written. The motivation are well explained which connects well with the method and results section.
The authors clearly had a good understanding of the clinical problem and the proposed method can well addresses the problem."	"Well written
Consistent bibliography
Clear contribution"
235	GradMix for nuclei segmentation and classification in imbalanced pathology image datasets	A new way of data augmentation techinique is proposed to improve the nuclei segmetnation and classification tasks. Compared with GAN model, the proposed method doesn't need the supervised datasets.	The paper proposes a method for synthetically creating nuclei of rare class types in a given imbalanced training dataset to improve class balance and achieve a more balanced diversity in training data. The experimental evaluation with two datasets and one deep learning network shows performance improvements compared with using real training data only.	The authors propose a method to augment rare-class nuclei with major-class nuclei to overcome class imbalance. This is a common problem because nuclear classes are indeed imbalanced. The results show an improvement in classifying rare-class nuclei. Specifically, Table 3 shows results of nuclei classification are improved. F1-scores of miscellaneous nuclei (a rare class) in both datasets increased more than other nuclei types when using GradMix. For the first dataset, F^M increased by 0.035 while F^E and F^L changed less than 0.01. For CoNSeP, F^M increased by 0.011 while F^E increased by 0.016 and F^I and F^S changed less than 0.01. Showing more improvements in miscellaneous nuclei would meet the main purpose of GradMix.
236	Graph convolutional network with probabilistic spatial regression: application to craniofacial landmark detection from 3D photogrammetry	Elegant approach giving SOTA performance (compared to various well known methods).	"In and of itself, the spectral model approach used here is an adaptation of the well known Chebnet (Defferrard, M., Bresson, X., & Vandergheynst, P. (2016)). The extension and therefore technical contributions, include a multi-resolution feature quantification approach leveraging different orders of Chebyshev polynomials; a mechanism for weighted spatial feature aggregation where the weighting is cognisant of the local density of vertex data; and a probabilistic regression framework for regressing landmark coordinates as a combination of graph node coordinates.
The method caters for both connected and unconnected nodes which makes their approach more applicable generally for automating point-based data analysis. 
Their probabilistic framework to regress landmark coordinates as a combination of graph node coordinates provides a general improvement in landmark placement accuracy that  improves not only their approach but also Pointnet++.
The use of multi-resolution spatial feature calculation and aggregation schemes makes the proposed approach somewhat robust to local data density issues. Although this reviewer feels that perhaps this issue could be managed more cheaply with some mesh preprocessing (see below in weaknesses)"	The geometric deep learning was applied for craniofacial landmarks detection from 3D surfaces.
237	Graph Emotion Decoding from Visually Evoked Neural Responses	This study showed a novel method integrating emotional responses and brain responses of fMRI. Even using the GED, the model can decode using emotion and using the connections of the neighboring emotions. Additionally, this paper showed reasonable performance by interpreting and comparing with the other state-of-the-art model. GED uses more integrated information, making the performance better and even gradually improving performance by stacking layers.	The authors proposed a relatively simple network architecture to achieve a relatively difficult problem, and proved the effectiveness of their method.	"It seems an interesting idea to perform embedding propagation.
t-SNE Visualization generates interesting visualization, similar emotions tend to be closer.
It shows significant improvement above the state-of-the-art brain-network-based models."
238	Graph-based Compression of Incomplete 3D Photoacoustic Data	"(1) As claimed by the authors, it is the first work to apply graph signal processing in incomplete PA compression.
(2) The proposed method allow acceleration of data acquisition and small data size.
(3) Medical doctors are invited to assess the proposed method."	"The compression shows good performance compared to classic compression.
Compression performance has been tested with clinical data and experts rated that there is no clinical value lost with the compressed data."	"The topic is interesting and clinically significant.
The paper is well organized and easy to follow.
A series of experiments in real clinical data demonstrated the superiority of the proposed method over DCT."
239	Greedy Optimization of Electrode Arrangement for Epiretinal Prostheses	"The paper is well written and organized.
To my knowledge, this is a novel approach for optimizing retinal prosthesis design, which is an important clinical area. 
This approach could be broadly applicable to the design of other neuromodulators.
A validation study shows potential performances advantages over state of the art design."	This paper's strenght is in modeling of a clincal problem and proposing a solution in form of adapting existing methodological approaches and evaluating the results in terms of simulated visual subfield coverege.	"Nice paper that describes, by using a formulation of dictionary optimization, how to achieve an optimized electrophysiological simulation with, e.g. the Argus II implant.
The methodological foundations are quite well exposed and is complemented by an analysis of the algorithm's performance. This approach suggests that a rectilinear array of electrodes not necessarily be the optimal one when compared to the results of this approach."
240	Hand Hygiene Quality Assessment using Image-to-Image Translation	To my knowledge, this is a novel application of AI methods to establish a better processing, monitoring and documenting of hand hygiene. Using hand templates to document the outcome of UV test for hand hygiene were previously proposed, although templates were generated manually. The proposed method has the potential to measure, document and compare effects of different hand hygiene procedures with considerable more participants, in multiple centers and in different settings.	The paper describes and interesting application / problem domain. The paper is well written in principle.	The key strength of the paper is the proposal to use a neural network (NN) for hand hygiene quality. NN overcome the difficulties of manual labelling or hand-crafted ML approaches on this task. Automatically analyzing fluoresence images and mapping them to a common template provides a relatively inexpensive and rapid way to analyze hand hygiene.
241	Harnessing Deep Bladder Tumor Segmentation with Logical Clinical Knowledge	"The motivation of Integrating clinical rules into bladder tumor segmentation methods is suggestive.
2.The neural network is very cleverly designed, and the figures in this paper are well-drawn.
3.The transformation of graph neural network is described very carefully, and the definition of loss function is innovative."	The method is novel and provides an original way to use clinical data. The paper and the figures are clear. The authors provide comparison with other state-of-the-art methods.	"the paper is well-written and not organized. 
-There is a novelty, not big,  for fusing DCNN with clinical logic rules."
242	Hierarchical Brain Networks Decomposition via Prior Knowledge Guided Deep Belief Network	"This work proposed a novel algorithm to incorporate prior knowledge to DBN for fMRI data analysis. The idea of this work is clearly conveyed. The algorithm is clearly formulated.
It is an interesting topic how to incorporate prior knowledge into deep models. This work contributes a novel idea on how to introduce prior knowledge to unsupervised deep models for fMRI data analysis."	The results are interesting as providing task labels will help form more reliable brain networks.	This work contributes a novel idea on how to introduce prior knowledge to unsupervised deep models for fMRI data analysis. This is the first supervised hierarchical FBN identification method as far as I know.
243	Histogram-based unsupervised domain adaptation for medical image classification	The most important aspect is that the results show an improvement over baseline only for the proposed methods. Additionally, the paper is well written; it explains the underlying idea well and explains how it is implemented.	The method may work.	"The proposed method is very straightforward and effective, which can be utilized as a general method for another medical image applications.
The motivation and the method part is well explained.
The experiments are sufficient to show the robustness and the effectiveness of the proposed method."
244	How Much to Aggregate: Learning Adaptive Node-wise Scales on Graphs for Brain Networks	The comparison with already existing solution is very meticulous and the idea is original, based on a very good literature review. The story of heat kernels and GNN is really reported in a compelling manner.	"(1) The paper focuses on how to aggregate the information for the brain networks adaptively. In this paper, the authors proposes a flexible GCN model that learns adaptive scales of neighborhood for individual nodes of a graph to incorporate broader information from appropriate range. The paper is well written and the problem is clearly motivated.
(2) The authors also derive a gradient-based learning on local receptive field of nodes using a diffusion kernel. Extensive experiments on various datatsets show that the proposed method outperforms the state-of-the-arts methods."	"This paper proposes the adaptive range of individual nodes. This idea is consistent with the property of the brain network that each ROI has different biological topological properties, thus different local receptive fields should be provided to understand the subnetwork structure.
The training on the scale is well derived and the paper is well organized.
Some interpretations such as key ROIs are provided with visualization."
245	Hybrid Graph Transformer for Tissue Microstructure Estimation with Undersampled Diffusion MRI Data	"1) The HGT method includes modules for both q-space and x-space learning that is very suitable for modeling diffusion MRI and different from previous methods.
2) This work is claimed to be the first one on leveraging transformers for tissue microstructure estimation.
3) Extensive comparison with several SOTA methods and the ablation study make the results convincing"	"1) The idea of jointly exploiting the data structure in the q-space and the nonlocal information in the spatial domain is novel. Previous works have not considered the joint use of these different types of information.
2) The selection of competing methods is quite comprehensive.
3) An ablation study was performed to justify the use of residual learning and dense connections."	The paper is well written and looks at an important topic.  The technical aspects of the method are novel and clearly defined.  The experiments are expansive in their evaluation across different approaches.
246	Hybrid Spatio-Temporal Transformer Network for Predicting Ischemic Stroke Lesion Outcomes from 4D CT Perfusion Imaging	"The text is well-written and easy to follow. In particular, this Reviewer appreciated the Introduction, with a literature overview and motivations.
Hybrid CNN-Transformer models [1] were previously proposed, but, to the best of the knowledge of the Reviewer, this particular model and its application to CTP is novel.
The use of Transformers for this purpose, as proposed by the authors, seems capable of leveraging the best of these models, i.e., learning temporal relationships in CTP.
The results are positive, improving over CNN-based naive baselines with perfusion maps, or even considering the temporal component."	The usage of transformer on this specific problem can be considered novel. The manuscript is well written.	"1, Using 3D CT perfusion images for segmentation has not been well studied in the field. This topic is some kind of new for the community. 
2, The paper is smoothly written and easy to understand. 
3, The authors successfully showed that the proposed method outperformed segmentation from perfusion parameter maps."
247	Ideal Midsagittal Plane Detection using Deep Hough Plane Network for Brain Surgical Planning	"The main strengths of the paper is the interesting methological approach combining hough transform and deep learning. In this way, a nice framework is being created which could also be of interest for other applications.
Another strength is the evaluation on a decent number of 519 cases providing first indication of clinical usibility."	"The method proposed in this paper is novel: combining two kinds of spatial characteristic information into training can accomplish tasks more efficiently and accurately.
This paper has high practical value: based on real clinical data sets, it has good training performance."	"Following are the strength of paper:

Introduction of sparse DHT, which increases the sparsity of features, which further increases the computation speed.
Introduction of hough pyramid attention network to extract non local features, which increases the detection.
Introduction of dual space supervision, which integrates the training loss from both the spaces (image and hough)."
248	Identification of vascular cognitive impairment in adult moyamoya disease via integrated graph convolutional network	"The methodology of dual-modal GCN is reasonable.
The motivation for designing the node-based normalization and constraint is sound, although the design of such mechanisms is not quite clear to me"	This paper design different ways to extract complementary information from rs-fMRI and DTI when constructing graphs. The personal biomarker interpretation is interesting.	This paper tackles the recognition of VCI in MMD by an integrated GCN. By constructing graphs that extract complementary information from two modalities that contain the corresponding important information, node-based normalization and similarity constraint item are combined to improve performance. The results from the private dataset demonstrate this method can highlight some salient brain regions related to VCI in adult MMD while achieving high accuracy.
249	Identify Consistent Imaging Genomic Biomarkers for Characterizing the Survival-associated Interactions between Tumor-infiltrating Lymphocytes and Tumors	"The graph attention network can characterize the interaction between TILs and tumors by weighting graph edges.
The experimental design is comprehensive, especially integrating several scenarios using imaging only and using genomic data only.
The correlation between particular genes from the concrete autoencoders and TIL and tumors is demonstrated."	The paper proposes a new methodology that outperforms 9 other methodologies, this is a good performance.	"The proposed approach is well motivated. Experiments are carefully done. Multiple neural networks such as U++, graph attention network, concrete autoencoder, and co-expression network, are used to process and combine imaging and genomic data. For that it became an end-to-end deep learning based framework.
Clear analysis of the results are done. Comparisons with existing approaches are done."
250	Identifying and Combating Bias in Segmentation Networks by leveraging multiple resolutions	Experiments and analysis have been done well on the direction of the problem and solution caused by the resolution bias. The contents of the experiment and the analysis also seem appropriate. This work is expected to provide useful information in the field of deep learning-based segmentation research.	"Strengths

This paper explores a very relevant problem of image resolution bias in DL segmentation

Usage of publicly available datasets and assessment on two different tasks (cortical segmentation in adults and children and hippocampus segmentation)"	The major strength of this paper is using the volume bias to check for the generalizability of trained models from data acquired at one resolution to data acquired at another. This metric provides a better method of investigating differences resulting from scale variance, and can highlight which augmentation and network setup leads to the least bias.
251	Identifying Phenotypic Concepts Discriminating Molecular Breast Cancer Sub-Types	The authors apply the TCAV method on a multi-modal training image dataset. This application is an important contribution towards interpretable identification of breast cancer sub-types. Evaluation of the classification accuracy is competitive with recent state of the art approaches, while using a smaller dataset, and takes advantage of the multi-parametric multi-modal data.	Strength of this paper lies in the pioneering application of concept calculation on medical images for breast cancer patients, which is one step closer to find the co-relation between phenotypic traits and microscopic categories.	The paper poses a relevant question in the field: can we identify phenotypes with non-invasive imaging and what features in the image may be associated to each phenotype? This is a relevant and timely question. The paper is well written, clearly exposed and the results present interesting insights. The formulation of patient-specific concepts is rather interesting, as it allows to describe each patient by a set of measurable imaging features and their respective values.
252	Implicit Neural Representations for Generative Modeling of Living Cell Shapes	the work proposes a novel and effective cell shape representation method which is able to generate sequences of cell shapes in 3D+time	"This paper is creative and interesting. 
It is well-written and a pleasure to read.
I regret that due to the hour of the day I will not do it justice in these comments."	The method is simple and appears to be quite efficient with quite modest memory requirements. The integration of time as equivalent to the three spatial dimensions is important. The paper is written extremely well. The model seems to be able to cope well with anisotropic resolution (ec C.elegans dataset).
253	Implicit Neural Representations for Medical Imaging Segmentation	"The training speed is accelerated.
The proposed algorithm is suitable to solve problems which are computationally heavy, like super resolution image processing."	The paper is well organized and it is easy to follow. Combine different resolution features  to make segmentation prediction.	"This study is well-motivated by a practical but longstanding problem, i.e., the trade-off between the image resolution and the memory footprint of the deep networks for image segmentation.
The application of the INRs in the medical image segmentation task is novel and interesting and has been demonstrated well-suited for solving the above problem."
254	Improved Domain Generalization for Cell Detection in Histopathology Images via Test-Time Stain Augmentation	"*The test-time augmentation and fusing these results are simple and easy to implement.
*In experimental results, the proposed method improved the detection performance in several methods."	"Simplicity: The approach is simple and based on the OD space decomposition and generating multiple test augmented images with different weighting factors.
Flexibility: The method is a generic test-time augmentation approach and can be combined with any trained method during testing. Hence, it can be utilized with different training strategies. The method is also generic because it can be tilted towards source or target with the selection of weighting factors.
Performance: When used during inference, the approach improves the performance of different training methods."	"The main strength of the proposed method is that the stain normalization model is not required to be trained, i.e. the generation of source-target domain mixtures is executed at a test time only.  Furthermore, source domain images can be pre-selected including the case with one source image only. That also can resolve the privacy issue if it exists. Another important strength is that proposed test-time concept is agnostic on detection model as long as it  produces bounded 
boxes and confidence."
255	Improving Trustworthiness of AI Disease Severity Rating in Medical Imaging with Ordinal Conformal Prediction Sets	"Clinician trust in AI prediction is an important topic. Mathematical guarantee such as presented could have significant impact on adoption of AI technologies.
The algorithms proposed is simple, and relatively intuitive.
The paper is well-written and easy to follow. The symbols are mostly clearly defined, and the explanation is intuitive."	"A novel ordinal prediction set algorithm that was shown to perform similarly to a non-ordinal algorithm in output set size and coverage.
A method for quantifying uncertainty in this setting is provided."	The motivation for the work is sound, uncertainty estimation is known to be a serious problem for deep learning methods deployed in clinical settings. Overall, the paper is well structured with no immediate flaws.
256	Incorporating intratumoral heterogeneity into weakly-supervised deep learning models via variance pooling	A novel patch-level features pooling method taking tumor heterogeneity into account.	"The paper is well written and easy to follow.
The idea of capturing the intratumoral heterogeneity information is novel and interesting in pathology image analysis. The motivation and the implementation method are well explained.
The proposed module can be easily incorporated into existing MIL frameworks and improve the performance.
Visualizations of patches (selected via attention scores, or ordered variance projection scores) show a good interpretability of the proposed method."	"The authors have developed a framework, based on variance pooling which aims to capture intratumoral heterogeneity by quantifying ITH as variance along a collection of low-rank projections of patch features.
The authors have designed variance projection contrast visualization to provide model interpretability, which is clinically relevant. Further, the ability to obtain the biological signals captured by the deep learning architectures further promotes trustworthiness of the system upon expert's approval (in this case a pathologist).
The mathematical formulation of the proposed strategy is well described.
The implementation details are well described.
The choice of parameters, loss functions, parameter initializations are justified.
An exhaustive set of results from different experiments with standard measures is provided.
Visual illustration of the proposed interpretability tool highlights diagnostically useful regions which can be useful for assisting pathologists in decision making."
257	INSightR-Net: Interpretable Neural Network for Regression using Similarity-based Comparisons to Prototypical Examples	"The paper is clear and well-written.
The work is novel. The novelty of the work mainly arises from the extension of ProtoPNet (Chen et al. [https://arxiv.org/pdf/1806.10574.pdf]) to regression tasks.
New similarity function and additional loss components led to better explanations (measured in terms of sparsity and diversity)."	"Interpret CNN for regression with similarity-based comparisons is interesting and intuitive.
The studied problem is clear and well formalized.
The presentation throughout the paper is clear and even reader-friendly."	The authors propose a nice validation scheme with out of sample evaluation and prototype analysis that corroborates retinopathy gradation.
258	InsMix: Towards Realistic Generative Data Augmentation for Nuclei Instance Segmentation	"Strengths:

a difficult and important problem is addressed
the method is well motivated, the strategy of the authors is clear
several novel ideas are composed into a single pipeline
the evaluation includes quantitative and qualitative results on multiple datasets
the method clearly outperforms other state-of-the-art augmentation strategies"	"image augmentation specifically for nuclei instance segmentation
great idea with applied morphology constraints (SSD)"	"The InsMix is based on Copy-Paste augmentation method, with some unique improvements which were especially designed for nuclei segmentation problem, such as SSD (scale, shape, distance) constraints. All the three components presented a complete pipeline and show performance increasements. The overall novelty of this paper is good.
The experiments were done in two widely used public datasets, also with the detailed ablation studies. The evaluation is strong.
The paper is well organized and easy to follow."
259	Instrument-tissue Interaction Quintuple Detection in Surgery Videos	The proposed spatio-temporal attention layer can effectively take advantage of the domain-specific spatio-temporal features to boost quintuple detection performance. The experimental results confirm the effectiveness of these additional components in enhancing instrument and tissue localization performance.	"The proposed method extends the state-of-the-art models of representing instrument-tissue interaction as triplets to quintuples of instrument
bounding box, tissue bounding box, instrument class, tissue class, action
class. Moreover, they model these quintuples in a localized manner.
As part as QDNet, they propose a spatiotemporal attention layer (STAL) to aggregate spatial and temporal information of the regions of interest between adjacent frames. STAL is a modification of the commonly used spatio-temporal attention module (STAM) but aggregates spatial and temporal information of the ROIs instead.
They build a cataract surgery video dataset with annotations named Cataract Quintuple Dataset. According to what is stated in the Reproducibility checkbox list, the authors intend to share this dataset."	"Detailed method description
Real data
Ablation study"
260	Interaction-Oriented Feature Decomposition for Medical Image Lesion Detection	"1, The global context embedding module receives two forms of supervision during training: one is standard whole image classification and the other is a feature adaptation branch for later interaction with the localized detection heads of the original Faster RCNN design. This design enforces a good embedding at the global level.
2, Self-attention module is leveraged for the interaction between global context and local features. This interaction directly enhances the local features and proved to be beneficial for the performance.  Combined with the Global embedding, the whole design is novel.
3, Experiments are well designed and conducted thoroughly. They provide good support for each proposed new component."	"The authors pointed out that many types of lesions are distinguished by the position and the relative proportion of the lesion to the tissue,
The idea of using attention-weighted global features to do classification is novel and intuitive."	"This paper introduced two new modules, global context embedding module and global context cross attention module, to enhance lesion features for better lesion detection. The introduced modules are well motivated and simple.
Experiments on two datasets show the effectiveness of the proposed method. Both GCE and GCCA modules are validated through an ablation study.
This paper is well-written and easy to follow."
261	Interpretable differential diagnosis for Alzheimer's disease and Frontotemporal dementia	"This method seems novel in its approach to classification, using an ensemble of 3D-UNets and then applying an SVM to classify the data.
Reproducing other methods that have been used in the past to solve the classification problem
Testing the DG framework + SVM against other methods, using the same data, in order to test performance of their method.
The authors demonstrate a clear understanding of the problem of disease classification, not just from a technical perspective, but from a medical perspective."	The combination of the graph convolutional network and an SVM for classification is interesting.	"The authors explored the potential of using machine-learning methods to classify multiple dementia subtypes, while previous work mainly focused on the binary classification of either Alzheimer's disease or Frontotemporal dementia.
The authors performed a careful ablation study for the proposed method and showed some interesting findings such as aggregating data from multiple dementia sub-types may improve the binary classification results, and the deep-learning strategy can provide complementary diagnostic information to the hand-crafted features such as volumetric atrophy.
The proposed method revealed the signature ROIs for each studied dementia sub-type. The agreement between their findings and previous research work indicated that the proposed method might be clinically useful."
262	Interpretable Graph Neural Networks for Connectome-Based Brain Disorder Analysis	This paper proposed a novel interpretable GNN framework for connectome-based brain disorder analysis. It's an interesting work that combined an explanation generator to make the GNN could interpret the brain biomarkers in the group level.	"focus on interpretation of predictions
model is carefully derived
cross-validation on several datasets
superior accuracy compared to 9 other methods !"	"Learning a sparse masking matrix is an interesting approach to impose implicit regularization on brain networks and produces more robust results under the limitation of data size.
Visualizations for both salient ROIs and important connections are helpful to understand the clinical relevance of the proposed model."
263	Interpretable Modeling and Reduction of Unknown Errors in Mechanistic Operators	"The method is capable of correcting errors in the forward operator when solving inverse problems. The authors claim that these errors are difficult to account for when solving inverse problems and instead update the forward operator in a cyclical process.
By clustering in the latent space of the vector controlling the update to the forward operator, the type of error in the original forward operator can be evaluated."	A new model was proposed to reconstruct medical images.	The paper is well written and structured.  Interpretability is highly desired in clinical settings.
264	Interpretable signature of consciousness in resting-state functional network brain activity	The Modular Hierarchical Analysis (MHA) linear latent variable model was used to differentiate the various conditions of consciousness using resting-state fMRI. The statistical analysis showed the signature of consciousness from 5 monkey data.	This work adopted a constraint linear latent varialble model to identify the spatial signatures of consciousness, which provides a novel application of the existing method and probably holds potential in clinical applications.	"The authors have a clear scientific/ medical understanding of the problem. This shows that the authors weren't just applying cool technology to a common problem, but chose a framework that was backed by having a clinical understanding of consciousness.

All sections of the paper, including the introduction which introduces the problem in a very detailed matter, were very clear and thorough

The statistical analysis seems robust, in that data was tested for normality and after discovering it was non-normally distributed, switched to using non-parametric analysis.

All graphs are easily interpretable."
265	Intervention & Interaction Federated Abnormality Detection with Noisy Clients	"The novelty of the work is in mixing the features/evidence provided by local models so that if there is any noisy evidence then it will be suppressed.
The second important aspect is to consider share information across local model while training. 
I"	The proposed method is well motivated and it can be considered as the typical effort to leverage Federated learning to solve the problems  in computer aided diagnosis. The proposed method designs two different strategies to solve the main issue-recognition bias.  The experimental setting is designed reasonably and ablation studies and comparison experiments demonstrates the efficacy of the proposed method. Finally, the presentation is good and the readers easily follow the method.	"The use of SCM in a federated setting for noisy clients is novel. By identifying and intervening on the causal factor (noisy client), the overall recognition bias is reduced. Unlike approaches where noisy labels are handled by robust losses, regularization, etc., this method intuitively adapts to the distributed learning paradigm. Instead of only improving the globally learned model, it naturally also identifies the confounder clients. This may help in a clinical setting by automatically identifying sites that may consistently differ in their labeling strategy or data quality.
The approach addresses two problems simultaneously. First, how to use the global model to intervene and debias clients causing recognition bias. This in turn, improves the overall global model as well. Second, how to find the optimal way to intervene, by using an adaptive weighting scheme for each client that best reflects the current noise status, locally and globally.
Extensive experiments have been shown, including comparison with several related approaches. The paper is well written and nicely condenses many aspects of the problem and method within the page limit."
266	Intra-class Contrastive Learning Improves Computer Aided Diagnosis of Breast Cancer in Mammography	"Well written detailed paper
The extensions to the contrastive learning triplet loss to incorporate label-free information is a unique extension
Thorough experiments and ablation studies."	"This paper is well written and easy to follow.
The technical part is sound and novel. Various latest learning strategies are included to validate the effectiveness of the proposed methods.
The subgroup analysis is interesting and integrates with domain knowledge."	"The paper compared the results with the recent approaches and experimentally provided evidences that the improvement is statistically significant.
The formulation of LCL and NCL is intriguing and adapted from the domain knowledge.
The results are provided on test dataset and they shows the merit of the proposed solution."
267	Invertible Sharpening Network for MRI Reconstruction Enhancement	This paper newly adopted an invertible sharpening network for reconstructing undersampled MR images which could be different from conventional deep-learning-based MR image reconstruction methods.	"(1)	This proposed invertible network is a one-to-one mapping which relieves the ambiguity of the final reconstructed image.
(2)	The motivation of this work is clear and the method adopted is intuitive.
(3)	Experiments verify the effectiveness of the proposed method."	"The idea of applying the invertible neural network (INN) to enhance undersampled MRI reconstruction is novel. The INN improves the visual quality of the reconstructed image, which is not fully discussed in the current related works.
The reconstructed image using the InvSharpNet has a better qualitative results, as shown in Table 1.
The experiments are comprehensive - evaluation on 3 datasets, comparison on SOTA algorithm and GAN-based method.
Generalizability & network size are discussed, the Lipschitz constant experiments are included.
The paper is easy to follow."
268	Is a PET all you need? A multi-modal study for Alzheimer's disease using 3D CNNs	"This paper demonstrate that a single-modality network using FDG-PET performs better than MRI and does not show improvement when combined.
This paper gives an evaluation framework for multi-modal fusion to systematically assess the contribution of individual modalities."	"Paper is well-written and hypothesis are clearly stated.
Evaluation framework is adapted and results are convincing.
Experiments present interesting framework that can be used by the community for a better use of multimodale stratregy."	"(1) This paper re-evaluates single- and multi-modal DL models based on FDG-PET and structural MRI for classifying healthy vs. AD subjects. 
(2) The experimental results show that FDG PET alone is sufficient for AD diagnosis, which conforms with established clinical knowledge about biomarkers in AD."
269	iSegFormer: Interactive Segmentation via Transformers with Application to 3D Knee MR Images	"Obtains good results in interactive 2D segmentation of knee cartilage MRI images.
Obtains acceptable results in cross-domain evaluation."	In my opinion, the paper's greatest strengths are the novelty of the architecture used and the demonstration of what seem to be new state-of-the-art results using said architecture. The architecture uses simple building blocks proposed in other works (e.g., Swin Transformer blocks); however, the conscious effort to design a lightweight network that is memory efficient results in an effective tool for the task at hand. With a memory overhead nearly identical to state-of-the-art CNN-based models, their new architecture demonstrates improved 2D interactive knee cartilage MRI segmentation (see Table 1). The authors also do a good job of demonstrating their due diligence in architecture design. They demonstrate that other transformer-based backbones with similar numbers of parameters have a considerably larger memory overhead than their proposed architecture and worse speed. They also perform an ablation study investigating different pre-training datasets and fine-tuning configurations, comparing to CNN-based models, and demonstrate that their architecture demonstrates the best results overall across all configurations. Overall, their design of experiments seems to make sense. Finally, the extension to demonstrate how their results in 2D can be used to segment 3D images using pre-existing propagation techniques accurately wraps up the paper nicely and ties back to their ultimate goal of segmenting 3D images with limited training data.	"Super-interesting approach, especially the use of video-based methods to extend into 3D (which makes conceptual sense) although this aspect is not the main contribution of the work according to the authors (section 3.4)
Code was made available
Public datasets were used
The comparison between methods was fair in that the different models were trained on the same datasets and evaluated on the same datasets"
270	Joint Class-Affinity Loss Correction for Robust Medical Image Segmentation with Noisy Labels	"The idea of exploring the pair-wise pixel interdependencies for reducing noise rate sounds reasonable. 
The experiments are extensive, and the results look good."	"(1) This paper takes into account the pixel pairwise affinity relationships for dealing with noisy segmentation masks. This perspective is novel and interesting.
(2) The proposed DAR module is novel and simple.
(3) The Class-Affinity Consistency Regularization loss is novel. In particular, this loss is developed with theoretical rationale.
(4) The proposed method achieves the best overall segmentation results compared to previous works. This demonstrates the advantages of the proposed designs.
(5) The proposed method is well motivated. The use of pairwise affinity is reasonable."	"The proposed Differentiated Affinity Reasoning and Class-Affinity Loss Correction modules are novel and effective.

The proposed framework is indicated to be effective under various types of noise labels.

Overall, the paper is well organized and clearly presented with nice illustration."
271	Joint Graph Convolution for Analyzing Brain Structural and Functional Connectome	"The jointly analysis of functional and structural barin connectomes might provide some insight for medical use.
The method is simple and effective. The performance shows some improvement."	The authors designed a novel learnable inter-network edge model to capture coupling strength between SC and FC in different tasks such as age and sex prediction.	The main strength of the paper is coupling the structural and functional connectome with inter-network edges between corresponding brain regions.
272	Joint Modeling of Image and Label Statistics for Enhancing Model Generalizability of Medical Image Segmentation	"The approach tackles generalizability of deep learning segmentation models in medical imaging which is obviously relevant to the MICCAI community.

As far as I am aware the approach, such as the use of image decomposition and modelling of image basis and contour to achieve more generalizable representation, is novel and the architectural choices in this make sense to me.

The results are surprisingly good, with much smaller reductions in Dice scores when the method is applied to new modalities and datasets than the compared to approaches."	"definitely an interesting topic to all the segmentation & learning community, particularly given the challenges with image appearance and leveraging multimodal data.
thorough derivation
convincing evaluation  results"	"I believe the proposed method is a novel approach and addresses an important challenge in the medical image segmentation field.
The theoretical analysis of the framework design seems to be relatively thorough. And the use of CNNs for posterior distribution inference avoids some technical challenges that could be difficult for conventional Bayesian methods. 
Quantitative evaluation of the proposed method was done properly."
273	Joint Prediction of Meningioma Grade and Brain Invasion via Task-Aware Contrastive Learning	"The strengths of this paper include:

Using image data typically collected in MR brain tumor protocols.
A good number of studies (n=800) for training and testing for proof of concept.
Use of disentanglement contrastive learning layers to split image features into common and specific features to improve the prediction, and verified with ablation testing."	"The authors state that this is the first example of multitask learning for meningioma grade and brain invasion prediction.
The proposed multitask framework is intriguing and improves model performance. The use of a task-aware contrastive loss is unique and lends itself to multitask learning.
Sufficient ablation experiments are provided to support the proposed method for multi-task learning."	"Clinical interest (it could avoid invasive assessment by biopsy).
Simplicity of the method"
274	Joint Region-Attention and Multi-Scale Transformer for Microsatellite Instability Detection from Whole Slide Images in Gastrointestinal Cancer	The framework is reasonable. The result is promising.	"The paper uses powerful ML techniques such as attention and transformer architectures to solve a challenging and relevant problem.
The architecture proposed is sound and novel and has valuable contributions.
The sampling method using attention map sounds like a good idea, and is shown to perform well.
The combination of region level and patch level features using transformers is also a good idea and seems to perform well for this task. 
The combination of auxiliar and primary losses is a positive addition and it is convincingly explained. 
The aggregation of regions in the slide level architecture is also very valuable.
The results show a superior performance compared to state of the art methods for MSI.
The ablation study is convincing and shows the superiority of using slide level and the use of the sampling technique with the attention map.
The paper is well written and the main concepts reasonably well explained.
Fig 1 is very informative and informs visually very well about how the method is designed."	Well motivated proposed approach, good analysis of the problem at hand, latest deep learning based approach to solve problem, careful experiments and clear analysis of the results, comparison with state-of-the-art methods are given.
275	Kernel Attention Transformer (KAT) for Histopathology Whole Slide Image Classification	"Strengths:
1). constructs an abstract concept over the patch.
2). proposes the kernel attention module, its main novelties  comes from: (a) reduce computational cost by replacing patch-to-patch attention with patch-to-anchor attention, (b) introducing  hierarchical context information by adjusting N, a hyperparameter which can controls the scope of calculating the self attention."	"A novel transformer named kernel attention transformer (KAT) is proposed. It can describe hierarchical context information of the local regions of the WSI and thereby is more effective.
A very large (~ 5K WSIs) dataset is collected for experiments. Results have shown the effectiveness of the proposed KAT."	"The paper is well-written and the methods clearly described with all details provided. 
The authors have included computational and memory requirements, which is a useful addition.
There is a thorough and fair appraisal of the method compared to SOTA and, although no confidence intervals are provided, the method's value is clearly shown.
The method draws upon a number of already high-pedigree methods (ViT, efficientNet etc.) but adds credible novelty by combining them with other techniques such as Kmeans to compute the anchor points for the weighting masks."
276	Key-frame Guided Network for Thyroid Nodule Recognition using Ultrasound Videos	"1.The idea of making use of ultrasound video clips to guide the CAD classification task. A video clip is the successive 32 frames centered by a key-frame which have been detected to contain clinically typical nodules.
2.There are ablation experiments to evaluate the effectiveness of each network module: the usage of keyframes, the motion attention, and the 3D SPP."	"A novel framework for thyroid nodule recognition using US video.
The proposed method is addressing an important clinical problem."	This paper, according to the actual clinical situation, extends the deep learning based thyroid nodule recognition method to the common B-scan ultrasound videos. The proposed method with motion attention mechanism achieves higher classification performance on self-collected dataset as compared to baseline methods, verifying the effectiveness of the method.
277	Knowledge Distillation to Ensemble Global and Interpretable Prototype-based Mammogram Classification Models	A new proposition for ProtoPNet. - Interpretable results in the network.	"The proposed method is simple but effective to improve the model performance and interpretability.
The paper is well organized and description of the motivation is clear.
The experimental results supports the validity of the proposed method."	"There are three major contributions of this work (1) adding interpretability; (2) higher accuracy benefited by ensemble learning and (3) improve performance by introducing diversified training strategy. The research topic is highly interesting, since the interpretation of deep learning models have been a heated topic in recent years.
The authors implement knowledge distillation from GlobalNet to ProtoPNet through minimizing KD loss, forcing the networks produce similar results on the same sample. The training signal, i.e. loss functions are well designed, with thoughtful considerations of margins/diversity/over-fitting prevention.
The studied dateset, though private, is relatively well-sized. What interests me most is the activation maps that can visualize the cancer localisation across different methods, which allows deep model interpretation."
278	Landmark-free Statistical Shape Modeling via Neural Flow Deformations	flow parametrization and latent representation	"The paper is well written
It introduces a novel representation of shape spaces (compared to shapeflow) by adding a local neural flow deformer to a global one. This local NFD is based on RBF with fixed control points.
The authors provide examples of their approach on 2 datasets liver and femur and show the discriminative power of the latent space on one test case.
The author provide a comparison with 3 other techniques one of them being also based on LDDMM. They show that their technique leads to improved results."	"The proposal is based on a continuous model of a velocity field in 3D. The differential equation is solved via a parametrization model solved by a flow net.
Results seem correct and applications to shape reconstruction, segmentation and classification."
279	Layer Ensembles: A Single-Pass Uncertainty Estimation in Deep Learning for Segmentation	"Most of the sections of the paper are well written, which are easy to follow.
The idea of using layer ensemble to estimate uncertainty is interesting."	"The paper is well written and easy to understand.
The speed up of ensembles for uncertainty estimation is highly relevant given that it is frequently used and the state-of-the-art in the field.
The motivation of the method is clear and well explained.
The results are promising."	"-The uncertainty assessment only requires single-pass testing
-The idea of ensembling multiple layer output is newly proposed
-The method is validated in one 2D dataset and one 3D dataset"
280	Learn to Ignore: Domain Adaptation for Multi-Site MRI Analysis	"the method is simple but elegant and outperforms baselines and state of the art approaches on the target domain by a large margin
the approach is compared to multiple baseline and state of the art approaches
the setting is clinically relevant, as data collected in a hospital is often from the same scanner"	The paper is trying to tackle an interesting problem: how to generalize a classification model when the training data of each class comes from different studies.	"[1]	The research topic is of practical value for MR image adaptation/harmonization for dealing with the between-site variations caused by scanner differences.
[2]	The authors have clearly presented their motivation and insights for the model design. The overall architecture is appropriate.
[3]	The extensive experiment on diverse MR datasets is appreciated. The comparison with several state-of-the-art or classic adaptation methods makes the results solid.
[4]	The authors released the source which is helpful to reproduce the proposed method and the experimental results."
281	Learning Incrementally to Segment Multiple Organs in a CT Image	"The paper describes a method that seems to yield interesting results in the scope of incremental learning.
Particularly interesting are the results in Table 2, where models trained sequentially on different datasets do not forget the information learned in previous steps and yield good results on all the different anatomies even though training for these anatomies has happened in the past.
We can see that the ""ours"" row in table 2 shows good performance on all dataset, with an average performance close to the upper bound. As far as I have understood the authors have trained MargExcIL in 4 (or 5) separate rounds, and obtained these validation set results using the model obtained after the last round. Models such as FT, LwF, ILT, MiB were actually trained in the same way but since they did not have any IL specific strategy they basically fail on the first two tasks yielding very poor dice."	"1) The movtivation of using the partially labeled datasets for multi-organ model training stands for its novelty. 
2) The proposed method is clinical practical and the overall pipeline is designed in principle. 
3) The results has demonstrated its effectiveness
4) The paper is clearly written and easy to follow."	"Building a single multi-organ segmentation model from partially labelled, sequentially constructed datasets is innovative
Incremental learning is applied to multiple organ segmentation for the first time
A newly designed light memory module is proposed to further mitigate knowledge forgetting in incremental learning
Strong assessment on various datasets using Dice and Hausdorff distance and including comparisons with both existing approaches and ablated versions"
282	Learning iterative optimisation for deformable image registration of lung CT with recurrent convolutional networks	"The authors propose a recurrent framework using an iterative dynamic cost sampling and a trainable optimizer that mimics Adam optimization but can substantially reduce the required number of iterations.
The method uses a total of 45 features for each image voxel/control point. These features consist of 3 predicted displacements, 8 fixed grid of subpixel offsets (resulting in 24 features), 8 dissimilarity costs at the 8 fixed subpixel offsets, and 10 hidden states that are propagated through all iterations. Through these, the model is able to save information about previous update steps and incorporate them similar to how Adam uses momenta. All features get updated with each recurrent application of the network. That means the coordinates and dissimilarity costs dynamically change across recurrent states and mimic the iterative fashion of conventional registration.
The authors show that a good initial condition generated by the VM++ algorithm is important for fast and accurate convergence of both the Adam optimized approach and their L2O approach."	"(1) This paper employs a recurrent network to emulate instance optimization, which is meaningful for intra-patient lung registration.
(2) It uses a dynamic sampling of the cost function and hidden states to mimic gradient-based optimization, requiring fewer iterations than traditional techniques."	The main strength of the paper lies with the fact that it uses recurrent network framework to emulate instance optimization. The paper is well written and easy to follow.
283	Learning Robust Representation for Joint Grading of Ophthalmic Diseases via Adaptive Curriculum and Feature Disentanglement	"Novelty of the task: it is the first strong attempt to propose a joint grading system for DR and DME.
Novelty of the proposal: the authors, aiming to offer a generalization framework, realised some approaches to deal with the potential bias in grading the two pathologies.
Experimental evaluation: well conducted and presented. Strong results in both intra-dataset and cross-dataset experiments.
Conclusions: supported by the presentation and results."	"Strengths

Proposing dynamic adaptive weighting of samples and disentangled representation of DR and DME.
Comparison with other existing methods
Performing Ablation study
The paper is well written"	"The relationship of DR and DME is considered and modeled.
The DETACH does proved its improvement in performance and generalizability
The paper is well written and easy to follow"
284	Learning self-calibrated optic disc and cup segmentation from multi-rater annotations	"The novelty of the use of multi-rater annotations. The authors propose a recurrent method to fuse-separate the annotations from multiple raters. The way that the DivM recurrently returns its output to the ConM makes good use of the Attention mechanism. Furthermore, the authors provide the proof of the estimation of multi-rater expertness from the segmentation, which is theoretically persuasive.
The experiments and the evaluation are robust. The authors' evaluation methods are sound and the result comparison with SOTA is clear (the authors have taken both the calibrated and non-calibrated methods into account).
The paper is well organized and fluently written."	"This work is well-motivated and presents a novel approach for an important topic. The multi-rater consensus problem is ubiquitous in clinically relevant algorithm development and the proposed solution has the potential to be applied to other imaging modalities, like digital pathology.
A novel and interesting application of half-quadratic optimization in multi-rater calibration for optic disc and cup segmentation. The proof and proposed recurrent design seem pretty solid.
Solid experimental validation with two public datasets."	The idea of using self-fusion label and SSIM loss for the combined segmentation  is new.
285	Learning shape distributions from large databases of healthy organs: applications to zero-shot and few-shot abnormal pancreas detection	Different from previous methods, this paper learns a variational autoencoder based on binary segmentation masks with data augmentation, which is used to reduce the risk of overfitting and make the model more focused on the anatomy of organs.	The problem proposed in this paper is quite interesting	"The overall strength of the paper is, from my perspective, that it focuses more on the idea than on the technical details. This makes the paper really interesting and might boost the discussion rised by it. The benefits are therefore:

The intensive and detailed evaluation, which considers different aspects of the techniques and reports numerous experiments.
An interesting technical approach that clearly stands out from the typical ""Segmentation or image classification"" tasks.
An (for MICCAI papers) extensive discussion of the work.
The clear and good organization and writing style of the paper."
286	Learning towards Synchronous Network Memorizability and Generalizability for Continual Segmentation across Multiple Sites	"Good description of the asymmetry and problems of joint minimisation.
The proposed SGA approach is interesting and similar to the idea behind cosine losses in a multi-task setup.
Very interesting heuristics and insights in how to setup the replay buffer for the SGA approach
There was a quasi-ablation study due to the fact that completing methods have a subset of the proposed features"	"The paper is well-written
It tackles an important problem of continual learning + domain generalization which is a relatively new task.
The performances are promising, showing improvements on new unseen sites while minimizing the performance degradations on the old sites."	The authors by using the SGA learning method (objective, Dual-Meta algorithm and replay buffer) deliver in the same time memorability and generalizability of the network in unseen datasets.  Their method outperformed existing state of the art learning approaches (Continual Learning and Domain Generalization) and the baseline fine tuning technique.
287	Learning Tumor-Induced Deformations to Improve Tumor-Bearing Brain MR Segmentation	"Very interesting problem to segment brain structures despite very large tumors
Method is sound, interesting to smartly inject the tumor into the atlas including deformation of other brain structures in the atlas."	"The paper is very well-written and clear.
The use of synthetic data for the evaluation of the method is valuable."	"The proposed point-based deep regressor used to learn the tumour deformations is interesting. I like the idea of improving on traditional methods with deep learning components rather than blindly training deep models to perform everything. This particular task is also lacking ground truth segmentation data that would be required by a deep learning method.
The paper is well written and clear.
Despite the lack of ground truth, the author proposed few ways to evaluate the method."
288	Learning Underrepresented Classes from Decentralized Partially Labeled Medical Images	"The application is interesting and shows the real problems in clinical setting.
The authors presented strong evaluation on the efficiency of their method compared to baselines."	The problem in discussion, i.e., federated learning with partial label and underrepresented classes, is quite interesting and underexplored indeed. From the results, the conventional baseline cannot solve the problem, while the proposed method provide a practical solution.	"The proposed method is very effective in solving the under-explored problem in federated learning.
The three-stage framework is novel, 1. use federated self-supervised learning to learn class-agnostic representations 2. learn from common classes 3. classify uncommon classes.
The empirical results are impressive on Chest X-ray14 dataset. And the ablation study demonstrates that including EBM in the training can improve the performance."
289	Learning with Context Encoding for Single-Stage Cranial Bone Labeling and Landmark Localization	The method is interesting and appears to be performing well. The authors had a thorough analysis of their experimentation with both ablation studies and p-value tests. Adequate discussion about related works	The authors used displacement vector maps to learn landmark context to improve representation learning.	"As segmentation and landmark annotation is a tedious process which has high variability between raters and subject to errors. While previous studies make use of a multi-step process, this study attempts to perform the segmentation and detect landmarks jointly in a single step and on a 3D image.
The context encoding attention mechanism which is further augmented by landmark displacement maps to guide the learning of context. Together with the spatial relationships of all the other landmarks, the final objective for the model is formulated as a weighted sum of all the regularizing terms. Thus enforcing contextual learning in a novel way.
The experimental design is well set up and the authors have also evaluated the contribution of the context encoding mechanism through an ablation study.
Moreover, The paper is well written, with the information presented in a clear and logical manner. At the same time, the methods and results are well explained."
290	Learning-based and unrolled motion-compensated reconstruction for cardiac MR CINE imaging	"The method is interesting and the results quite impressive. The network is also  extremely  fast to execute. 
Testing is adequate for papers in this venue and all the information about training was provided."	A dynamic motion estimation was embed into the unrolled optimization, which can deliver more precise and deailed estimation. Furthermore, the proposed method provides a motion-resolved image sequence in which all frames are motion-corrected.	"Paper targets an important clinical problem. High spatial and temporal resolution is important for dynamic MRI scans.
While MRI data undersampling is performed to reduce scan time, motion corruption is tackled by methods such as group registration (and of course, lower scan time implies reduced chances of motion). Conventional group wise registration methods are effective, but take a lot of time. The proposed method reduces this processing time by multiple folds.
The most important highlight of the work is how unrolling reconstruction along with undersampled MRI reconstruction helps in improving the results both qualitatively and quantitatively."
291	Learning-based US-MR Liver Image Registration with Spatial Priors	The main strength of this work is the whole processing system including segmentation of MR and ultrasound volumes, initial alignment, surface-based rigid registration, and the final deformable registration. The whole workflow is a feasible solution for preoperative registration of liver MRI-ultrasound images.	"This is an interesting and difficult problem. As the authors point out, a good initialization is required, and that is a key contribution of this work.
The method was well-engineered, assembling a number of techniques into a pipeline that produced good results.
The algorithm is, by necessity I think, somewhat bespoke.  While the specifics may not be directly generalizable to other domains, the strategies employed are valuable and will provide inspiration for further uses beyond this application."	
292	Lesion Guided Explainable Few Weak-shot Medical Report Generation	"Authors aim to tackle a novel task which has certain clinical significance.
The method of this article is innovative enough.
Experiments show the proposed method can achieve higher performance than the reference methods."	"Overall, the paper is well organized by putting together all technical components in a systematic way. Connections and interactions across different components are clearly illustrated. Below are the detailed strengths of the paper:
1, the few short setting is novel while making sense. From a system evolution perspective, it is highly possible that new classes are gradually added to the dataset. For a smooth system transition or evolution, the few short learning framework should provide great help and makes the solution more practical.
2, lexical embedding bridges different modality and strengthen model training in a multi-task manner. This embedding also enables a good easy cold start for future new classes and makes the efforts for adapting models to new classes minimum. This is achieved by enforcing a soft label that is calculated by using textual similarity for the class branch of Faster RCNN with the RoI features.
3, when generating the report visual features and lexical embedding are combined to guide the generation process. The conceptually can better gears the report to a more lesion-focused fashion.
4, extensive experiments and promising results."	The authors propose a novel approach for reducing annotation requirements by using common global findings between seen and unseen classes. The promise of the methodology is seen in comparison with SOTA models and ablation studies.
293	Lesion-Aware Contrastive Representation Learning for Histopathology Whole Slide Images Analysis	"The paper is well organized and easy to follow.
The proposed contrastive learning method which can guide the negative samples selected from different classes is novel and interesting.
Experiments conducted on different datasets with CLAM and TransMIL demonstrate the effectiveness of the proposed pretraining strategy."	"The organization of the paper is clear and easy to follow. The motivation and method are clearly demonstrated.
The experiment is basically complete. The proposed method achieves performance gain on different benchmarks."	"The main strength of this paper is the novel class-aware semi-supervised contrastive learning framework LACL. Unlike MoCo, LACL maintains several class-specific queues, so it can alleviate the class collision and provide reliable negative samples for contrastive learning. Besides, a queue refinement strategy is proposed to guarantee the queue purity.
Ablation studies show the contributions of class-specific queues and queue refinement."
294	Lesion-aware Dynamic Kernel for Polyp Segmentation	"The main contribution is the technical addition of dynamic kernels and ESA LCA to the endoscopic polyp segmentation problem. While inspired by work in general vision/learning it is novel in this setting.

Thorough experiments and comparative analysis are reported using public endoscopic datasets. Experiments on a new dataset are also reported with an indication (in form, not in the paper) that it will be released but no link."	This paper is well-written and -organized. The novelty is interesting in this field. The performance is competitive when compared with other approaches.	"Authors bring together various elements including a U-net segmentation architecture, dynamic kernel generation and update, and self-attention and cross-attention modules.
Evaluations show high accuracy in lesion segmentation across various datasets."
295	Less is More: Adaptive Curriculum Learning for Thyroid Nodule Diagnosis	"The motivation of this paper is innovative and attractive. There are few papers about solving the inconsistent label issue between FNA and TI-RADS.
The key innovations of this work include designing a function to discriminate the hardness of a sample, and designing a general learning strategy. There are few works about applying curriculum learning on thyroid nodule classification.
The authors contribute a new thyroid nodule classification dataset."	"Novel architecture
Can be used with different backbone networks"	"The proposed adaptive threshold function T_{ada} can effectively reflect the predicting state of hard samples during training, and this has been illustrated in the experiment.
The quantitative results show the superiority of the proposed method."
296	Leveraging Labeling Representations in Uncertainty-based Semi-supervised Segmentation	"I like the idea of DAE, which encodes the global shape prior of the segmentation masks. It helps to predict a plausible segmentation mask for the teacher model and then provides a more reliable reference for uncertainty estimation.
The proposed method reduces the total computation since it only needs one single inference for the uncertainty.
The experimental comparisons with existing methods and ablation studies demonstrate the SOTA performance of the proposed method on the MRI dataset.
This paper is very well-written and easy to follow."	This paper proposes a labeling representation-based uncertainty estimation algorithm for semi-supervised segmentation. It obtains better performance than SOTAs on left atrium segmentation from 3D MR volumes in two different settings.	"-The paper proposed a novel way to estimate the pixel-wise uncertainty, which requires only single model inference.
-The ablation studies demonstrate the effectiveness and robustness of the proposed uncertainty estimation method.

The writing of the paper is clear."
297	LIDP: A Lung Image Dataset with Pathological Information for Lung Cancer Screening	"The strengths of the paper are:

A new database of pulmonary nodules with pathology-based gold standard
Proof of lack of generality of algorithms developed on the LIDC-IDRI database"	The key strength of the paper is that it provides an open set of images by which future research can build off of to develop and evaluate new approaches (detection, classification, etc.) for lung cancer detection. It addresses weaknesses of LIDC-IDRI used in broad research topics by having pathologically confirmed ground truth. This is data, if easy to share and access, would be of a big benefit to the research community in general.	"*	A new dataset (according to the authors, the largest available dataset with pathological gold standard) is presented to be used as a benchmark for early lung cancer detection and has pathological information instead of radiological analysis. 
*	The presence of hard-to-classify samples. 
*	The main disadvantages of the LIDC-IDRI dataset compared to the LIDP are explained, and reasons are given why only one other dataset is used for comparison.
*	The advantages of using this dataset, which can be used as a supplement to the LIDC-IDRI, are explained in detail.
*	It correctly explores the statistical and demographic distribution.
*	Overall, good arguments for the dataset presented."
298	LifeLonger: A Benchmark for Continual Disease Classification	"The authors provide an extensive evaluation of five baseline methods for task and class incremental learning.
Using a public available dataset such as the MedMNIST dataset is highly beneficial for a benchmark."	"a benchmark for continual learning algorithms on medical data is needed
the authors compare state of the art continual learning methods on 4 medical classification tasks"	"Using MedMNIST as a standardized dataset for benchmarking continual learning methods in the clinical domain is a simple yet sensible idea. The data is small enough that experiments would require minimal computational resources, but the results would be likelier to transfer to medical applications than those obtained with datasets such as SplitMNIST or SplitCIFAR.

Figure 1 successfully helps illustrate the setting and the different learning scenarios.

While many papers have compared EWC, MAS, LwC and iCarL, the fact that the authors include ""End-to-End Incremental Learning"" as a bias correction method is a good idea, especially for the class incremental experiments."
299	LiftReg: Limited Angle 2D/3D Deformable Registration	This is a very well written paper with some interesting ideas as well as good experimental methods. It does a good job explaining the overall reasoning and details of the methods and goes on to do a good amount of experiments, especially comparing to multiple prior works.	"The proposed network architecture operates based on first, ""lifting"" the 2D projections into a 3D space. This 3D space can be noted as a pseudo CT representation, whereby a deformation field is regressed between the lifted 3D space and the source 3D space. This problem formulation is unique and may help in alleviating the spatial ambiguity of traditional 2D-3D registration methods. The training loss is also an interesting point, where it combined a regularization term dedicated to the deformation field's basis coefficients and the similarity between the warped and the original 3D volume. The provided evaluation study is feasible and compares the performance of this algorithm to the state-of-the-art techniques such as regnet. The paper is clear and follows a proper structure."	The use of deep learning to solve the iterative 2D-3D registration problem.
300	Light-weight spatio-temporal graphs for segmentation and ejection fraction prediction in cardiac ultrasound	"Application of GCN for efficient LV segmentation in echo is interesting and relevant.

A public dataset is used for the experiments and the source code will be released."	"The main interesting aspect is the adaptation of mesh based formulation of spiral net, to contours (which, makes sense since contours are even simpler than meshes), and using that to do keypoint regression of the LV boundaries. This sort of approach would be ideal if estimating well defined keypoints in an anatomy was necessary.

Having the keypoints/segmentations is also helpful in enhancing the explainability of the model. Clinicians generally like it better if they can visualize the LV contours used for EF calculation.

Different components of the method are presented as building blocks and can be mixed and matched as needed.

Results are presented for both keypoint regression errors and the EF errors."	"Strong comparison against the SOA
The research is clinically relevant.
Authors focus on prediction time, which is critical for real-world applications but often omitted in research."
301	Local Attention Graph-based Transformer for Multi-target Genetic Alteration Prediction	"A framework integrates a novel local attention graph-based Transformer that restricts self-attention calculations in Transformers by using kNN graphs to model regional regimes within a tile.
Validations were done on two TCGA datasets for gastrointestinal cancer with reasonable baselines."	"The proposed method addressed important issues in current MIL methods for WSIs. For example, passing bag labels to instances may introduce noises as instance labels might be inconsistent with bag labels. Also, a lot of existing methods are not leveraging spatial correlation between instances, which contains important information in WSIs.
The method is clearly described and the visualization helps to understand the proposed method more intuitively."	Well motivated proposed approach, good analysis of the problem at hand, latest deep learning based approach to solve problem, careful experiments and clear analysis of the results, comparison with state-of-the-art methods are given.
302	Local Graph Fusion of Multi-View MR Images for Knee Osteoarthritis Diagnosis	The paper is well organized and clearly clarified. It proposed a novel LGF-Net to gradually fuse the multi-view MR images for knee OA grading. Experimental results show the best performance of the proposed LGF-Net and the effectiveness of GTN. This work can benefit the clinic diagnosis of OA based multi-view MR images.	"I agree that fusing local patch from multi-view images could benefit the knee OA diagnosis problem, and I think the local information can better reflect the degree of OA than the global information.

Combining the local patch information from multi-view slices and the GTN obtains good performance increase."	The authors proposed a novel method to fuse images from multi-view knee images using graph transformer network and local information. Previous approaches of fusing multi-contrast MR images relied only on late fusion strategies. The authors evaluate their approach in a comparative study with the current available approaches and presented that the proposed approach provided superior performance. The proposed approach can be extended to other MRI relevant tasks where multi-contrast images are used.
303	Localizing the Recurrent Laryngeal Nerve via Ultrasound with a Bayesian Shape Framework	This paper is well-written and organized. The idea of mimicking the standard approach surgeons take to identify the RLN according to its surrounding organs and using the inherent relative spatial relationships between organs is interesting and proved helpful.	This paper puts forward a method which could solve a practical clinical problem. The method's performance is good. The study design is impressive: lots of patients were involved; the new method is compared with many current methods; an ablation study shows that both local information and global context contributed to the good performance; visualization of the result is convincing.	"The authors proposed a novel approach to obtaining the candidate ROI centers that utilized prior clinical knowledge. In particular, Bayesian shape alignment introduces the prior knowledge that models the spatial relationship of RLN, common carotid arteries (CCA), thyroid, and trachea, which gives a good initial location for subsequence refinement.
The final results of RLN localization are significantly better than the baseline heatmap-based/regression-based methods."
304	Local-Region and Cross-Dataset Contrastive Learning for Retinal Vessel Segmentation	"The strengths of the paper:

The overall paper is well organized and the writing of the paper is great.

Although deep learning segmentation network methods are extensively studied for vessel segmentation, the authors present a novel way to further improve the segmentation results by contrastive learning approaches.  The presented method consists of local and global contrastive learning means to select hard samples and provide additional supervision into the segmentation network.

The authors provide experiments to show the effectiveness of the proposed contrastive learning methods. Results compared to previously reported methods are also analyzed in the paper."	"The paper is well written, and easy to read.
The algorithm is well presented."	"Authors motivate this work concisely - to extract discriminative features from those challenging vessel pixels by using context in local and global areas. The paper structure is clear and all sections echo the motivation well.

The contrastive strategy fits well with this retinal vessel segmentation task. Retinal vasculature is long and tortuous, some vessel pixels in complex vascular structures and low contrast background are elusive, which makes those vessel features are indiscriminative from the background. The idea of the contrastive strategy can enhance the model's capability of extracting discriminative features.

A variety of results are shown, including segmentation visualisation, quantitative segmentation metrics (two connectivity scores), and t-SNE maps."
305	Longitudinal Infant Functional Connectivity Prediction via Conditional Intensive Triplet Network	The main strength is, as in any other Deep Learning work, the better performance when compared with other available methods. The description of the architecture is rather clear and greatly appreciate from the reader's point of view. Personally, I think that given appropriate testing, this model shows great potential to be accepted in the clinical atmosphere given its simplicity with respect to the current competitors. Congratulations on designing from scratch an architecture that performs good.	The prediction of brain FC maturation at individual level is hard. The authors designed a simple but high efficient conditional intensive triplet network model to capture age and individual information separately in two extractors.	"identity and age related information could be extracted in the network.
the predicting result looks promising."
306	Long-tailed Multi-label Retinal Diseases Recognition via Relational Learning and Knowledge Distillation	"This work is dealing with an important problem, i.e., the long-tailed effect in multi-label classification.
The newly added components are reasonable for this specific task.
Comparably thorough related works.
Well written and easy to follow."	The ablation study and the qualitative and quantitative analysis performed for the authors.	"The motivation, problem description, and the proposed solution are very clear
The paper is well-written and pleasant to read
The method is evaluated on a public datasets and outperforms other relevant approaches."
307	Low-Dose CT Reconstruction via Dual-Domain Learning and Controllable Modulation	"The motivation is well clarified and meaningful.
This paper proposed a novel method to learn from the image and sinogram domain, resulting in an improved final reconstruction. The experiments show that the introduced controllable modulation module can control the degree of denoising according to the needs of doctors' diagnosis."	"It is an interesting research problem
The analysis is performed in several databases
The authors take into account the radiologist perception and not only image processing metrics"	"1 a dual-domain network to fully explore the mutual dependency between the CT image and raw projection data.
2 design a controllable module to achieve fine tuning of low-dose CT recon process with different noise levels."
308	Low-Resource Adversarial Domain Adaptation for Cross-Modality Nucleus Detection	The problem is defined well. The proposed stochastic data augmentation is formulated well. Experiments are quite comprehensive; they are conducted on 5 different datasets (4 public, 1 in-house) and consists of comparison with 4 other methods and ablation studies.	"The authors present a creative approach of transforming a source image, force this transformation to have a coherent structural meaning and back (i.e., get a target image, transform it into the source's domain and compare the structural meaning again). In this case, the structural information is forced by training a nuclei detector. This way, they guide the network on the creation of results that structurally reassemble more to each other, despite changing the domain.
The authors have worked on the definition of a fully differentiable data augmentation that works on the"	"* Strong and complete submission: clear and advanced methodology, convincing validation on versatile data.
* Results superior to the current state-of-the-art and on pair with direct training in the target domain."
309	LSSANet: A Long Short Slice-Aware Network for Pulmonary Nodule Detection	"The method is relatively new.
The logic is clearer.
The experiment is relatively sufficient."	"Effective design and comprehensive experiments: authors compare their method with several proposed methods, and LSSANet achieves convincing performance.
Clear writing: it is easy to follow the writing."	
310	MAL: Multi-modal attention learning for tumor diagnosis based on bipartite graph and multiple branches	"The idea of multi-modal attention learning is interesting and address an imortantresearch problem.
Authors used a relatively large clinical dataset to demonstarte the performance of their proposed method.
Performing extensive experiments and acheived high performance."	"1)	In this paper, images of different modalities and different planes are considered at the same time.
2)	It is novel to use bipartite graph structure to model the correlation of different modality data."	"1) An interesting multimodal fusion framework based on bipartite graph and attention learning to explore the correlation between different modalities;
2) The PMSLoss/PiTSLoss seem to encourage the model to learn the inherent similarity between features from different modalities at patient level;
3) The results show the effectiveness of this approach, through ablation study and comparison to doctors."
311	MaNi: Maximizing Mutual Information for Nuclei Cross-Domain Unsupervised Segmentation	"While employing mutual information for domain adaptation is not a new idea (i.e. 1, 2,3), the proposed approach, using masked average pooling, contrasting the averaged representation, and leveraging JSD as a surrogate loss for MI, can be considered a novel contribution.

Results show clear improvements over recent approaches for UDA in segmentation.

The paper is well written and easy follow. The motivation and contributions of the work are clearly described in the introduction, and the method is presented with sufficient details."	"1)The proposed method has achieved state-of-the-art performance under various UDA nuclei segmentation benchmarks.
2)This work has studied an important research topic, i.e., UDA nuclei semantic and instance segmentation tasks, which can enhance the models' generalization ability."	"The paper is well-written and well-motivated.
The use of Jensen-Shannon divergence (JSD bound) based mutual information estimator in the context of nuclei segmentation is novel. JSD has been used in feature alignment for text and image data. To the best of my knowledge, applying JSD for domain adaptation for nuclei segmentation is novel.
The paper has strong empirical results on different datasets. The paper evaluates on Nuclei Semantic Segmentation (TNBC-> KIRC/ TCIA and TCIA -> KIRC/ TNBC shift) and Nuclei Instance Segmentation (CoNSep -> PanNuke) and demonstrates competitive results over the baseline approaches."
312	Mapping in Cycles: Dual-Domain PET-CT Synthesis Framework with Cycle-Consistent Constraints	"a)  Different from previous cross-modality image synthesis methods that only exploit image domain information, the authors designed a novel dual-domain PET-CT synthesis framework to perform synthesis in both image and sinogram domains. 
b)  To enhance the PET-to-CT synthesis performance, the authors introduce a secondary CT-to-PET synthesis task and a two-stage training strategy with dual-domain consistency and cycle consistency to build a bidirectional mapping framework, encouraging structural consistency and stable convergency.
c) Experimental results show the effectiveness of the main contributions and the state-of-the-art image synthesis performance of the proposed method.
d) The methodology section including the network architecture as well as the objective functions is clearly described and the entire writing is easy to understand."	"The method is novel that using dual-domain learning in image-to-image translation. It makes sense to use FP and FBP operators to connect image and projection domain.
The experiments extensive to support the conclusion."	This paper is generally well written. By exploiting the dual-domain information, the proposed method outperformed the previous SOTA methods substantially in both quantitative and visual evaluations.
313	Mask Rearranging Data Augmentation for 3D Mitochondria Segmentation	"To increase the usually limited training data of 3D EM segmentation datasets, the authors propose an original method based on state-of-the-art image generation models adapted to 3D. The mask layout generator is a simple and effective solution to produce more diverse but realistic masks, from which synthetic EM images can be later generated. This is an interesting approach that opens the door to also generate synthetic images on other domains.
The results of using this data augmentation method are evaluated against the state of the art in the field of mitochondria segmentation on EM volumes and its impact is analyzed with a proper ablation study and by simulating the scarcity of training labeled data."	"The paper is fairly well written, albeit the method and presentation of results can be improved.
The authors  synthesize more diverse  images by producing more synthetic instance layouts
The paper performs rigorous analysis with ablation tests."	"The proposed generative module is independent of, and thus can be integrated into, any segmentation network, which can be leveraged to benefit various existing and new segmentation network designs.
The authors designed and conducted experiments with decreasing numbers of accessible annotations and demonstrated the increasing superiority of the proposed model compared with baseline methods. Such type of experiment dealing with data scarcity issue is very valuable to the community."
314	MaxStyle: Adversarial Style Composition for Robust Medical Image Segmentation	"1) The method is innovative, especially the part where adversarial mechanism is used to further improve the MixStyle layer perturbation.
2) The experiments conducted are robust. The Reviewer appreciates the amount of MR data that the Authors are able to collect and test. The Reviewer also appreciates the paradigm of comparing training on high-data regime vs low-data regime. The Reviewer also appreciates the inclusion of prostate dataset in the Supplement."	"The idea of adversarial learning between segmentor and style augmentor to generate ""hard"" style for segmentation is kind of interesting.

The organization is good, which is easy to follow.

Many aspects of evaluation of the effectiveness of the method."	The idea of expanding style space with additional noise and search for harder style composition is interesting and somewhat noble. Extensive experimental results and ablation studies shows the superiority and effectiveness of proposed model. Also, the clarity and organization of the paper is good.
315	MCP-Net: Inter-frame Motion Correction with Patlak Regularization for Whole-body Dynamic PET	"A kinetic model (Patlak) is added to account for tracer kinetics in dynamic PET imaging. Although Patlak only applies to irreversible tracers, the model itself is very favourable for motion correction, as the plasma input Cp on the right hand side of the equation is not affected by motion and can provide some robustness for using this as a constraint to estimate motion.
The evaluation in this work is done extensively."	"The motivations described in the paper define the need for an image registration technique in whole body PET very well.
The integration of a Patlak fitting module into the registration framework is novel. The addition of a Patlak loss penalty through a mean squared percentage fitting error in the loss function is new.
The comparison of the proposed approach against previous methods is insightful and the metrics chosen to describe the performance are adequate (e.g. normalized mutual information, avg-to-ref SSIM etc.).
Statistical analysis was also conducted, which is a plus given that not many statistical tests are run these days in DL in medical imaging papers.
The paper is easy to read and organized clearly."	This work makes use of tracer kinetics, which is a key characteristic of dynamic PET.  For this particular problem that the authors are trying to address, it makes a lot of sense to treat the motion correction not as a merely geometry problem.
316	Measurement-conditioned Denoising Diffusion Probabilistic Model for Under-sampled Medical Image Reconstruction	"This paper is well organized. The presentation is clear.
The diffusion and sampling process are defined in the measurement domain and conditioned on under-sampling mask, which makes the proposed method different from the existing DDPM methods.
Experimental results show that the proposed method is superior than compared baselines."	"As one of the highlights, the diffusion and sampling process are defined in
measurement domain rather than image domain."	"-The application of DDPM to accelerated MRI reconstruction is novel. 
-The condition is on the measurement."
317	Mesh-based 3D Motion Tracking in Cardiac MRI using Deep Learning	"The proposed method models the heart as a 3D geometric mesh and propose a network to estimate 3D motion of the heart mesh from 2D short- and long-axis CMR images.
The paper is well-written and easy to follow. The authors provided sufficient details about the proposed method."	"*	Experiments are performed on a large cohort of 530 subjects from the UK Biobank (testing set of 80 subjects).
*	Ablation studies clearly demonstrate the design decisions for both the input image configuration (using 3 views) (Table2) and the loss functions (Table 3).
*	A (brief) discussion regarding the choice of algorithm hyperparameters is presented (Sec. 3, Discussion).
*	The proposed method demonstrates improvements in registration accuracy compared to three other cardiac registration methods.
*	The clinical problem and background literature are covered well."	The inclusion of the mesh-to-image rasterizer is a bright idea. Usually combining 2D image information into any 3D tracking result needs an underlying interpolation step which takes time and extra computation resource (also introduces error). The rasterizer used in this work extracts 2D shape information in multiple directions and summarizes its together for 3D, which is a computationally more efficient process.
318	Meta-hallucinator: Towards few-shot cross-modality cardiac image segmentation	This paper tackles a challenging domain adaptation problem, for which the source domain only has a few labeled data and other data are unlabeled. A reasonable method is proposed and obtains improved and promising performance.	"The paper is well written.
The idea of meta-hallucination framework is novel. Unsupervised domain adaptation is a useful technique for segmentation problems where labels are sacrce. Combining meta-learning and semi-supervised augmentation might be a good attempt.
The experiment results are outstanding and convincing. The performance seems to be much better than other few-shot methods, and comparable with the fully supervised method."	"The manuscript is well-written and easy to understand.
The idea to achieve efficient few-shot cross-modality segmentation with limited labeled source data is interesting.
The experiment is sufficient to prove the effectiveness of the proposed method."
319	MIRST-DM: Multi-Instance RST with Drop-Max Layer for Robust Classification of Breast Cancer	"The proposal of multi-instance RST and drop-max layer seems novel.

The proposed approach performs significantly well against the adversarial attacks."	"The authors investigate the adversarial robustness of the deep models on small medical image classification tasks.
A multi-instance robust self-training with a drop-max layer is proposed to make robust training.
The proposed drop-max layer can remove unstable features to learn robust representations.
Experiments validate these claims for medical image classification purposes."	"The lack of large datasets if very common in the medical field, therefore adapting approaches to work well will less data is beneficial.
The paper is well written.
Cross-validation is used, which is critical for such small datasets."
320	Mixed Reality and Deep Learning for External Ventricular Drainage Placement: a Fast and Automatic Workflow for Emergency Treatments	"*The paper is very clear and well written
*The validation method is sound for every aspect of the system presented
*The validation procedure is run with a good number of surgeons"	The main strength of the paper is the fully automatic MR and deep learning-based workflow, which can provide fast navigation for the emergency EVD placement.	"A complete workflow is proposed
Meaningful application in the clinic"
321	mmFormer: Multimodal Medical Transformer for Incomplete Multimodal Learning of Brain Tumor Segmentation	"The paper is well written and results are properly presented.
The manuscript is focused on dealing with incomplete data which is a general issue in most of the medical datasets.
The mmFormer architecture is presented well to discuss each individual module in it."	The model developed here addresses an important clinical need as in many cases a complete set of all 4 MRI sequences are not acquired. The network combines the extracted features per input MRI sequence using an elegant modality correlated encoder. Forcing the network to learn meaningful representations from individual encoder for a specific MRI sequence using the auxiliary regularizer is novel.	The paper is of certain novelty to apply transformer as a new tenchinique in solving incomplete modality segmentation. It has good knowledge of background about multimodal brain tumor segmentation.
322	Modality-adaptive Feature Interaction for Brain Tumor Segmentation with Missing Modalities	"1) The problem addressed in this paper is important.
2) The authors address the brain tumor segmentation with missing modalities by 
introducing Modalityadaptive Feature Interaction (MFI) with multi-modal code. 
3) The method has novelty, although the novelty is not significant. 
4) The validation results show the improved peformance."	"1) To adaptively learn the complementary features among modalities (i.e., graph nodes), this paper introduces a multi-modal code to represent if different modalities are observed or not, to guide the learning process. Introducing MFI guided by multi-modal code into the different stages of a U-shaped architecture makes the multi-modal features hierarchically interact.
2) The experimental results demonstrated the positive effect of the proposed MFI."	"1- Simplicity: The proposed MFI is a simple yet effective approach for tumor segmentation with missing modalities.
2- The paper was validated on the BraTS 2018 dataset achieving the state-of-the-art results in incomplete mutli-modal brain tumor segmentation."
323	ModDrop++: A Dynamic Filter Network with Intra-subject Co-training for Multiple Sclerosis Lesion Segmentation with Missing Modalities	This paper presents a solution to the clinical practice where one or more MRI input sequences are absence during training and inference phase for a deep-learning method. Specifically designed dynamic head to scale the input and th intra-subject co-training to enhance the learning ability of network to learn similar features for different combinations of the input sequences. Extensive experiment of all possible input scenarios were conducted. The demonstration of the propsoed method and paper writing is clear.	"-The proposed approach is designed to be a plug-and-play method that can be easily integrated in any existing segmentation CNN.
-For the first time, dynamic filters are applied to the missing modality problem, showing interesting performance. 
-A novel strategy for intra-subjects co-trianing is proposed to leverage the intra-subject relation between the full and missing-modality data. Ablation studies are performed showing that this further improved the segmentation performance.
-Missing modalities are a persistend problem in MS imaging and, if confirmed by further studies, this method could have a significant impact on lesion segmentation automated tools.
-The manuscript is well written and straightforward to understand."	"novel application of dynamic filter network and modality weighting strategy to the ModDrop method of multimodal training
novel application of co-training to improve segmentation results
What I like about this approach is the way the fillter scaling matrices  adaptively adjusts to missing modality.  This is a much better way to handle missing modality than the original ModDrop approach that learns a fixed set of filter coefficients for all possible cases of missing modalities."
324	Modelling Cycles in Brain Networks with the Hodge Laplacian	The authors propose a novel algebraic method to identify and represent 1-cycles in a weighted graph. The simulation experiment shows high accuracy in discriminating networks with different topology.	"The topic of this submission is within the focus of MICCAI, and of potential
interest to a broader audience. The text is understandable for a reader with 
knowledge in network methods for modeling structural and functional data.
Interesting on-going work is presented here."	The paper is well-written and addresses all the necessary theoretical aspects, both Hodge Laplacian theory and persistent homology. Their novel 1-cycle basis helps to extract brain multi-way interaction between regions as opposed to conventional connection-based analysis. This is even more fruitful for analysis of DTI based networks which are more sparse and can be more discriminative in normal-patients comparison.
325	Momentum Contrastive Voxel-wise Representation Learning for Semi-supervised Volumetric Medical Image Segmentation	"While the novelty of each component is limited, the combined 3D semi-supervised segmentation network learning pipeline is, to the best of my knowledge, novel.
In particular however, the main selling point of this work is the final semi-supervised segmentation performance achieved by the proposed method, beating out competing methods by a notable margin especially in the low-supervision regime."	The method description is very detailed and clear. Over all, the paper is easy to follow. The evaluation seems to be complete, and the ablation study provides a good validation of the effectiveness of the different loss functions. Grid search for hyperparameter tuning is also performed. According to the results, the proposed method provides a good solution for 3D semi-supervised segmentation if only very few labeled images are available.	The strength of this paper is to adapt the contrastive learning idea in 3 dimensional-space and use the unlabeled dataset with dimensional-wise contrastive objective as semi-supervised setting.
326	Morphology-Aware Interactive Keypoint Estimation	"This submission tackles the problem of automatic keypoint estimation correction in X-ray image, where manual correction of multiple keypoints could be time-consuming and inefficient. Brute force approach is to correct each keypoint independently, the proposed method aims to reduce user interaction by introducing an interaction-guided gating network, to propagate the user input across the image.

A morphology-aware loss is proposed based on the observation that the degree of freedom between the keypoints is small in X-ray vertebra images, which regularizes the network to learn the inter-keypoint relationship to be similar to that of the ground truth."	The underlying assumption about keeping the clinician in the loop of landmark identification is very reasonable given that the presented network can fully benefit from the contextual knowledge of the clinicians in revising its predicted landmarks. The implemented network architecture (despite being already published as an RITM network) along with the morphology-aware loss seem appropriate choices for the application at hand. The provided evaluation study can support the paper's conclusions by providing a comparison to the state-of-the-art interactive segmentation methods.	"The authors present an interesting interactive strategy for landmark detection with convincing improvements compared to other approaches.
The authors evaluate their strategy against three other approaches.
The method is comparatively straight forward and modular with an interesting combination of attention-based interaction and additional regularization based on expected morphology."
327	Moving from 2D to 3D: volumetric medical image classification for rectal cancer staging	"The paper is nicely organised and written. Very good introduction, nice background on the disease and current methods of generating 3D features for classification.
Good experimental design and the results are clearly presented.
The finding in this paper is a good start point for other work in this direction."	"The manuscript is well-written and organized.
The author creates a good combination between center loss, triplet loss, and depth aggregation function to enhance the results."	The method idea of this paper is acceptable. And it yields encouraging results which exceeds performances of radiologists.
328	MRI Reconstruction by Completing Under-sampled K-space Data with Learnable Fourier Interpolation	"In MRI related studies, the reconstruction of missing/corrupted k-space data has been a challenge. In this work, the authors have suggested a deep learning methodology for MRI image reconstruction. It considers MRI reconstruction as an interpolation problem in k-space. The interpolation scheme suggested in this paper is focusing on  adaptive interpolating weights trained
with DNN. For benchmarking, they have evaluated the performance of the proposed method with a few available algorithms such as zero-filling method (ZF), TV-regularization-based method,
ADMM-Net and the plug-&-play methods. According to their results, it shows that their proposed method has outperformed all those work and it takes much less training and testing time.
Further, the proposed method has outperformed all those methods in the presence of noise, too."	-  The interpolation strategy is simple yet it seems somehow effective.	The major strength of the paper relied on the novelety of the proposed method. The authors addressed the MRI reconstruction problem by interpolating directly the under-sampled k-space with a deep learning method, which seems to be not frequently done in the MRI reconstruction field. This proposed method provided better image quality endpoints values (PSNR, SSIM) than state-of-the-art methods and appeared to be computationally efficient.
329	mulEEG: A Multi-View Representation Learning on EEG Signals	The manuscript is well organised.	"The proposed method is significant in EEG Domain.
The experiment setup is good and the evaluation process.
The training aspect is novel by utilizing two views."	"Using complementary information to construct positive pairs in contrastive learning for EEG is novel.
The paper is well-written."
330	Multidimensional Hypergraph on Delineated Retinal Features for Pathological Myopia Task.	"The authors propose a hypergraph learning to detect early or mild pathological myopia. 
*	This approach extracts features from several prominent retinal structures, instead of the conventional methods, which focus on only one structure.
*	The results from hypergraph learning on a mixture of retinal structure provides highest performance, which is statistically significant than conventional CNN based method."	"The idea of modulating delineated retinal anatomical features from fundus images using a multimodal hypergraph learning technique is an important task. In this sense, the paper is attempting an important problem in a timely manner.
The authors used a hypergraph to learn higher-order associations, which is novel and smart way to solve the overall problem.
The proposed method is validated on a real dataset (I the paper and the supplementary material) and show promising results."	"Main strengths of the paper:

The authors present a timely and interesting application of hypergraphs to the problem of classifying pathological myopia

They also present sub-algorithms for segmenting choroid tubular patterns, and make the code publicly available on github"
331	Multi-head Attention-based Masked Sequence Model for Mapping Functional Brain Networks	"Novel application
o	One main strength of this paper is the novel application of using multi-head attention and masked method to extract features in fMRI time-series.
Intuitive design
o	Also, the application of cosine similarity loss is also notable because it is simply and effectively making their model retain original task design curve during task fMRI scans.
Systematic evaluation
o	They evaluated the results of MAMSM using more than three different models to extract functional brain networks and reported a comparison of extracted temporal features and spatial features, respectively. Especially, comparison to spatiotemporal attention autoencoder (STAAE) enhanced the results of this paper, because STAAE is the current proposed deep learning-based model for extraction of functional brain networks."	"a) This paper extracts the functional brain network of tfMRI based on a pre-trained model for learning latent representation, which is novel.
b) The new proposed loss function fully considered the potential feature distribution and the relationship with the task design curves.
c) The idea is easy to follow and implement."	"Contributions:
1). It is very interesting to introduce Natural Language Processing (NLP) techniques for revealing the time series and task-evoked brain networks from task-based fMRI.
2). The methodological validation is presented with the other algorithms, using the identified task-evoked brain networks, time series, and intrinsic brain networks.
3). This paper is written well."
332	Multi-institutional Investigation of Model Generalizability for Virtual Contrast-enhanced MRI Synthesis	"The paper is well organized and has presented enough figures and tables to support authors' ideas.
It is novel to investigate the generalizability of the proposed method."	The problem addressed by the paper is clinically relevant. Generation of virtual contrast-enhanced MRIs from T1 and T2 MRIs may help for improving patient care and decreasing the acquisition time of MRI protocols. One of the strengths of the paper is the multi-centric dataset the authors gathered for studying the generalizability of their model. Studying the generalizability of deep learning models may facilitate their integration in clinical practice. The paper is globally well written.	"1) Well organised and written paper. Easily Readable, and high reproducibility.
2) Well planning study which answers clearly the initial hypothesis.
3) Clinical contribution and conclusions about generalization."
333	Multimodal Brain Tumor Segmentation Using Contrastive Learning based Feature Comparison with Monomodal Normal Brain Images	"The proposed method take advantage of both multimodal and monomodal data to increase the performance of tumor segmentation.

CLFC module, seems to be simple, yet effective. It improves the efficiency of segmentation backbone.

The experimental results show that the proposed method improves segmentation over the method which does not use the contrastive learning."	"The writing of the manuscript is generally good and clear.
To the Reviewer's knowledge, the idea of using normal brain images to help brain tumor segmentation with CNNs is novel. This is further enhanced by the feature alignment module for regions of the normal brain. This idea is inspired by how radiologists learn to identify brain tumor, i.e., by knowing well the normal brain structure. Incorporating this concept is interesting.
The ablation studies show the effectiveness of the proposed method over the baselines."	"The paper well-developed the following points:
1)a novel method to generate normal appearance MR slice from the corresponding tumoral slice. 2)they employed an advanced model to efficiently capture the information from so called paired images of healthy-unhealthy slices. 3)Extensive experiments were conducted to evaluate the efficacy of the model.
In general, the studied problem is of great interest for the MICCAI community, the proposed method sounds both theoretically and experimentally, and the reported results on comprehensive standard data represent the efficacy of the proposed method. The paper is well-written and easy to follow."
334	Multimodal Contrastive Learning for Prospective Personalized Estimation of CT Organ Dose	"The approach includes different sources of information.
Excellent agreement with predicted TCM and reference organ doses.
Low computation time required."	"The clinical value is high.
The idea to leverage contrastive learning between two profile views of a same patient to improve dose prediction is very interesting and quite original in the field, especially given the demonstrated improved performances"	The paper is well written and the method seems sound, with an appropriate use of CL for learning meaningful representations.
335	Multi-Modal Hypergraph Diffusion Network with Dual Prior for Alzheimer Classification	"1.This paper attempted to introduce a dual embedding strategy for constructing a semantics robust hypergraph.
2.This paper presents a dynamically adjusted hypergraph diffusion model, via a semi-explicit flow, to improve the predictive uncertainty
3.This paper performed two ablations studies regarding their design and the modalities used to support the design of their technique.
4.The experimental results of'EMCI vs LMCI'shows outperform current techniques for Alzheimer's disease diagnosis."	"Firstly, the method of this paper is innovative. Specifically, this paper uses multi-modal data (i.e. imaging and non-imaging data) to deal with the classification of Alzheimer's disease diagnosis. And based on those data, the paper introduces a semi-supervised hypergraph learning framework. 
Secondly, in order to adjust the diffusion of hypergraph, the authors proposed an uncertainty hypergraph minimization of Eq. 3.
Thirdly, the author's experiments are very informative. The authors performed experiments not only for binary classification but also for multi-classification to verify the effectiveness of the proposed method."	The overall framework is clear and the proposed model has shown its effectiveness.
336	Multi-Modal Masked Autoencoders for Medical Vision-and-Language Pre-Training	"Open dataset: All results were obtained from publicly available datasets.
Large improvement: Compared with existing methods, this paper achieves noticeable performance gain in multiple public benchmarks.
Clear illustration: The description and illustration of the proposed joint pre-training are clear and easy to implement.
Sufficient comparison: The proposed method is compared with several competitive methods in each benchmark dataset and shows great improvement."	"The proposed approach is simple yet effective.
Experimental results on three downstream tasks show that the proposed method is effective."	"A multimodal pretraining method for the medical field is proposed. That is, the proposed multimode masked autoencoder learns in a self-supervised way.
Due to different information densities, the input image and text using different masking ratios. Reconstruction takes advantage of different levels of visual and textual features to deal with different levels of visual and language abstraction.
Evaluate three tasks, including Med-VQA, medical image-text classification, and medical image-text retrieval, and achieve great improvement."
337	Multi-modal Retinal Image Registration Using a Keypoint-Based Vessel Structure Aligning Network	"The proposed method in general works for different imaging pairs such as CF-FA, IR-OCTA-OCT
The proposed method is unsupervised/self-supervised and does not require any manually labeled ground truth for training network
Overall the paper is well written with good illustrations."	"The authors provide an end-to-end method, combining the RetinaCraquelureNet (based on ResNet) and SuperGlue networks into a single system.
The method is build on top of 2 individually proved neural networks, with extra refinements and fine tuning to improve both their individual and joint performances. So while it doesn't present a great innovation, is a push towards the good direction.
The paper is very clear, and has a very detailed description of the system and the experiments."	The method is novel, the manuscript logic is clear, and the verification experiments are abundant.
338	Multi-Modal Unsupervised Pre-Training for Surgical Operating Room Workflow Analysis	"Relevant problem
Novel approach
Good dataset for evaluation
Comparison against different methods"	"-Multi-modality usage: this work proposes to fuse different modalities to pretrain the model encoder. It forces semantically similar group together for different modalities.
-Training process: the current methods fall into the directly end2end training process while rare works focus on the pretraining + finetuning process. This paper shows a potential way to pretrain the image encoder with multi-modal data."	"experiment parameters are provided
leveraging multimodal data to pretrain models
experimental results on two tasks"
339	Multimodal-GuideNet: Gaze-Probe Bidirectional Guidance in Obstetric Ultrasound Scanning	In my estimation, this is a great paper overall. Well written, informative and innovative. The proposed method can be useful in the real world, shows improved performance over the state of the art and may inspire further innovative research.	"This approach is entirely novel - and as far as I am aware, this is the only group pursuing these ideas. While the use of eye-gaze has in the past been used as part of skills assessment for sonographers, this is the first time it has been used as part of a dataset to  train a network. The key point is the use of  gaze and probe movements as random variables to account for inter- and intra-sonographer variation. The underlying assumption is that a sonographer will react to the next image inferred from their hand movement on the probe, and conversely that the probe motion can guide gaze. To this end, the authors have developed a platform  ""Multimodal-GuideNet"" that observes  scanning patterns from a large number of actual obstetric scanning studies where  probe motion and gaze trajectory data have been collected along with the US images.
The authors have shown convincingly that the model can generate real-time predictions to guide the operators, based on the probe  motion and gaze trajectory signals."	"This paper explores a novel idea to leverage the gaze information to guide the US probe. The idea is nicely formulated in a multi-task learning framework where graph convolutional network is used. 
The paper is scientifically sounding and also well structured and written. The experiments were thoughtfully designed with results clearly presented."
340	Multiple Instance Learning with Mixed Supervision in Gleason Grading	"A novel stragety to incorporte both slide-level and limted pixle-level labels.
A random masking stragety to mitigate the effects caused by the inaccurate instance-level labels."	"The authors proposed to use separate instance-level and slide-level labeling, which leads to a mixed supervision problem. 
They proposed, so called mixed supervision transformer to mix the two labels and to improve the overall performance of the model.
The experimental results supports the introduction of mixed supervision and Transformer."	"The mixed supervision of slide-level label and instance-level label is an interesting idea in the field of digital pathology, which is reasonable to alleviate the lack of supervision for WSI classification.
The work is built upon the state-of-the-art Transformer backbone."
341	Multi-scale Super-resolution Magnetic Resonance Spectroscopic Imaging with Adjustable Sharpness	"The organization of this paper is good, and the idea of this work is novel. 
Proposed model could dynamically update the network with the different metabolites and be conditioned on the weight of adversarial loss to adjust the sharpness of the resolved image. Extensive experiments demonstrate that the proposed network could realize efficiency in training time and the number of parameters, and verify the effectiveness of adjustable sharpness. Besides, it achieves competitive performance compared with Hypernetworks and AMLayer."	"The proposed framework can achieve comparable performance as the networks are trained under a single-scale setting.
The developed model can  provide multiple levels of sharpness for each super-resolved metabolic map learn the super-resolution process based on the specific metabolite."	"The idea of applying the filter scaling strategy for adaptive super-resolution was well-motivated.
The proposed method considered the distinct spatial characteristics of different metabolites and proved to improve the performance of the model.
The experiments were extensive and proved the effectiveness of each modulating module of the proposed model."
342	Multiscale Unsupervised Retinal Edema Area Segmentation in OCT Images	"clearly written
good results
related work relevant
experiments well performed"	Overall, the manuscript is well written and well presented. The design of the framework in two stages has been effective, as well as the incorporation of multiscale information in both stages. The quantitative analysis on the public retinal dataset demonstrated the superior performance over state-of-the-art unsupervised approaches.	The authors introduced scale-invariant regularization in image clustering, which is considered novel since the proposed network outperforms the SOTA substantially.
343	Multi-site Normative Modeling of Diffusion Tensor Imaging Metrics Using Hierarchical Bayesian Regression	"A novel application of the normative modeling Hierarchical Bayesian Regression framework in modeling age effects on white matter diffusion tensor imaging metrics.
Strong evaluation of different model fitting strategies under the HBR framework, illustrating their impact on 1) modeling age effects in multi-site brain DTI data, and 2) subsequent hypothesis testing based on the fitted outcomes."	"This study uses a large-scale dataset consisting of multiple site datasets, provide a more sensible explanation.
Also, the work provides new insight into the detection of rare genetic copy number variants, noting how model complexity can impact findings."	"The paper is generally well written, It is work on exciting ensemble of data in relation to clinically relevant metrics. The authors are not creating a new method, but rather trying to understand the impact of modelling choices on downstream analysis. This is important work that has a direct relevance for applications in this domain.
The major finding of the paper is that it surely matters how you model age in your data. This is very often overlooked, but yet a very important thing to investigate. Nonlinear age effects can be pervasive in biological data.
The authors do a good job of describing the dataset and the way they process and model their data. They provide clear references to methods used and clearly cite the source of all software that they use in their analysis.
The visualizations are ok, and the statistical comparisons are mostly good."
344	Multi-Task Lung Nodule Detection in Chest Radiographs with a Dual Head Network	The paper has been well laid out, clearly presented, and with improved results. Ablation study has been conducted to study the effect of the proposed modifications to the original Faster R-CNN approach.	The authors use a double headed network to predict the presence of a global label indicating the presence of nodules, and use a local label to predict the location of nodules,In addition, the authors propose a new double headed enhancement (DHA) strategy, which proves the importance of DHN in further improving the prediction of global and local nodules.	"The paper is logically organized and very easy to read.
The paper proposed multi-task lung nodule detection to help the false negative detection in chest radiograph analysis. By learning global case-level prediction and local detection simultaneously, both tasks show performance improvements.
Dual-path augmentation is novel as the global and local paths may need to adopt different augmentation strategies."
345	Multi-task video enhancement for dental interventions	"The paper is well organized and written. The figures are very well made, and the method design and experiment setup are well described with sufficient details for readers to understand the work.
The multi-task architecture design seems interesting and reasonably thoughted, and the authors demonstrate the comparable performance of the proposed method against some state-of-the-art works on several tasks."	"(1) First dataset of dental videos with multi-task labels. In this work, a new application of macro-camera for dental is proposed. 
(2) A solid multi-task benchmark model for 3 important dental video tasks. The video restoration is important for deblurring and noise suppression. Segmentation could be used to assist doctors. And homography estimation could be used for video stabilization."	"The paper is well-written, easy to follow and addresses an important issue.
adequate amount of literature review, experiments have been done."
346	Multi-TransSP: Multimodal Transformer for Survival Prediction of Nasopharyngeal Carcinoma Patients	"A architecture to incorporate both CT image and text data to predict patients' overall survival
New state-of-the-art performance on the task."	"Broad benchmarking even including text
Well-motivated task
Related work is clearly discussed
Figures are well-prepared"	"The paper tackles an important problem of fusion between text and imaging data, which is commonly overlooked. Most works focus on fusing the information between different imaging modalities, or imaging and genomics modalities.
The paper employs the transformer model to perform the fusion. Given that the transformer model has been shown to work very well in other contexts, it is natural to try this model for key tasks with medical data.
The paper provides an elaborate ablation study to evaluate the model."
347	Multi-view Local Co-occurrence and Global Consistency Learning Improve Mammogram Classification Generalisation	There is novelty in the local aspects and the specific application area.	"1) The idea of using both view of mammogram through global Consistency and local occurrence is interesting and methodologically sound. 
2) The authors proposed using global consistency module to enforce similar representation of both view of mammogram is very applicable since the important features for diagnosis should be available in embedding of both views.
3)  The multi-head attention modules is correctly used to derive interactions between samples from both views.
4) The authors provided good comparisons and ablation study to show the performance of their model."	"This study considers both local and global information from two views for mammogram classification by designing global consistency module and multi-view local co-occurrence module.

The generalization of the performance of the proposed approach was verified by four testing sets."
348	MUSCLE: Multi-task Self-supervised Continual Learning to Pre-train Deep Models for X-ray Images of Multiple Body Parts	"As the authors claimed, the multi-task learning,  self-supervised learning and continual learning are jointly unified in one learning scheme.
The overall learning paradigm is clear and the authors employ many tricks to improve the accuracy of the prediction on X-ray images.
Many experiments validate their claims on different datasets."	The innovative point of this paper is the extension of MoCo framework into multi-dataset training with cyclic and reshuffled learning schedule and continuous learning strategy. It uses multiple datasets pre-training to solve the heterogeneity problem and uses continuous learning to tackle catastrophic forgetting.	The use of 9 publicly available datasets makes it possible for others to compare against. Evaluation of MUSCLE shows improvements for many of the reported performance metrics.
349	NAF: Neural Attenuation Fields for Sparse-View CBCT Reconstruction	"To my knowledge the first paper which shows a variation of a CT reconstruction algorithm inspired by Neural Radiance Fields on measured data and in the practically CBCT acquisition geometry.
Very good presentation, easy to follow. Also very good graphics to illustrate the method.
Well prepared and fair evaluation against many competitive methods."	"The organization and presentation is clear.
The proposed neural attenuation field extends the application of implicit function for CBCT reconstruction. A tailored solution of hash encoder is adopted for position encoding for human organs.
Experiments demonstrate promising results of this proposed method in terms of reconstruction quality and computation cost compared with iterative based methods and another baseline of implicit function based method."	As claimed by the authors, no external data or priors is required using the proposed self-supervised model.
350	NerveFormer: A Cross-Sample Aggregation Network for Corneal Nerve Segmentation	The problem is relevant, and the approach is sound.	The combination of internal local attention and external attention is novel. The proposed method outperformed other state-of-the-art methods on two public CCM datasets. Ablation study shows the effectiveness of the prosed two blocks.	"The paper points out a common issue in corneal nerve segmentation - the background artifacts (e.g., Langerhans cells).
The proposed method combines the merits of two transformer designs (deformable DETR and external attention) and successfully applied it to alleviate the identified issue.
The state-of-the-art performance is achieved on the two CCM datasets, and an ablation study is included to verify the effectiveness of each component."
351	NestedFormer: Nested Modality-Aware Transformer for Brain Tumor Segmentation	"The paper is well written.
The results are presented on two different brain segmentation dataset.
The proposed NestedFormer is discussed in detail."	"This paper is overall well written and easy to follow.
The usage of transformer is relatively novel and could be of interest to many readers.
NestedFormer provides an alternative and new approach for multi-modality fusion, which still an active research problem, and look promising."	"Proposal of a new combination of UNet and Transformer.
Comparison with the latest methods such as TransBTS and Unetr."
352	Neural Annotation Refinement: Development of a New 3D Dataset for Adrenal Gland Analysis	"The mask annotation refinement problem that this paper tried to solve is an interesting problem;
With the refined annotations produced by the proposed method, the model can diagnose adrenal glands better than the original ones."	"The main strengths are as follows:

Incorporating HU values of CT images to a part of the input of implicit function-based shape modeling method.

The refinement of segmentation masks reduces noise and improve diagnosis as a downstream classification task.

A new dataset with smoother shape and less noise for image segmentation and classfication."	"Contribution of a new dataset.

The neural refinement idea is interesting, the method novelty itself might be incremental but I don't see it becomes a major issue. This paper is addressing a common issue that the human annotation is normally not smooth and full of mistakes because of annotations on slices for instead the whole volume, surface-level correction is expected.

This paper might also help active learning researchers.

Extensive experiments."
353	Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in Robotic Surgery	In addition to small optimization improvements and surface smoothness improvements, the biggest advance of this paper appears to be the incorporation of a frame-to-frame deformation model and surgical tool mask to reconstruct soft tissue surfaces lying beneath  the surgical tool. Figure 2 suggests that the algorithm is very effective in achieving this task, and the video  in the supplementary material reinforce this conclusion. The video  in particular clearly demonstrates the ability of this approach to render regions for which  other methods have problems.	"1) Tool mask-guided ray casting is designed for eliminating tool occlusion. 
2) Depth-cueing resampling and depth-map loss are introduced to make NeRF effective on single-view reconstruction.
3) The proposed method is complete and the results are impressive."	"1) The authors proposed an innovative and effective design. For example, the NeRF structure is incorporated with mask-guided ray casting which solves the issue from tool occlusion. 
2) The authors also did thorough evaluation by comparing against the most recent SOTA method. Furthermore, ablation study was done to further investigate the contribution of each customized modules to the significant improvement on performance. And lastly, the fact that the method was tested on clinical dataset is another highlight of the paper."
354	Neuro-RDM: An Explainable Neural Network Landscape of Reaction-Diffusion Model for Cognitive Task Recognition	"Interesting premise of inferring functional brain networks based on steady-state solutions of a reaction-diffusion equation.

The authors map each component of the reaction-diffusion model onto a neural network that can be optimized using standard gradient-based techniques.

The approach blends structured model-based assumptions with the representational power of deep learning. The authors demonstrate that this structure provides robustness over RNNs.

The model achieves higher state-recognition accuracy than two RNN methods and a PDE solver."	The idea of re-expressing differential equation models in a neural network via component decomposition or equivalent counterparts	Novelty in the formulation is the salient point of this work. The utilization of GNNs as Neural ODE solvers for modeling the dynamics of functional connectivity is an interesting perspective in the field and a departure from more popular neural architectures such as RNNs, LSTMs or transformers. In my opinion, this line of analysis may provide interesting new insights in the field.
355	Noise transfer for unsupervised domain adaptation of retinal OCT images	"SVDNA is relatively simple to apply, and does not appear to require in-depth training with deep models
Evaluation on public datasets"	"The proposed idea seems to be novel. The idea is very simple and it seems to properly adapt the domain when moving from a less noisy one to a more noisy one. The performance in the opposite scenario is uncertain.
The paper is well written and clear."	It is interesting that style transfer between the source and target domain can be achieved by combining content components from the source image and noise components from a target image after singular value decomposition. The proposed method is simple and does not require the modification of the basic model architecture or extra training of a style transfer model. The experimental results and discussion presented in the paper and supplementary material are sufficient.
356	Noise2SR: Learning to Denoise from Super-Resolved Single Noisy Fluorescence Image	"Novelty: method does not require multiple noisy observations and external noise distribution assumptions.
The method shows a good performance in terms of PSNR and SSIM when compared to some state-of-the-art methods."	"Novelty. It's a neat idea to make use of image subsampling to generate the image pairs for self-supervision. (1) Compared to the previous Noise2Self work, the sampling of pixels for prediction is straightforward in this work. (2) Instead of simply predicting masked pixel intensities, this work trains a super-resolution network to effectively regress with 1/4 pixels to the rest pixels.

Convincing experiments. On both simulated and two types of microscopy images, the proposed method significantly outperforms (0.2-0.4 dB) its counterpart Noise2Self and achieves competitive results with the SOTA N2N that requires multiple observations.

The paper is well-written and easy to follow. The method is described in detail and straightforward to reproduce."	"Simple idea of using self-supervision
Easy to follow the paper"
357	Non-iterative Coarse-to-fine Registration based on Single-pass Deep Cumulative Learning	"1) Injecting the deformed moving image into the decoder is a novel idea. 
2) The paper is well written."	"The main strengths of the paper can be concluded bellow:
1) Proposed a coarse-to-fine unsupervised learning-based registration framework by using a single network.
2) Relatively large experimental datasets."	"1- This paper presents a non-iterative coarse-to-fine deformable registration for medical applications
based on cumulative learning.
2- Better performance: Compared to other iterative deep registration methods, NICE-Net can perform more accurate registration with a single network in a single iteration with the advantage of being fast."
358	Nonlinear Conditional Time-varying Granger Causality of Task fMRI via Deep Stacking Networks and Adaptive Convolutional Kernels	"The non-linearity in Granger causality is a known-issue therefore the paper focuses on a relevant topic. 
The paper is well-written."	It is intuitive and novel to substitute the linear regression in Granger Causality analysis into non-linear functions, such as the stacked Deep Stacking Network used in this work. Using a network will not only improve the performance of fitting the underlying relationship between time series (thus obtaining more faithful GC estimation), but also has the potential of extending the scope of modeling (like the ACK operator introduced in this work).	The presented method is novel and applicable to real world datasets. The problem considered has a long history and is relevant to the community.
359	Nonlinear Regression of Remaining Surgical Duration via Bayesian LSTM-based Deep Negative Correlation Learning	"This work purposed a novel formulation for RSD. Based on the architecture of CNN+LSTM, the Bayesian LSTM(B-LSTM) is introduced and implemented with deep negative correlation learning method for this regression task.
The network is trained in a multi-purpose manner which perform phase classification, surgeon's experience estimation, RSD estimation and uncertainty estimation simultaneously. The number of B-LSTM models allows estimation of uncertainty in a single sample during inference by setting different dropout probabilities for feature diversity with each model, rather than multiple sampling to detect uncertainty as in previous work.
A comparison on MAE results with three other state-of-the-art methods is provided with significant test showing a reliable result on 5min and 2min to the end RSD estimation performance."	"The proposed method is simple and achieves strong results, even without phase/expertise labels (as opposed to CataNet)
The authors use a statistical test to demonstrate the significance of their results
Uncertainty estimation is likely very useful for future-prediction tasks like RSD prediction. To my best knowledge, previous RSD methods have not considered uncertainty.
The uncertainty-related plots (Fig. 2(A) + suppl. Fig. 2) look very promising.
The proposed architecture is builds on the one in CataNet as it used the same backbone and same-size LSTM and is therefore directly comparable. (However, this could maybe be made clearer in the paper.)
Also, the training procedure is similar but simpler than the one from CataNet (essentially the first 2 stages from CataNet)."	"BD-Net achieves better results than the SOTA methods when applied to predicting RSD for cataract surgery.

This work validates the effectiveness of Bayesian-LSTM and DNCL for improving generalization ability on RSD prediction task."
360	NVUM: Non-Volatile Unbiased Memory for Robust Medical Image Classification	"The idea is relatively novel.
Well written. The overflow and structure are very clear.
The method is relatively clear.
Experimental results are good."	"Noisy multi-label imbalanced learning is of great significance for both computer aided diagnose systems and clinical applications.
The idea of penalising differences between current and early-learning model logits together with logit adjustment is interesting.
The paper is well organized and the implementation details are well described."	"The paper has a well-organized writing and clear motivation for each part of the proposed method: memory module with regularization term for noisy label issue, and class prior update for imbalanced issue.
The paper pay attention to the combined challenges in robust learning of MIA: noisy and imbalanced multi-label medical image classification, which is a common issue in the real-world datasets but rarely explored.
The paper provides detailed analysis of the gradient effect of the novel regularization term in noisy label classification with BCE loss.
The proposed method NVUM is evaluated on two benchmarks with real world noisy multi-label chestXray datasets, and achieves SOTA results with large performance gain compared with other SOTA methods.
Comprehensive ablation studies are reported and the effect of different hyper-parameter and prior settings are fully explored."
361	On Surgical Planning of Percutaneous Nephrolithotomy with Patient-Specific CTRs	"This work presents a novel optimization approach of kidney stones for the purposes of surgical planning. When further validated, this could prove informative for patient-specific planning of PCNL procedures.
The use of CTRs is usually justified by the need for more granular maneuverability because of their ability to create complex curves.
The importance of this work also lies in the fact that the algorithm doesn't require human intervention which makes the process much more autonomous, contrary to previous works cited."	"Method evaluated on real patient data with clear clinical utility
Thorough description of the optimization process
Fairly accessible compute requirements"	"1- The topic is interesting 
2- Well-Structural writing"
362	On the Dataset Quality Control for Image Registration Evaluation	"Quality control and the ability to independently evaluate quality is absolutely key to the deployment of public data sets for registration evaluation. This paper proposes and evaluates a novel method to evaluate fiducial point quality using variograms.
I am not aware of prior use of this methodology, nor I am aware of other practical methods for the evaluation of fiducial point quality. The methodology described in the paper (with some exceptions, see weaknesses) could be applied to most data sets used for registration evaluation, and therefore is potentially a very valuable contribution to the field."	A well written contribution that introduces the method to a new field and applies to the use case of fiducial / landmark selection within a clinical environment.	"The main strength of the paper is it topic itself: enhancing the quality of medical annotations. This topic is rarely addressed but is of prime importance as annotations are extensively used for training or evaluation of methods both in the MIC and CAI communities.
The ""specificity"" appears good: most (if not all? see details below) variograms tagged as problematic correspond to landmarks of poor quality. Once identified, these landmarks could thus be improved.
The methods is sound and clear, and several patterns of variograms are clearly described (isolated landmarks, clusters, ...).
While not fully automatic, the proposed tool clearly fasten the control quality process."
363	On the Uncertain Single-View Depths in Colonoscopies	"The paper starts off strong, introducing the domain topic and terminology around uncertainty.

The self-supervised learning and teacher-student model with uncertainty are novel. Especially, the latter as the paper links this well to domain shift and label reliablity.

The paper combines both aleatoric and epistemic uncertainy and the results indicate a clear distinguishment between both.

The results from the paper can have impact on a wide variety of endoscopic CAD applications, where a more accurate and reliable (monocular) depth estimation, could lead to a better performance."	"The authors claim that they are the first to apply Bayesian networks for depth estimation with uncertainty on colonoscopic images. 
The paper is well structured and both quantitative and qualitative validation results of the proposed methods are also provided."	Authors present clear explanation of the methods with thorough explanation of the intuition behind the methods.
364	One-Shot Segmentation of Novel White Matter Tracts via Extensive Data Augmentation	The motivation for one-shot WM tract segmentation is sound, and their implementation in the random cutout and tract cutout is easy and clear to understand	"The authors address the ongoing challenge of reducing the annotation time for novel white matter tracts, their presented method could lead to further improvements in this field.
Using their approach, the authors find a solution to extend the performance of an already existing and established method (TractSeg) and enable it to perform well in a one-shot scenario.
The authors use an in house and public available datasets and on both datasets the performance compared to the baseline is improved."	Given the fact that in the field the studies of analyzing white matter are limited by the number of available tract segmentations, the proposed method can be useful to generate potentially more based on existing data without requiring tons of manual seminations.
365	Online Easy Example Mining for Weakly-supervised Gland Segmentation from Histology Images	"*The approach that weights the loss based on the confidence of the segmentation network is reasonable.
*In the experiments, the proposed method was better than the compared method."	"(1) This paper analyzes the difference between histology image and natural image in segmentation task, and the difficulty of gland segmentation.
(2) The paper proposes a method that encourages the network to focus on credible supervision signals rather than noisy signals."	"*	The paper is well motivated, clear and easy to understand. Weakly supervised glandular segmentation is non-trivial due to the underlying homogeneity of tissue morphology and low contrast, especially since existing WSSS methods for natural images may underperform.
*	The  proposed OEEM and normalized losses are novel with several ablations highlighting it's effectiveness.
*	The use of a publicly available dataset is a plus, with a strong supervised baseline.
*	I appreciate the intuition employed for the different variants of the losses, especially considering the several assumptions drawn regarding normal and diseased images."
366	Online Reflective Learning for Robust Medical Image Segmentation	"The paper is well written and easy to understand. The problem is well motivated.
The method of synthesise and ""reflect"" is interesting, novel and technically sound.
The demo/video included in this paper is a plus.
The experiments and results are extensive."	"The paper addresses an important topic in medical imaging of ""on the fly"" model adaptation to a new test domain.  The approach appears to be novel, and most design choices are sound. The method is evaluated on 3 datasets, and achieves the best results. The method is compared to relevant competitors as well as to general sota segmentation models."	"The proposed structure similarity loss is sophisticated yet effective, which is a combination of mutual information loss and the normalised cross-correlation loss, weighted by predicted heatmap.
Extensive experiments were performed on three cross-vendor datasets. Results demonstrate the efficacy of the method.
Ablation study has also been conducted to verify the contribution of each component.
The online demo provided is impressive."
367	OnlyCaps-Net, a capsule only based neural network for 2D and 3D semantic segmentation	"-Implementing two novels squashing functions softsquash and unitsquash.
-Introduce unit routing, a parameter-free single pass routing mechanism
-Comparing with state of art public method on public datasets
-New convolutional capsule, depthwise convolutional capsule."	The three contributions seem interesting liste above, in particular the gain in matter of speed and memory consumption (while preserving the accuracy).	"The rationale of the method is clear
The performance of the method are validated using a cross-fold validation
Ablation study
The improvements introduced in this work can be adapted to 2D and 3D applications"
368	Only-Train-Once MR Fingerprinting for Magnetization Transfer Contrast Quantification	"An Only-Train-Once MR fingerprinting (OTOM) framework that estimates MTC tissue parameters from MR fingerprints regardless of the MRF schedule was proposed, thereby avoiding time-consuming process such as generation of training dataset and network training for different MRF schedules.
The deep neural networks were constrained to a single MRF schedule corresponding to the training dataset. If the MRF schedule is changed, the deep neural network has to be trained with new training dataset that was generated with the new MRF schedule. This process is very time consuming and inefficient.So the utility of MRF techniques would benefit greatly from the development of streamlined deep learning frameworks or even only-train-once methods for various MRF sequences. And OTOM can be applied to any MRF schedules unlike the previous deep learning based studies dedicated to only a single fixed MRF schedule."	"Application of the bidirectional LSTM seems apt for the magnetization evolution signal
The ability to apply it to different MRF schedules is attractive although a clear explanation of how this happens needs to be detailed. Please see next section"	"The proposed Only-Train-Once MR fingerprinting (OTOM) seems a promising solution of estimating quantitative parameters from different MRF schedules. 
Solid investigation of the OTOM method in digital phantom and in vivo data."
369	Opinions Vary? Diagnosis First!	"The idea of somewhat value the expertness level of each expert by using a diagnosis network is quite original and, and at the same time, sound.

Proposal is well explained and elaborated"	"High frequency filtering technique
learning multi-rater expertness maps
comprehensive results"	The authors displayed the relationship between the glaucoma diagnosis and the OD/OC segmentation labels. It's a good view to improve the performance of the glaucoma diagnosis by fusing the multi-rater OD/OC segmentation labels.
370	Opportunistic Incidence Prediction of Multiple Chronic Diseases from Abdominal CT Imaging Using Multi-Task Learning	"The strengths of the paper are related to the problem statement. Once we have a CT, we have a clear view of the status of the patient and a lot of information can be extracted. The method presented, planar reformats guided by anatomy, and outcomes obtained from ICD codes are an 'easy' way to obtain both the input and the output of the system.
The evaluation with respect to the percentage of training points is interesting and valuable. The more training points, the better performance, as one could imagine."	"A multi-planar 2D CT processing method is designed to extract useful information for five diseases, which reduces the dimensionality of the volumetric 3D data and outperforms 2D single-plane approaches.
A multi-task low-label learning method is designed for opportunistic incidence prediction of multiple chronic diseases from abdominal CT imaging, and achieves outperformance in 5-year incidence prediction of CKD, DM, HT, IHD and OST."	"The concept is an interesting one, trying to utilise all information available on an image for predcitions - mimicing a real world situation - as most DL models focus on a particular singlar disease/prediction. Therefore the idea of having a source and target disease is interesting and novel for this type of application when used together with a multi-planar apparoach.
I like that you include a statistical test into your work - always appreciate seeing this in comparative anlaysis.

The paper is nicely laid out and easy to follow."
371	Optimal MRI Undersampling Patterns for Pathology Localization	The idea is interesting, and the paper is well written and content rich.	"Overall, the manuscript is nicely written. The Methods, Experiments, and Discussion sections are nicely presented. The Introduction also nicely summarises the motivation and related research works.
The proposed methodology is interesting, and as the authors have demonstrated, retains the segmentation quality in ACDC dataset even at moderate to high acceleration factors."	The main strength of the paper is the development of MRI under sampling for pathology localization. Unlike other MRI under sampling based SSIM or PSNR on whole image domain, the proposed method can be more effective on specific tasks such as organ segmentation or pathology bounding box detection, which are clinically  meaningful. The paper is well validated on existing public data and showed the improved performance for downstream tasks.
372	Optimal Transport based Ordinal Pattern Tree Kernel for Brain Disease Diagnosis	"The paper details a method that on the base on my (limited) knowledge of the state of the art is novel.
The approach is explained in detail and the paper could be reproduced by other research groups engaging in similar topics.
Table 1 shows a comparison with other state of the art approaches. The proposed method yields better results."	"The adoption of OPT for brain network analysis is novel.
The OT kernel is also novel for the OPT comparison."	This paper introduces a novel idea of utilizing the brain network to analyze brain disease patterns. The proposed ordinal pattern tree is a good idea of establishing hierarchical relationship of nodes in a brain network. The whole paper is written in a smooth way and it is easy to follow.
373	ORF-Net: Deep Omni-supervised Rib Fracture Detection from Chest CT Scans	"Overall the paper is well organized making it easy to follow. Below are detailed strengths from my view:
1, Using Omni-supervised learning to handle the heterogeneous annotations. This helps to simultaneously leverage the different forms of supervision for model training is novel.
2,The (1-W_i) multiplier introduced in the classification loss further strengthens the ""dynamic focal"" idea. This effectiveness is confirmed by the ablation study
3,Extensive experiments. In table 1, the paper fairly compares other state-of-the-art semi-supervised strategies for the task and proves the effectiveness of its proposed ORF-net. Table 2 further proves that the soft confidence multiplier can help to improve the model."	"The manuscript is overall well-written and easy to follow
The proposed method tries to utilize all levels of annotations and actually transform them all into pixel-level supervision. The idea is valid and sound
Ablation study on the components in the proposed method is conducted and discussed."	"This paper introduced an omni-supervised learning framework, which can leverage box annotation, dot annotation, and unlabeled data.
This paper introduced a dynamic label assignment strategy to combine the output from multiple branches for model training.
Experiments on the new dataset demonstrated the efficacy of the proposed method and the dynamic label assignment strategy."
374	Orientation-guided Graph Convolutional Network for Bone Surface Segmentation	"The author(s) proposed an orientation-guided graph convolutional network
for bone surface segmentation.
The proposed method outperforms UNet and a couple of other machine learning methods on the test set.
Overall, the paper is written and organized very well."	The dataset is fairly large. The method has been compared with the common UNet approach and 2 other methods used in the literature on bone surface segmentation. Evaluation is fairly thorough with suitable metrics.	"-Experimental Rigour: The experiments presented in this paper are thorough, assessing the proposed approach with both the connectivity metric and traditional Dice score, including comparison to existing approaches and an ablation study, as well as providing many details about the implementation and hyperparameters used.
-Novelty: Although this problem has been investigated in other works, this paper provides a new approach with novel features, including the incorporation of orientation information."
375	Orientation-Shared Convolution Representation for CT Metal Artifact Learning	The methodology has a solid theoretical background and shows promising results in both synthetic and real image data. The unnecessity of the sinogram is preferable from a practical point of view, where sinograms are not available. The proposed image-domain algorithm can also reduce the secondary artifacts due to the error in the geometric calibration (i.e., slight inconsistency between the physical imaging geometry and the geometry calculated by the calibration.)	"Novel formulation for the existing DICDNet by integrating the rotationally symmetrical streaking property and filter parameterization.
The method is also demonstrated on clinical data."	"Evaluation against multiple competitive modern methods.
Novel and innovative, independent ideas."
376	Out-of-Distribution Detection for Long-tailed and Fine-grained Skin Lesion Images	"As far as the reviewer knows, mixup between different occurrence groups is a novel approach (at least for skin lesion images). 
Authors extensively tested on various combinations of mixup."	"The paper is generally well-written and ideas are well-presented.
The authors does a good job in citing the previous work, exploring the different OOD methods, and briefly explaining the idea of the relevant papers.
The authors identify a limitation with the current OOD methods as these methods are not suitable for practical clinical applications where the differences between in-distribution (ID) and OOD samples are visually subtle. They design their study to be able to tackle this limitation and also evaluate on a real-world clinical dataset collected by the authors.
The idea of using targeted mixup augmentation and prototype learning in OOD is novel and seems to give better performance than baselines.
The method is evaluated against several OOD methods and on two different datasets. The proposed method has superior performance in OOD in both ISIC and the in-house dataset, this shows the robustness of the proposed method in real-world clinical datasets."	Overall the paper is clear and quite comprehensive. The addressed topic is clinically and methodologically relevant and the proposed method has a potential to be applied to other types of the imaging. There is a reasonable amount of ablation and comparison reported to allow a fair understanding of the method's interest .
377	Overlooked Trustworthiness of Saliency Maps	"Important class of problems where in saliency maps for trustworthiness is quantified and explored.
First attempt at quantifying the lack of trustworthiness by saliency maps.
Good experiments and coverage of the saliency maps techniques used to demonstrate their case."	"This work helps to draw the community's attention to the (lack of) trustworthiness of most interpretability saliency map methods.
It presents a novel analysis of the interpretability saliency map methods' quality by introducing two desired properties: relevance and resistance.
Conclusions are well-supported by the experiments."	"The authors propose the relevance and resistance criteria to evaluate the trustworthiness of saliency maps.
The authors experimentally demonstrate that some popular saliency map-based methods either lack relevance or resistance qualitatively and quantitatively."
378	Parameter-free latent space transformer for zero-shot bidirectional cross-modality liver segmentation	"use of modern transformer approaches
integration of a clever transform model to adapt target intensity
solid descriptions of latent spaces"	The authors propose a zero-shot bidirectional cross-modality liver segmentation method by investigating a parameter-free latent space through the prior knowledge from CT and MR images,which address the domain shift in cross CT-MR liver segmentation task. The evaluation is done on a variety of datasets. The structure of the manuscript is clear. This is an interesting and good paper.	This paper proposes a novel way to solve the cross-modality segmentation puzzle: its main focus is on feature commonality from different modalities images, without relying on deep learning models, and most of the existing research is devoted to the optimization of neural network models. Through the inherent prior knowledge (liver intensity distribution), a bidirectional parameter-free latent feature space is found. When one modality is not marked, the cross-modality segmentation is realized by using the data of the other modality.
379	Patcher: Patch Transformers with Mixture of Experts for Precise Medical Image Segmentation	"The authors present a transformer-based network for medical image segmentation by embedding mixture of experts, and it has achieved a superior performance over state-of-the-art methods.
The writing of this work is easy to follow.
Two datasets are employed for evaluating the proposed segmentation method."	"The proposed model structure, including Patcher and MoE, is novel and interesting.
The experimental results are comprehensive and convincing. I appreciate Figure 4 showing the function of each expert."	The design choices of the presented architecture are justified properly, the paper is well written and organized. The ideas are either novel, a novel combination of existing ideas or well executed.
380	Patch-wise Deep Metric Learning for Unsupervised Low-Dose CT Denoising	This paper proposed a novel method for low-dose CT denoising based on the patch-wise deep metric learning. The algorithm can successfully make the network focus on the anatomic information and neglect the noise features by the push and the pull between the features in the embedding space.	"Use deep metric learning by setting two hidden embedding space in the generate network before the output layer to make the GAN more stable
Set the positive pair from same location of noisy input and denoised output to maintain the structural and set the negative pair from different location of same image to suppress the noise level"	"Most denoising papers do not take into account CT numbers, but purely consider PSNR and SSIM. This is an excellent view of the problem.
The method is simple and can be easily reproduced. The results are very promising statistically. The ablation studies provide good explanation for hyper parameter choices."
381	PD-DWI: Predicting response to neoadjuvant chemotherapy in invasive breast cancer with Physiologically-Decomposed Diffusion-Weighted MRI machine-learning model	"1) Very well written manuscript.
2) The clinical relevance is well motivated (avoiding the need for contrast-enhanced MRI).
3) The methodological choices are well motivated.
4) The method is validated on a public challenge dataset, and shows promising results."	"Used the BMMR2 challenge dataset for training and testing for the proposed machine learning model.
Breast DWI data were analyzed by the bi-exponential signal decay model, generating D (pure diffusion coefficient), D* (pseudo-diffusion coefficient), and F (pseudo-diffusion fraction). Both ADC and F were used to extract 3D radiomics features for model prediction."	"The main strengths of this work:
(1) One novel medical imaging method, called Physiologically-Decomposed Diffusion-Weighted MRI (PD-DWI), demonstrated a substantial improvement in pCR prediction, without the need for lengthy DWI acquisition times, Gadolinium-based contrast agent injections, and DCE-MRI imaging. I think it's interesting, and it is a good study of medical physics. But the work only demonstrated that PD-DWI could improve the machine learning model performance, not further finding new imaging patterns or biomarkers, that were the most important for clinical application.
(2) Some interesting finds. The work found the relation between DWI signal attenuation decay and pCR prediction and accounted for the different physiological cues associated with pCR as reflected by the DWI signal rather than using aggregated information by means of the ADC map.
(3) The top prediction performance. The model got an AUC of 0.8849, which overperformed the top-performance in the challenge (AUC = 0.8397)."
382	Personalized Diagnostic Tool for Thyroid Cancer Classification using Multi-view Ultrasound	"A novel approach with three main components towards personalized diagnosis.
Application of multi-view US images for better diagnosis output."	"The research topic is relatively novel. There are few works on multi-view ultrasonic image classification at present.
This work designs a view-weighted fusion module. The existing multi-view ultrasonic image classification work treats different views without distinction, however different views have different degrees of importance in different tasks. Based on this, the authors design a personalized weighting allocation network to dynamically fuse different views.
This work designs a self-supervised view-aware contrastive loss. Based on the original contrastive loss, the authors design a contrastive loss from the perspective of multi-view, and verify that the new Loss has better effect than the original loss through experiments."	The overall framework is clear and the proposed model has shown its effectiveness.
383	Personalized dMRI Harmonization on Cortical Surface	"1) The problem of the harmonization of surface-based imaging data is very relevant in clinical studies. To the best of my knowledge, this is the first work to consider this problem.
2) A method is developed to analyze inter-subject local correspondence which includes the geometric properties of the surface and the cortical thickness information."	"The idea of reducing cortical mismatch for better harmonization is novel.
The paper is well-written.
The authors stated the problem and motivation well and clear."	"Well-motivated
Decently written
Well structured
Strong study design
Strong technical implementation
Neat figures"
384	PET denoising and uncertainty estimation based on NVAE model using quantile regression loss	"Enabling uncertainty estimation when processing images is important to increase trust in computational tools, especilly in a clinical context.
Thanks to the quantile regression loss, uncertainty is estimated in a more computationaly efficient way than in previous works."	The major strengths of the work are reflected in 1) improved image denoising based on the PSNR and SSIM metrics, 2) NVAE-QR model avoids the variance shrinkage issue, and 3) shorter processing time compared to the other two methods.	Using the quantile regression loss avoids variance shrinking and allows estimating the variance directly from the quantiles, which is faster than using Monte Carlo sampling.
385	PHTrans: Parallelly Aggregating Global and Local Representations for Medical Image Segmentation	"The studied problem is important.
The designed trans&conv block is neat."	It outperforms nnUNet and some medical image segmentation transformer models such as TransUNet and CoTr.	"This work looked at a popular and important problem in medical image segmentation - how to efficiently hybrid CNN and ViT.
Reasonable novel method has been proposed.
Extensive experiments have demonstrated substantial benefits of the proposed method on two datasets.
The manuscript is overall well written."
386	Physically Inspired Constraint for Unsupervised Regularized Ultrasound Elastography	The problem of displacement estimation in ultrasound elastography (and similar applications) is still an ongoing unsolved problem and this paper's approach of using biomechanics-motivated constraints is a solid approach.	The paper proposes a novel Loss function that enforces physical correctness during unsupervised training of the network. The experimental results demonstrate strong effectiveness.	"The motivation and innovation of this work are good.
A new constraint based on the Poisson's ratio for lateral displacement estimation."
387	Physiological Model based Deep Learning Framework for Cardiac TMP Recovery	Using dynamics to approach the inverse problem in ECG is  indeed  necessary and useful. That is particularly true for  3D (or 2D endo-epi)  cardiac models. Adapting a Kalman  filter to work for  a non-linear  dynamic  model with neural networks is interesing as well.	The paper presents a novel framework for predicting TMP from BSP using data-driven Kalman filtering network. The paper introduced a novel method and compares its results to various recent methods with favorable results for the presented method.	"Designing a hybrid physiologically meaningful DL-based network for recovering TMP from BSP and embedding state update equations into the DL-based framework and which makes this approach interpretable.
Taking into account the inaccuracy in the state transition equation and adding the noise variable to compensate for that.
Interesting design of the loss function to ensure the accuracy of the state transition results and the final results.
Careful design of experiments and superior performance compared to a few related works."
388	Physiology-based simulation of the retinal vasculature enables annotation-free segmentation of OCT angiographs	"The proposed formulation is novel, to the best of my knowledge.

The preliminary results shows advantages in the use of the synthetic data for pretraining + refinement on real data, improving the performance of the 2D segmentation achieved with only training on real data.

Preliminary results on 3D segmentation of real OCTA volumes using the synthetic data only.

Ablation study."	"The paper is very well written.
The paper addresses an extremely important and clinically relevant medical imaging problem.
The results are promising and authors did a lot of experiments."	"The simulation of OCTA images and their corresponding labels are based on two novel components: a physiology-based simulation and a suite of physics-based image augmentations.
The authors demonstrate the feasibility of the proposed method by successfully training several segmentation algorithms, providing an effective tool for solving manual annotation.
It appears that the proposed method holds considerable promise for expansion beyond vessel segmentation and ultimately to advance the quantitative analysis of OCTA in clinical practice."
389	Point Beyond Class: A Benchmark for Weakly Semi-Supervised Abnormality Localization in Chest X-Rays	"While the work focuses on applying Point DETR to abnormality localization with chest X-rays, the two regularization terms (multi-point consistency and symmetric consistency) proposed to improve the original framework seems interesting and novel.
The multi-point consistency cleverly utilize the strongly labeled data to generate more point-labeled data and drives the model to generate the consistent bounding box from different point annotations inside the same abnormality. 
The symmetric consistency adopts a self-supervision scheme and drives the model to generate consistent predictions under different transformations (flipping and masking)."	"The presentation is clear and easy to follow.
The proposed solution is driven by the medical formulation, and the self-supervised learning loss make great sense.
The authors have done detailed analysis on a dataset by changing the backbones and the children model.
The released benchmark is likely applicable to other researchers in the same field."	"The method. Point DETR is a promising method for weakly-supervised object detection (WSSOD) and to the best of my knowledge the authors propose the application of this method to CXR images.
 
The regularization. Most importantly, the authors propose some novelty in the form of stronger regularization for Point DETR. This regularization makes sense for the chosen application and improve the mean Average Precision.
 
The experiments. The method's evaluation is quite thorough as an ablation study is first performed before comparing their new method to the existing ones for WSSOD of CXR. This evaluation is notably performed on two publicly available datasets."
390	Poisson2Sparse: Self-Supervised Poisson Denoising From a Single Image	Use of convolution sparse coding network to denoise the  image by maximizing the likelihood function for poisson distributed noise	"This paper leverages existing methods and combines them with neural networks. This is both interpretable and in this case may actually reduce the number of free parameters in the process.
The challenge dealt with is about self-supervised learning, which is a well-known problem in biomedical imaging. The authors have demonstrated their results on a variety of problems, which are not limited to a single modality.
The mathematics of the paper are very strong and equations are clear and easy to follow."	"1)	This paper presented a novel self-supervised approach to denoise biomedical images that follow the Poisson noise model.
2)	The proposed method only needs a single noisy image which is desirable in many practical applications like biomedical imaging.
3)	This work unrolls traditional iterative optimization methods into neural networks-based methods, which provides a new perspective of using modern deep learning technologies to deal with the traditional learning methods."
391	Pose-based Tremor Classification for Parkinson's Disease Diagnosis from Video	"1) The proposed network is explained in detail and in an easy-to-understand manner.
2) The reasons for the design choices are thoroughly explained."	The proposed methodology based on graph neural nets to represent postural configurations is promising and coherent. Also, the attention models proposed inside the strategy avoid the loss of weakly relationships among joints. Also, the authors show an interesting back propagation of probability output to support the explainability of results.	"The solution is light weight (only seven 2D body joints as input), low-cost, and only needs videos of the subject to get an indicator about a potential Parkinson's diagnosis, therefore the system is very accessible, and the potential clinical impact is high.
The authors present an extensive evaluation, including a comparison against the state-of-the-art and an ablation study and show that the proposed modules improve the model's performance.
By inspecting the attention weights, the network performance and also failure cases can be interpreted."
392	Position-prior Clustering-based Self-attention Module for Knee Cartilage Segmentation	"Based on some experimental results and some related work that this paper referred, I think the PCAM is a flexible plug-in module, and could be treated and utilized as a self-attention module to strengthen the relative features for the segmentation targets in certain layer. Although the authors only apply the PCAM for the knee cartilages segmentation problem, I think this module could be further used for other organ/tissue segmentation.

The reproducibility of the PCAM is not difficult."	"The proposed position-prior and clustering-based attention module is technically novel.
The paper is well-structured.
Validation is thorough. Comparisons between the proposed method and previous methods are provided."	PCAM is a novel formulation that can be added to an available DL model to improve knee cartilage segmentations. The evaluation of the approach was done by comparing the approach with the current state-of-the art segmentation methods.
393	Predicting molecular traits from tissue morphology through self-interactive multi-instance learning	The proposed method achieves the best performance (AUC score) on all four benchmarking datasets; the paper is well-written and the analysis is performed thoroughly.	"The motivation of this paper is clear and reasonable.
The paper is well-organized and the method is clearly introduced and demonstrated by figure 2."	"The paper is very well written, easy to follow with and with a clear presentation of results.
I find the multi-stage framework for both feature and endpoint learning quite interesting and well motivated considering the current literature on WSI classification."
394	Predicting Spatio-Temporal Human Brain Response Using fMRI	The paper proposed a novel framework based on Siamese network to predict high temporal and spatial resolution brain activities using fMRI data. This framework is interesting since current brain observation techniques have limitations in either spatial or temporal resolution. The current study adopts Siamese network to establish the relationship between cross-modal network prediction and original brain activity time series, and uses Polynomial projection operators to overcome the problem of gradient vanishing when long time series are taken into consideration.	"This paper proposes a general framework for discretizing time points and projecting them onto a polynomial basis by a novel recurrent memory optimization method, which connects the mapping between brain regions and time points.
This method enables high-resolution temporal signal prediction for each voxel of the brain using only fMRI data.
The method can simultaneously consider the spatial and temporal aspects of neural activity."	"a) Modeling the brain dynamics is an interesting and important problem.
b) The proposed method can predict the brain state with both high spatial/temporal resolution.
c) A feasible approach for dealing with gradient vanishing in modeling MEG data with RNN."
395	Privacy Preserving Image Registration	This is a pretty cool idea! In light of all the hype around federated learning, it is quite interesting to see a work that addresses the low-level implementation details of image registration algorithms using encryption.	the problem of preserving privacy is pratically valid	The main strengths of the paper lies in the fact that the authors have used cryptographic tools to develop an image registration algorithm. The paper is well written and easy to follow.
396	ProCo: Prototype-aware Contrastive Learning for Long-tailed Medical Image Classification	"Long-tailed medical image classification is studied in this paper, and the authors make an investigation on this task.
Contrastive learning and prototype learning are jointly considered in the overall learning framework.
A recalibration idea is given to make the alignment.
Experiments show the effectiveness of the proposed method on different datasets."	"The paper addresses an important problem in practical medical image classification, class imbalance. The motivation is good.
The experiments show promising results."	"The proposed framework, ProCo, is a novel contrastive learning method for the long-tailed medical classification problem. By introducing synthesized adversial proto-instance into the contrastive learning, ProCo can encourage the network to rectify the decision boundaries of the tailed categories. A prototype recalibration strategy is also proposed to address the prototype bias problem during training.
Sufficient experiments are conducted on two public long-tailed medical datasets (ISIC2018 and APTOS2019). Accuracy and F1-score are reported on these two datasets, and the experimental results are consistent with the conclusions.
Ablation studies were performed on the three proposed modules. The results show that each component contributes to improvement."
397	Prognostic Imaging Biomarker Discovery in Survival Analysis for Idiopathic Pulmonary Fibrosis	the proposed framework could detect novel biomarker, which is very useful to guide the radiologist.	I believe this paper to be novel not only in the proposed method (that combines contrastive learning, spherical k-Means clustering, ViT clustering, etc), but also by the fact that using the proposed method a novel biomarker was found.	The proposed approach is interesting, because it offers some degree of explainability (by relying on image patches) and lowers the complexity of ViT by assigning image patches to clusters (via K-means). Evaluation on hold-out data indicates a strong improvement of the proposed approach over 3D ResNet approaches.
398	Progression models for imaging data with Longitudinal Variational Auto Encoders	"provided a progression model that disentangles temporal changes from changes due to inter-patients variability, and allows sampling patients' trajectories at any time point, to infer missing data or predict future progression;
proceeded to dimension reduction using a convolutional VAE with the added constraint that latent representations must comply with the structure of a generative statistical model of the trajectories;
demonstrated this method on a synthetic data set and on both MRI and PET scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI), recovering known patterns in normal or pathological brain aging."	"The paper successfully addresses the difficult problem of generating disease progression models from images.
The solution is original and very innovative. It successfully combines the finding of a latent space representation with the effects of disease evolution in a very original way.
The simulated experiments are smartly selected and they show a proof of concept of the ability of the method to generate appropriate diseased image models. Indeed, the experiments in MRI and PET data show that the method is able to provide patterns typically seen in the real images."	Although the idea of mixing VAE with Euclidean regression models is not new, the proposed method is a good try to futher move this direction forward. The results on the synthetic data domenstrates the effectiveness of the proposed method to some extent.
399	Progressive Deep Segmentation of Coronary Artery via Hierarchical Topology Learning	"-Anatomical structure relationships and topological features of segmentation target contribute to segment small targets. The proposed framework well combines this information with deep learning-based segmentation models.
-The proposed method achieved better segmentation accuracy in the quantitative evaluation."	There are two main strengths of the paper: 1) This paper proposed a novel architecture that takes into account the dependency of vessel and chamber. 2) The HTL proposed in this paper improves the segmentation results.	"Clear structure: The workflow of proposed framework is clear and detailed, which visually illustrates the main method flow.
Valuable motivation: The paper addresses the optimization of practical details in coronary artery segmentation problems.
Detailed method: It provides a very detailed description of method details, including formulas and diagrams. The method is reasonable in design and specific in description.
Intuitive experiment: Different evaluation indexes are compared objectively with those of advanced methods. The ablation experiment also demonstrates the necessity of each network module."
400	Progressive Subsampling for Oversampled Data - Application to Quantitative MRI	"The paper recognizes signal reconstruction is only a means to obtain downstream results and provides qualitative downstream results.
The paper adopts the task framing from the 2019 MUDI challenge and compares from the winning baseline from that challenge.
This work presents results clearly superior to the baselines, however the reason for the improvements is unclear (see weaknesses).
The RFE idea seems to be a good idea, but it is unclear at this point. (I would assume this is connected to ""Alg.-line 8 is m et = max {m t - (e - E d )I e-E d * I iD (i), 0}"", see Table 2; Judging from Table 2, this would be the critical bit, but it remains a guess)"	"The method is well described and the paper well written. The description of the method is very precise in algorithm 1.
The building blocks for improvement over previous methods like the exponential moving average for sample selection and the neural architecture search are well motivated.
I appreciate the effort making an anonymous version of the code available during review and the long-term usable links to the relevant websites."	"Replacing a weighting scheme with an elimination of features is a more robust implementation approach
Comparison with the SARDU-Net and related new versions is commendable and shows improved stability and performance"
401	Prostate Cancer Histology Synthesis using StyleGAN Latent Space Annotation	"(1) The paper is well written and easy to follow with. 
(2) The authors asked independent pathologist to evaluate the generated images, who provides professional opinion from clinical view. 
(3) The paper provides limitations of their work."	"A novel approach to produce and evaluate learnt latent features in PCa;
An evaluation by a pathologist with annotations;
Challenging indication (PCa) and relevant problem (synthetic data generation and validation)."	"The paper describes a very interesting approach
The finding that there seems to be ""semantic"" structure in the latent space of an unsupervised generative model that can in principle be used for downstream classification opens some interesting directions for further research for digital pathology.
For a first proof-of-principle study, I think the paper has some encouraging results."
402	PRO-TIP: Phantom for RObust automatic ultrasound calibration by TIP detection	The main strength of the paper is a new calibration phantom for US probe. The tip of the phantom can be detected using machine learning automatically for easier probe calibration.	"Their goal is not achieving better accuracy than current state-of the-art methods, but they compare their results to the ""Expert"" calibration without human intervention. Accordingly, their method achieved similar results to the expert calibration both in average error and distribution shape.
Their proposed phantom design is easy to manufacture"	"Generalizability: The inclusion of multiple set-ups with different probes and vendors in the dataset is a key strength of this work. As well, the experiment explicitly introducing images from a new system and quantifying the error strengthens the claim of generalizability.
Dissemination: The commitment to providing openly available plans for 3D printing the phantom in different scales and the code is another major strength of this work."
403	Prototype Learning of Inter-network Connectivity for ASD Diagnosis and Personalized Analysis	"The pape is well-written.
The design of the model, problem formulation and experimentation are in good standing.
They demonstrate better results than GNN methods with predefined ROIs and other convolutional methods with and without prototypes."	"The paper is well organized with clear writing and explanation, and is easy to follow.

Adopting prototype learning to generate neuroscientific explanation is an interesting premise and is novel for this application.

The experimental results demonstrate improvements over state-of-the-art baselines for classification"	"The paper proposes an interesting method for learning global inter-network relationships - considering each ROI a seed of a network, the sequence of FCs values for each ROI are analyzed using a transformer encoder architecture.

The classification approach uses prototype learning, thus embedding some interpretability directly into the classification model learning.

I greatly appreciate that the parameter settings for all the models are shared (in the supplementary), enhancing reproducibility and assessment of experimental results.

The experiments use the public ABIDE dataset, also enhancing reproducibility.

The general flow of the paper is well-organized."
404	Pseudo Bias-Balanced Learning for Debiased Chest X-ray Classification	novel approach to debiasing	"Conceptual innovation
Novel methodology"	"Dataset bias is truly noteworthy problem in medical image domain. A simple example, most of the subjects who choose to receive specific medical scans may have similar symptoms and diseases. It is often hard to handle such conditions since the labeling processing is troublesome and require additional experts labor. The method proposed by this paper tries to deal with this problem without explicit labeling process.

The method itself, PBBL, is straight forward, easy to follow and seems feasible to me. The use of data is also very reasonable. The authors first generate two types of highly biased dataset which are biased towards data source and gender information respectively. Then the models is trained with a bias-balanced softmax.

To generalize the algorithm to unknown bias, rather than data source or gender information, the authors took a step further by applying a generalized cross entropy loss. The major assumption is ""dataset biases would be preferred when they were easier to be learned than the intended features"", which matches the intuition."
405	Radiological Reports Improve Pre-Training for Localized Imaging Tasks on Chest X-Rays	The authors demonstrate that text-supervised methods outperform all other methods on 13 out of 18 tasks and are less sensitive to the downstream dataset size on some tasks. The authors show that transfer from classification does not perform well and common supervised classification methods seem to be unable to utilize image labels effectively for localized downstream tasks. The authors provide a good justification for the results.	I appreciate the huge amount of experiments in this paper. They show the effectiveness of existing text-supervised methods and compare them with image-only self-supervised methods and transfer from classification. The experimental results show the text-supervised methods outperform all other methods on 13 out of 18 tasks.	"The comparison of the performance of contrastive and text-supervised on localized imaging tasks such as sementic segmentation and object detection is interesting. It is inspiring to show that text-supervision is even better than contrastive supervision in most of the tasks.
The experiments are extensive and includes several datasets."
406	RandStainNA: Learning Stain-Agnostic Features from Histology Slides by Bridging Stain Augmentation and Normalization	"Combination of SA and SN is a great way to augment the dataset size and train more robust deep learning networks in computational pathology. RandStainNA has a simple yet effective manner to combine both.

The evaluation is done in two standard open-access computational pathology datasets for colorectal cancer classification and nuclei segmentation.

The paper is well written and easy to follow.

The proposed method is evaluated with many recent backbone DL architectures which highlights the superior performance of  RandStainNA to the baselines."	the idea of combining SN&SA is interesting	"The attempt of combine SN and SA into one unified framework is interesting and there are few previous research works address on this topic. Overall, this topic has some degree of novelty.
The experimental design is relatively complete. It considers two different tasks (classification and segmentation), different baseline CNN architectures, three color spaces (LAB, HSV, HED).
The organization of this paper is clear and easy to follow."
407	Real-Time 3D Reconstruction of Human Vocal Folds via High-Speed Laser-Endoscopy	The dataset is an important contribution for anybody working in vocal fold reconstruction.	"The proposed framework appears to be clinically feasible: 
(a) The images are acquired using a clinical grade endoscopic projection unit (and high-speed camera);
(b) The framework is automated and consistent with the clinical workflow time constrains;
(c) Real-time (~25 fps) performance is achieved using off-the-shelf computing hardware (i7 CPU and NVidia Quadro RTX 4000 GPU).
Surface reconstruction: appears to be an innovative extension and application of well-established methods (M5 Model to 3D using B-splines)
Reasonably extensive evaluation of the proposed framework using a physical (silicone) model of the human vocal folds and established labelled image datasets is  reported."	"A fully automatic method is presented for dense reconstruction of human vocal folds using a structured light endoscopic system, and a parametric model of the vocal folds. The entire pipeline runs in 25fps, which seems adequate for the intended application.
The dataset used in this work will be made publicly available which will encourage further development in the field."
408	Recurrent Implicit Neural Graph for Deformable Tracking in Endoscopic Videos	A method that is adaptable to varying number of points over time.	"The method is a novel combination of Graph Neural Networks to parse keypoint information, an attention mechanism to refine displacements, a recursive network to carry information to the next images and a sampling strategy to turn the encoded sparse displacements into a dense output.
The result works well on datasets that were not part of the training data (generalization is shown for datasets collected at different sites)."	"Detailed descriptions of the method;
Extensive experiments;
Fast inference."
409	Reducing Positional Variance in Cross-sectional Abdominal CT Slices with Deep Conditional Generative Models	"The application is interesting. As the paper mentioned, this is the first method proposed to tackle the 2D slice positional variance problem.
Since this is the first attempt to handle such a problem, the proposed method can be treated as a pioneer for the subsequent studies.
This paper proposes a new way to evaluate the position variance."	"The paper addresses an important problem of reducing the positional variance in cross-sectional abdominal CT scans.

The qualitative and quantitative results are quite impressive and show the superior performance of the proposed approach."	I believe that there is not enough novelties except proposing dealing with positional variance problem.
410	RefineNet: An Automated Framework to Generate Task and Subject-Specific Brain Parcellations for Resting-State fMRI Analysis	They present RefineNet, a new method to optimize the functional brain parcellations  based on the existing parcellations,  wihch is a a Bayesian-inspired deep network architecture.	The network is flexible that it can be used solely to derive the best parcellation for resting state data, or can be used for joint training to optimize some task performance	The framework proposed in this paper integrates the prediction task with the process of individualized parcellation learning, which may benefit to understand the different brain functional organization contributes different prediction task.
411	Region Proposal Rectification Towards Robust Instance Segmentation of Biological Images	"The paper is well organized and easy to follow.
The proposed region proposal rectification (RPR) is well motivated and improves performances for both anchor-based and anchor-free approaches."	This work is well motivated with a clear problem setting and analysis of existing works. The method development is lucid and easy to follow with a nice method diagram. The improvement of the proposed method in the experiments is impressive.	The proposed module RPR module enriches the features for bounding box regression by progressively looking at the neighboring areas of the initial proposal and a self-similarity based attention module.The module was evaluated on three datasets using objection detection networks with anchor-based and anchor-free region proposal networks.
412	Region-guided CycleGANs for Stain Transfer in Whole Slide Images	The paper proposes an interesting application in WSI analysis. The manuscript is well-written and easy to follow.	"Strengths: Methodology: Introducing region guidance in the discriminator through segmentation is interesting. The proposed discriminator removes fixed size constraints for the PatchGAN, and can be applied to varying size regions.  As a  natural implication of this modification, the authors have utilized this discriminator for the detection task. This task is also introducing supervision in the GAN that leads to better performance in stain localization as compared to CycleGAN that lacks any supervision. As the quality of the stain transfer depends upon the stain localization, the proposed modifications lead to better quantitative and qualitative results (Fig-2 and Table-1) in comparison to CycleGAN (without any supervision). It also motivates to introduce some sort of supervision for the related applications.
Analysis: A detailed analysis is presented on two datasets in terms of qualitative and quantitative performance. The analysis is able to highlight the effect of supervision introduced through the proposed region-guided discriminator in the CycleGAN. Quantitative results (Fig-2) shows the superior stain transfer quality because of region guidance and in turn supervision over vanilla CycleGAN. Similarly, Table-1 shows the better performance of the proposed method as compared to CycleGAN trained under different settings. However, the analysis is limited to one application but it validates the proposed approach.
Performance: Qualitative performance shows significant performance improvement over the existing methods (Table-1). The quantitative results also show good performance of the proposed region-guided cycleGAN."	The proposed method is sound. When extra knowledge about the image is available, it is a good idea to find ways to incorporate such knowledge during training. This paper achieves this via a region-based discriminator, and the knowledge is leveraged in the form of bounding boxes. The use of RoIAlign properly consumes the bounding box inputs and induces the generation of more biologically meaningful outputs.
413	Regression Metric Loss: Learning a Semantic Representation Space for Medical Images	"The paper is very well organized and written. I have pleasure to read it. It is clear and self-contained.
The RM-Loss proposed in EQs. 2-3 is novel and interesting as it allows to capture interpretable representations and could be optimized with small dataset.
The authors provide clear and in-depth analysis with ablations. The results are consistent and the performance achieved by the loss supports the claim about performance superiority."	The proposed loss  appears as pertinent for medical applications in the results section. The methodology also appears as mathematically solid.	This paper provided ablation analysis to clarify the results. And visualization of the learned representation space on provided dataset is given. The organization of this paper is good.
414	Reinforcement Learning Driven Intra-modal and Inter-modal Representation Learning for 3D Medical Image Classification	Paper is well written. All the section of the papers are well explained. The idea of combing the reinforcement learning for inter and intra modality representation learning is novel.	"The authors present a  novel RL based method for 3D image classification:

A RL module is used to learn the most discriminative features from each modality.

Another RL module is used to learn to weight the features from different modalities.

Experiments are extensive. The authors not only compared with the several other comparison methods, but also conducted comprehensive ablation studies."	"(1) This paper introduces the RL strategy into multi-modality learning.
(2) An iterative hybrid-enhancement network is proposed to integrate intra-features and inter-features.
(3) The overall structure is clear and well-organized.
(4) Experimental results demonstrate the superiority of the proposed method against other existing methods."
415	Reinforcement learning for active modality selection during diagnosis	"The motivation and writing is clear- 
The method is interesting and well supported"	"The paper works on an interesting topic that can actively help select the next exam modality or end the examination to get the diagnosis and minimize the cost while maintaining high accuracy. The topic is promising as the decision is made for each individual patient.
The decision-making process is formulated into an RL problem and solvable by traditional RL algorithms.
The authors validate the proposed method's effectiveness on two datasets and its superiority over the population-based selection method.
The authors show that the proposed decision-making framework can indicate which modality/ bio-marker is important for diagnosing on a population level."	"Novelty: the authors present a novel RL method that extends their previous strategy (ref. [1]) into a modality- and cost-aware method able to handle high dimensional data, further enhanced with strategies to avoid data sampling imputation. 
Clinical interpretability: the authors have thoroughly analyzed the results of their strategy with respect to the clinical knowledge of the selected application (hypertension), showing the validity (and clinical utility) of the decisions made by the RL method."
416	Reliability of quantification estimates in MR Spectroscopy: CNNs vs. traditional model fitting	The paper is well written and raises awareness of a previously-unknown issue for the application of deep learning methods to MR spectroscopy.	"A solid simulation study nicely executed with clear hypotheses, results and conclusions.
This is timely work extending recent demonstrations in other quantitative imaging scenarios that significant bias can arise when using regression type methods, e.g. CNNs as here, to estimate model parameters from high dimensional data.  The approach is appealing, as it can be much faster than traditional model fitting and potentially avoid problems like local minima. However, care is required to select an appropriate training set and even then it appears difficult to avoid bias towards the mean particularly for rare cases."	"The main strength of this work is that it provides a valuable counterpoint to previous studies on deep learning quantification for metabolite quantification, showing the possible pitfalls of deep learning in comparison to traditional model fitting algorithms.
The analysis of bias and variance were extensive."
417	Reliability-aware Contrastive Self-ensembling for Semi-supervised Medical Image Classification	"Detailed formulation of the problem and methods, formulas are easy to understand and follow. Corresponding codes are also published for accessing.
Bi-level optimization is addressed properly, which is interesting to explore in the other different tasks
Solid experiments and analysis"	The proposed method is novel since it can concurrently capture both the reliable data-level and data-structure-level information of the images, thereby improving the robustness and generalization power of the model. The proposed method achieves state-of-the-art performance on two public datasets.	"The idea of assigning each data different weights by a learned model is novel.
The paper is well-written and easy to follow. I enjoy reading this paper.
By employing the proposed weight function in the consistency loss and contrastive loss, improved accuracy is observed on two datasets."
418	ReMix: A General and Efficient Framework for Multiple Instance Learning based Whole Slide Image Classification	"The paper is easy to read and well-motivated.  The use of latent space augmentation for Histopathology is novel and addresses a relevant problem for WSI analysis in healthcare.
The authors report competitive results on public datasets with significant gains over recent methods.
Augmentation strategies for WSI classification are often under-explored, thus; the use of LA augmentation and it's variants is in this work very interesting. Especially in the multi-class setting when considering different pathologies, LA facilitates better model generalization.
I appropriate the extensive experiments to validate LA, including ablations on computational efficiency and several hyper-parameters regarding."	"A general, simple yet effective method to improv the training efficiency of MIL framework for WSI classification.
An efficient latent augmentation for MIL-based WSI classification.
Improved performance can be observed on two public datasets."	"This work aims to address the resource consumption of MIL framework, which is a bottleneck in WSI classification. From the experiments, the proposed ReMix can improve the performance and reduce the resource cost at the same time.
The proposed reduce and mix steps are simple yet effective, and can be easily extended to existing MIL framework.
Significant improvements for two baselines on two datasets.
The work is well written."
419	RemixFormer: A Transformer Model for Precision Skin Tumor Differential Diagnosis via Multi-modal Imaging and Non-imaging Data	As above	"1)The idea of multi-modal fusion with transformer is smart. 
2) Experiments show superiority of the model in terms of F1 score and Accuracy."	"a new multi-modal cross-fusion transformer for multi-modality data fusion
Disease-wise Pairing as Augmentation to address the problems of missing modality.
a new cross-modality fusion model to use global features
solid experiments"
420	Removal of Confounders via Invariant Risk Minimization for Medical Diagnosis	The paper is very clearly written and tackle an interesting problem: removal of confounders in nonlinear models. The use of the IRM framework is very welcome in this community and the proposed variants have sound explanations and descriptions. The two experiments - sex as confounder, age as confounder - are compelling.	This work proposed a modified IRM framework, namely ReConfirm to accommodate class conditional variants for NIH chest X-ray classification tasks , where the invariance learning penalty is conditioned on each class. This work designed a strategy for optimally splitting the dataset into different environments based on the maximum violation of the invariant learning principle.	"An important problem is considered, and a viable solution is presented for the same. I have not seen application of the invariant risk minimization framework to medical image analysis before. For situations where the exact confounding variables are known, the proposed method seems to be promising.

Writing is fairly clear.

Experiments with two confounding variables (age and sex) show that the proposed method improves performance over empirical risk minimization."
421	RepsNet: Combining Vision with Language for Automated Medical Reports	"Prior context knowledge for open ended answers is an interesting idea. 
Contrastive loss for vision and text learning is also a good idea.
Paper is well written and understandable as well as reproducible.
Huge experimentation as well as a demo is shown in supplementary material."	The paper presents an important and original contribution. The work appears to be technically sound and well-thought. Results are well presented.	"This work introduces contrastive learning into feature representation learning;
The proposed method combines medical images and text for multi-tasks ( categorical and descriptive natural language answers)."
422	Residual Wavelon Convolutional Networks for Characterization of Disease Response on MRI	The main strengths of the paper are that it is written very clearly, the rationale for the approach seems fundamentally sound, and there is a dedicated experiment and set of results on the optimization of the skip connection weights, which is critical for understanding the impact of those connections.	RWCN solves the problem of gradient disappearance	Novelty in architecture, design in network to layer and activation level. A very well organise manuscript with very sientific evaluation of the hypothesis. Nice Figures and verification of the ideas.
423	Rethinking Breast Lesion Segmentation in Ultrasound: A New Video Dataset and A Baseline Network	"The author presents a breast lesion segmentation dataset in an ultrasound video. The temporal information contained in the proposed dataset contributes to accuracy in automatic breast lesion segmentation.
A dynamic parallel and spatial-decoupled transformer framework is presented. The DPSTT achieves computational efficiency through the proposed non-local spatial, and temporal transformer module.
A dynamic memory selection scheme is proposed to eliminate unnecessary features of the past frames. Through ablation studies, the author verifies that the scheme contributes to the segmentation accuracy.
Quantitative assessment is conducted by comparing DPSTT with other SoTA models including image-based, and video-based segmentation models. The results demonstrate that the DPSTT outperforms other SoTA models with a large margin.
A comprehensive ablation study is provided. The study well explains the effectiveness of the proposed temporal and spatial transformer model, and dynamic memory selection scheme."	"A.	The paper introduces an automated breast lesion segmentation dataset using ultrasound video. Recently a line of works has demonstrated that proper utilization of the spatio-temporal information enhances the reconstruction accuracy. The proposed temporal breast data is expected to be applied in a diverse neural network that is using temporal information and contributes to the accuracy of breast lesion segmentation.
B.	The proposed spatial and temporal transformer reduces computation compared to baseline while showing enhanced performance. 
C.	Extensive quantitative comparison and ablation studies are provided. The proposed decoupled spatial and temporal transformer network outperforms other State-of-the-art neural networks with reduced inference time.
D.	Overall, the paper is well written. The organization is well structured."	The dataset is probably a valuable resource for the community.
424	Rethinking Surgical Captioning: End-to-End Window-Based MLP Transformer Using Patches	"The authors proposed to borrow patch-based shifted window technique to realise real-time robotic surgery.

Surgical video captioning is an interesting topic, which is still not well-explored yet. It's encouraging to see studied proposed to apply advanced vision techniques into this domain.

The paper is well-written with clear demonstration."	"Surgical captioning is an interesting research direction that goes beyond a simple phase, tool or activity recognition.
Novel architectural choices for task of surgical captioning creation
Addition of Video is interesting and adds to the value of the work"	"-Unify the structure: this work releases the limitation that the transformer-based captioning model needs a feature-extractor or detector ahead, which shows a transformer-only unified network structure for the surgical video captioning task. This make the network not limited by the pre-trained detection models/ feature extraction models. 
-Parameter efficient: Interestingly, the model replace the multi-head attention with group convolution to keep the design of transformer and save the computational cost. The time complexity comparison between conventional swintransformer and this work is discussed and provided. This operation is based on the observation that it is the structure of the transformer that make things work, not the self-attention. 
-Evaluation: this paper evaluates upon the surgical video captioning task on the large public dataset and compared with suitable baseline methods."
425	Rethinking Surgical Instrument Segmentation: A Background Image Can Be All You Need	Clarity and the simplicity of the approach	"The use of limitate annotate images to train a segmentation pipeline is quite relevant for the medical imaging community.
The paper is well written and well organized.
Public available datasets are used in the experiments.
The code is provided."	"The strength of the paper is its simplicity: it proposes an intelligent method of ""augmentation by simulation"" similar in spirit to using driving video games to help train self-driving cars. Although the results given in Table 1 look uninspiring at a glance, knowing how the last three rows are generated is actually quite impressive."
426	Retrieval of surgical phase transitions using reinforcement learning	The idea of using a multi-agent RL to find phase transition is interesting.	"The abstract is clear and well written.
There is a clear contribution in this paper.
The results were compared with the relevant SOTA models (TeCNO, Trans-SVNet) in the domain.
The paper presents significant insights for research continuation."	"Reformulating offline phase recognition as the task of finding phase transitions is a novel approach and more closely resembles how humans would solve this task.
The proposed task/method has the advantage that it (supposedly) produces contiguous phases.
The authors discuss limitations of the approach."
427	Revealing Continuous Brain Dynamical Organization with Multimodal Graph Transformer	"The proposed study incorporates the areal heterogeneity map (T1-to-T2-weighted MRI) to improve the model fit to structure-functional interactions.
The authors also introduced a novel graph transformer pooling layer to learn the global representation of the entire graph.
Meta-analysis was adopted to evaluate the proposed model to explore the behavioral relevance of different brain regions."	"adopt graph transformer with multi-head attention
use contrastive learning to integrate multimodal imaging details
evaluation with meta-analysis"	"a) Incorporating the heterogeneity map constrained by T1-to-T2-weighted (T1w/T2w) to improve the model fit to structure-function interactions is novel.
b) Contrastive learning is used to associate the different data modalities.
c) The experimental results of behavior related global gradient are very interesting."
428	Rib Suppression in Digital Chest Tomosynthesis	"The paper is very well-written and easy to follow. The physics of DCT is clearly explained followed by the logic of the design. Good job!
The method is a dual-domain method that first learns in the projection domain, then learns in the reconstruction DCT domain.
The experimental results on simulation data show clear quantitative and visual improvements.
Additional reader study is performed to validate the method."	"The idea of modeling rib artifacts in DCT with information from both 2D and 3D domains is novel and interesting. The evaluations with the simulated data as well as the clinical study also demonstrated the feasibility of this idea.

The paper is fairly well written and the exposition of the results is good."	"The proposed method leverages 3D information with the FBP operator to remove the rib artifact from DCT images consistently. 
The paper is well written and backed up with a clear description of mathematical image formation. 
Experiments were carried out qualitatively and quantitatively. 
A user study shows that two doctors appreciate higher TRIPLE-Net ratings than its ablations and other state-of-the-art methods."
429	Robust Segmentation of Brain MRI in the Wild with Hierarchical CNNs and no Retraining	"Proposal of a novel segmentation framework for clinical MRI scans that is robust against varying MRI protocols including contrast, resolution, deformations, low SNR and partial volume effects.
No retraining necessary.
Clearly stating the issues with current models and how SynthSeg+ tackles them with its novel architecture and how the configurational changes of intermediate stages impact the robustness and accuracy of the respective frameworks. Further, the paper also provides the rationale behind the outcome with respect to those changes.
POC volumetric study on age-related atrophy demonstrating the volumetric trajectories of respective brain structures. This fosters their work on adopting the framework toward neuroclinical use cases."	"The authors evaluate a previous tool, SynthSeg, on an uncurated, heterogeneous dataset of more than 10,000 scans, which is a remarkable number. 
The authors propose SynthSeg+, a novel method which uses a hierarchy of conditional segmentation and denoising CNNs. The authors show that this method is considerably more robust than SynthSeg, while also outperforming cascaded networks and stateof-the-art segmentation denoising methods.
The paper is clear and readable. The figures are high quality."	The description of issues is very clear. This method yields promising results and is feasible in clinic.
430	RPLHR-CT Dataset and Transformer Baseline for Volumetric Super-Resolution from CT Scans	The authors aim at creating a public real-paired dataset for volumetric SR and provide a benchmark.	"A new publicly available dataset for super-resolution benchmarking is a valuable contribution for the medical imaging community.
Authors demonstrated the superiority of the transformer-based model compared to the standard convolutional models in terms of PSNR and SSIM.
Ablation study is present."	"1)  Artificial pseudo LR/HR training samples make the SR model have poor generalization for application scenarios. The RPLHR-CT dataset presented in this paper consists of real LR/HR image pairs, narrowing the field generation gap between handcrafted samples and real samples.
2) The writing is great and easy to follow and understand. Moreover, the work is technically novel due to two-fold reasons: (1) the first public real paired dataset RPLHR-CT as a benchmark for volumetric SR; (2) the TVSRN based on the volumetric transformer.
3) The authors re-implemented several state-of-the-art methods tested them on the proposed RPLHR-CT datasets, providing benchmark comparison and reference for volumetric CT SR."
431	RT-DNAS: Real-time Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation	"*	The proposed method RT-DNAS incorporated MS-NAS with a genetic algorithm to consider the latency and throughput constraints
*	RT-DNAS could be a good application for real-time cardiac MRI images which needs on-the-fly segmentation to avoid noticeable visual lag
*	RT-DNAS was evaluated on the extended 2017 MICCAI ACDC dataset and obtained overall better results when compared to both manually and automatically designed network architectures"	"The paper is well-written and provides a good description of the proposed method.
The inclusion of latency and/or throughput in NAS has relevance for many other medical imaging applications.
The method finds an architecture which produces better performance compared to baselines segmentation and NAS methods."	"meaningful extenstion to neural architecture search to optimize for latency.
good set of experiments to make a case for their hypothesis."
432	RTN: Reinforced Transformer Network for Coronary CT Angiography Vessel-level Image Quality Assessment	"On the used data collection, the experimental results clearly show the benefit of adopting the suggested approach and additional network components in comparison to using less elaborated schemes.
The ambition to formulate the method in a formal mathematical manner has to be appreciated."	"The author formulate the CCTA vessel-level quality assessment as the typical multi instance learning problem, and introduce transformer to aggregate multiple instances and map them to final quality.
The authors proposed a progressive reinforced learning based instance discarding strategy to mine the most informative instances for transformer network."	"Overall, this paper is well organized and all technical modules are well explained. Below are the specific strengths:
1, the idea to leverage the RL based instance discarding strategy to exclude irrelevant instances is novel and proved to be quite efficient in the end to improve the performance. It adopts Markov Decision Process and uses the output of T-MIL as the state. This design enables an end-to-end training pipeline and keeps the architecture light.
2, the transformer based architecture fits well with the dynamic input sequences introduced by the instance discarding process. Experiments show that without PRID, this T-MIL is already a very strong baseline outperforming other existing approaches.
3, the ablation study on the pooling layer inside PRID (Table 3) justifies the choice of PMA versus other common pooling strategies such as max and average pooling."
433	S3R: Self-supervised Spectral Regression for Hyperspectral Histopathology Image Classification	"a. They designed a self-supervised method tailored for microscopy HSI classification, which had not been concerned before. It's a novel idea to utilize the properties of hyperspectral images that one band can be represented as a linear combination of the remaining bands. 
b. The experiments results show up to 14% improvements."	"The idea of characterizing spatiospectral information from hyperspectral images using self-supervised spectral regression of histopathology images is a novel application.
Hyperspectral images contain rich information and processing them for accurate diagnosis is challenging. The authors have done a good job in providing sufficient background information, related work, and motivated the study in the right direction.
Further, the authors have compared their strategy to the emergent contrastive learning approaches with greater performance and faster convergence which is interesting."	"This paper used the intrinsic relationship among different bands of HSI in self-supervised pre-training to extract the low-ranking contexts in the spectral domain.

The design of loss is straightforward and concise to the characteristic of HSI.

3.The proposed methods provide an efficient and effective pre-training strategy for unlabeled HSIs with high spatial-spectral dimensions."
434	S5CL: Unifying Fully-Supervised, Self-Supervised, and Semi-Supervised Learning Through Hierarchical Contrastive Learning	"Well organized and written. 
This work analyzes the problem of self-supervised learning in medical image field and introduces the method logically.

Motivation is clear and the method is novel. 
It extend the SupConLoss to devise loss in supervised, semi-supervised, and unsupervised levels.

Improvement seems okay. 
Compared with three most relevant baselines, the improvement is about 1~2% with very limited training samples. And ablation study shows the effectiveness of different loss terms."	"(1) This paper proposes a novel framework, called S5CL, that unifies fully-supervised, self-supervised, and semi-supervised learning through hierarchical contrastive learning. Experiments show the effectiveness of this method: for a H&E-stained colorectal cancer dataset, the accuracy increases by up to 9% compared to supervised cross-entropy loss; for a highly imbalanced dataset of single white blood cells from leukemia patient blood smears, the F1-score increases by up to 6%.
(2) The resulting framework is easy to use and highly flexible: one can omit unlabeled images and train fully-supervised; also can set the weights of the supervised and semi-supervised loss to zero and train self-supervised; or train with both labeled and unlabeled images in a semi-supervised way."	"The paper is very well written and organized, the figures are clear and one can easily follow it.
The combination of supervised together with semi/self-supervised losses is well motivated in the field of computational pathology.
The experimental configuration is convincing and well presented."
435	Sample hardness based gradient loss for long-tailed cervical cell detection	"An interesting method to dealing with long-tailed datasets. A complete derivation for the loss function is given and the basic idea behind it is well explained.
A proper dataset is created to imitate the real-life situations, which is large-scaled and has a strong data imbalance.
The impact of the hyper-parameters in the loss function is separately studied and a proper analysis explained their significant contribution.
The Grad-Libra loss is applied to other detectors, showing its generalization ability."	"(1) The proposed Grad-Libra loss is relatively simple and intuitive.
(2) The paper is well written and easy to follow with. 
(3) Extensive experiments are performed to demonstrate the effectiveness of the proposed loss function on different detectors, both head and tail classes etc."	"1.The experiments results are comprehensive and the qualitive analysis precisely illustrate the improvement.
2.Author uses gradient information of each sample to re-weight the cross-entropy of each class so that the method can solve long-tailed at sample level. This is an innovative loss re-weighting method.
3.This paper firstly summarizes the existing scheme for solving long-tailed problem and then this paper clearly claims what sets this work apart from other works.
4.Illustrated explanation about how the method works."
436	SAPJNet: Sequence-Adaptive Prototype-Joint Network for Small Sample Multi-Sequence MRI Diagnosis	"this paper proposed to use Transformer and additive-angular-margin loss for small sample multi-sequence MR image classification. However, this paper has several major flaws and fails to illustrate their point:

The first component, Transformer model, is claimed to filter intra-sequence features and aggregate inter-sequence features, based on attention mechanism. But I didn't see any details about how to achieve these 2 goals in section 2.1. The overall writing quality is poor and difficult to follow.
Similarly, neither the section 2.2, prototype optimization strategy, illustrates how to approximate the intra-class prototype and alienate the inter-class prototype. For example, the query sample q^a and support sample s^b corresponding to which modalities, the loss_2 should be explicitly expressed like loss_1, and why you choose the additive-angular-margin loss instead of the ordinary cross-entropy loss for classification.
Fig 2 is very ambiguous and lacks sufficient explanation. E.g., what are the vectors besides the local significance block, how to aggregate into global correlation (through concatenation, pooling, or others), where does the support prototype come from, where are the 2 stages in Prototype optimization strategy, and how to approximate intra-class prototypes and alienate inter-class prototypes.
The experiment section lacks the explanation of 3 modalities of data (SAX, LAX, and LGE).
Some minor issues:
a.	P2, 1st paragraph, the hyperparameter p's explanation is ambiguous.
b.	Section 2.2 mentions robust classification. So what kind of attack methods you are dealing with?
c.	Section 2.2 2nd paragraph says ""two outputs of the SAT ..."" what does the two outputs referring to?
d.	Still in Section 2.2 2nd paragraph, ""The former is reserved for ..."". After this, where is the latter one? What's the purposes of two stages here?
e.	Table 3 didn't explain what's VOT."	"1) Developed a new neural network approach to deal with common clinical MRI issues
2) Compared the proposed method with several other methods in the literature
3) Added a brief 'ablation study' to gain insight of the proposed technique"	"Different sequences of MR images depicting structure, motion are utilized effectively for the classification purpose.
Redundant intra-sequence features have been filtered using self-attention while inter-sequence feature correlations have been explored.
Instead of simple fusion, multiple sequence features have been fused effectively.
The authors introduce a contrastive learning inspired loss function to better classification performance even in sparse data scenarios.
The paper groups like and unlike pairs according to disease category and alienates similar class prototypes.
The results section is nicely presented."
437	SATr: Slice Attention with Transformer for Universal Lesion Detection	"The idea of the paper is simple but solid. This paper presents a natural way to combine transformers into the multi-slice fusion problem.
The paper is well-written and easy to follow. The figures are illustrative.
The results are promising. The authors compare various baselines and show their innovation is a ""plug-and-play"" module with consistent improvements over the baseline methods."	"A novel transformer block for multi-slice-input ULD backbone is proposed. Compared to the naive version, the proposed method has clear motivation: (1) enhancing the key-slice feature, as the key-slice is where the supervision applied; (2) using the adjacent slices as query and key to further strengthen the key-slice representation; Ablation study also clearly demonstrates the contribution of each modification;
Extensive evaluation on multiple networks to show the effectiveness of the proposed SATr block."	"Strength:
1.This paper is well written and organized. It is easy to follow and read.
2.The proposed SATr is easy to understand and implement. It is easy to transfer to other network structures.
3.The comparison in Table 1 between the vanilla network and the version with SATr shows that the proposed SATr does help with the lesion detection."
438	Scale-Equivariant Unrolled Neural Networks for Data-Efficient Accelerated MRI Reconstruction	This paper newly combined scale-equivariant CNNs with unrolled nerual networks for reconstructing undersampled MR images which could be different from conventional deep-learning-based MR image reconstruction methods.	"(1)	The paper is very well written and the presentation is clear.
(2)	As far as my knowledge goes, inserting a scale-equivariant proximal network for MRI reconstruction is a novel and interesting idea.
(3)	Good evaluation: comparison to state-of-the-art unrolled neural networks, generalization validation."	"The proposed network architecture provides better reconstruction results even under constraints on the network.
The use of scale equivariance is well motivated for practice."
439	Screening of Dementia on OCTA Images via Multi-projection Consistency and Complementarity	"To predict dementia from OCTA is attractive, less-explored and of great clinical value.
Authors adapted the recently popular scale dot-product attention machnism to fuse the multi-view features of OCTA, which is a good and novel application of deep learning techniques.
Experimental results show the proposed method outperforms SOTA multi-view fusion models."	"The method proposed in this paper specifically solves the problem of dementia screening on Optical Coherence Tomography Angiography images. The complementarity and multi-projection fusion proposed in this paper is rarely studied in this problem and is an advantage.
This article is well organized. In this paper, the background of the problem and the deficiencies of the previous work are clearly explained, and the corresponding modules are designed. There are certain comparative experiments and ablation experiments to illustrate the effectiveness of the method."	"(1) The idea about Consistency and Complementarity in Screening of Dementia is interesting.
(2) The experimental results in Table 1 are very good.
(3) The structure of this paper is clear."
440	Scribble2D5: Weakly-Supervised Volumetric Image Segmentation via Scribble Annotations	"This method achieves SOTA performance in 3D using weekly supervised scribble annotations, reducing the gap between fully supervised methods. 
The use of scribble annotations provides practical utility as it greatly reduces the workload of manual segmentation for 3D images. 
The authors successfully extend previous 2D methods to 3D, in which few alternative options exists.
The authors propose label propagation module that uses a combination of existing methods to generate
both pseudo masks and pseudo boundaries. Inclusion of these existing methods may provide additional somewhat orthogonal signals to help generate more accurate pseudo labels."	"Scribble annotation is a promising type of supervision signal in terms of expense and performance. The paper proposed a scribble-based method and tested on three different medical image analysis datasets, which is of certain clinical feasibility. The experimental protocols were overall clear and results were extensive.
In terms of technical contribution, the paper integrated several methods such as SLIC, 2.5D attention UNet, HED, ASPP, into the context of scribble supervised learning. A 3D active boundary loss was proposed based on its 2D ancestor. The ablation studies were well conducted."	"It proposes a scribble2D5 network for segmenting medical image volumes with sparse scribbles for training only.

It proposes a label propagation module for 3D pseudo mask generation and an active boundary loss to regularize 3D segmentation results.

It provides some reasonable results on three public datasets."
441	Scribble-Supervised Medical Image Segmentation via Dual-Branch Network and Dynamically Mixed Pseudo Labels Supervision	"The paper addresses a very relevant problem, i.e. the elevated cost of pixel-wise annotations for medical image segmentation.
The methodology is novel, sound and interesting.
The literature review and comparisons with other available approaches, both in the realm of weakly supervised and semi-supervised methods, are detailed and sensible.
The experimental set-up is (mostly) well-devised and the results are convincing.
Different settings, ablation studies and comparisons against a rather ample set of baselines allow a rather good assessment of the robustness of the proposed approach.
The paper is very well-written and generally easy to follow."	The paper is well-written and easy to follow. The proposed method adopts dual-branch network and a dynamically mixed pseudo labeling strategy to train segmentation models with scribble annotations, which reduces annotation costs and makes good use of a small amount of supervision information. Experiment results demonstrates the effectiveness of the propose method.	
442	SD-LayerNet: Semi-supervised retinal layer segmentation in OCT using disentangled representation with anatomical priors	"Contributions:
1). It is very interesting to propose a semi-supervised paradigm into the retinal layer segmentation task, using of the information present in large-scale unlabeled datasets.
2). In this work, it is promising to notice a variety of reconstruction loss such as Eq (1) and the others proposed in Section 2.2.
3). A comprehensive methodological validation has been included in this work."	"This paper solves a very interesting and practical problem, which makes use of unlabeled datasets for semi-supervised learning in retinal layer segmentation task.
This paper is well organized, the idea of innovation is concise and reasonable, and it is easy for readers to follow.
This paper also points out the potential application for other tasks, e.g. inner and outer vessel lumen wall, cardiac wall, knee cartilage, etc."	"The authors propose a fully differentiable topological engine, which converts the surface positions to pixel-wise structured segmentations for anatomical representation learning.
The authors propose a series of self-supervised tasks tailored for retinal layer segmentation based on several anatomical priors.
The proposed method shows the promise of semi-supervised learning in retina layer segmentation."
443	SeATrans: Learning Segmentation-Assisted diagnosis model via Transformer	"The motivation is good by segmentation task to boost the classification task. Especillay with the non-regional information.
The experiment results are very good.
The method includes the Transformer to deal with segmentation-diagnosis feature interaction."	"The author proposes asymmetric multi-scale interaction to correlate each low-level diagnosis feature with multi-scale segmentation features. 
The author supplies a variety of experiments to validate the effectiveness of different components in SeATrans.
The experiments show that SeATrans can achieve state-of-the-art performance on three publicly available datasets."	"Generalizability - Their method doesn't make any prior assumptions about the medical images it is being used on. So it can be used on any kind of images. 
Novelty - Although the authors have used the well-known networks of UNet and ResNet, they have joined the multi-scale segmentation features and the high-level features extracted by the first layers of ResNet, in a novel way to account for the non-regional feature dependencies missed by the convolutional layers. 
Extensive validation - The authors have validated their performance by comparing to many existing methods that make the disease diagnosis based on the segmentation annotations."
444	Segmentation of Whole-brain Tractography: A Deep Learning Algorithm Based on 3D Raw Curve Points	First, a 3D image data with high-quality labels of the major white fiber tracts is introduced in this study, which carries extensive manual efforts. This large data containing 25 individuals might benefit future studies in the related area. Second, an automatic fiber tract classification pipeline is proposed and its technic novelty sounds solid.	As the author claimed in the introduction, the main contribution of this work is the model that can take the raw 3d curve data. It may provide an end-to-end structure and more raw information to the model. This is also partly confirmed by the results section, table 1. However, since the dataset are different, it is hard to evaluate directly.	Deep models cannot directly consume 3D curves in their raw data format, therefore additional preprocessing steps are needed, which adds  the complexity of the segmentation task. This work uses 3D raw curve points to represent the curves of fibers and can solve the above-mentioned problem.
445	Self-Ensembling Vision Transformer (SEViT) for Robust Medical Image Classification	"Strength:
1.This paper is well organized and easy to follow.
2.The idea of using ensembling learning of intermediate features and novel and seems work well.
3.The work allows us to know more about the combination of adversarial learning and transformer"	The paper is well-written and easy to understand. Extensive experiment results show the superiority of the proposed model. Different modalities are used for the experiments.	original evaluation of the robustness of Transformer models.
446	Self-learning and One-shot Learning based Single-slice Annotation for 3D Medical Image Segmentation	The method is very interesting, addressing an important problem in medical image segmentation. The work is well motivated, and the empirical results are convincing. A good number of baseline / alternative methods have been used for comparison and an ablation study provides insights about the importance of individual components. Four datasets/applications have been used for evaluation.	"Very useful strategy to allow users to annotate a single slice - this is a very user-friendly interaction strategy.

Good comparison to lots of alternative methods for dealing with small annotations and good improvement as measured by Dice score, ASSD, HD, etc.

Investigation into domain shift from one dataset to another."	"clearly written
good visualisation
appropriate references
convincing results
good ablation study
methodology well explained
comparison to relevant work
usage of good data sets"
447	SelfMix: A Self-adaptive Data Augmentation Method for Lesion Segmentation	"1)It is the first one that notices non-tumor information among data augmentation
methods for lesion segmentation. It may improve the accuracy of lesion segmentation when the training data set is small.
2) Good evaluation. The author compared this method to trandiational methods and recent related papers."	"The proposed 'SelfMix' extends existing 'CutMix' and 'CarveMix', which is tumor-aware and consider background information.
More realistic images for training.
Improved numbers on baselines."	Motivation is strong. Method is easy to understand. Experiments on two public lesion segmentation datasets show that the designed method improves the lesion segmentation accuracy compared with other data augmentation.
448	Self-Rating Curriculum Learning for Localization and Segmentation of Tuberculosis on Chest Radiograph	The paper proposed an effective ranking function using self-ranking scores instead of using prior knowledge of human experts. The experimental results show the SRCL has improved mAP although AUC has not been improved.	The proposed difficulty ranking algorithm was fully automatic, therefore making it more efficient to perform curriculum learning without human intervention.	The idea is simple and applicable to all types of medical images and most of the medical image analysis tasks.
449	Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT)	"Open dataset: Most results were obtained from public BTCV dataset. Recent top solutions on BTCV benchmark were reported and compared.
Clear illustration: The description and illustration of the proposed knowledge distillation approach (both local and global) are clear and easy to implement.
Sufficient comparison: The proposed method is compared with several up-to-date self-supervised methods under both CNNs and Transformer backbones."	"The method is novel. It combines MIM and MT to train a ViT.
Experiments and ablation study are thorough."	"It is interesting to exploit powerful self-supervised learning techniques to improve the performance of target downstream tasks.

The improvements over other SSL methods on two datasets look nice."
450	Self-supervised 3D Patient Modeling with Multi-modal Attentive Fusion	"1) There is a novelty in the network combining RGB and depth image features/heatmaps with intra-modal attention and inter-modal attention.
2) The application shown in Section 3.3 is appropriate and demonstrates the usefulness of the proposed framework."	The manuscript presents a medically relevant problem of estimating 3D mesh from the multi-modality depth images. The manuscript is well written and presented. The authors have proposed the attentive fusion approach that accurately fuses multi-modality heatmaps helping in achieving the final 3D mesh reconstruction.	"*	The training strategy proposed in the paper is very clever. To the best of my knowledge, the split supervision of 2D keypoint detection and 3D model generation, the latter of which can be supervised with synthetic training data only, is a novel concept. Aside from the proposed clinical setting, where it is used to overcome challenges associated with variability in patient positioning for different imaging modalities and coverage of the patient with sheets, the same strategy could also be applied for other, non-medical but non-generic scenarios, in which current state-of-the-art methods perform poorly.
*	The paper is well motivated and timely. Scanning automation is an increasingly important topic, especially considering the current situation, where clinical staff is typically short, and it can be advantageous to avoid too much close contact between staff and patient. Although many pose and human shape estimation methods exist, generalizing them to challenging clinical conditions seems to be an open problem.
*	The paper is well written and pleasant to read. I could not spot significant grammatical, spelling errors or typos."
451	Self-Supervised Depth Estimation in Laparoscopic Image using 3D Geometric Consistency	The paper is well written and presents a convincing demonstration that the proposed approach out-performs a number of other techniques, as shown by Fig 2. Although the quantitative results are presented in Table 1,  Fig 2 would be more informative of a) a colour scale was provided, and if the colour showed the deviation from ground truth instead of absolute depth. Some more details of the collection of the LATTE dataset (perhaps provided in supplementary material), would be appreciated, along with some indication of its quality. The 3D Geometric Consistency loss and  Blind masking approaches are quite novel, but it would be helpful to understand their impact more clearly. For example, how does  left & right 3D model consistency contribute to a more accurate disparity map? In experiments, is it possible to  show a comparison with and without 3D consistency loss to demonstrate its effectiveness?	"The paper method is well written, clear and easy to follow.
The validation is clear and shows a good improvement over some previous methods. The authors are also using a benchmark dataset which makes comparison more interpretable."	"Writing is clear and easy to follow.
Applying geometric constraints to endoscopic depth estimation is worth studying. This work can inspire future work to further explore this direction.
The framework yields significantly better results compared to the listed previous work.
A new dataset with ground-truth depth is collected, which will certainly benefit future research."
452	Self-Supervised Learning of Morphological Representation for 3D EM Segments with Cluster-Instance Correlations	"Strengths:

As far as I'm aware, the idea of class-instance contrast is novel
Excellent validation results, proper comparison to state-of-the-art
The paper is well written and well illustrated
The method itself is not specific to EM and is likely to be applicable to other problems which require a representation of morphology.
A new dataset will be made available to the community
Failure cases are demonstrated, limitations are discussed"	"The technical writing is clear.

Contribution of a new dataset.

The proposed method outperforms previous baselines."	"The paper is well-written and easy to follow. 
The first self-supervised method for 3D EM segments.
The motivation is clear. The motivation is clear to integrate the feature correlations at the instance level and cluster level."
453	Self-Supervised Pre-Training for Nuclei Segmentation	The problem is relevant and well motivated. The approach is sound. Results are promising.	"The idea of using SSL for transformer pre-training is feasible for a wide range of medical application.

The idea of quantifying patch prediction difficulty to distinguish between nuclei and background is novel. The proposed-region triplet learning, combined with scale loss is well designed and showed satisfactory improvement."	"Overall the proposed method is novel. The pretext task of predicting the patch features is interesting. The employment of region-level triplet loss is reasonable.
Compared to previous approaches, the proposed method achieves better performance on two public datasets. This shows the benefits of the proposed method.
This paper is well written, with clear organization and motivation. The method is easy to follow."
454	Semi-supervised histological image segmentation via hierarchical consistency enforcement	"Writing quality is good.
The experimental setup is solid and design decisions of each stage are well-motivated with the aim of improving the standard semi-supervised mean teacher.
The method technicalities are well explained.
The method is evaluated on two state-of-the-art datasets for histopathological structures segmentation.
The comparison with strong SSL baselines makes the paper relevant and the results promising.
Is remarkable that with such a limited amount of data  (1 labeled image region), the proposed method reaches a dice >0.7 for nuclei segmentation."	"*	This work introduces several novel losses tailored to the hierarchical setting i.e., hierarchical consistency loss and self-supervised enforcement. 
*	The model is able to increase segmentation performance when with a limited amount of data e.g., 50% labeled data reports results comparable to fully-supervised baselines. 
*	The human based labeling process of histopathology images is an intensive task that also requires special expertise making it costly and difficult to scale. Therefore, the development of methods that leverage unlabeled data are important for larger scale medical studies and applications.
*	The framework presented does not depend on a special network architecture making flexible and perhaps easy to adapt in other models."	"1) The problem is important and should be interesting to the MICCAI community.
2) The idea and method presented in the paper are intuitive and easy to follow, and the organization is clear.
3) Experiments are conducted on two datasets, and comparisons include several previous semi-supervised methods. Compared with semi-supervised methods, the proposed HCE generally shows better performance; It is encouraging to see that HCE achieves comparable or better performance even when compared with the full-supervised method, indicating the great potential of semi-supervised segmentation methods."
455	Semi-supervised Learning for Nerve Segmentation in Corneal Confocal Microscope Photography	The paper is well written, methods and results are clear. Some parts of the proposed method are a novelty, and consequently the overall method is a novelty applied to corneal nerves images. The proposed method could be applied to other types of images.	This is a novel application for segmentation to Corneal Confocal Microscope images. The framework they proposed is solid and strong to deal with the small labelled data size problem and they tested the model both in public and private datasets to show it effectiveness.  To overcome the loss of pixel details, they used Refine Reparing Network to help refine the learning results of Coarse Repring Network which is excellent.	"(1) The organization of the whole manuscript is quite good with clear illustrations of the implementing pipeline.
(2) The whole framework is reasonable to deal with the annotation problem in microscope images."
456	Semi-supervised learning with data harmonisation for biomarker discovery from resting state fMRI	"The paper is well written and eacy to follow by making their contributions clear.
The performances on two public datasets are improved by large margin."	"Large multi-site cohorts
Multiple diseases"	"This paper aims to solve a very important problem in neuroimaging studies - data harmonization across imaging sites, which would allow for combining different datasets for more generalizable analysis and thus learning neuroimaging biomarkers that truly represent the disorder/disease under study and not specific to a single imaging site/study.

The novelty in this work lies in the incorporation of a linear data harmonization module in the encoder and decoder of a VAE model.

The authors provide a link to the code and test on a public dataset, enhancing reproducibility.

The experimental validation methodology is thorough, with 5-fold cross-validation performed with 10 random starts, and hyperparameters optimized using a separate validation dataset and set before running all the test experiments.

The paper is generally well-organized and easy to follow."
457	Semi-Supervised Medical Image Classification with Temporal Knowledge-Aware Regularization	"The designed AdaPL to mitigate confirmation bias is based on a theoretically derived loss estimator.
The proposed IPH to encourage the harmonious clustered prototypes across different training iterations works in an unsupervised way.
The paper is well written."	"the idea of using loss estimating function across training iterations to calibrate pseudo labels is interesting also reasonable. The author provides theoretical proof of the feasibility of the loss estimating function.

the proposed method achieves SOTA results on three datasets. And the author provides sufficient ablation results to demonstrate each components and effect of hyper-parameters."	"*The theoretical analysis for an upper bound of a loss of unlabeled sample was conducted and it is used to soften the pseudo labels. This is interesting.
*To match the feature prototypes across different training iterations, IPH is proposed, which takes the advantage of the knowledge from different training iterations and provides the coherent optimization.
*The evaluation is sufficient. It contains the comparison with a sufficient number of compared methods, ablation studies, and the hyper-parameter sensitivity. This shows the effectiveness of the proposed method."
458	Semi-Supervised Medical Image Segmentation Using Cross-Model Pseudo-Supervision with Shape Awareness and Local Context Constraints	The proposed local context loss is new and showed improved segmentation performance.	"The design of the framework is clear and reasonable
The results look positive compared to other methods"	It addresses a valid problem, namely incorporating shape information in neural networks segmentation. It is motivated by the publications referenced in [4][9], that are interesting.
459	Semi-Supervised PR Virtual Staining for Breast Histopathological Images	Well-written, use of significant metrics for evaluating achieved results	interesting idea with pos/neg classifier to improve consistency	The paper is well written about a smart architecture to virtually stain histopathological tissue in IHC (PRC) from H&E slides taking into account classification into PRC+ and PRC- consistency in the the architecture.
460	Semi-Supervised Spatial Temporal Attention Network for Video Polyp Segmentation	"Motivation is well founded. There is a need for methods which can segment polyps from video, and even creating datasets for such a task has been a shortcoming in the community.

2.The use of transformers to exploit both spatial and temporal information (although not novel to computer vision in general) is novel for this application.

The authors achieve state of the art results, especially a fairly significant bump in terms of mIoU score. Further the authors get a good bump over the other transformer based PVT technique which shows the importance of the extra data for the data hungry transformers."	The paper is proposing a novel framework for a well-known clinical problem and represents a stronge evaluation.	The paper introduced the recent two main modules and proposed a Semi-Supervised Spatial Temporal Attention Network (SSTAN) for the polyp video and showed the higher performance in the segmentation problem.
461	Sensor Geometry Generalization to Untrained Conditions in Quantitative Ultrasound Imaging	"The proposed framework presents an original approach to synthetize AC images starting from sensory data, even when acquired with US probe geometries different from the ones considered at training time. The proposed approach provides an interesting contribution in the context of US-guided procedures in general. In fact, learning-based methods are generally trained on images or methods acquired with a single fixed probe geometry, and they thus fail to generalize to images acquired with different US probes or systems. This paper presents a promising idea to improve the generalization capabilities of such methods.
Experimental evaluation is performed to assess the performance of the method both on numeric examples and in in-vivo settings. An ablation study is also reported to show the contribution of each of the presented modules."	"They improved the accuracy of the AC image by 9.7%.
In comparison with other methods, their method demonstrates 11.8% reconstruction improvement of the unseen data.
Their proposed method demonstrates 26% enhancement for the reconstruction of out-of-distribution sensor geometry."	"The work has good novelties
It is highly required for ultrasound imaging
Very good abalation experiments
convncing improvements"
462	SETMIL: Spatial Encoding Transformer-based Multiple Instance Learning for Pathological Image Analysis	"1.The pyramid multi scale fusion is interesting, combining the T2T(tokens to tokens) and MSA(multi-head self attention) enhances the features map's local representation and this process is trainable.
2.In SET module, the relative encoding leverage the MSA ""pay more attention"" to local information of neighbouring instances.
3.The network has some advantages in dealing with the tasks, whose local information of the neighbouring patches is vital for the pathological feature."	"The paper is technically sound.

The idea of aggregating representations of both
neighbour instances and globally correlated instances simultaneously, which mimick the clinical practices, seem to be novel and improve results.

-Experiments are comprehensive."	"In general, the work seems novel, and the results are promising. I would support this work as it addresses the main computational pathology concerns.
1-   Providing slide level description for WSIs is what people need with current datasets like TCGA. MIL approaches are an excellent way to use this slide-level information. 
2-   The idea of preserving all patches coordination is new to the best of my knowledge. This is important as tissue morphology is meaningful with looking at its neighbours. 
3-   Multi-level view is necessary when dealing with WSIs, and this work uses the multi-scale approach smartly.
4- Experiments are well designed and multiple datasets have been explored, however, I have some concerns regarding the experiments comparison."
463	SGT: Scene Graph-Guided Transformer for Surgical Report Generation	"The novel method which leverages the scene graph to generate surgical report
Promising results achieved with thorough ablation study"	"The task of surgical report generation is relevant to the medical image analysis community.
The method introduces technical novelties that improve the empirical results of the task.
This work significantly outperforms the state-of-the-art in this task."	"The proposed approach is novel, which first generates a scene graph for each frame, and then uses the scene graph to guide the report generation. To solve the redundancy issue for the entire video, a determinant point process (DPP) is adopted to sample the most important frames. Besides, the graph neural network is used to encode the scene graphs.
The experimental results on the MICCAI 2018 challenge show that the proposed approach could significantly outperform the baselines."
464	Shape-Aware Weakly/Semi-Supervised Optic Disc and Cup Segmentation with Regional/Marginal Consistency	"The paper is overall well written and well motivated, and the topic is of interest.
The dual prediction and regularization is interesting."	"The paper proposes a dual task which injects geometric consistency between the pixel-wise segmentation and distance map;
It proposes a differentiable estimation layer to predict the vCDR directly without offline post-processing."	The research is of practical significance and can solve the problem of less labeling in medical image segmentation. In addition, the manuscript is well organized and fluent in language.
465	Shape-based features of white matter fiber-tracts associated with outcome in Major Depression Disorder	"The paper describes a study, where the authors have defined a proper experiment. The description of methodology is mostly clear and the paper is generally well written. Technical aspects are described, all the way from getting ethical permissions for the study, image acquisition, preprocessing of data, major extraction of relevant features and statistical analysis.
The authors furthermore describe their findings."	The method is good, according to accepted standards	"Very few studies are focused on tractography as a biomarker for treatment resistant depression. 
As we still don't have widely accepted imaging biomarkers for depression, this is study is a relevant contribution to the field. 
It is appreciable the cure into the neuroanatomy details of the results."
466	ShapePU: A New PU Learning Framework Regularized by Global Consistency for Scribble Supervised Cardiac Segmentation	"*	Novel ways to ease the time and labor-intensive annotation work are very important especially in the medical domain, to allow doctors to focus their time directly on patients.
*	The paper introduces a novel multi-class PU learning framework with a interesting integration of shape information in the loss function
*	Results are demonstrated on publicly available data sets, are accompanied by an ablation study and are compared to different levels of contender methods with superior performance (even on par with fully supervised approach)"	"They propose a new learning framework that can use unlabeled data to use the Expectation-Maximization (EM) algorithm to estimate the proportion of each class in the unlabeled pixels.
Their background is strong and well posed. And their experiments demonstrate advantage compared against other methods."	"Clearly written introduction and motivation
Novelty of the method: Using a probabilistic PU learning framework combined with shape/texture information for weak supervision is promising for this application. It would be interesting to see if introducing weighted version of PU loss would be more helpful (as a future work).
Evaluation on multiple datasets: The evaluation is done on multiple datasets and the results look good. While the main statistically significant improvement seem to be with respect to the UnetF method."
467	Show, Attend and Detect: Towards Fine-grained Assessment of Abdominal Aortic Calcification on Vertebral Fracture Assessment Scans	"Cardiovascular Disease (CVD) is the main cause of death globally, and it contributes to disabilities significantly, too.
When calcium deposits in arteries, Vascular calcification happens, resulting in heart attacks or strokes.
The abdominal aorta is one of the first vascular beds where calcification is seen. Since AAC happens well before clinical events, there is a chance to identify people at risk and intervene in a timely manner before they suffer cardiovascular events.
The main strength of this paper is the usage of an attention based encoder-decoder network to mimic the hAAC-24 scoring.
Compared to the 3 previous works found in literature, the proposed methodology outperforms them.
Further, it can classify patients into the three risk categories (low, medium and high), with certain levels of accuracy, sensitivity, and specificity.
The positive aspect of this work is that it has achieved satisfactory outcomes for a small dataset of 1,916 scan.
If a considerably larger dataset (with labels) can be found, the results could be justified better."	The approach of using an LSTM to treat the problem as a sequence is interesting and generally follows clinical practice. Having score breakdowns can be a major advantage for model explainability, which is necessary for eventual clinical implementation.	"Improvement over previous methods, which only provide a global AAC-24 scoring classification per exam/image
Very thorough explanation of the clinical significance of the research"
468	Siamese Encoder-based Spatial-Temporal Mixer for Growth Trend Prediction of Lung Nodules on CT Scans	"Authors proposed a Siamese Encoder-based Spatial-Temporal Mixer for Growth Trend Prediction of Lung Nodules on CT scans.
Their method can help predict the growth of the nodule, to facilitate the diagnosis and treatment of theses nodules, which is a very targeted task in now a days medical field application.
The framework is simple, though authors succeeded to achieve reasonable classification results.
This work can serve as a starting point of formulating a much complex problem as: whether a treatment is efficient or no in the treatment of lung cancer or whether a nodule will grow into a malignant nodule."	The authors of this paper construct a CT dataset NLSTt for predicting the evolution of lung nodules based on the NLST dataset, which combines automatic inference and manual review to obtain reliable labels for nodule texture types and evolution classes. In our proposed method for pulmonary nodule growth trend prediction, a s spatial-temporal mixer (STM) module is proposed to exploit both spatial and temporal information. A two-layer H-loss is also proposed to pay more attention to the nodule growth (dilatation class) related to possible cancerogenesis in clinical practice.	Clinical feasibility: The test with in-house datasets demonstrates the feasibility of the proposed framework.Extendibility: this work can be extended in lesion trend prediction in other diseases with time series images, such as cervical cancer lesion trend in colposcopy.
469	Simultaneous Bone and Shadow Segmentation Network using Task Correspondence Consistency	This paper is well-written, clear and follow a proper methodology. As far as I can understand, the implementation is consistent and the results good after a proper comparison with previous algorithms.	"Novel framework for multi-task learning
Thorough validation and ablation studies"	The method presented explicitly considers bone surface and shadow artifact, in the segmenation of bone structure in US images. The study involved IRB-cerfitified data collection, plus three additional virgin data not included in the network development. The wriging is clear and purposefully highlights the key items for sucessfull MICCAI submission.
470	Skin Lesion Recognition with Class-Hierarchy Regularized Hyperbolic Embeddings	"The paper strengths of the paper are:
1) The introduction of hieralchical relations between classes and the introduction of this informataion in the loss function.
2) The use of hyperbolic geometry for image embedding, more suitable for hierarchical relations then Euclidean according to [5] and [11]
3) They include an ablation study in which they evaluate the improvements of each of the proposed contributions.
4) They include two evaluations metrics of great interest to analyse the contribution that they propose: mistake severity and hierarchical distance of he top k (HD-k)."	"Elegant problem formulation.
Clear theoretical background introduction.
Thorough literature review on related work.
Extensive validation experiments."	The paper has novel contributions because it incorporates recent developments in hyperbolic embedding learning. It also presents a novel loss function that uses the class hierarchy of the underlying problem in their architecture. The paper is technically sound, mathematically well-funded, and enjoyable to read.
471	SLAM-TKA: Real-time Intra-operative Measurement of Tibial Resection Plane in Conventional Total Knee Arthroplasty	According to the reported results, the proposed method outperforms previous methods with regards to robustness and accuracy, while ensuring a short runtime.	The authors novelly formulate intraoperative tibial resection plane estimation as a SLAM problem, and their simulation results show the possibility to apply their method in the clinical settings.	"Clinical significance was well illustrated. The authors clearly showed the impact of using this technique on TKA.
The problem has been re-modeled mathematically to be solved by SLAM. The definition of different data term were well formulated.
Validation on simulation and in-vivo experiments showed promising results."
472	SMESwin Unet: Merging CNN and Transformer for Medical Image Segmentation	"The authors proposed an improved design of transformer-based method for image segmentation. In particular, it combines CNN with Transformer with the help of superpixel and a multi-scale fusion module. As the results show, the addition of superpixel aids in improving the performance, which is effective and useful since superpixel is simple yet generic methodology that can be applied to similar problems.
The multi-scale fusion module incorporates multiple features from both CNN and Transformer, which would be one of the key aspects of the proposed work since the combination of CNN and Transformer happens in this module. 
The authors obtained good results for two datasets and conducted a full ablation study on one dataset. These show the superiority of the proposed work and the effect of different design components of the proposed work."	"1: The proposed architecture seems to be general to another segmentation tasks. I think it will work for many applications.
2: The experiments results are enough for the evaluation and give good evidence for the claims of the authors.
3: The paper is also well written; most of the parts are easy to follow."	"The manuscript is well-written and well-organized. It is easy to follow and also should be easy to reimplement the system.
The system was comprehensively tested in three datasets with different segmentation target."
473	Sparse Interpretation of Graph Convolutional Networks for Multi-Modal Diagnosis of Alzheimer's Disease	"Applying Graph convolution networks (GCN) on multi-modal neural-images is an interesting idea as it shows evidence that a single modality of images is not sufficient.
Imposing sparsity in GCNs (SGCN) as attention shows that the method is better than the conventional GCN.
The experiments show performance metrics higher than related works."	Proposed method applies an attention mechanism with sparsity to identify the most discriminative subgraph structure and important node features for the detection of AD. The model learns the sparse importance probabilities for each node feature and edge with entropy, l1 , and mutual information regularization.	This paper proposed a novel  sparse interpretable GCN framework (SGCN), which applies an attention mechanism with sparsity to identify the most discriminative subgraph structure and important node features for the detection of AD.
474	Spatial-hierarchical Graph Neural Network with Dynamic Structure Learning for Histological Image Classification	"The proposed GNN method dynamically learns the graph structure that employs feature representations and position attributes to connect nodes, i.e. entities. The feature extraction and aggregation for classification have been improved using a vision transformer that improves method performance.
The evaluation has been done on two datasets and the proposed method has been compared to its relevant competitors. Selected methods have been compared based on quantitative metrics.
Use of the proposed method can result in the generation of more explainable graphs that can better relate to the medical explanation of the problem and can therefore result in more reliable / accurate results."	"The paper has a clear structure and well-written, it is overall easy to follow.
The method is described with details, and enables interpretability of prediction outcomes.
The code is open sourced and one of the datasets is publicly available."	"the concept of dynamic learning in GNN is new, with respect to my knowledge
the use of a vision transformer in GNN is a novel approach and it is particularly interesting"
475	Spatiotemporal Attention for Early Prediction of Hepatocellular Carcinoma based on Longitudinal Ultrasound Images	"This paper focuses on early prediction of HCC based on longitudinal ultrasound images. The authors claim that few studies have focused this topic and I also could not find similar studies.
The authors made a large sized dataset of longitudinal US examination for HCC including 619 subjects (although the dataset is not public).
The proposed method achieves better performances compared with popular sequence deep learning models such as LSTM, BiLSTM, GRU and vanilla Transformer."	The ROI attention block and age-based encoding are simple and sensibly designed. Good baselines and ablations. Other researchers working on classification tasks from longitudinal imaging data can draw inspiration from this work.	"The task investigated in the paper is clinically important.
It is interesting to try to include age-information features in the position embedding.
The figures are illustrative."
476	Spatio-temporal motion correction and iterative reconstruction of in-utero fetal fMRI	"The spatio-temporal formulation is intuitive and makes sense
The use of well-established regularizer such as TV makes it easy to implement and reproduce"	"Motivation of the proposed is well illustrated.
The presented method is well presented and easy to follow.
Experiments were performed on real clinical fetal fMRI data.
Down-steam tasks were used to measure the effect of motion compensation (Section 3.4)."	"Novel reconstruction of a 4D image from a single sequence acquired over time by employing the spatial-temporal similarity
Solid evaluation in real clinical data"
477	Stabilize, Decompose, and Denoise: Self-Supervised Fluoroscopy Denoising	"Proposed framework utlized the knowledge of fluroscopy imaging physics to design the method.
It is a self supervised method, so paired data is not required for training.
The first two stage, i.e., stabilizing and decomposition has contributed significantly to improve the denoising performance of existing self supervised denoising methods."	"They built a framework which does stabilization, decomposition, and denoise which is novel.
They provided mathematical proofs that support their claim."	Please see below
478	Stay focused - Enhancing model interpretability through guided feature training	"The authors claim that the explanatory power of the model is improved when the proposed guided feature training is performed. Authors also propose the eCDF-Area method to quantify the explanatory power of enhanced artificial intelligence. For quantification of heat map-based explanatory methods such as GradSmooth, the authors utilize eCDF-Area methods with target RoI information to be recognized.
At the same time, guided feature training increases the generalization performance of the model, which can be seen in SmoothGrad visualization."	"The idea of blurring the background for guiding the feature learning of the features is simple and interesting for improving the interpretability. The authors propose a metric (eCDF) to measure to quantify the interpretability or focus of the model. A simple figure could help the reader to better understand the eCDF metric.
The proposed method seem to improve the 'focus' of the model on to the surgical instruments in the samples shown by the authors and in the performed experiments
The paper is well presented, written, and easy to understand"	"The eCDF-Area metric is an interesting measure introuced for numerical evaluation with heat maps and the mask for the region of interest.
Using the features to guide improvements is a nice approach and made for an interesting read."
479	Stepwise Feature Fusion: Local Guides Global	"Local emphasis operator (LE). Although there are similar techniques to emphasize locality, e.g. swin transformer and NesT, the LE module is somewhat different.
The experimental results are good."	"The paper is well organized
A new pipeline is designed for polyp segmentation. The experiments show it has a better learning ability and generalization ability
Ablation study on different combinations of encoder/decoder is conducted to show the effectiveness of PLD."	"The paper has a clear motivation for its method. Pyramid transformer encoder is selected for better generalizability of the model, especially for challenged polyp segmentation with various size and shape. And progressive locality decoder (PLD) is designed to emphasize local features of small structures.
The model is evaluated on both in-domain testing set as well as unseen dataset, and the results demonstrate the robust generalizability of the model performance.
The model is further trained and tested on other segmentation tasks, i.e. skin lesions, nucleus segmentation, which shows the model' potential for common medical segmentation tasks.
Comprehensive horizontal and ablation studies are reported in Results, which further convinced the improvements of the model.
The paper provides attention maps of each scale and method to better visualize better local feature extraction ability of PLD."
480	Stereo Depth Estimation via Self-Supervised Contrastive Representation Learning	"Methods are novel and interesting. Authors formulate CRL as a dictionary look-up problem as the contrastive learning for self-supervision. Methods are pretty well presented and easy to understand.
Results are convincing. Following Figure 1, we notice that such a method can show the differences between different categories. Fig 5 also shows that such a method can be extended to general images.
Authors have promised to release codes used in the paper.
This paper is well written and easy to follow."	"The paper is well written and easy to follow in general.
The authors proposed a novel contrastive learning algorithm tailored for the stereo depth estimation problem. Self-supervised stereo depth estimation is an important problem given the lack of ground-truth labels, especially in medical domain.
The proposed method is evaluated on two surgical datasets and one non-surgical dataset and demonstrates state-of-the-art performance."	This paper focus on the self-supervised stereo depth estimation. This is important as it is hard to collect abundant ground truth clinical data for supervised leaning.
481	Stroke lesion segmentation from low-quality and few-shot MRIs via similarity-weighted self-ensembling framework	"The capacity to exploit a large dataset to help training with a small dataset in a different problem could help to approach problems that has not been properly explored due to the lack of data. So this work could have an important impact.

Based on the tests, both proposed modules (IDN and SDU) had an clear impact in improving the performance of the baseline, surpassing the other three methods."	"-The new contributions are explained well are in details. Both the attention mechanism and the soft-distribution aware-updating are novel ideas 
seamlessly integrated in the framework. 
-This work has potentially a real-world applicability, aiming to improve stroke lesion segmentation in low and middle-income countries. 
-The method proposed was compared with and outperformed different state-of-the-art approaches on publicly available datasets."	The two innovations are interesting and fairly novel. The Identify-to-Discern Network is well-designed and sophisticated without being overly-complicated. SDU with co-training is a simple and effective approach that successfully eliminates poor outliers compared to a pretrained baseline.
482	Structure-consistent Restoration Network for Cataract Fundus Image Enhancement	"(1) In order to overcome the difficulty of collecting paired cataract images, the authors designed a cataract simulation model to generate synthesized cataract sets as training data
(2) To enforce the structure preservation in the restoration, they designed a model to extract the HFCs from the SCS to boost the model training."	The article focuses on capturing cataract-invariant features of retinal structures in image restoration, generates a synthesized cataract set by a simulation model with several parameters. Moreover, a low-pass Gaussian filter is adopted to extract the low -frequency components and maintain structure consistency. The authors expound the design of the algorithm clearly with detailed formulas and experiments. The comparison of several algorithms is also intuitively showed and demonstrated with restoration image results.	The way of generating SCS is well explained and easy to follow. Additionaly, the SCR-Net is technically sound.The evaluation is not limited to the restoration but to various clinical applications such as segmentation and classification.
483	Super-Focus: Domain Adaptation for Embryo Imaging via Self-Supervised Focal Plane Regression	"* Strong and complete conference submission: various data, clear methodology and presentation, convincing validation.
* Simple but efficient methodology resulting in improved performance."	"Relevant problem solved with an interesting combination of different methods.
Results studied from various aspects (Embryo grading, cell segmentation, expert qualitative assessment)
impact of the training dataset is shortly discussed"	"Nicely written and well-understandable paper that tries to solve an important problem.
Self-supervised , i.e., no manual annotations required.
Large training / test data set
Several interesting ablation studies including the fact that FID apparently is more suitable to judge the realism of generated images."
484	SUPER-IVIM-DC: Intra-voxel incoherent motion based Fetal lung maturity assessment from limited DWI data using supervised learning coupled with data-consistency	The method is sound and the experiments are suitable for showing the improved performance of the approach. The method has the potential of reducing required acquisition times for the MR signal, which is clinically relevant.	Novel concept for IVIM parameter estimation that would be applicable for the clinical routine since it needs fewer images to be acquired, saving some time	This paper proposed a data-consistency term that enables the analysis of diffusion and pseudo-diffusion biomarkers based on DNN. Their work demonstrated the added-value of SUPER-IVIM-DC over both classical and recent DNN approaches for IVIM analysis through numerical simulations, healthy volunteer study, and IVIM analysis of fetal lung maturation from fetal DWI data. This paper has clinical significance in fetal lung maturity analysis.
485	Supervised Contrastive Learning to Classify Paranasal Anomalies in the Maxillary Sinus	"Nice addaption of supervised contrastive training for paranasal anomalies and combination with a CE-loss.
Experiments and evaluation seem to be done well."	"The paper is mostly well-written and clear.
The method achieves good performance on the authors' private dataset.
Most of the aspects are described in sufficient detail to enable the reproduction of results."	"Self-supervised learning methods such as the SimCLR used in the paper is a high interest to the readers in the field. The paper does a good job in introducing the method to the clinical problem with good experimental results.
The experiments are thorough and sufficiently backs the contribution.
The visual examples are well illustrated.
Limitations are clearly mentioned."
486	Supervised Deep Learning for Head Motion Correction in PET	In this paper, the authors proposed a new deep learning-based method to correct the head motion and diminish the artifacts and quantification errors in PET imaging. This is supposed to be a good start on algorithm-based motion correction in PET imaging.	"This paper aims to address a very challenging task, i.e. to estimate motion on a second-by-second basis from noisy low resolution PET data. I have not found previous work which this paper makes incremental extension from.
The transparency of including all kinds of results, like in Fig2 is valued.
The authors discussed the limitations of the current results thoroughly."	The approach is methodologically interesting in 2 ways 1) Instead of using the PET image sin image space and trying to register them, the 1-second frames are back projected along the LOR and used to construct a point cloud. This seems to make it much easier to register, since a regular 1 second PET image, not even FDG, would have enough contrast to else register it. 2) The motion tracking is properly evaluated against an external tracking device, the Polaris Vicra. This is very nice and the proper way to do it instea dof only assessing motion improvements visually or image based as is often the case. Furthermore, the paper addresses an important clinical issue, motion degradation due to motion in PET acquisitions and provides a solution that is feasible to implement without acquiring an external tracking system.
487	Suppressing Poisoning Attacks on Federated Learning for Medical Imaging	"Well motivated and presented paper
Places work in context to other works and compares against them in empirical results"	The key strength of this paper is developing a robust aggregation rule for FL against attacks from malicious clients. The aggregation rule employs a parameter-free outlier detection algorithm, namely COPOD, to detect abnormal values among the distance metrics of model parameters between the clients and the global model.	"The proposed method achieves improved results over previous methods indicating the effectiveness of the method.

The method leverage two distance metrics to achieve robust distance and outlier measurements and could be extended for other distance metrics.

Rich experiments are conducted. Visualizations shows clear model performance under different situations."
489	Surgical Scene Segmentation Using Semantic Image Synthesis with a Virtual Surgery Environment	"Extensive experiments on instance and semantic segmentation with different models and different combinations of real/synthetic data;
More sophisticated surgery simulator with more organs and tools;
The first large-scale dataset for surgical scene segmentation, also tackling class imbalance, is released."	"This work demonstrate the feasibility and effectiveness of surgical image sythesis based on complex virtual surgery simulation, which is valuable and inspiring for the surgical vision field.

Systematical experiments are carried out with various configurations and different models.

The dataset will be released to public, and can be used for both semantic and instance segmentation."	"The datasets and synthetic data generation pipeline could be valuable for the community. The presented approach for advanced training of surgical scene segmentation models is interesting and promising and the implementation and considerations of the authors for dataset generation are thorough.
The authors compare state-of-the-art models (ResNeSt, Swin Transformer,...) on the proposed  datasets and perform an extensive evaluation."
490	Surgical Skill Assessment via Video Semantic Aggregation	The method includes a data-driven approach to emphasize relevant semantic information for skill assessment. While the experiments illustrate instrument motion as the semantic information, the introduction claims that the method can isolate information beyond the instrument. The findings are expected, reiterate current understanding of relevance of information in video images for surgical skill assessment. The method is evaluated on two datasets.	The idea of this work is interesting. Without supervision it can find different sementic parts in the surgical videos. The visualization results confirm this. This is helpful to discover structures from complicated surgery scenes.	"The authors' motivation to address the shortcoming of state-of-the-art models by discovering and aggregating different semantic parts of the surgical setting across spatiotemporal dimensions is an interesting approach.
As the authors cluster spatial features, no supervision is required to discover these semantic features which are expected to belong to different surgical elements such as tools, the tissue, and the background. However, a supervised version is also proposed. This supervision is achieved with kinematic data.
They experiment on the commonly used JIGSAWS, and another dataset HeiChole, which is in-vivo, therefore a more realistic one. The method proposed is able to achieve an improvement over the state-of-the-art models.
The organization and the flow of the paper is good, as well as the technical writing."
491	Surgical-VQA: Visual Question Answering in Surgical Scenes using Transformer	"The introduced model is evaluated on three datasets and achieves promising results. Rich experiments are conducted on two tasks as well as module ablations.

Leveraging VisualBERT and ResMLP on Surgical-VQA is novel and is shown effective over the previous methods. This helps promote related work with similar data scale and requirements.

Ablative studies on temporal visual features are also given which is helpful for related video tasks."	"The task of surgical VQA is relevant to the medical image analysis community.
The paper is easy to read.
This work reports a complete ablation study over the model hyperparameters."	The main strength of the paper is the novel application, visual questioning answering to release the burden of clinical experts. It introduces the Visual Bert and its variation ResMLP to achieve cross-token and cross-channel fusion during the text-image feature extraction. Secondly is the newly proposed dataset in Cholec80 with classification-based and sentence-based VQA dataset. Finally, the proposed method is compared with state-of-the-art methods and achieves the promising results.
492	Survival Prediction of Brain Cancer with Incomplete Radiology, Pathology, Genomic, and Demographic Data	"The significant contribution of this work is that it provides a comprehensive study of multimodal fusion for survival prediction. It gives a detailed guideline for the readers to integrate multiple data modalities in the presence of missing data. In addition, the modeling components are straightforward and well established in the field, which makes this model generalizable for solving other problems.
The model contains two key components, the first one is a uni-modal feature extractor module, and the second one is a fusion module. The unimodal feature extractor module learns a lower-dimensional representation of the input data, and the fusion module combines the learned features and extract discriminative patterns which improve survival prediction.
The authors use well-established models to build the unimodal feature extractor module. This allows them to use pre-trained weight, which reduces computational complexity. In addition, due to this choice, the authors can combine the power of multiple state-of-the-art models already proven to be robust for representing imaging, genomics and demographic data.
The fusion module contains a two-layer MLP that further projects the output of the unimodal feature to a latent space where a mean vector is calculated for data fusion. The authors take a unique approach to dropout modalities, enabling the model to learn discriminative patterns from the rest of the data when a modality is absent. This approach boosts their performance, and they can take advantage of a larger dataset.
The authors have provided a detailed study explaining their choice of optimization strategy. They compared their model by training on complete data. They showed that the model could improve performance by extracting discriminative patterns from multiple data modalities in the presence of missing data.
In an ablations study they show the importance of data fusion compare to uni-modal approaches.
Finally, the model shows improved performance compared to the baselines."	"Survival prediction based on multi-modality dataset is a meaningful problem in clinical research, and handling dataset with missing data in different modalities is a very realistic problem.
The comparison between end-to-end and two-stage training strategies and the ablation study on data fusion strategies are conducted systematically."	The problem tackled here is both interesting and challenging. Many of the recent methods which try to work with multi-modality data tend to assume that the information of all the modalities of interest are available for all the patients. This makes the task easier, but not applicable to all patients in clinical settings. When ground truth information of some modalities are missing, it is an interesting problem to somehow use the information from the patient to extract relevant information for the training. The paper also summarizes the previous works neatly, enabling us to clearly understand the contribution of this work.
493	SVoRT: Iterative Transformer for Slice-to-Volume Registration in Fetal Brain MRI	"To my knowledge, transformers have never been used before in the context of slice-to-volume registration, as such the proposed method is novel
Comparison with existing techniques
Provided results illustrate overperformance on synthetic data as regards SOA"	"This work produces a novel solution to a challenging clinical problem. Deeplearning methods [11,23] have been proposed to predict transformation, which process each slice independently, ignoring the dependencies between slices. 
This work process the stacks of slices as a sequence, SVoRT registers each slice by utilizing context from other slices, resulting in lower registration error and better reconstruction quality. Instead of predicting the transformations alone, this work also estimate a volume from the input slices, so the estimated volume provide 3D context to improve the accuracy of transformation. Specially, during volume estimation, this paper consider some wrong slices, resulting in artifacts in the reconstructed volume. They proposed addition SVT to predict weight of slice, where represent the image quality of the slice."	"The paper elegantly merges strengths of CNNs through ResNet by extracting meaningful features from original stacks, transformers strengths to know where to attend to the most and a weighted inverse problem formulation to construct the final volume using the transformations and the weights learned.
They apply the method to two datasets
They performed ablation experiments to support some components of their model"
494	Swin Deformable Attention U-Net Transformer (SDAUT) for Explainable Fast MRI	"The paper is well-written and the idea is easy to follow overall
The combination of Swin Transformer and deformable attention is a novel design and can help to reduce computation while maintaining/improving performance
SDAUT achieves state-of-the-art performance and can provide explainability
The authors provide an extensive ablation study to validate the design of the proposed method"	"The article is clearly written, the drawings are informative, the motivation is sound.
The resulting architecture is much more computationally efficient than classical feedforward neural networks, including those based on transformers."	"The deformable field and the attention score in Fig.4 attempted to provide insights of how the model works for the undersampled reconstruction task.
The swin deformable transformer is somehow novel in undersampled MRI reconstruction application."
495	Swin-VoxelMorph: A Symmetric Unsupervised Learning Model for Deformable Medical Image Registration Using Swin Transformer	"- as far as I known, this is the first implementation of swin unet for image registration
- the method compared favorably to state of the art w.r. dice, negative Jacobian percentage and computational time.
- the resulting registration method have all the good expected properties of a registration method: regularity, symmetry, invertibility."	The main strengths of the paper lie in the fact that they use a transformer based network for deformable image registration task. The paper is well written and easy to follow.	It constructs a objective functions including orientation and inverse consistency constraint to guarantee the topology-preservation and inverse consistency of the predicted transformations.
496	Tagged-MRI Sequence to Audio Synthesis via Self Residual Attention Guided Heterogeneous Translator	Authors raised an interesting research topic: transfer imaging data (tagged MRI) to audio data (spectrograms). Specific self-residual attention guided heterogenous translator and utterance disentanglement were designed for this specific task. The proposed method outperformed the available method for similar task.	They are the first team to try to translate tagged-MRI sequences to audio waveforms and they proposed  an efficient fully convolutional asymmetry translator with help of a self residual attention scheme to specifically focus on the moving muscular structures for speech production. And they used a pairwise correlation of the samples with the same utterances with a latent space representation disentanglement scheme. Furthermore, we incorporated an adversarial training approach with GAN to yield improved results on our generated spectrograms. The topic and results are very interesting.	The proposed architecture is sophisticated and tailored to the target application and data format, and the authors present an ablation study which shows the benefits of each part of the proposed model. The approach is novel and interesting, the results seem consistent, and the paper is well written.
497	Task-oriented Self-supervised Learning for Anomaly Detection in Electroencephalography	"Self-learning for anomaly detection of EEG based on CNN may have some novelties
The way of generating abnormal EEG signals is interesting even if there exist deficiencies."	The idea is simple and natrual. In other words, domain experts may add as many SSL transformation rules based on their understanding of the problem.	"The experimental results are quite good ! 
It is great to see the simulated based anomaly detection is such effectiveness in EEG modality.

The ablation study is well designed.

Using Mahalanobis distance as anomaly score is reasonable."
498	Task-relevant Feature Replenishment for Cross-centre Polyp Segmentation	"The paper faces a very important problem in the medical imaging field, the domain-shift problem.
The idea to join domain-invariant features and task-specific features is interesting.
The paper is well written and simple to follow. 
Extensive quantitative comparisons are conducted, and all the methods are trained using the same data splits."	"The paper is generally well-written and easy-to-follow;
The paper explore multiple techniques in computer vision and effectively combine them into a single framework; also, each proposed module are modified to tailor the segmentation task;
Extensive experiments on multiple datasets demonstrate superior performance of the proposed methods;"	The paper is well organized and clearly written. Tables and some of the figures are well presented. The authors present a new method for unsupervised domain adaption which is really a challenging problem.
499	TBraTS: Trusted Brain Tumor Segmentation	"* This paper provides a smart way to be able to predict uncertainty related to the resulting segmentation
* comparisons with existing methods are detailed"	The idea of using Dempster-Shafer theory for uncertainty quantification is attracting and the proposed  methods show good performance on model's reliability with Entropy, ECM and UEO.	"The application of evidential deep learning on medical image segmentation is an interesting use case and can be helpful for the community.

The experimental results demonstrate the effectiveness of the proposed method over other methods."
500	Test Time Transform Prediction for Open Set Histopathological Image Recognition	"Proposed a simple yet novel self-supervised way of filtering out the irrelevant patches.
The source code will be made public with the publication."	The authors proposed a decoupled color-appearance data augmentation strategy and a test-time transform prediction model.	The paper is clearly written and easy to follow. It offers a good depth of background information, rationale for approach, and contains valuable ablation studies and comparisons.
501	Test-time Adaptation with Calibration of Medical Image Classification Nets for Label Distribution Shift	"A novel method for test-time adaptation, i.e., TTADC, is proposed, with strong and convincing empirical evaluations.
Experiments on real-world clinical data demonstrate clinical feasibility.
The paper is well written with clear logic."	"S1: This paper presents the first work to effectively tackle the label distribution shift in medical image classification.
S2: The paper is overall clearly structured.
S3: Authors have tested the proposed method on two public datasets to demonstrate the effectiveness of the proposed method and have conducted extensive ablation studies."	"Well-conducted research. The paper is well written and the research is well conducted. every choice is well documented and results are convincing and presented in a proper way (mean and std)
different tasks are evaluated (Liver fibrosis staging and Covid19 severity prediction)
Ablations showed that their proposed components are actually improving results
Results. They compared with different SOTA models (even if these SOTA methods were not built with a medical setting in mind) and achieved the best results"
502	Test-Time Adaptation with Shape Moments for Image Segmentation	The paper is well written and easy to understand. The authors use publicly available datasets to validate their approach. The validation benchmark includes the entire range of methods : From NoAdap (lower bound) to Oracle (Upper bound). The proposed approach has been compared against methods that include TTA, DA and SFDA.	The major strength of the presented test-time domain adaptation method is the increase in performance over classical and source free domain adaptation methods, which is shown to be achieved by the addition of the introduced shape moments.	"This work proposed a shape-guided entropy minimization objective with shape moments to achieve the task of test-time single-subject adaptation. From the experiment section, the proposed method exhibits better performance compared with other methods.
The chosen datasets in section 3.1 are appropriate to exhibit the performance of the proposed method, by dealing with MRI-to-CT adaptation and cross-site adaptation."
503	Test-time image-to-image translation ensembling improves out-of-distribution generalization in histopathology	"Very intuitive idea and the proposed algorithm gets a good boost
Experiments were conducted using multiple seeds on  large enough datasets while comparing many mainstream ood generalization methods"	"The application of generative models at test time is a novel idea for improving the model's performance.
The proposed approach is evaluated for two different tasks and compared with a number of other approaches."	Domain gap is very practical and challenge challenges for almost any multi-center histology, due to stain variations. This paper provides a new strategy (i.e., test-time augmentation) in addition to the previous stain normalization/augmentation for addressing this issue, where the previous methods are training-time based or prior to the training time.
504	TGANet: Text-guided attention for improved polyp segmentation	"The proposed label attention can further utilized classification information to constrain the feature maps for segmentation.
The experimental results demonstrate improved performance using four datasets."	"The motivation is clear and the idea is reasonable. The network is expected to be aware of the context attributes and the authors realize it in terms of size&number.

The text guided attention module is portable for different networks. The text labels of polyp attributes are easy to generate automatically, so that the training does not need extra manual annotations.

The experiments are comprehensive. The authors evaluated the proposed TGANet on four publicly available polyp datasets and compared it with five recent medical image segmentation methods."	"The authors exploit size-related and polyp number-related features in
the form of text attention during training. It helps the network to improve the performance  for the 'small', 'medium' and 'many cases'. Also, they conduct lots of experiments to show the improvement on four different datasets."
505	The (de)biasing effect of GAN-based augmentation methods on skin lesion images	(de)biasing effect of using GAN-based data augmentation is discussed in great detail.	"The second experiment on counterfactual artifact insertion is the defining strength which strongly supports their conclusions regarding the exascerbation of certain biases in the data caused by artifacts present in both conditional and unconditional GANs. The first experiment demonstrates some of the effect that the authors claim, although not to the same degree.
The cautionary motivation for the paper is really quite strong, and it provides a measured response to the argument that generative models can completely solve the problem of data availability."	The authors explore a large and relevant range of possible bias in skin lesion images, sharing these annotations is acknowledgeable. Besides classical metrics, counterfactual bias insertion metrics provide complementary information to the bias effect.
506	The Dice loss in the context of missing or empty labels: introducing Ph and 	"The paper provides a formulation that generalizes several loss functions in the context of missing or empty labels.
It demonstrates how to tune the parameters 'phi' and 'epsilon' based on the problem at hand (correctly handling missing labels or empty labels."	"(1) This paper provides a theoretical analysis on the derivative of Dice loss, as well as the effects of $\Phi$ and $\epsilon$. Such an analysis provides a deeper understanding of Dice loss.
(2) The experimental setups are reasonably designed, and the evaluation results verify the claims made in the paper to some extent."	"The paper is well written and structured.
Missing and empty labels are common problems in medical image segmentation that will benefit the clear formulations and proposed heuristics.
Beside the limitations mentioned in the weaknesses, the experiments are well designed and described, the results support the hypotheses."
507	The Intrinsic Manifolds of Radiological Images and their Role in Deep Learning	"Great topic
Great organization of the paper
Very lean approach
Large enough benchmark"	"Empirical results are sound by applying the ID estimation on multiple medical image dataset and natural image dataset. The different choice of neural network shows similar results.

The finding of negative dependence between test accuracy and ID is foreseeable, but the difference of scope between natural image and medical image is novel and interesting."	
508	The Semi-constrained Network-Based Statistic (scNBS): integrating local and global information for brain network inference	The strong aspects of this work are: the detailed description of the scNBS, corroborated by excellent figures; the very interesting experimental design and data, which mixes Human Connectome Project resting-state fMRI data with somewhat-realistic synthetic phenotypic data.	The proposed method could account for both local and network-level interactions that might have clinical significance.	"*	Novel approach grounding on solid statistical basis
*	Important impact in the field, with possible applications even in clinical scenarios (e.g., comparing patient data)"
509	Thoracic Lymph Node Segmentation in CT imaging via Lymph Node Station Stratification and Size Encoding	Stratified LN-statin and LN size encoded segmentation are validated based on the LN size variations.  Three super LN stations and learning framework were proposed and showed the high performance in metrics compared with the previous approaches.	"The formulation of the framework is interesting.  It seems intuitive to group the LN-stations to form ""super-stations"" to try to help the learning.  Similarly with the large/small differentiation. These ""pre-processing"" of the data seemed to have helped the learning.
The use of an external dataset to validate the result is also interesting, as they have different resolution comparing to the training data."	"Thoracic LN-stations are segment and then grouped into 3 super lymph node stations firstly. A multi-encoder deep network is designed to learn LN-station-specific LN features
To learn LN's size variance, two decoding branches are proposed to concentrate on learning the small and large LNs, respectively.
Validated on the public NIH dataset and further tested on the external esophageal dataset, the proposed framework demonstrates high LN segmentation performance while preserving good generalizability."
510	TINC: Temporally Informed Non-Contrastive Learning for Disease Progression Modeling in Retinal OCT Volumes	"The proposed method is a simple yet interesting extension/adaptation of VICReg to longitudinal medical images. To the best of my knowledge the method is novel, and I'm not familiar with other demonstrations of the VICReg method to medical images.
The experiments and results are satisfactory, in terms of showing that the proposed method can have superior performance over other self-supervised  non-contrastive methods: including vanilla VICReg, and simpler adaptations of it (which can be viewed as ablation study)."	Modified the VICReg's invariance term by constraining it with the normalized absolute time difference between the input images	"This paper addresses a interesting clinical question, i.e., Disease progression in the longitudinal contexts. This problem is not only existed in Eye, but also other organs.

Superior performance has been achieved when comparing with some baselines."
511	TMSS: An End-to-End Transformer-based Multimodal Network for Segmentation and Survival Prediction	"SOTA results on survival prediction
Complementary segmentation which can potentially be used for RECIST computation etc.
Combining multimodal data."	"The problem is of clinical importance.
Although Transformer-based Multimodal Network has been used to solve other problems, it is used for the first time for head and neck cancer segmentaion and survival prediction"	"Overall the paper is very well-written, easy to follow and soundly evaluated.
The manuscript clearly states its contributions and has a strong focus, adequately leading through the overall concept.
The authors provide a good overview on the current state of the art and demonstrate a profound knowledge in the field.
The authors have agreed to disclose their code on acceptance.
Finally, the authors achieve state of the art performance."
512	Toward Clinically Assisted Colorectal Polyp Recognition via Structured Cross-modal Representation Consistency	The paper is well-written and address a clinical issue. Also, it presents a novel designed Spatial Attention Module to calculate similarities.	"Well written paper
The addressed topic is of interest for the surgical data science community
Experiments and comparison with the literature are performed"	This manuscript has detailed mathematics, designs and implementations for each module, it is easy for people to follow even for those readers who are not familiar with attention model.
513	Towards Confident Detection of Prostate Cancer using High Resolution Micro-ultrasound	The main strength of the paper is that the faced problem is clinically directly related, and the evaluation experiments also consider the clinical concerns.	"The development of a predictive algorithm to assist in the detection of prostate cancer using micro-ultrasound, without the need of additional MRs, which can be expensive and prone to co-registration error, is a welcoming direction.
The paper is well organized and presented. The ""Methodology"" section, with the aid of Figure 1, which is well done, is especially easy to follow.
Given the available data, the authors presented a thoughtful and well-designed validation experiment."	The main strengths are providing methods to adapt to sub-optimal training data, which reflects a challenge with most real-world machine learning tasks in medical imaging; and a means of interpretability by utilizing adjustable confidence thresholds which better integrate with an operator's decision making.
514	Towards Holistic Surgical Scene Understanding	"PSI-AVA: Novel dataset and benchmark code, shared publicly (license unclear, please indicate in paper)
Hierarchical/multi-level annotation and learning targets: Compared to other dataset, a very comprehensive set of target labels (see Table 1 - incl. phase/step/instrument recognition, instrument detection, action/task annotaiton, spatial annotations )
Novel method: ""Transformers for Action, Phase, Instrument, and steps Recognition (TAPIR)"" able to leverage multi-level annotations, from tool localization over task classification to surgical phase recognition. Experiments underline TAPIR's ability to make use of hierarchical knowledge. This is shown in Table 3, where TAPIR performs better than e.g. a SOTA model ""SlowFast"", both on the (non-hierarchical-labels) EndoVis challenge data and disproportionally better on the PSI-AVA dataset with hierarchical labels.
PSI-AVA intrinsic validation: the dataset is also briefly validated by comparing two non-TAPIR models (Faster R-CNN vs. Def. DETR), which yield more consistent performances on PSI-AVA (at similar FLOPs/#Param characteristics). This probably indicates a high quality and consistency of annotations in PSI-AVA.
Appropriate and informative supplementary material."	"The first strength of the paper is introduction of a new data-set (PSI-AVA) with annotations for phase and step recognition,instrument detection, and the novel task of atomic action recognition in surgical. The dataset is novel and unique and can serve as a new benchmark for multiple tasks in surgical video understanding.
The paper is well written and with enough level of detail on the dataset, methods and validation strategy.
The authors also propose a new transformer-based model for feature extraction in spatio-temporal domain from surgical videos. Given the evidence in the computer vision community related to merit of vision transformer models, the paper and it's validation can benefit the miccai community.
Experimental validations are sufficient to prove the claims made by the authors and can serve as a guideline for other to follow."	There are two main advantages of this paper. First, the paper proposes a new dataset for phase and step recognition, instrument detection, and the novel task of atomic action recognition in surgical scenes. This dataset is adapted to a variety of tasks and is publicly available. It is very helpful for researchers to follow-up work in this field. Second, the authors propose a transformer-based framework.
515	Towards performant and reliable undersampled MR reconstruction via diffusion model sampling	"The authors leverage the recent diffusion model-based generative methods to learn the distribution of fully-sampled images. Therefore, the proposed method doesn't rely on a certain sampling pattern or acceleration factor.
The authors did thorough studies on ablation studies, and different sampling factors, and provide enough details on the training and inference, Fig.3 shows the robustness of the proposed method. Solid work."	"This paper provides the first data point, to my knowledge,  where the diffusion model is introduced to MR reconstruction framework.
Experiments show that the model can outperform other baselines consistently, especially the proposed method can  adapt different under-sample rates."	"The k-space guidance module uses $x_obs$ added by a zero-mean Gaussian noise as the condition and mixes it with the reconstructed image in k-space, allowing for stochastic sampling.

The coarse-to-fine sampling module accelerates the speed of selecting reconstructed images by averaging samples generated for the estimation of E[q(y_full
x_obs)].

The ablation study supports the benefit of using each module. The evaluation experiment shows the improvement with the proposed method in both increasing performance and less time-cost."
516	Towards Unsupervised Ultrasound Video Clinical Quality Assessment with Multi-Modality Data	The model appears novel and the method may make the measurements of the fetus more reproducible and less dependent on the operator. The analysis appears sound and the results are convincing.	"Research motivations and its clinical importance are clearly stated
Scalability of the method
The method does not require anatomical annotations for training, which is an important improvement over state-of-the-art methods
A strong validation of the results is provided, with extensive result comparison and ablation studies, which support the proposed methodology"	"The paper is well written and easy to follow.
The proposed approach for unsupervised training seems interesting.
The experimental results are acceptable."
517	Tracking by weakly-supervised learning and graph optimization for whole-embryo C. elegans lineages	Despite its incremental methodological novelty over Linajea, the idea of hyper-parameter fune-tuning to alleviate the need for identifying a suboptimal hyper-parameter configuration using grid-search seems to be promising. However, it is unclear whether such a strategy is viable for other types of embryonic image data, or time-lapse cell image data in general. The authors also promised to make two fully annotated datasets publicly available along with the paper, with the aim of accelerating further algorithmic developments in this area.	"* Developed methods improve the performance, both in terms of higher validation scores and ease of use.
* Top-ranked performance on the challenge data."	"The achieved tracking quality of the proposed method is a strength of the paper (although the scores of the prior methods linajea are already impressive as well).
Although not invented by the authors, an interesting way of automatically identifying hyperparameters via a structured SVM is applied to eradicate the need for manual hyperparameter tuning / grid searches.
The additions to the ILP formulation are reasonable extensions and it's generally a great approach to incorporate biological constraints directly to the optimization problem.
Last but not least the paper is nicely written, comprehensible and I didn't even spot a typo."
518	TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis Framework Using Spectral Embedding and Vision Transformers	"The formulation of the representation is novel, interesting and sensible.

It offers genuine advantages over more ad-hoc solutions one might imagine.

Simulation results are promising and show the approach works as expected in one example scenario.

Real-data results are reasonably compelling showing good discrimination between psychiatric groups and highlighting reasonable features of the tractogram as salient features."	"The topic is interesting and clinically significant.
The paper is well organized and easy to follow.
The idea of embedding tractography information into 2D representation seems effective and interesting."	"The proposed TractoEmbedding method can encode the 3D fiber spatial relationships by 2D image, which allows image-based models such as CNNs and ViT to leverage fiber spatial similarity information.

The figures of this paper are clear, which is very helpful to understand the main idea of the proposed method."
519	TransEM: Residual Swin-Transformer based regularized PET image reconstruction	This work assesses the performance of incorporating swin transformers into PET image reconstruction.	The swim-transformer is relatively new in the computer vision field. It is a good attempt to apply swim-transformer to the PET reconstruction field. The article is well organized. The authors analyze the robustness of the proposed TransEM on down sampled cases and perform the experiments to investigate the generalization ability of different models, which validates the excellent performance of the proposed method. The experiments demonstrate the claims set out by the authors.	The introduction well steers the proposed method, which is well divided into three parts. We understand why the authors want to use transformers in PET reconstruction. Moreover, starting from a recent state of the art idea (FBSEM) and combining with recently proposed transformers instead of CNN is a relevant combination of recent methods.
520	Transformer based feature fusion for left ventricle segmentation in 4D flow MRI	"generally an interesting problem, as it brings cardiac segmentation to a novel imaging method with potentially brings new diagnostic and therapeutic benefits
novel approach to concurrently learn anatomical appearance from multiple images
strong evaluation both in terms of technical (DICE & surface distance) and clinical measures (ejection fraction, volumes etc. - both absolute errs as well as statistical metrics)"	"Application novelty. The automatic assessment on 4D flow MRI has been little investigated before. As the authors states, it may be the first work for this application.
The employed techniques are sound. The authors introduce different attention modules for intra- and inter-modality feature extraction and fusion. The results also support the performance improvement thanks to the attention mechanism.
The choice of evaluation metrics. Since the most significant of the paper is the application novelty, the authors employ both geometrical and clinical metrics."	"They propose the first study to segment the LV directly from 4D Flow MRI data.
They propose a Transformer based cross- and self-fusion layer to explore the inter-relationship from two modalities and model the intra-relationship in the same modality."
521	Transformer based multiple instance learning for weakly supervised histopathology image segmentation	"-Overall, the paper is very well-written and presents a successful combination of current methods for achieving a successful weakly-supervised segmentation method on histopathology images.
-The state-of-the-art segmentation results are achieved on the colon cancer dataset.
-The authors carry out enough ablation studies on the components of their method, proving the efficacy and contribution of each of these parts."	"This paper introduced Swin Transformer to MIL and semantic segmentation of pathology image.
Many comparison and ablation study proved the effectiveness of the proposed method."	"1.From the perspective of the characteristics of the semantic segmentation task, this paper proposes to improve segmentation performance by overcoming the problem of independent instances in MIL.
2.Weakly supervised methods are relatively sufficient in the experiment, which can prove the effectiveness of Swin Transformer Based MIL."
522	Transformer Based Multi-task Deep Learning with Intravoxel Incoherent Motion Model Fitting for Microvascular Invasion Prediction of Hepatocellular Carcinoma	Altought this paper uses well-known techniques and algorithms, the authors compile a robust and (from my point of view) innovative solution. They provide proper methodology and implementation details and compare its results with previous studies.	"The use of transformer and multi-task learning to leverage information from 2 tasks that are linked is interesting.
the comparison to other methods is extensive."	"Design a transformer-based multi-task learning model
Perform simultaneous IVIM parameter model fitting and MVI prediction
Demonstrate better results with multi-task strategy."
523	Transformer Based Multi-View Network for Mammographic Image Classification	This paper proposes a new method for classification of mammography images.	"Cross-view attention is interesting.
The proposed model performs the best on the DDSM dataset (Table 2).
This paper provides empirical studies on the fusing stages (Table 1)."	The proposed pure transformer based multi-view network seems to be novel. Intuitively, it can better utilize cross view attention mechanism, which is verified by the experiments. Previous multi-view approaches rely on hand crafted attention blocks, which are kind of ad hoc.
524	Transformer Lesion Tracker	"Significant improvement in performance, from 79.5 to 87.7 in CPM@10mm.
Clear ablation study, including SSS, RAMM-CAT, global regressor"	"The paper addresses the clinically relevant problem of lesion tracking over time.
In general, I enjoyed reading the manuscript. It is well structured, has a clear motivation, and is well written.

the authors propose a novel approach using Transformer to predict the center of the propagated lesion in the follow-up scan
The experiments were conducted on the publically available DeepLesion dataset indicating good performance.
code will be available on Git"	
525	Transforming the Interactive Segmentation for Medical Imaging	The results of the proposed method are better than five previous methods. The results improves fast with more user interaction. Also, ablation study shows that the new components (click encoding and label assignment) both contribute to the improvement of the results.	"The major strength is that most of segmentation methods, in order to have less error, they have to be trained for the specific application. This method ensures they can segment most cases of cancer organs, doing a refinement through clicks given by the users. This method is natural for the clinicians for example.  Where they are used to delineate manually the structures and lesions. 
So usability is a must on this paper."	The paper is well written, the proposed architecture is is quite innovative (although I am no expert in interactive segmentation), and results are very convincing, with consistent improvement improved by both the click encoding mechanism as well as the label assignment step.
526	TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation with Transformers	"The problem is well-formulated. 
The authors claim that the size, modality and even dimension can be different among views. This is an interesting take."	"Following are the strength of the paper:

The paper is well written and the work flow is explained properly.
The novelty of the work is satisfactory.
The algorithm was tested on multi-centric, multi-View and Multi-disease data."	"The proposed method is crucial to improve the performance and robustness of automated methods for disease diagnosis, which combines information from multi-view images.
The authors propose a divergent fusion attention (DiFA) module to handle the multi-view inputs.
A Multi-Scale Attention (MSA) is used to collect global correspondence of multi-scale feature representations."
527	TranSQ: Transformer-based Semantic Query for Medical Report Generation	"Motivation for the paper is clearly explained.
Methods used in the paper are interesting and distinct from the current state of the art work in the medical report generation field.
First approach to treat report generation as a sentence set prediction and selection problem.
Methods section has been clearly explained with the motivations for each aspect of their work (visual feature extractor, semantic encoder, and report generator).
Comparison against other methods has been shown and results surpass previous state of the art methods."	"The paper advances the SOTA on the report generation problem on two widely used datasets.
The comparison to previous work is thorough and clear."	"The paper is well-written and easy to follow.
The proposed approach is interesting and novel.
The experiments on two benchmark datasets show that the proposed approach can achieve state-of-the-art performances."
528	Trichomonas Vaginalis Segmentation in Microscope Images	"The proposed HRF and FBA modules are indicated to be effective via ablation studies.

The proposed method is making an early attempt on the Trichomonas Vaginalis segmentation in microscopy images.

The overall paper is clearly presented and easy to follow."	"The publication of a new large-scale annotated dataset is of interest to many biomedical computer vision developers and poses new challenges to the existing methods.
The proposed baseline architecture combines very recent modules in order to improve the segmentation results. Such modules are justified using an ablation study."	"Both contributions (dataset and segmentation method) are significant: The dataset is very large and extensively annotated, including common annotations like object-level segmentation masks, but also more detailed attributes at image level (labels like ""multiple objects"", ""out-of-view"") and object level (labels like ""complex shape"", ""out-of-focus""). The segmentation method outperforms latest methods."
529	UASSR:Unsupervised Arbitrary Scale Super-resolution Reconstruction of Single Anisotropic 3D images via Disentangled Representation Learning?	"Using a GAN for single image SR is novel in medical imaging, as far as I know.
The results presented are comparable and potentially superior to the SOTA methods for SR."	"Interesting idea with novel method: this paper introduces using an unsupervised arbitrary scale super-resolution reconstruction (UASSR) based on disentangled representation learning to eliminate the requirement of paired images for training.
Good writing: this paper is well written. The whole method is clearly presented and, overall, easy to understand.
Good results. Authors compare their methods with some existing SOTA methods and show better performances."	"The proposed method focused on unsupervised learning, which gets rid of paired training data.
Splitting the images into content space and resolution specific space seems reasonable.
Eventuating on two different modalities is a strong point."
530	ULTRA: Uncertainty-aware Label Distribution Learning for Breast Tumor Cellularity Assessment	The claimed contributions are original. The concept of learning distribution of labels along with fusing multiple augmentations to mimic clinical uncertainty is very powerful.	The main strength of this work goes to the novel idea. Considering the uncertainty of TC score, authors transfer the regression problem to a label distribution learning problem. They use normal distribution to model the uncertainty of the given TC score and train a multi-branch DNN to fit the normal distribution for TC score prediction.	"interesting clinical problem
simplicity of the method"
531	Uncertainty Aware Sampling Framework of Weak-Label Learning for Histology Image Classification	The methodology seems correct and it's interesting. The paper is clear and easy to follow.	"-Simplify. The models for training are all basic convolutional neural networks. It is easy to implement. 
-The improvement is significant. The two-stage training strategy delivers significant accuracy improvement for histology image classification to the baseline the authors defined."	"Uncertainty estimation with Bayesian neural networks is a powerful tool in medical image analysis, which this paper uses to select highly informative samples from otherwise weakly labeled WSI. The method is straightforward and the experimental results suggest its effectiveness.
I appreciate the use of statistical tests to show the significance of the results. This should become the standard in medical imaging with deep learning."
532	Uncertainty-aware Cascade Network for Ultrasound Image Segmentation with Ambiguous Boundary	"The motivation and innovation of this work are good.
A novel recurrent edge correction module (RECM) adjusts the low-confidence pixels based on the neighboring high-confidence pixels to decrease the weights of the indistinguishable features."	"1) The proposed components seem reasonable and relevant to clinical practice.
2) Extensive experiments were conducted to show the effectiveness."	"The overall structure is clear and informative.
The experiment is comprehensive and the compared methods are new and related.
The performance is good with in-depth discussions.
The method is novel which utilizes multiple forms of uncertainty to enhance feature sharing and embedded in a cascade network."
533	Uncertainty-Guided Lung Nodule Segmentation with Feature-Aware Attention	"The is technically sound.
The observation that areas of uncertainty and disagreement between radiologist correspond to different tissue density when compared to the areas where agreement can be found is clever.
The statement that disagreements are not random and therefore can be modelled is interesting
The authors provide ablation studies
The number of other approaches used for comparison is sufficient"	The paper is in a good format and is easy to understand.	"The paper is well organized and easy to read.

The paper has interestingly found that uncertainty is associated with certain HU distributions in ambiguous regions. As the HU value relates to the tissue's density, the authors take advantage of the uncertainty in the HU value and guide the segmentation network to learn from the uncertainty to generate better results on the edges and ambiguous regions.

The attention module by integrating the multiple annotations is novel. The proposed network takes all annotations in training as well as includes intersection and union to enrich the attention on the uncertainty regions. As the state-of-the-art methods focus more on automatically learning the variance with VAE, this paper provides an alternative method to focus on the uncertainty region. "
534	Undersampled MRI Reconstruction with Side Information-Guided Normalisation	"This paper is novel and addresses an important area of research in the field to further improve image reconstruction accuracy.
The proposed formulation is sound and experiments are solid."	"(1) The idea of using side information to improve undersampled MRI reconstruction is novel and interesting. The motivation of the design is also clearly presented. 
(2) The proposed SIGN is simple and effective. The SIGN module only contains a few embedding and fully-connected layers. They can be inserted in the reconstruction backbones easily. 
(3) The improvement is significant, as demonstrated in the Table1 and Fig.5. 
(4) The paper is really clear and easy to follow."	"The SIGN module is a novel way of providing prior information to the network to improve the learning performance
Solid investigation of the SIGN module by inputting the wrong side information"
535	UNeXt: MLP-based Rapid Medical Image Segmentation Network	"UNext is computationally efficient and performs well for segmentation.
Shifting of feature maps appears novel but is poorly explained and, more importantly, is not well motivated and is poorly validated. It remains unclear what is done, why it is done, and whether it is really a good replacement of positional encoding. It may be a regularizer. Or it may not do much at all."	"The method appears to be novel, pulling in state-of-the-art papers and techniques from ViT and MLP-Mixer which have previously mostly focused on classification techniques.

The motivation is well founded, being able to learn maintain or slightly improve while dramatically reducing the runtime and memory is essential in many applications.

The authors proposed approach achieves slightly improved results over state of the art, but more impressively, it does so with a fraction of the complexity (space and time). Not only are their practical benefits to this, it shows potential theoretical benefits where strong features are able to be learned without needing the massive parameter counts of similarly performing networks.

The experiments and ablations appear to be thorough and show the contribution of each proposed novelty. Further, the authors splitting of the data and inclusion of error bars was very appreciated."	"The efficiency improvement is satisfactory.

The idea of combining ConvNet and MLP-based Network is interesting.

The application is of broad interests (i.e., point-of-care applications)."
536	Uni4Eye: Unified 2D and 3D Self-supervised Pre-training via Masked Image Modeling Transformer for Ophthalmic Image Classification	"The general framework design to adapt to different types (fundus and OCT, 2D or 3D) of ophthalmic data
-Implementation of mask autoencoder is original, as far as I know and efficient 
-Comparison with state-of-the art method is performed
-The authors perform some ablation study, to evaluate the impact of the different components of their architecture (mixing 2D and 3D data, use of two different decoders..)"	"Universality of features: the dataset collected include numerous ophthalmic images modalites and the pretrained model is able to achieve state-of-the-art results on several classification tasks (proposed by different challenges) by fine-tuning, which could make their model a universal pretrained backbone for ophthalmic images features generation and a variety of downstream tasks. 
New large public ophthalmic images dataset: authors collected and created a dataset that will be made publicly available containing a wide variety of ophthalmic images modalities as well as 2D and 3D images (although missing some description on the contribution to the data collection)."	"The paper is well-orgnaized.
The evaluation is complete and thorough.
The authors contributed what they claimed to be the  largest ophthalmic image dataset."
537	Unified Embeddings of Structural and Functional Connectome via a Function-Constrained Structural Graph Variational Auto-Encoder	"-The idea is very interesting, which combines the functional and structural connectomes of individuals to inferences about their differences.
-The methodology is explained beautifully, albeit it could be improved."	The author proposed a novel application of graph variational autoencoder model in incoporating the functional and structural connections and identifying joint embeddings.	"Contributions:
1). It is very interesting to employ an approach of incorporating function-constrained structural graphs from both functional and structural connectome in an unsupervised fashion to generate a variational graph autoencoder.
2). In this work, the authors provide a comprehensive experimental study and hyperparameter tuning."
538	Unsupervised Contrastive Learning of Image Representations from Ultrasound Videos with Hard Negative Mining	"The paper is well-motivated with good writing. They propose a novel hard negative mining strategy from the prior knowledge of USG videos, which is quite reasonable.

The paper release a large-scale USG video dataset.

The proposed contrastive learning method suppresses both ImageNet and SOTA contrastive learning based method."	"The paper is clearly written, and easy to understand.
The dataset is a contribution to the community.
The intra-video hard example mining mechanism is interesting and looks effective."	"I think the idea of hardness-sensitive negative mining curriculum learning is novel.
The authors performs evaluation against a wide range of baseline methods, 10-fold cross-validation is reported.
Ablation study is performed to demonstrate the contribution of proposed components.
The USG image datasets related to GB malignancy can be useful for future study.
Expert radiologists are involved in this study."
539	Unsupervised Cross-Disease Domain Adaptation by Lesion Scale Matching	"1)	Identified the problem of knowledge transfer between two different diseases.
2)	proposed a lesion scale matching approach by searching for bounding box size in latent space together with the Monte Carlo Expectation Maximization"	"The paper addresses a critical important problem that may be of help in other similar scenarios for cross-disease transfer of knowledge;
The paper propose an original approach, with clear methodology and experimental results."	Due to the data limitation in medical domain,  this work holds a valid and practical motivation.  Extensive experiment studies have been conducted.  Especially how the scale disparity affects the estimation accuracy in target domain which address the key argument in this work.
540	Unsupervised Cross-Domain Feature Extraction for Single Blood Cell Image Classification	The idea is interesting and might contribute towards building generalized models for wbc classification.	"Novelty: although the authors employed some well known methods (Mask R-CNN), the proposal contains novelty characterisation, because it attempts to perform a cross-domain feature extraction based on instance features of a Mask RCNN.
Experimental evaluation: The authors exploited three very different blood cell data sets and the two tables show precisely the results obtained, which I consider to be of great interest to the community in this specific task."	"The workflow of the proposed method is interesting, which combines self-supervised learning and domain adaptation.
Using feature from the Mask R-CNN is smart as the object detection algorithm is pretty robust.
The writing is very clear."
541	Unsupervised Deep Non-Rigid Alignment by Low-Rank Loss and Multi-Input Attention	The main strength of this work is that inspired by robust alignment by sparse and low-rank decomposition (RASL), the authors introduce a low-rank loss in current registration network to deal with the images with noises or corruptions.	"The paper is well organized and written.
Considering the actual problems in photoacoustic microscopy imaging, a complete pipeline is designed for multi-scaning pam images alignments."	"Main philosophy of the paper is novel and make sense. Compare to previous robust image alignment algorithms, proposed method has following advantages: (1) it could handle non-rigid transformations, (2) since it is NN, we could generalize for dataset. And compare to previous NN based image alignment methods, it is robust since it decomposes sparse noise and corruptions from the data.
It could handle non-rigid alignment where severe noise exist, it could be potentially used in pratice."
542	Unsupervised Deformable Image Registration with Absent Correspondences in Pre-operative and Post-Recurrence Brain Tumor MRI Scans	"1 Pre-operative and Post-Recurrence Brain Tumor registration is an important research area.
2 The proposed strategy is sound"	"The paper is very well structured and easy to follow
The method is well classified into the state of the art
The novel approach of estimating regions without correspondences is very interesting and well embedded into the overall approach
No segmentations (e.g. of tumors) needed
Strong evaluation with several compared algorithms (both conventional and deep learning based)"	This work addressed the unsupervised deformable registration method for the preoperative and post-recurrence brain MR registration and tumor segmentation.
543	Unsupervised Domain Adaptation with Contrastive Learning for OCT Segmentation	"The paper is easy to follow and well organized.
Utlizing the adjacent slice to be the positive sample is interesting and reasonable.
The ablation studies is exhaustive and improve a lot compared with the baseline methods."	I find this paper interesting, especially application of the contrastive learning to the problem of the domain shift between OCT devices. The method seems to be well-motivated, novel to some extent, as the majority of the methods focus on adversarial domain adaptation, and validated.	The paper is well written and clearly structured. The method and the performed experiments are described in detail. The evaluations, comparison to SimCLR and SimSiam, as well as the ablation study are sound. The presented method  can outperform existing frameworks on the given dataset for the segmentation task. While the contrastive framework is well known, the novelty lies in the combination of the adapted contrastive loss, the augmentation strategy, and a new projection head. The supplementary material also includes a hyperparameter analysis.
544	Unsupervised Domain Adaptive Fundus Image Segmentation with Category-level Regularization	"The global distribution matching via adversarial learning cannot align subtypes or subcategories efficiently, and thus the authors proposed category level regularization approaches to align categories.
The authors proposed the novel formulations alongside the extensive experimental results including the ablation study."	The method section is well explained.	"Different from previous global distribution alignment, category information is also considered in this work.
It solves UDA from both intra-domain and inter-domain perspectives."
545	Unsupervised Lesion-Aware Transfer Learning for Diabetic Retinopathy Grading in Ultra-Wide-Field Fundus Photography	"The proposed method does not require ground truth labeling of UWF images. Instead, it takes advantages of existing labeled dataset of narrow-field images.
The ablation studies validate the effectiveness of the proposed modules."	"The paper is well written.
The paper performed a lot of experiments including relevant ablation studies.
The results are better than the other methods."	"Large number of CFP involved in training
Usage of CFP pixel annotations, not just labels
Attempts to generally adapt/transfer rarer (UWF) features into more common (CFP) features"
546	Unsupervised Nuclei Segmentation using Spatial Organization Priors	"The way to leverage spatial organization prior between HE and IHC images is interesting and shows good performance.

The experimental details are clearly described.

Ablation studies show the effectiveness of different components."	"Unsupervised segmentation is a challenging problem. This paper present a working system for this task.
The experiment is extensive and sufficient."	"novel unsupervised method
stain independence
good results on 3 datasets in comparison with SOTA methods
good results with nuclei and membrane staining images"
547	Unsupervised Representation Learning of Cingulate Cortical Folding Patterns	This work tackles a challenging task: encoding cortical folding patterns and using the latent layer features to represent and cluster cortex in a unsupervised manner. Adding a decoder to the methods of SimCLR and b-VAE helps to recover folding patterns.	"The topic is novel, important, and quiet significant in neuroscience.
The paper is clear, easy  to follow."	The research topic of exploring cortical folding patterns of human brains is novel and of great importance.
548	Usable Region Estimate for Assessing Practical Usability of Medical Image Segmentation Models	The paper is clearly organized and easy to follow. The problem of model usability is a major concern in medical machine learning that is not adequately addressed in current literature. The idea of combining usability with accuracy in a single metric can potentially be highly useful in real implementation of machine learning models in healthcare.	"(1) The paper is generally well-written and easy-to-follow;
(2) The paper successfully identified the limitations of current model evaluation and selection pipeline, and propose a novel quantitative measure that is more concrete and practicable."	extended experiments on different  clinical  applications
549	USG-Net: Deep Learning-based Ultrasound Scanning-Guide for an Orthopedic Sonographer	To attempt to remove the need for IMU signals simplifies the setup and allows use of this approach in existing clinical pipelines, with minimal changes.	"The paper is well-writen following the structure of Dataset construction, USG-Net Architecture, Loss function.
The contributions are clear: A deep learning-based scanning-guide algorithm that guides to the exact target diseased region.
The Dataset is constructed and the automatic dataset construction method to train the deep learning-based scanningguide network is summarized."	"Clinical Relevance: User dependence in the acquisition of 2D US images is a consistent and clinically relevant challenge. This also extends to sonographer training, which could be a potential application of this work.
Experiments and Results Section: The results presented are quite thorough and clearly described, including an ablation study."
550	Using Guided Self-Attention with Local Information for Polyp Segmentation	The main strong point of this paper is combination of transformer and CNN/. For long capture of features, they utilize the transformer. The authors achieved very high scores in several datasets	(1) A novel self-attention block that encourages the model to focus on high-confidence region, which potentially improves the quality of attention; (2) A bottom-up two-stage self-attention strategy for better capturing local context. Both the two techniques are shown to improve the performance.	"The method presented in the paper is well explained and the design decisions are well justified. It mixes modern techniques from other works that leverage both attention mechanisms and CNNs to design a novel architecture and blocks that achieve results that seem considerably improve the state of the art.
The paper is well structured and complete, and the motivation and challenges are clearly described.
The quantitative evaluation is thorough and suggests significant improvements over the state of the art for multiple relevant datasets."
551	USPoint: Self-Supervised Interest Point Detection and Description for Ultrasound-Probe Motion Estimation during Fine-Adjustment Standard Fetal Plane Finding	"The paper organization and writing are clear. The figures are also well made and helpful. I can well understand the proposed method.
The end-to-end pipeline involving several stages is interesting and intuitively should be more generalizable to unseen cases compared with a regression-based pose estimation method. Additionally, the proposed pipeline is explainable, and developers could look into the different stages of the pipeline to figure out the source of errors if degraded performance were to be observed in practice."	"The method proposed by the authors seems fairly new for US imaging. The direct regression methods (of motion parameters) perhaps don't work well for subtle motions as described here. Essentially the direct regression method is trying to equally optimize for all points in the image (including many noisy, non-informative points), whereas here, it'd learn to optimize only for a select key interesting points. So this sort of approach provides an alternative in these situations.
The method doesn't require annotated keypoints/segmentations for interesting point generation, which is great.
Visualizing the keypoints and their matches is a great way to interpret whether or not the method is working - so this is bonus explainability.
The data used for training/testing is quite thorough."	"Very good novelty in using graph network and SVD alongside the learned features.
Good Novelty.
Strong fondation
compelling results"
552	Vector Quantisation for Robust Segmentation	"Vector Quantization has been widely used in Speech Disentanglement and Image Generation. The paper provides a novel formulation of incorporating a discrete bottleneck (VQ) in a segmentation framework for increasing the robustness(noise perturbation of the input as well as domain shift in the datasets) of the trained model.

Thorough experiments have been performed to justify the claim in both binary and multi-class settings.

Perturbation study of the latent space corroborates the robustness claim.

Provides a simple bound on the amount of perturbation needed to change the output of the quantization block."	This paper introduces vector quantisation, a method proposed in the generative model , i.e., VQ-VAE, into the U-Net architecture to improve the robustness of the segmentation model. The author shows that vector quantisation of latent features could effectively solve the domain shift and noise perturbations in the input space.	"Vector quantization of the low dimensional space has been shown to be promising in many areas and I think it is not too popular in medical image segmentation.
Strong evaluation: various datasets, two metrics, and two ways to measure the robustness against variance: 1) via adding noise (Section 3.3) and 2) by testing on data from a different domain (Section 3.2)."
553	Video-based Surgical Skills Assessment using Long term Tool Tracking	The paper is generally well written. The fact that the proposed method only needs the surgery videos makes it applicable in a wide range of surgical settings. Testing the proposed methods on real surgery (not dry lab exercises for example) is another strength of this paper.	As far as my knowledge, this paper proposes new ways to track and assess surgical tools in a video sequence. At least in the field of surgical tracking and surgical workload the proposed algorihtms are innovative and provide good results (vs. bytetrack that is not specifically designed for this purpose).	"The abstract is clear and well written.
The motivation for the work is clear and matches the goal provided in the abstract. The requirement of automated skills assessment and what those typical skills consist of are clearly mentioned.
The novelty lies in the new tracking algorithm for generating a cost function and track recovery method based on the Hungarian algorithm.
There is a potential of extending the public Cholec80 dataset with spatial labels if the used annotations are made public."
554	Vision-Language Contrastive Learning Approach to Robust Automatic Placenta Analysis Using Photographic Images	"The authors introduce contrastive learning to reduce the data scarcity on placenta images.
The authors build up the placenta datasets with different modalities, which will benefit the community in this research area.
The authors address the feature suppression problem in VLC approaches to improve generalizability and robustness."	"I think the VLC framework used here is reasonably novel, particularly as it is applied to placenta analysis.
The new loss function introduced is also novel, particularly in the context of the VLC task
The results are strong - and the new loss function seems to give better results."	"The paper is easy to follow.
The state-of-the-art in the problem is well-mentionated and the proposed method is well justified.
The idea of stabilizing feature importance using the hyperbolic cosine is interesting and it deserves further exploration in various multimodal clinical scenarios.
The evaluation in placental pathologies highlights the model's usefulness."
555	Visual deep learning-based explanation for neuritic plaques segmentation in Alzheimer's Disease using weakly annotated whole slide histopathological images	"The authors propose a deep learning framework for plaque segmentation in brain WSIs.
The authors explore the interpretability and explainability of the deep features.
Integrates domain knowledge in the segmentation method.
The observations and the dataset provided can be helpful to improve the AD study wrt plaques.
The proposed method shows interesting application for quantitative estimation of plaques."	This paper uses deep learning to analyze AD tauopathy which has been rarely explored.	"A baseline for neuritic plaques is established;
The expert annotated database is released as well as the code."
556	Visual explanations for the detection of diabetic retinopathy from retinal fundus images	"Authors attempt to address the dilemma: a plain model usually has better prediction accuracy but less reliable visual explanations; in contrast, an adversarially robust model has more reliable visual explanations but suffers from dropped accuracy. The authors propose a simple ensemble model (Equation 2) to maintain high accuracy and improved visual explanations simultaneously.

The ensemble model can also generate a saliency map by the difference between visual counterfactual explanations and the original image, which can serve as a complementary method to existing saliency-based techniques."	The authors propose an ensemble model (including an adversarially robust model) to mitigate the trade-off between classification performance and quality of visual explanations. That makes sense since sometimes a good performance results from spurious correlations in the data, and is not driven by clinically-supported evidence. Improved saliency maps show precisely that models become more robust.	The strength of the model is the clear prediction regarding ensembling traditional and adversarially-learnt models and what the effect would be on accuracy and interpretability. This hypothesis is largely supported by the data, although with a lower robust accuracy than expected (i.e. the ensemble models seem to err on the side of the traditionally-learnt models).
557	vMFNet: Compositionality Meets Domain-generalised Segmentation	The idea of using vMF kernels is novel and interesting, and has not been well explored in the fields of medical image processing. This provides an alternative perspective of decomposing image into style and content as in traditional disentanglement approaches. Besides, this paper conducted a strong evaluation by comparing against the state-of-the-art domain generalization methods in the semi-supervised setting.	"The idea of modeling compositional components using vMF kernels has not been explored for domain generalization. Although inspired by [20], the application setting of the proposed method differs from this previous work.

Experiment on M&M and SCGM show clear advantages compared to recent baselines for domain generalization.

The extension of the method to test time adaptation adds depth to the paper."	"This is the first time that I have seen use of concepts from the compositionality literature in medical image segmentation + domain generalization papers. In principle, I agree that the notion of compositionality might play an important role in helping us build more robust algorithms. Kodus to the authors from bringing up this topic - I am confident that this will of high interest to the community.
Strong evaluation for domain generalization. Usage of multiple datasets and anatomies.
Extremely clear writing and overall presentation."
558	Vol2Flow: Segment 3D Volumes using a Sequence of Registration Flows	The paper is well-written and organized. The experiments is sufficient.	The volume segmentation problem is addressed busing slice-wise image registration. Only one slice needs to be annotated to segment the whole volume in test time.	The paper presents an approach for semi-automatic segmentation, combining ideas from self-supervised learning and registration. It builds up upon Sli2vol algorithms to take advantage of a global 3D context.
559	Warm Start Active Learning with Proxy Labels & Selection via Semi-Supervised Fine-Tuning	The manuscript deals with an interesting research topic, i.e., how to select samples for being labeled by the user. The manuscript is well written (primarily). The main idea is to use a self-supervised approach to pseudo-label the data. Then, a fully supervised training procedure takes place for further fine-tuning under a semi-supervised learning framework. That final model is used to select data for annotation. Pseudo labels are created by thresholding and other standard image operators. The proposed approach is good as well. Several and different concepts are used to compose the final methodology.	The proposed method is simple and straightforward. The results from the figures are strong, meaning at least one setting is outperforming the baselines.	"Use of uncertainty from some proxy task to tackle cold-start problem is an interesting take of the problem.
The build up of method from initial to no labels to using unlabelled data to select for annotation is applicable to many medical image data in clinical setting.
Extendability to other tasks - Changing the pseudo label process and proxy task could help implement the same method to other medical image modalities."
560	WavTrans: Synergizing Wavelet and Cross-Attention Transformer for Multi-Contrast MRI Super-resolution	"Technical contribution. While the proposed method builds on existing building blocks, I think it is sufficiently novel.
Extensive comparison with chosen state-of-the-arts methods
Extensive ablation study demonstrating the advantage of the proposed contributions
Code has been provided in the supplementary material"	The paper presents a novely way of synergizing wavelet with swin transformer to obtain super-resolution images from multi-contrast MRI. The ideas proposed are interesting and the obtained results have been compared to various recent methods with an improvement over all of them.	"The proposed WavTrans method outperformed the state-of-the-art multi-contrast SR reconstruction methods. 
This study provides a potential direction for further research into the processing between multi-contrast images for MRI super-resolution.
The paper is well organized  and the experiment is credible."
561	Weakly Supervised MR-TRUS Image Synthesis for Brachytherapy of Prostate Cancer	"The author collected a dataset and carried out detailed experiments on this basis.  Compared with the baselines, the performance of the proposed method is much improved.
Prostate Contour Segmentation and MRI Pattern Exaction contribute to realize the weakly supervised learning for DCLGAN."	The method for synthesizing US images from MRI images is novel, the application has significant clinical value. Comparison and evaluation of the results are provided.	"The proposed method creatively constructs the style transfer architecture upon a generative adversarial network based on cycle consistency. Particularly, the discriminator classifies the real and synthetic MR images, TRUS images, MR prostate contours, segmentation of tiny anatomical structures of prostate.
Adopt weakly supervised learning to alleviate the requirement of paired data for training, which is usually too challenging to have segmentation masks on MR Images."
562	Weakly Supervised Online Action Detection for Infant General Movements	"1) Detailed and accurate mathematical modeling of the three introduced modules (local feature extracting, clip-level pseudo labels generating, and online action modeling)
2) Learning without frame-level annotation
3) Showing the same performance by reading 20% of the video as if the system had read the whole video"	As the authors argue, the development of automated FM action detectors for early medical interventions for cerebral palsy in infants is important. The authors designed a 2D key point estimation-based WO-GMA in a trainable form by appropriately borrowing the ideas of [7] and [19], which are used for natural vision. Although the authors did not evaluate the clinical effect of the FM action detector, the performance of the detector itself was adequately compared with other SOTA models.	"The strengths of the paper are as follows.

The application is novel. The applications for infant general movements are rare compared with segmentation of organs or image classifications. As a reviewer and a reader, I would like to read new applications which can broaden my horizon.
The techniques used in this paper are reasonable. By using the weakly supervised method, the annotation cost can be cut and the whole diagnosis time could be accelerated.
The paper is well-organized and easy to follow.
The experimental results are convincing. The authors evaluated the proposed framework on a relatively large dataset. And the methods used for comparison are all recent works."
563	Weakly Supervised Segmentation by Tensor Graph Learning for Whole Slide Images	"*	The authors proposed an interesting approach that combines different techniques and ideas, including such as learned and hand-crafted features, neuronal classifiers and graph classifiers. 
*	The paper is generally well-written and good to understand, I really enjoyed reading it. (Although there is still room for improvement)
*	The authors indicate that they will release the source code of the paper. This, and the fact that the data is public lead to reproducible results."	The method seems to be novel with a complexed setting. The results of the proposed method are better than the baselines.	Please see below
564	Weakly Supervised Volumetric Image Segmentation with Deformed Templates	"Interactive approaches are undoubtedly the correct tool to get large amounts of data annotated.
The paper experiments on multiple images from multiple modalities.
Results seem good even though they limited in number
The method is relatively quick considering it works in 3D"	This paper is well written. The idea of using deformable templates and self-supervision together to address the weakly supervised segmentation is quite novel.	An interesting idea, proposing a method requiring only sparse point annotations to supervise the training.
565	Weakly-supervised Biomechanically-constrained CT/MRI Registration of the Spine	The paper is well written and organized. The results support the main hypothesis of the paper.	"1, Authors introduced a new anatomy-aware losses only depended on the CT vertebra segmentation to improve the CT-MRI deformable registration. The idea is interesting to let the warped label be similar to its regid transform. Besides, using only one sgemtation map to calculates loss function is innovative since that segment vertebra from MRI is not as easy as segment that from CT. 
2, Another loss that force the deformation fields to be regid in bone region is also a good try."	The introduction of the novel rigidity loss terms.
566	Weakly-supervised High-fidelity Ultrasound Video Synthesis with Feature Decoupling	"Generating video from static images for US procedures that can be used for training junior medics.
Considering the effect of deformation and occlusion in the design and using a discriminator to increase the quality of the final video."	"The paper is clear and well-organized. The embedded demo is helpful for understanding the task and observing the results.
Unsupervised image animation is currently a popular topic in general cv domain, but it is indeed less-explored in the medical domain due to some realistic issues such as noises and varying sizes as mentioned in the paper. Accordingly, the authors resort to a weekly-supervised approach for motion transfer, which is more suitable for more complicated medical problems, and could be generalizable to other tasks.
The proposed framework has a two-branch architecture to learn content and texture separately. I think it is an interesting idea and could have the potential to help better understand the motion transfer process."	"Introduce the animation generation techniques to medical image analysis. The major framework is from existing methods but this is a good application.
Achieve good video quality. The video quality is measured by quantitative, qualitative and user study."
567	Weighted Concordance Index Loss-based Multimodal Survival Modeling for Radiation Encephalopathy Assessment in Nasopharyngeal Carcinoma Radiotherapy	For the first time, both image and non-image data were used in an NPC radiotherapy regimen to predict radiotherapy-induced REP. A deep multimodal survival network (MSN) with two feature extractors is designed to learn to identify features from multimodal data. One feature extractor performs feature selection on non-image data, and the other learns visual features from images. A new weighted CI (WCI) loss function is proposed, which allocates different weights to all representative samples through a double averaging operation, thus effectively utilizing all representative samples. A temperature hyperparameter is introduced to sharpen the risk differences in sample pairs and help the model converge.	"The author propose way to use multi-modality data from both images and non-image data is new to this task.
The proposed WCI loss is helpful to alleviate data imbalance issue and improve the accuracy."	"The strengths of this paper include:

Large number of subjects available for training and testing.
Combined use of image and non-image data.
Use of survival analysis methodology and loss functions to train model.
Inclusion of ablation to examine empirically derived parameters such as weights for image versus non-image risk outputs to final output and temperature parameter used for WCI loss function."
568	What can we learn about a generated image corrupting its latent representation?	"This paper is well written and easy to read.
Sufficient experiments.
The results are described and analyzed in details"	"Noise injection is easy to use in deep learning models, such as GANs;
Conducting pre-experiment to observe that noise injection can identify uncertainty parts;
Carried on adequate experiments including image translation and downstream tasks."	"Easy to read. The idea presented in this paper is very clear and easy to follow.
The experiments are solid
The idea presented in this paper is somehow novel and can provide insights in medical imaging. Becasue the uncertainty estimation method is unsupervised, which make it value in medical imaging domain considering that most datasets cannot provide proper label."
569	What Makes for Automatic Reconstruction of Pulmonary Segments	"The topic is interesting and can provided useful info for the surgical treatment
The ImPulSe network have the potential to generate high resolution output when the input resolution is low."	"The strengths of the paper are:

Extremely well written.
Very good problem statement.
Thorough analysis of the problem."	"The paper makes the pulmonary anatomical segmentation further, from lobes to segments. 
The method will benefits for clinical applications, like surgical planning for patients with lung cancer. 
The method ImPulSe achieves better performance comparing to fully-convolutional methods."
570	White Matter Tracts are Point Clouds: Neuropsychological Score Prediction and Critical Region Localization via Geometric Deep Learning	"The proposed point cloud based analysis is innovative and provides additional spatial information compared to other fiber representation methods.
The proposed WCRL algorithm identifies critical areas that are both consistent across subjects and with previous research regarding language performance as measured by TPVT scores.
The results hint that the presented approach might yield more information and thereby enables better predictions, but this is not confirmed using statistical tests."	"Looks like this is the first work to predict individual cognitive performance based on microstructure measurements of the white matter fiber tracts.

- Overall, the paper is well written, and the experiments are well designed.

Also, this work shows some promising results and is good for clinical application."	"The idea of using deep point-cloud network for neuropsychological score prediction is new.
The proposed paired-Siamese cost for training the network seems an interesting formulation.
The proposed method outperforms traditional methods, and it does not require a very deep architecture, making its interpretation easier.
The proposed critical region localization algorithm effectively detects the regions relevant to language processing."
571	Whole Slide Cervical Cancer Screening Using Graph Attention Network and Supervised Contrastive Learning	A novel formulation that uses graph attention network and supervised contrastive learning in whole slide cervical cancer screening.	The study objective is interesting as the authors worked on cervical cancer screening. The manuscript has been structured properly. Comparative analysis showed that the proposed approach outperforms the existing approaches.	"(1) Two graphs of the top-K and bottom-K patches are built to describe relationships between suspicious patches.
(2) Loss function is designed based on cross-entropy loss and supervised contrastive learning. Thus, the latent distances for positive WSIs are enlarged, while the latent distances for negative WSIs are reduced."
572	Why patient data cannot be easily forgotten?	This is an interesting topic and challenging problem from a machine learning perspective. The paper provides good arguments and a sensible approach for patient-wise forgetting.	"This paper addresses an important aspect of AI in healthcare applications, and is of great interest to the MICCAI community.
The paper is well-written, well-structured and easy to understand.
The distinction between common cluster data and edge case data seems to be important and the comparison between computer vision and medical datasets is very interesting and relevant.
In general, the results and conclusions in this paper are convincing and relevant."	Intuitive approach to the patient forgetting problem. Albeit the empirical validation issues that are highlighted later, the proposed idea (separation of patients in common and edge cases) is intuitive and has the potential to be a useful contribution to the field once properly validated.
573	XMorpher: Full Transformer for Deformable Medical Image Registration via Cross Attention	"This work extended the Cross Attention Transformer (CAT) for communication
between a pair of features from moving and fixed images, promoting the features matching for image registration."	The idea is fine, and their experimental result shows the proposed method is efficent.	The concept of dividing XMorpher into feature extraction part and correspondence matching part using Transformer framework is valuable. The proposed CAT block advances the feature communication between the fixed and the moving images in a multi-level semantic scheme. The results show the improvement of efficiency and accuracy of the XMorpher.
574	Y-Net: A Spatiospectral Dual-Encoder Network for Medical Image Segmentation	"-- The main idea of the paper to combine both the spectral and spatial features extracted from the OCT volumes for segmentation tasks.
-- The authors present the dice for the proposed method in relation to the results on public dataset.
-- Ablation study on different setting of the proposed framework strengthens the method.
-- The paper is well written and easy to follow."	The paper seems to be orgainized well. And all training details are well adressed.	-The paper is well written and organized.
