id	title	review1	review2	review3
001	3D CVT-GAN: A 3D Convolutional Vision Transformer-GAN for PET Reconstruction	This paper aims to reconstruct standard-dose PET (SPET) images from low-dose PET (LPET) images, via a  3D Convolutional Vision Transformer GAN (3D CVT-GAN), which extends the 2D Convolutional Vision Transformer under the framework of 3D Transformer-GAN, with the extended 3D CVT and TCVT blocks equipped into both generator and discriminator of GAN.	The paper proposed a 3D convolutional vision transformer-GAN model for low-dose PET synthesis.	This paper proposes a novel 3D convolutional vision transformer GAN framework to reconstruct standard-dose PET image from low-dose PET image.  Specifically, they utilized 3D CVT blocks as the encoder for feature extraction and 3D transposed CVT as decoder for final SPECT reconstruction. Furthermore, the proposed 3D CVT and TCVT blocks employ 3D convolutional embedding and projection instead of using linear embedding and project which overcomes the semantic ambiguity problem.
002	3D Global Fourier Network for Alzheimer's Disease Diagnosis using Structural MRI	The paper proposes a deep learning model for Alzheimer's Disease Diagnosis from MRI images which works in the Fourier domain.	This paper proposes a 3D Global Fourier Network (GF-Net) to utilize global frequency information in predicting the Alzheimer disease (AZ). Authors used exist techniques to show the importance of frequency filter by comparing to other techniques in predicting the AZ.	This paper proposed to utlize the Fourier transformation to catch the global information to improve the AD diagnosis, so-called GF-Net. It divides each image into several patches to meet the patch embedding operation and use a sequence of global Fourier/ inverse Fourier transform with element-wise multiplication to capture global information in the frequency domain. Multi-instance learning (MIL) strategy is utlized to randomly drop patches to augment samples for training.
003	4D-OR: Semantic Scene Graphs for OR Domain Modeling	This paper proposes to represent the OR via semantic scene graphs to achieve a holistic understanding. A new 4D-OR dataset is constructed and will be made public. Several state-of-the-art computer vision methods are pipelined and tested on the new dataset.	"This paper presents a neural network-based approach to generate semantic scene graphs of the activities happening in the OR during a surgical procedure. The principal goal of the proposed approach is to accurately predict the role of every human present in the OR.  A quantitative evaluation is performed on a dataset composed of simulated total knee replacement surgeries recorded with six RGB-D cameras, with annotations of human and object poses, SSG labels and clinical roles. The authors propose to make this dataset public, which can be a big contribution to the field.
A complex methodology is presented to process the images and point clouds, and also to automatically obtain human and object pose information using off-the-shelf approaches, and then generate an SSG to be able to predict the role of everyone in the scene. The approach achieves good performances especially for patient and head surgeon role prediction."	The paper tackled the problem of understanding surgical scenes. It proposed semantic scene graph to construct a holistic knowledge of the operating room. The paper generated a multi-view dataset and relied on state of the art model to detect 3D human and object poses. These were then used to build a scene graph and predict roles.
004	A Comprehensive Study of Modern Architectures and Regularization Approaches on CheXpert5000	"The paper presents a methodical study of modern architectures applied to a fixed low data regime of 5000 images on the CheXpert dataset. Specifically, it studies the BiT and ViT models through experiments, as well as established regularization methods Mean Teacher and MixUp. These are compared to the well-known and frequently used ResNet50 architecture. They find that models pretrained on ImageNet21k achieve a higher AUC and larger models require less training steps. All models were quite well calibrated and performed well. Regularization of Bit-50x1 with MixUp or Mean Teacher improves calibration and accuracy. Vision Transformer achieve
comparable or on par results to Bit-50x1."	The general computer vision literature is moving towards larger models pretrained on increasingly larger scale datasets, much larger than ImageNet-1K which is still the standard approach in medical imaging. Although the role of transfer learning has been repeatedly questioned, recent results support this widespread practice especially when the size of the target dataset is small, and when using architecture with weak inductive priors such as transformers [1]. In this paper, the authors experimentally evaluate the performance of Big Transfer Model (ResNet50, BiT50 and BiT-101) and Visual Transformers (DeiT and ViT) pretrained on ImageNet-1K, ImageNet-21K and JFT when transfer learning to the medical domain. They experiment on CheXpert downsampled to 5000 images to focus on the small data regime. Results show that BiT outperforms ResNet50, and show the advantage of ViT over DeiT, which is inline with previous results  [1].	The authors conduct an extensive set of experiments to demonstrate the feasibility of large-scale transfer learning on chest x-ray classification.
005	A Deep-Discrete Learning Framework for Spherical Surface Registration	"Deep neural nets-based surface registration
Reshaping existing methods to a CNNs framework
Validation on a large dataset with other spherical registration methods"	This paper proposes a deep learning framework for registration on a sphere. The problem is framed as a discrete matching problem - where each control point on a sphere is assigned a label corresponding to one of a possible set of displacements, with regularization by a conditional random field network. The approach is evaluated in a large dataset of brain surfaces against both deep learning and conventional algorithms, and has competitive performance.	This paper presents a learning-based pipeline to co-register two Cortical surfaces using spherical representations of the surfaces. Followed by a learned rigid alignment of the surfaces, the author's apporach includes the successive prediction of displacement fields eventually aligning one spherical surface to the other.
006	A Geometry-Constrainted Deformable Attention Network for Aortic Segmentation	This work is dedicated on the automatic segmentation of the aorta from injected CT-scan using a deep learning approach that is geometry-constrained.	"The paper introduces a geometry-constrained pipeline for the automatic segmentation of the aortic lumen in healthy and diseased cases. 
The diseased cases include coarctations and aortic dissections. 
The proposed method uses geometry-constrained deformable attention which consists of an extractor and a guider. The former generates variable-size patches and, thanks to self attention, captures long-range dependencies."	The paper proposes a geometry-constrained deformable attention network (GDAN) for segmenting aorta. There are two main contributions: morphological constraints and deformable attention mechanism are added to the segmentation network.
007	A Hybrid Propagation Network for Interactive Volumetric Image Segmentation	This is a well written and organized paper that presents a hybrid (two network) approach for interactive, semi-automatic segmentation of 3D medical images.	"The paper proposes a method for interactive segmentation of 3D medical data.
The method uses two modules, 1) a slice propagation network (SPN) for transferring user interactions to adjacent slices and 2) volume propagation network for transferring user hints over the entire volume. The main motivation of using SPN is to avoid having to run a 3D model on whole volume, which would require higher memory usage.
The proposed method improves upon existing interactive segmentation methods."	"This paper introduces a method for interactive segmentation of 3D medical scans.
The pipeline relies on two networks working iteratively on the input volume, the user scribbles and the previous segmentation: one in 3D working on a crop of the volume, and one in 2D that propagates the segmentation from one slice to another.
The former is based on a 3D Unet, while the second one is based on the Deeplab architecture with a memory module that takes as input both the 2D input and the corresponding slice of the 3D feature map of the first network.
The method is evaluated on four segmentation tasks from public CT databases: kidney, tumour, lund and colon."
008	A Learnable Variational Model for Joint Multimodal MRI Reconstruction and Synthesis	In this paper, a learnable variational model is proposed for joint multimodal MRI reconstruction and synthesis. Numerical experiments are performed to validate this method.	In this paper, the authors present a learnable optimization algorithm to jointly do the image reconstruction and image synthesis, the method takes undersampled radial k-space MRI acquisition and outputs the reconstructed image as well as the synthesized third-modality image.	Based on the theoretical analysis, this paper proposes a new deep model, which can simultaneously reconstruct the source modal image from partially scanned k-space MR data and synthesize the target modal image without any k-space information. In addition, the network proposed in this paper adopts the double-layer optimization training algorithm to optimize the network parameters and super Cen book, and a large number of experiments on different modes of brain magnetic resonance data verify the effectiveness of the proposed algorithm.
009	A Medical Semantic-Assisted Transformer for Radiographic Report Generation	"The paper introduces a bilinear pooling-assisted sparse attention block and embed it into a transformer network to capture the fine-grained visual difference existed between radiographic images. It can explore higher-order interactions between the input single-model (in the encoder) or multi-model (in the decoder) features, resulting in a more robust representative capacity of the output attended features; 
2.The  paper proposes a medical concepts generation network to provide enriched semantic information to benefit radiographic report generation;
The paper extensively validates the model on the recently released largest dataset MIMIC-CXR."	First, this paper proposed a memory augmented sparse attention block to capture the higher-order interactions between the input fine-grained image features. Besides, a novel Medical Concepts Generation Network is proposed to predict fine-grained semantic concepts and incorporate them into the report generation process as guidance. At last, this method outperforms multiple state-of-the-art methods on MIMIC-CXR.	The authors propose a medical report generation model using various components such as  sparse nonlinear attention in the transformer, pseudo-medical concepts using RadGraph, and reinforcement learning. This study was evaluated on a MIMIC-CXR dataset, and the importance of each component was justified through structured logic from literature logic as well through experimentation.
010	A Multi-task Network with Weight Decay Skip Connection Training for Anomaly Detection in Retinal Fundus Images	This paper proposed a new encoder-decoder based architecture that uses (scheduled) skip gating (what the authors called weight decay) and multi-task learning with HOG feature prediction. The proposed method has been evaluated on one public dataset for anomaly detection.	This paper explores the applicability of skip connection and multi-task learning to anomaly detection tasks and presents a multi-task encoder-decoder network with weight decay skip connection (WDMT-Net). The authors first design a weight decay training strategy to alleviate the identity mapping problem of U-Net architecture as well as leveraging its strong capacity in feature representation learning. Then they integrate an auxiliary histograms of oriented gradients (HOG) prediction task to the anomaly detection framework for fully exploiting the significant commonalities of normal fundus images. The quantitative and qualitative experimental results indicate the advancement of the proposed method compared with other state-of-the-art method.	In this paper, the author explore the applicability of skip connection to reconstruction-based anomaly detection.Specifically,a weight decay skip connection training strategy is presented to mitigate the identity mapping problem of the U-Net architecture and meanwhile leverage its advantage on feature representation learning. Then, the author integrate an auxiliary task, i.e.,HOG prediction,to the anomaly detection framework, which can fully exploit the significant commonalities of normal fundus images.
011	A New Dataset and A Baseline Model for Breast Lesion Detection in Ultrasound Videos	The authors report on the development of a network for breast lesion detection in ultrasound video clips. In addition, the authors collected and annotated a video dataset consisting of 118 videos for use in breast lesion detection and classification.	The authors focus on DL for breast nodule detection and classification in sequences of ultrasound images. They provide a data set of expert annotated 188 videos. They also design and propose a network using local information of consecutive US frames and shuffled ones, aiming at using both local and global features. The network is well explained. The results are nicely analyzed through a comparative and an ablation study. The authors offer the data set and their code to the community.	This paper presents an empirical study on detection and classification of breast lesions in ultrasound videos by utilizing transformer. The general topic of the paper is very interesting specially in the domain of ultrasound videos. The authors further proposed the release of their annotated dataset upon the acceptance of their work. The paper proposed inter- and intra-video fusion blocks based on attention mechanism prior to transformer block.
012	A Novel Deep Learning System for Breast Lesion Risk Stratification in Ultrasound Images	The paper presents new architecture for training a cancer prediction in breast ultrasound images. This architecture has several key-elements:  (1) dual-task prediction of cancer label (pathology) and the BI-RADS score (radiologist)  (2) teacher-student architecture, with a potentially novel way to derive the soft labels from the teacher's prediction (3) consistency loss on cancer and BI-RADS predictions, as the two labels are usually correlated (4) cross-class loss on BI-RADS predictions, as the 6 BI-RADS classes are ordinal, so the loss depends on the distance from the true class and the predicted class. Evaluation results include comparison to single-task state-of-the-art architectures, and an ablation study.	The paper presents a framework for classifying the BI-RADS score (malignancy risk stratification) as well as true (path-proven) malignancy of breast lesions from ultrasound. The framework uses a teacher-student model, where the teacher provides soft labels to the student. The student is also required to output consistent predictions for BI-RADS and path-malignancy (Consistency Supervision Mechanism), and is penalized more strongly for greater errors (Cross-Class Loss Function). The authors demonstrate this framework outperforms current approaches, which typically train a model to jointly classify BI-RADS and path-malignancy.	The paper presents a novel use of soft-labels to improve the breast lesion malignancy prediction and BI-RADS category prediction. The soft labels are generated using a teacher network which intern trains a student network. Two loss functions are proposed, CSM to enforce consistency between the 2 tasks and CCLF to penalize large deviations in BI-RADS class.
013	A Novel Fusion Network for Morphological Analysis of Common Iliac Artery	This paper proposed a new method for morphological analysis of the common iliac artery. This paper provided a new framework that combines CNN and Transformer, addressing the challenging task of CIA morphological analysis. This paper is the first automatic approach to morphological analysis of the common iliac artery.	The paper proposed a new module Cross-Fusion block and Transformer structure. And the paper designed to provide a new solution for common iliac artery segmentation and morphological analysis tasks.	The authors propose a novel fusion network, combining CNN and Transformer is proposed to address the morphological analysis of common iliac artery issues. The experiment demonstrates that their method outperforms the best previously published results for this task.
014	A Novel Knowledge Keeper Network for 7T-Free But 7T-Guided Brain Tissue Segmentation	The proposed method fuses features from 7T-like images and 3T images to segment brain tissues. As 7T images are not available simply compared to 3T, the proposed method use 7T features without directly using 7T images.	This work proposed a knowledge keeper network to guide brain tissue segmentation by taking advantage of 7T representations without explicitly using 7T images.	The author proposed a novel knowledge keeper network (KKN), trained via KD and KT, to guide and train a brain tissue segmentation model using 7Tlike representations in a 7T-free domain.
015	A Penalty Approach for Normalizing Feature Distributions to Build Confounder-Free Models	The authors propose an alternative optimisation scheme to impose the orthogonality constraint proposed in the MetaData Normalization paper.	This paper proposed a penalty term for MetaData Normalization. Unlike the original linear regression based method, the PMDN learn the projection \beta using a neural network. Experiment shows improvement over the baseline method MDN on several dataset.	This paper proposed a Penalty MetaData Normalization (PMDN) method. PMDN extend the conventional MDN whose performance is confined by the sample size of a mini-batch, by using a penalty method so that the linear parameters within the MDN layer are trainable  and learned on all samples. The results show that the proposed PMDN method can improve the classification performance compared to other four methods.
016	A Projection-Based K-space Transformer Network for Undersampled Radial MRI Reconstruction with Limited Training Subjects	The authors propose a new  deep-network, based on Transformers, to reconstruct  radially-sampled K-space data.	The main contribution of this paper is the projection of k-space and the application of the transformer in utilizing both the real and imaginary parts of the k-space in prediction in the k-space domain.	"o	The paper proposes a method for reconstructing GRASP MRIs by arranging the radial k-space lines as a sequence (in order of acquisition time). This sequence is then fed into a transformer network which outputs the fully-sampled radial k-space as output. Further, the paper explores multiple data augmentation techniques to improve performance. This model obtains superior results compared to previous methods on a small dataset containing scans from multiple anatomies."
017	A Robust Volumetric Transformer for Accurate 3D Tumor Segmentation	This paper proposes a 3D pure transformer architecture, called VT-UNet, for volumetric medical image segmentation. The network can directly work on 3D volumes. The authors design an encoder block with two consecutive self-attention layers for feature extraction and a decode block with parallel cross-attention and self-attention to recover the learned features for segmentation. Experimental results on a large MRI dataset demonstrate its superior performance compared to other baselines. The author also did a robustness analysis to show the VT-UNet is more robust to artifacts.	The paper proposes a transformer architecture for volumetric segmentation with a new design that encodes local and global features. The method obtains competitive performance in BraTS data.	The author proposed a decoder block, which uses one shared projection of the queries and independently computes cross and self-attention. Besides, The author combined a lot of mature and well-known structures, and the performance of the network outperforms other SOTA.
018	A Self-Guided Framework for Radiology Report Generation	They presented a self-guided framework to obtain the potential medical knowledge from text report without extra disease labels. It can assist the network in learning fine grained visual details associated with the text to alleviate the data bias problem.	"*	The paper proposed to use labels from unsupervised clustering of radiology reports to learn visual feature-extractor from medical images. This approach alleviates the need of supervised image-level labels to train the visual feature-extractor. 
*	The learned visual features are then used in a transformer-based caption generator to write the corresponding report.
*	The report generator further used a supervised cosine similarity loss to compare the generated and ground-truth report."	Novel use of mixed image and text based strategies to build robust models that can generate reports without the need for tedious pixel level annotation and image captioning.
019	A Sense of Direction in Biomedical Neural Networks	"The authors propose an interesting convolutional module that combines local rotation and local scale encoding. They build upon [1] and propose three novelties to improve the design of [1]: 
A calibrated Response shaping instead of the response shaping proposed in [1]. 
An additional loss term that promotes the rotational symmetry of the learned kernels by computing a distance from the kernels at different orientations to a set of reference Gabor functions.
An additional module, called index map featurization allows encoding the local scale and local orientation of the input and propagates this information to downward layers.
[1] Liu, Zewen, and Timothy Cootes. ""MASC-Units: Training Oriented Filters for Segmenting Curvilinear Structures."" International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2021."	The paper presents an improvement of the MASC method which introduced computation of oriented filters in CNN networks to detect curvilinear structures while significantly reducing the needed parameters compared to having to learn each orientation individually as in standard CNNs. The main improvements of the method proposed in this paper are a new regularisation function added to the loss which aims at better balancing orientational relationships between kernels as well as integrating pyramid representations to handle responses at different scales.	This paper proposes a network, called G-MASC, to encode rotation and scale into the convolution to adapt the model to vessel segmentation and histology segmentation tasks. This explicit encoding can reduce the redundancy of kernels in traditional CNN, thus largely lowing the size of the network. Information on the direction and scale can benefit the analysis of curvilinear structure, e.g., retinal vasculature, and authors evaluate the proposed model with MoNuSeg, DRIVE, and CHASEDB1 datasets.
020	A Spatiotemporal Model for Precise and Efficient Fully-automatic 3D Motion Correction in OCT	The paper introduces a novel model and an optimization for volumetric distortion correction in OCT. The method allows for performing. It estimates A-scan positions in a single mapping, combined with a forward warping that allows correction in all 3 dimensions while avoiding the need for repeat scans. It also performs parameterization with respect to time, which allows for fully continuous parameters. Finally, by structuring the feasible distortions in OCT, a forward interpolation scheme is utilized, providing more accurate results while requiring less computational time than competing methods	The authors proposed a motion model and a corresponding fully automatic, reference-free optimization strategy for volumetric distortion correction in OCT.	eye emotion during scanning OCT images causes artifacts, This paper, introduce a registration method to compensate 3D-OCT eye motion.  The author claim that their result are promising and improved dramatically  compare to the state-of-art.
021	A Transformer-Based Iterative Reconstruction Model for Sparse-View CT Reconstruction	This paper proposed a novel transformer-based iterative reconstruction model for sparse-view CT reconstruction problem. The authors combined convolution and transformer branches to simultaneously extract local and non-local regularization terms. Besides, an iteration transmission module was introduced to further promote the efficiency of each iteration. The experiment results demonstrated competitive performance in artifact reduction and detail preservation.	This paper proposed a sparse-view CT reconstruction network incorporated with transformer. The proposed network introduced FBP into the iterative schemes instead of back-projection to accelerate the convergence.	"1 combine both local and nonlocal regularizer with neutral networks to achieve general prior.
2 apply IT module to connect the iterations to improve deep feature extraction."
022	AANet: Artery-Aware Network for Pulmonary Embolism Detection in CTPA Images	The authors propose a novel 3D fully convolutional network for pulmonary embolism (PE) detection with artery-aware. An artery context fusion block is embedded in the network to generate artery context to guide PE detection. Even-dice loss is introduced to avoid gradient exploding. The method was evaluated with a public dataset (CAD-PE), and achieved state-of-the-art performance.	The authers proposed an artery-aware 3D fully convolutional network (AANet) that encodes artery information as the prior knowledge to detect arteries and PEs. They developed An artery context fusion block (ACF) generating the context of artery as in-network prior knowledge to guide PE prediction. The methods are evaluated on the CAD-PE dataset with the artery and vein vessel labels which shows good performance.	Clinically, this paper aims at pulmonary embolism detection. Technically, this paper puts forward a way to introduce attention to arteries in the segmentation networks.
023	Accelerated pseudo 3D dynamic speech MR imaging at 3T using unsupervised deep variational manifold learning	The authors pursue improving the spatio-temporal resolution (and image quality) of dynamic speech imaging using a manifold approach to collect 2D slices and time to arrive at a composite 3D volume over time.	The authors propose an unsupervised deep variational manifold learning approach for reconstructing pseudo-3D dynamic speech MRI from sequentially acquired under-sampled (k-t) space measurements of multiple 2D slices. The propose method shows better performance than conventional compressed sensing reconstruction methods in 2 initial subjects.	In this paper, an unsupervised deep variational manifold learning was applied for temporal-spatial fast speech MRI. The experimental results show some subjective superiority of the proposed method over other TV-based methods.
024	Accurate and Explainable Image-based Prediction Using a Lightweight Generative Model	The model presents a Lightweight Generative Model. It is not a deep learning model, and consequently has as its main advantage its linearity and invertibility. The model is illustrated in prediction of age and gender from brain scan images.	The main contribution is a demonstration that an extremely simple Gaussian model for image-based exogenous variable prediction may perform as well or better than far-more-complex peers that have significant disadvantages (larger number of free parameters, lower interpretability), especially when the training set size is relatively small.	The paper proposes an alternative to non-linear discriminative methods for predicting variables of interest such as a subject's brain age from images. The alternative is formulated as a generative model that models the subject's image as a linear function of the subject's covariates (such as age, gender, etc.). This is then used as a likelihood model and a posterior of the variable of interest is constructed for discriminative analysis. To learn the generative model, maximum likelihood method is used and closed form solutions are employed. For tractability of the covariance of the noise matrix (which is underconstrained), the noise variable  is modeled using factor analysis with a smaller latent noise vector. To estimate these new variables, Expectation-Maximization is used. Experiments are performed on the UK Biobank dataset.
025	Accurate and Robust Lesion RECIST Diameter Prediction and Segmentation with Transformers	This work proposes an architecture and set of training objectives for RECIST lesion diameter prediction on DeepLesion data. As in some other works, the architecture involves a convolutional encoder followed by a transformer encoder (with positional encoding). As in prior work, the architecture includes a convolutional decoder path that outputs a weakly supervised segmentation and heatmaps which indicate RECIST diameter keypoint positions. This work proposes the addition of a second decoding path which uses a transformer decoder with a keypoint regression output. Furthermore, this work proposes two consistency losses between the two decoding paths. Ablative experiments show that the transformer encoder is particularly useful (this has been proposed before for other tasks but not validated on this task) and the transformer decoder path with consistency losses yields an additional (though small) gain in performance.	The paper proposes a model for semi-automated RECIST diameter prediction and segmentation. The model is applied in two, consecutive steps, in which the first step aims to predict a rough bounding box, while the second aims to predict a segmentation map, heatmaps for long- and short-axes diameter keypoints, as well as an additional direct regression of these points. The paper evaluates the algorithm on a seemingly manually chosen and annotated subset of the DeepLesion dataset and achieves superior performance in comparison with a variety of other algorithms.	"the authors propose a transformer-based network (Meaformer, Measurement Transformer) for lesion RECIST diameter prediction and segmentation
(LRDPS), which involves three related and complementary tasks, including lesion segmentation, heat map prediction and key point regression. Two consistency losses are introduced to explicitly establish the relationship between these tasks."
026	Accurate Corresponding Fiber Tract Segmentation via FiberGeoMap Learner	This paper proposes a fiber classification method to identify fiber bundles from the whole brain tractography. The proposed method uses a new descriptor to represent the shape and position information of the fiber bundles, which are combined and then fed to the network for training a transformer-based deep learning model. Experiments have been performed to investigate the effectiveness of FiberGeoMap. In addition, the proposed method has been applied to autism data.	The authors propose a tractography segmentation method. This is a nicely designed method and shows a good result.	A novel fiber tract segmentation approach is proposed. First a novel descriptor, called FiberGeoMap, encodes the geometric features of the fiber by transforming to spherical coordinates and binning to predefined bins. Second, a computational framework, based on Transformers and multi-head self attention, is proposed for segmentation. Extensive evaluation using 103 fiber tracts plus no-tract categories on 205 HCP subjects are shown. Comparison with state of the art approaches shows significant improvement in dice scores over Tract-Seg and WMA. In addition, the application of proposed method in a clinical setting shows reduced fiber density (ratios) in Autism versus controls.
027	ACT: Semi-supervised Domain-adaptive Medical Image Segmentation with Asymmetric Co-Training	"Introduces the problem of semi-supervised domain adaptation (SSDA) into medical image segmentation
Proposes a co-training framework that integrates UDA and SSL (semi-supervised learning)
The empirical results show that the proposed approach performs well on the BraTS2018 dataset."	This paper focuses on semi-supervised domain adaptation (SSDA) in medical image segmentation. It first discusses the unsatisfactory performance achieved by unsupervised domain adaptation (UDA). Inspired by the recent success of SSDA methods on natural images, this paper proposes a new SSDA framework that is tailored to medical image segmentation. The proposed method is termed asymmetric co-training (ACT). Different from traditional co-training methods that describe each example using two different sets of features, ACT decouples SSDA into semi-supervised learning (SSL) and UDA, then applies the co-training strategy. Furthermore, this paper proposes exponential mixUp decay (EMD) to reduce the noise in generated pseudo labels. The proposed framework is evaluated on the BraTS18 database and outperforms previous UDA and SSDA methods by a large margin.	The authors propose an asymmetric co-training~(ACT) strategy to decouple labeled data into SSL and UDA for semi-supervised domain adaptation (SSDA). Two models are trained with labels from different domains and then boosted together with pseudo labels generated from each other. And exponential MixUp decay is proposed for gradual co-training. They validate the effectiveness of the proposed method on cross-modality brain tumor segmentation tasks, outperforming other SSDA and UDA methods.
028	Adaptation of Surgical Activity Recognition Models Across Operating Rooms	This paper proposes a domain adaptation method for surgical action recognition.	The authors have proposed a method to overcome the lack of generalization problem on models trained to recognize the surgical activity across different operating rooms. The authors propose to adapt the model that was originally trained on the source domain by predicting pseudo-labels on the target domain and using them to retrain the target model using augmented versions of the pseudo-labeled clips. The pseudo-labels are generated on the target domain based on the most confident labels from the source domain. The level of confidence is based on a threshold that is determined for each class during the model training on the source domain by taking into account the class imbalance. The authors evaluated the domain adaptation strategy by only providing labels in the source domain (unsupervised) and by also providing labels to a small portion of the samples in the target domain (semi-supervised). Both non temporal and temporal features are used for the surgical activity recognition.	This paper tackled the problem of phase recognition from external ceiling mounted cameras. The proposed approach wanted to address the problem of generalization from one operating room to another one. They have explored the use of both unlabelled data and labelled data from the target OR.
029	Adapting the Mean Teacher for keypoint-based lung registration under geometric domain shifts	This work is built on top of the mean-teacher-based framework (which was initially proposed for semi-supervised learning), where it adapts the perturbation (e.g., scaling, translation) and enforces consistency as well as introduces GCN to extract features. They also adapt the integration-based LBP to obtain the displacement fields. As such, the method can perform well in exhale-to-inhale lung registration.	In this paper, the author proposed a novel approach for domain adaptation registration. They introduced a method based on key-points registration, the Mean Teacher paradigm and graph convolution network. They experimented on a different lung registration dataset and compared with last published method.	A new registration to cope with domain shift was proposed via a keypoint-based registration model alongside self-embedding within the mean teacher framework.
030	Adaptive 3D Localization of 2D Freehand Ultrasound Brain Images	The authors developed a method to localize a 2D ultrasound image in the head of a fetus during an ultrasound examination.	This work contributes with a method to adapt a previously trained CNN for the localization a 2D ultrasound plane inside a 3D volume. The contribution allows for the application of the trained CNN to different sets of ultrasound volumes and video sequences.	Authors designed a framework that adaptively localizes 2D ultrasound images in the 3D anatomical atlas. They also fine-tuned their method after getting instances which provides double accuracy in quantitative results.
031	AdaTriplet: Adaptive Gradient Triplet Loss with Automatic Margin Learning for Forensic Medical Image Matching	"This paper improves triplet loss by imposing a panelty on the ""hard"" triplets whose negative sample stands close to the positive sample and the anchor in the feature space. The panelty was implemented by an adaptive gradients depending on the difficulty of negative samples. The proposed method greatly improved the matching results on the selected datasets."	This work proposed a new AdaTriplet loss modified from the Triplet loss to improve the image matching problem over the hard negative samples. It also proposed an AutoMargin method to adjust margin hyperparameters during the training.	This paper investigates image retrieval for forensic medical image matching by introducing a new triplet objective with corresponding margin adaptation method. In particular, the authors propose AdaTriplet, which combines the standard triplet loss with a simple regularization on anchor-negative distances, and AutoMargin, which uses distance statistics to automatically adapt both the standard triplet margin and the additional regularization margin parameter. The performance of these methods is evaluated on two FMIM benchmarks, showcasing convincing performance especially when the subject time differences increase.
032	Addressing Class Imbalance in Semi-supervised Image Segmentation: A Study on Cardiac MRI	This paper proposes an approach to improve the performance of semi-supervised learning for under-performing classes in imbalanced datasets. It proposes to record confidence indicators (entropy, variance, confidence) during training for every class. The indicators are combined using fuzzy fusion. A class sampling scheme uses the confidence score to sample classes. A dynamic training stabilization scheme is also proposed, which redistributes the losses from convincing and under-performing samples.	The paper presents a novel approach to address the class imbalance problem in semi-supervised image segmentation.	The submission presents a training strategy for student-teacher network to deal with the class imbalance problem in cardiac MRI segmentation. By investigating class-wise confidence and class-wise sampling rate, authors improve commonly used cross entropy loss by focusing more on less confident classes, and they further reach better training stabilization by utilizing dynamic modulation of weights.
033	Adversarial Consistency for Single Domain Generalization in Medical Image Segmentation	This paper proposes synthesizing new (unseen) domains in an adversarial manner for domain generalization in medical image segmentation. An adversarial domain synthesizer (ADS) is developed to generate images with the hardest perturbations. Mutual information is calculated to preserve the semantic information in the synthesis image. The performance has been evaluated on various organ segmentation tasks.	The authors propose a single domain generalization method that can be trained on a single source domain while being generalizable to various novel testing domains. The proposed method is based on an adversarial domain synthesizer that plays a contradictory role as a segmentor, making the segmentor sufficiently generalizable after model convergence.	"The paper proposes a strong assumption for single domain generalization that the distribution of unseen domains belong to the distribution of synthetic domains. Under this assumption, they design a new adversarial augmentation method for organ segmentation. The experimental results achieve the state-of-the-art and show the effectiveness under different settings.
In general, the organization and overall motivation are clear."
034	Adversarially Robust Prototypical Few-shot Segmentation with Neural-ODEs	The paper proposes a novel framework/architecture PNODE that can be employed to train adversarially robust few-shot segmentation models.	This submission proposes a novel adversarial defense framework against attacks on few-shot segmentation. Authors demonstrate the superior performance of their method to the traditional adversarial training. They also show the proposed framework generalizes well to common adversarial attacks such as FGSM, PDD and SMIA as well as to multiple data sets in both in-domain and cross-domain settings.	"In this work, the authors propose to use Neural-ODE for Few-shot Segmentation, which is robust to adversarial attack. The proposed PNODE method, based on Neural ODE, doesn't require prior knowledge on the type of adversarial attacks.
The authors perform experiments comparing with multiple baseline methods, the results show that the results are more robust to adversarial attack."
035	Agent with Tangent-based Formulation and Anatomical Perception for Standard Plane Localization in 3D Ultrasound	"This paper proposes an RL based approach to search for the standard plane in 3D ultrasound.
Contributions/claims:

This paper introduces a tangent-point based Standard Plane (SP) localization method that restricts the search space making optimization easier. Instead of relying on pre-registration it uses imitation learning to initialize the agent, thereby making optimization further easier.
It proposes an auxiliary task to enable differentiation between non-SPs and SPs.
It proposes a reward function that uses spatial and anatomical information to guide the agent."	The paper defines a new tangent-point-based plane formulation in RL to restructure the action space and significantly reduce the search space; designs an auxiliary task learning strategy to enhance the model's ability to recognize subtle differences crossing Non-SPs and SPs in plane search; and proposes a spatial-anatomical reward to effectively guide learning trajectories by exploiting spatial and anatomical information simultaneously.	The authors propose a localisation framework that uses RL with a novel tangent-based formulation and a novel anatomical landmark-based reward. Additionally imitation learning-based initialisation and an informative auxiliary task of state-content-similarity prediction, are used to aid  learning.
036	Aggregative Self-Supervised Feature Learning from Limited Medical Images	The manuscript presents two strategies of aggregation in terms of complementarity of various forms to boost the robustness of self-supervised learned features, i.e., a principled framework of multi-task aggregative self-supervised learning from limited medical samples to form a unifed representation, with an intent of exploiting feature complementarity among different task and an auxiliary loss function based on a linear centered kernel alignment metric to self-complement an existing proxy task. These two strategies can effectively boost the modeling robustness and capability.	"Authors propose strategies for various aggregate forms of pre-defined self-supervised learning tasks to boost the performance. The prior papers mostly combine all SSL tasks together, which can potentially harm performance.
This framework is helpful in general when we have several options for SSL tasks and want to find a way to combine these SSL tasks."	"This paper targets self-supervised feature learning (SSL) for low-data regime. To achieve this goal, two techniques of aggregation in terms of complementarity of various SSL tasks. The first technique is a principled framework of multi-task aggregative SSL. Tasks are iteratively added to exploit feature complementarity among different tasks. The second technique self-complements an existing proxy
task by an auxiliary loss function. Experimental results on two medical image classification dataset show improved accuracy over the existing works."
037	An Accurate Unsupervised Liver Lesion Detection Method Using Pseudo-Lesions	The main contribution of this work, applied to anomaly (tumour) localization, is a new form of data augmentation where lesions are simulated on healthy liver slices in CT. Each simulated lesion is a downscaled, randomly oriented, and jittered liver from some other slice/volume. An ablation study shows that this greatly improves lesion localization. By applying a CycleGAN for image-to-image translation between healthy and diseased images, applying a multi-scale gradient magnitude similarity deviation loss, and applying a UNet discriminator, performance is further improved.	"This paper proposes an unsupervised liver detection method. Unlike standard unsupervised anomaly detection models which are based on autoencoders trained on normal images only, the authors propose to use an auto-encoder like architecture that can reconstruct lesion-free images from input lesion image. As for standard anomaly detection models, the reconstruction error between the input and output data outlines the lesion localisations. The first step is to train a cycle-GAN like architecture based on couples of normal and pseudo-lesion images. Pseudo-lesion images are derived by adding ""lesions"" to the corresponding normal slice. Once the model is trained, the generator enabling to generate lesion-free image serves as for the anomaly segmentation model. The other generator of Cycle-GAN model serves for data augmentation. The proposed architecture is evaluated on different datasets : The LiTS public dataset containing 131 CT scans and a private dataset of 90 CT scans."	The paper describes a data augmentation approach to improve lesion detection. By learning to generate liver CT images with lesions from non-lesion images (via CycleGAN), a UNet segmentation network is trained to perform anomaly detection, i.e., detect lesions regions from the input images. Evaluation is performed on public (LiTS) and proprietary datasets.
038	An adaptive network with extragradient for diffusion MRI-based microstructure estimation	The authors proposed a deep-learning based method to estimate microstructure maps from undersampled diffusion MRI data. The main contribution of the work is the introduction of an extragradient that warrants the convergence of the network.	The authors proposed a novel network for microstructure parameter estimation from diffusion MRI. Specifically, they show their network reduced the prediction error when using few diffusion MRI measurements compared to other methods. Overall, the proposed method shows the least error when compared to the gold standard parameter maps. Results are shown on 2 in vivo datasets. The experimental design is sound, and the paper is well-written.	The paper approaches the problem of dMRI microstructure estimation by an adaptive network with extragradient. An integrated algorithm AEME is proposed, which can adaptively determine the number of iterative units and incorporate with extragradient unit (EG-Unit).
039	An Advanced Deep Learning Framework for Video-based Diagnosis of ASD	This work is a dataset release paper with an accompanying model which performs surprisingly well on such a small dataset. The work also suggests a strategy for such dataset collections.	The paper presented a method for ASD diagnosis in children, based on the analysis of videos and extracting head-related information. The proposed method was evaluated using a unique dataset, which will be made publicly available as the authors promised. The experimental results showed superior performance as compared to baseline approaches.	This paper aims to ASD detection on videos. To do that, a new dataset is collected. It describes the video acquisition strategy in detail. It also designs a new pipeline to detect ASD. Specifically, openface features are extracted from a small segment of videos. A designed HRC module is to enhance features. Finally, scores from different segments are aggregated to obtain a final result. It also has ablation studies to verify the effectiveness of the proposed module.
040	An End-to-End Combinatorial Optimization Method for R-band Chromosome Recognition with Grouping Guided Attention	This paper proposes a novel chromosome recognition method to improve the existing recognition performance. To address the recognition issues of karyotypes with numerical abnormalities, deep assignment module is proposed. Also, a grouping guided feature interaction module is proposed for feature aggregation. These proposed modules address the current challenges in chromosome recognition and as a result the proposed method outperforms the state-of-the-art algorithms.	"*	This paper proposed an end-to-end deep learning method to recognize both normal and abnormal karyotypes, without needing any feature extraction backbone.
*	A grouping guided feature interaction module (GFIM) is built for feature aggregation between similar chromosome instances to reduce confusion between chromosomes with similar lengths. 
*	A deep assignment module (DAM) is designed for flexible and differentiable label assignment.
*	An empirical study was performed on a large-scale R-band chromosome dataset collected and labeled by clinical cytogeneticists. The proposed method outperformed competing methods on both normal and abnormal karyotypes."	The authors state that they propose a novel approach for chromosome recognition, specifically R-band chromosome recognition. R-band chromosome recognition is, according to the authors, understudied. The authors claim that the method outperforms state-of-the-art for this problem.
041	An Inclusive Task-Aware Framework for Radiology Report Generation	Paper proposes a structure level description of X-ray images which is an interesting idea. In addition, the paper also conducts abnormality detection of each structure alongside an auto-balance loss to solve for the skewness of data availability between normal and abnormal patients.	This paper studies the medical report generation tasks. Different from existing approaches, it shed light more on the special structure of the medical report by introducing a task distillation module. This TD module leverage prior knowledge (keywords) to group sentences in reports into a set of anatomical structures. The text block of each anatomical structure will later individually be used for training a transformer decoder for text generation. The encoder part is built on top of a CNN feature extractor as well as a classer token embedding pool. Features extracted from the image and abnormality type are fed to a transformer encoder. During training to better battle the data imbalance issue, the authors also propose a special sampling method named Auto-Balance Mask. Extensive experiments on two benchmark datasets confirm the superiority of the solution.	"This paper describes a framework for radiology report generation. A novel task-aware framework is proposed that is composed of a task distillation module turning the image level report to structure-level description. There is also a
classification mechanism  to identify and emphasize the abnormality of
each structure."
042	An Optimal Control Problem for Elastic Registration and Force Estimation in Augmented Surgery	The manuscript describes a framework for non-rigid image registration and estimation of surface forces that generate the deformations observed in the images. The framework formulates image registration and surface force estimation as an optimal control problem. It utilises the hyperelastic material model to describe tissue constitutive behaviour. The Authors envisage application in force estimation for robotic surgery when direct force measurement (and haptic feedback) are typically not available.	"The authors propose a method to estimate surface forces needed to load a biomechanical model of the liver, so that the deformed model will fit observed data. An optimization problem is formulated along with an adjoint scheme to resolve it, with surface loads as the optimization variable.
This registration approach is evaluated on experimental phantom data from the Sparse Data Challenge. While the evaluation it not complete, the proposed approach currently ranks second in the challenge leaderboard.
An additional contribution of the method is that since the applied forces are estimated, the magnitude of these forces could be used as haptic feedback in a robotic system."	This paper introduces a non-rigid liver registration method between pre-operative and Intra-operative biomechanical models. The surface of the liver is registered and compared in rigid and non-rigid registration. The TRE approach is utilized for currency measuring.
043	Analyzing and Improving Low Dose CT Denoising Network via HU Level Slicing	The authors improve the performance of denoising CNN in low-dose CT by slicing the problem into different dynamic range levels, significantly improving the performance of different denoising networks.	"Authors proposed the use of HU level slicing to improve the performance of the vanilla convolutional network. Authors first use different CT windows to slice the input image into separate HU range. Then different CNN networks are used to process each slice. Then, a feature fusion module combines the feature learned by each network and produces the denoised image.
Quantitative (PSNR, SSIM, RMSE) and qualitative experiments are presented comparing the proposed technique and state-of-the-art methods.
The experiments show an good performance (PSNR, SSIM and RSME)"	The authors point out the importance of intensity resolution in LDCT. To tackle the issue by large dynamic range in LDCT and improve the deep neural network for LDCT denoising, the authors propose to use HU level slicing where feature fusion mechanism from multiple deep neural network for different HU levels is developed.
044	Analyzing Brain Structural Connectivity as Continuous Random Functions	The authors propose a spatially-continuous connectivity model for white-matter connections, to analyse dMRI data for possibly salient connections. The method does not need pre-existing atlases of connectivity, giving it more freedom to find new relevant inter-region connections.	This paper proposes to use low-rank embedding of continuous random function to represent the connectivity intensity matrix of white matter fibers. The paper is written in excellent English. The introduction part is educative and clearly summarizes the limitations of state-of-the-arts methods. The methodology section gives a good mathematical description of the algorithm, and the experiments clearly demonstrates the merit of this method.	This work theoretically analyzes brain structural connectivity as a continuous function.
045	Anatomy-Guided Weakly-Supervised Abnormality Localization in Chest X-rays	This paper proposed an anatomy-guided weakly-supervised abnormality localization model for chest x-rays. Specifically, the model consists of a cascade of two networks, one for identifying anatomical abnormalities and the other one for pathological observations. The model also utilizes an anatomy-guided attention module to guide the observation network to focus on the relevant anatomical regions generated by the anatomy network. Experiment results on two large public chest x-ray datasets show superior performance against other methods.	The authors proposed a weakly supervised disease localization approach for chest X-rays by integrating the classification of anatomical mentions (also extracted from the radiology reports) in addition to the disease/observation mentions. The CAM maps from the anatomy classification branch are further utilized as the weight mask of refined regions for the disease classifications. Two large-scale public datasets, i.e., MIMIC-CXR and ChestX-ray8, are employed here for the experiments. The radiologists also annotated bounding boxes of diseases in the MIMIC-CXR datasets. Superior results of the proposed framework (in both classification and localization) are reported compared to some prior arts (e.g., CAM-based localization).	This paper proposed Anatomy-Guided chest X-ray Network (AGXNet) which consists of two networks: Anatomy Network and Observation Network to make use of both anatomy mentions in reports and image-level label. An anatomy-guided attention (AGA) was then adopted to bridge these two networks. The proposed method achieves competitive results on two public datasets.
046	Anomaly-aware multiple instance learning for rare anemia disorder classification	This paper proposes an  interpretable pooling method for MIL to address the poor machine learning performance on rare anemia disorders classification from blood samples. Experiments demonstrate the superior performance of the proposed strategy over standard MIL classification algorithms, with providing a meaningful explanation behind its decisions.	The authors proposed an interpretable MIL network to increase the contribution of anomalous instances. This work shows SOTA performance when compared with other MIL approaches.	This paper proposes an anomaly-aware pooling strategy for multiple instance learning. The key idea is to design a latent space that uses Bayesian Gaussian mixture models to estimate the distribution of negative instances. Extensive experiments are conducted to validate the effectiveness on bag/instance classification and the anomaly analysis.
047	Assessing the Performance of Automated Prediction and Ranking of Patient Age from Chest X-rays Against Clinicians	In this work the authors present a study comparing the performance of three radiologists on chest X-ray age prediction and ranking tasks, comparing with data-driven models trained on a highly heterogeneous non-curated set of chest X-rays from a variety of clinical settings in six hospitals. The authors conclude that (a) the radiologists are significantly more accurate at detecting age-related changes in a single patient than at estimating age in single images and (b) the models significantly outperform humans on both tasks. The author'work indicates that accuracy gains are likely to be small from larger datasets, and that the majority of age-relevant information is present at resolution in this modality.	The authors present a framework aimed to determine patient age from a chest x-ray. The model was trained on a large database (1.8M chest X-rays). An ablation study investigating the model accuracy based on changing training size and image resolution demonstrates the generalizability of the approach. The approach is based on a conditional Generative Adversarial Network and allows the visualisation of the predicted scan that can be used to identify semantic features learned by the model.	In this study the authors  present a chest X-ray age prediction model trained on a large heterogeneous set of chest X-rays, with sensitivity analysis to training set size and image resolution, and  generalisation performance on the public dataset NIH ChestX-ray[14]. Moreover they present a study comparing the performance of human radiologists against their model on two tasks: (a) ground truth age prediction from a chest X-ray; (b) ranking two time-separated scans of the same patient in age order.
048	Asymmetry Disentanglement Network for Interpretable Acute Ischemic Stroke Infarct Segmentation in Non-Contrast CT Scans	"This work develops a segmentation method for stroke infarcts in brain CT based on asymmetry. It differs from previous works on asymmetry by developing a method to differentiate between 2 asymmetry types: Pathological (stroke) and non-pathological (anatomical). The steps are: 1. A registration net learns to align the CT with mid-sagittal. 2. Asymmetry map made via CT's reflection along mid-sagittal. 3. A second net takes the CT and predicts only the pathological asymmetries. This is learned via an intuitive regularizer designed based on domain-knowledge (main technical contribution). 4. Using output of (2) and (3), a synthetic ""asymmetry compensated"" image is made, where non-pathological asymmetries are removed. This is beneficial cause it can serve as human-interpretable side-output (secondary contribution). 5. A third network learns to segment given the ""asymmetry compensated"" image (4). Evaluated is done on a public database, AISD, outperforming 3D (Res)Unet and DeepMedic."	"the authors presented an asymmetry disentanglement network to provide extra supervision for the stroke segmentation on non-contrast-enhanced CT images.
the authors demonstrate the effectiveness of the disentanglement module."	Developed a novel network to disentangle asymmetries from non-contrast CT images for AIS segmentaion, trained with a tissue-awareness loss function to make the model more interpretable.
049	Atlas-based Semantic Segmentation of Prostate Zones	This paper proposes a novel segmentation approach for prostate zones, by integrating the anatomical prior into an atlas map. Besides, the weight of fusing with the atlas could be adjusted in the testing phase.	"The authors propose a new deep learning approach for automated semantic
segmentation of prostate zones by including prior shape information
from an anatomical atlas."	Multizonal prostate segmentation is performed on T2w MR images using a combined 3D anatomical atlas and deep learning (U-Net based) segmentation algorithm. The impact of each method on the final segmentation may be adjusted in real-time to optimize results by tuning a hyperparameter. This approach requires a whole-gland prostate segmentation as input, then predicts the central gland segmentation, and through elimination identifies the peripheral zone segmentation.
050	Atlas-powered deep learning (ADL) - application to diffusion weighted MRI	The paper proposes a novel framework to unify atlases and DL for dMRI biomarker estimation. It was used to estimate fractional anisotropy and neurite orientation dispersion from down-sampled data and achieved superior accuracy .	This paper proposes a novel method that exploits deep learning together with atlases of brain microstructure parameters. This is used for the estimation of microstructure scalar parameters from diffusion MRI.	The major contribution of this work is a framework that leverages atlas-based registration methods with deep learning for the estimation of dMRI of FA and orientation dispersion from tensor and NODDI estimation. Specifically the authors propose the use of atlas-based registered features, together with atlas-reliability map (as given by standard deviation) and registration error (proposed formulation). These three are concatenated to the diffusion signal as inputs to the DL fitting model.
051	Attention mechanisms for physiological signal deep learning: which attention should we take?	The paper investigates several self attention mechanisms in a range of CNN and multi-head self attention based architectures in application to ECG signals combined with other physiological data. Experiments are performed on a classification test for predicting hypotension and a regression task to predict intraoperative cardiac output. The authors identify best performing self attention mechanisms in each task and provide hypotheses as to why these models work the best.	Four attention mechanisms were compared.	This paper comprehensively investigates four attention mechanisms fused with three convolutional neural network (CNN) architectures for two processing physiological signal prediction tasks. This paper aims to provide a good guide for researchers who use attention-based convolutional networks for physiological signal prediction tasks.
052	Attentional Generative Multimodal Network for Neonatal Postoperative Pain Estimation	"The paper proposes an automated approach to asses pain in the neonatal intensive care unit. It is a multi-modal approach designed, developed, and validated for assessment of posoperative pain.
The multiple modalities include visual and auditory inputs."	"Authors propose a novel approach for neonatal postoperative pain assessment. The proposed model is consist of three stages: spatio-temporal feature learning (Stage 1), joint feature distribution learning (Stage 2), and attentional feature fusion (Stage 3). The main technical contributions are as follows:

develop a deep feature extractor followed by an RNN Auto-Encoder network
design a novel generative model that combines all the modalities
use a transformer-based attentional model
Compared to other state-of-the-art, the proposed method outperforms in the classification task. Authors also show the results of the pain intensity estimation."	The paper proposes a novel multi-modal approach for the assessment of postoperative pain of neonates. A deep feature extractor followed by an RNN Auto-Encoder network is used to extract spatio-temporal features from both visual and auditory modalities. A novel generative model is designed to combine all the modalities while learning to reconstruct any missing modalities. Instead of using early or late fusion techniques, a transformer-based attentional model is adopted to learn cross-modal features and generates final results.
053	Attention-enhanced Disentangled Representation Learning for Unsupervised Domain Adaptation in Cardiac Segmentation	"This paper addressed the problem of domain-specific information inherent in the domain-invariant features, especially under large domain shifts.
Hilbert-Schmidt independence criterion (HSIC) is used to restrict the independence and complementarity"	"The paper proposes a UDA framework for cardic segmentation, working with: i) Alignment of Imaging Characteristics. ii) Channel-wise Disentanglement. iii) Attention Bias for Adversarial Learning.
The proposed method archives better performance when adapting between MRI and CT on the cardic segmentation task."	This work presents an Attention-enhanced Disentangled Representation (ADR) learning framework for cross-domain cardiac segmentation, where Hilbert-Schmidt independence criterion (HSIC) is adopted for feature disentanglement and the attention bias module is used for alignment of task-relevant regions. The proposed method is demonstrated its superior performance on the MMWHS 2017 dataset.
054	Attentive Symmetric Autoencoder for Brain MRI Segmentation	The paper proposes an attentive symmetric auto-encoder based on ViT for MRI segmentation. The method does pre-training and resorts to the prior of brain structures and develop a Symmetric Position Encoding.	The paper proposed a 3D brain segmentation model based on Masked Auto-Encoder self-supervised learning scheme, with a novel symmetric positional encoding (SPE) to add anatomical symmetric prior, and a novel attentive reconstruction loss based on histogram of gradient reweighting in order to emphasize the informative patches. Experiments shows the sota performance on 3 benchmarks and the effectiveness of each novelty.	"The authors proposed an attentive reconstruction loss function.
The symmetric position encoding seems useful for this task.
The experimental performance looks good."
055	Autofocusing+: Noise-Resilient Motion Correction in Magnetic Resonance Imaging	In this work, the authors proposed the Autofocusing algorithm using a CNN extracted prior knowledge on specific k-space motion corruption models. The authors evaluated the methods using fastMRI datasets.	"The authors proposed an autofocus method based on a neural network to remove motion artifacts. Similar to autofocus and gradMC (L2 regularized autofocus method), the method does ""blind"" motion correction. However, it is constrained by a deep learning-based regularization term. The fast MRI database was used to compare the performance of the proposed method with other motion correction methods. The motion corrected images were compared using four quality metrics."	The work proposes a deep learning prior for MR motion artifact reduction that is used inside an autofocusing strategy. Rigid (translation and rotation) motion parameters are estimated together with scaling variances modelled by a UNet prior. Rigid motion simulations were conducted on the fastMRI database.
056	AutoGAN-Synthesizer: Neural Architecture Search for Cross-Modality MRI Synthesis	Authors propose a new MRI synthesizer, called AutoGAN Synthesizer, which automatically discovers generative networks for cross-modality MRI synthesis.	"Aiming at the recovery of realistic texture while constraining model complexity, authors propose a GAN-based perceptual searching loss that jointly incorporates the content loss and model complexity.
To incorporate richer priors for MRI synthesis, we exploit MRI K-space knowledge
containing low-frequency (e.g., contrast and brightness) and high-frequency information (e.g., edges and content details), to guide the NAS network to extract and merge
features. 
Considering that the low- and high-resolution of multi-scale networks can
capture the global structure and local details respectively, they use a novel multi-scale module-based search space which is specifically designed for multi-resolution fusion.
Their searching strategy can produce a light-weight network with 6.31 Mb parameters from module-based search space only taking 12 GPU hours and achieve state-of-the-art performance."	This paper presented a novel AutoGAN-Synthesis framework for cross-modality MRI synthesis by designing a generator to extract and fuse multi-resolution features. Moreover, the authors proposed a GAN-based perceptual searching loss to balance the model complexity and synthesis performance. Experiments on 2 datasets demonstrate that the proposed methods can outperform other cutting-edge methods qualitatively and quantitatively.
057	AutoLaparo: A New Dataset of Integrated Multi-tasks for Image-guided Surgical Automation in Laparoscopic Hysterectomy	This paper presents and describes a new data set for Laparoscopic Hysterectomy. The data set includes 1388 minutes of surgical activity. It is aimed to be used for research in multiple areas including workflow analysis, laparoscope motion prediction and instrument and anatomy segmentation. The authors reported results from applying several machine learning methods on their data set for each of the areas mentioned above.	"This work contributes an integrated dataset AutoLap with multi-tasks to facilitate learning-based automation in hysterectomy surgery.

A series of experiments are carried out on AutoLap with SOTA models.

The dataset will be released to public after the paper is published."	This paper presents a dataset for facilitating ML-based approach development laparoscopic video understanding. The dataset contains sub-datasets designed for three different tasks including workflow recognition, laparoscope motion prediction and instrument/anatomy segmentation. It is stated that this dataset is provided to encourage advances towards surgical automation. Example uses of the dataset were demonstrated by benchmarking multiple state-of-the-art DL approaches. The authors claimed that the dataset will be shared along with the publication of the work.
058	Automated Classification of General Movements in Infants Using Two-stream Spatiotemporal Fusion Network	This paper proposes an automated framework for GMs classification consists of preprocessing networks and motion classification network. With the former network getting rid of the background information and aligning the body orientation, the latter network processes the spatiotemporal features. The proposed method outperforms the listed comparing methods.	"The paper addresses the problem of Automated Classification of General Movements in Infants. This problem is known to be still difficult and ""unsolved"".
Authors propose an image based approach (using videos) to rate the GM category.
In the proposed approach, first a focus is made on removing the background of the video and the pose of the infant is normalized. From these processed images, authors use a two-stream spatio-temporal network to predict the GM category.
Authors evaluate on a proprietary dataset and make the code available.
Results outperform current state of the art."	"Focus on the infant general movement classification problem in this work, a preprocessing network is introduced to remove unnecessary background.from GM videos and adjust the infant' body position. 
A two stream structure for motion classification is proposed based on both spatial and temporal information."
059	Automatic Detection of Steatosis in Ultrasound Images with Comparative Visual Labeling	The authors propose a comparative visual labeling (CVL) + RankNet approach to develop comparative and reliable labels for training and testing computer aided diagnostic systems.	This is an interesting study about the fatty liver disease diagnosis in ultrasound. Authors investigated problems related to the lack of proper reference labels for the development of fatty liver disease diagnosis methods. To address the problem, a comparative visual labeling (CVL) along with the RankNet method were used to improve the quality of the labels determined by three annotators. Moreover, authors trained a CNN with differently obtained labels to classify fatty livers to confirm the quality of differently obtained labels.	"The authors have proposed to use a RankNet to improve the healthy/pathological label for Steatosis detection using Ultrasound images. The inputs to the RankNet are randomly selected paired images from the dataset, and they are trained on binary labels provided by the annotators showing first or second image has the highest degree of pathology. They have thresholded the scores generated by the RankNet to acquire labels and evaluated their quality by comparing to histopathology results, outperforming the visual labels provided by the annotators. 
The new labels did not enhance the classification performance using CNNs."
060	Automatic identification of segmentation errors for radiotherapy using geometric learning	X	The authors present a combined CNN-GNN model to perform segmentation error prediction. The model consists of three parts. First, a CNN encoder generates features from image patches extracted along the boundary of the contour, the intention is to include appearance information into the task. Second, a GNN operating on the meshed contour with the features of the CNN encoder attached to the nodes, updates each node's representation according to its local neighborhood. Third, a MLP classifies each node's features into five classes representing different bins of signed (inside/outside) distances to the surface of the true contour. The model is trained and evaluated with synthetically perturbed contours of parotid glands.	For developing a tool to automatically identify errors in 3D OAR segmentations without a ground truth, this paper proposes a novel quality-assurance (QA) architecture combining a convolutional neural network (CNN) and graph neural network (GNN) to leverage the segmentation's appearance and shape. Experiments demonstrate the effectiveness of the proposed QA method. Paper structure is good. Figures are nice.
061	Automatic Segmentation of Hip Osteophytes in DXA Scans using U-Nets	This paper deals with the automatic segmentation of osteophytes in hip dual X-ray absorptiometry scans (DXAs). The proposed approach uses U-Net.	The article presents a semi-automatic method for segmentation of hip osteophytes from DXA images. The first step of the method is manual localization of hip joint keypoints (can be done automatically with BoneFinder tool, as mentioned for a subset of the data). The second step is a vanilla UNet with minimal modifications applied to patches extracted around certain keypoints.	The authors proposed 3 deep learning networks (U-Nets) for automatic segmentation of osteophytes in DXA scans at three different sites: inferomedial femoral head, superolateral femoral head, and lateral acetabulum. The proposed framework provide good sensitivity and specificity for the detection of osteophytes and average Dice metric in terms of semgentation accuracy.
062	Automating Blastocyst Formation and Quality Prediction in Time-Lapse Imaging with Adaptive Key Frame Selection	This paper proposes a deep learning method to predict the viability for IVF of an embryo, based on microscope video timelapses spanning 3 days, and with groundtruth taken as an embryologist evaluation at day 5/6. The base structure of the method is a spatial-temporal CNN+LSTM with additional positional encoded features. The core novel contribution is a selection mechanism that decides which frames are relevant for the classification task, which shows an improvement in classification when compared to using all frames or other selection methods.	The paper proposes to adaptively select informative frames from the TLM video, to improve the blastocyst classification. A policy network with Gumbel-Softmax sampling approach and a reward function are developed for frame selection. Experimental results on the in-house dataset show the effectiveness of proposed method, outperforming the SOTA across various evaluation metrics.	"In this paper, the authors proposed a novel deep learning framework to adaptively select informative frames for blastocyst formation prediction using time-lapse monitoring (TLM) videos on D3.
Extensive experiments were conducted on a large TLM video dataset to evaluate the proposed method; experimental results demonstrated its superiority over the latest state-of-the-art methods."
063	Automation of clinical measurements on radiographs of children's hips	"The authors propose an automatic method to determine two radiographic parameters for the monitoring of hip anomalies in pediatric AP hip radiographs. The author propose to use the concept of Random Forest Regression Voting to detect automatically anatomical landmarks for acetabulum and femur. These landmarks are then used to determine the radiographic parameters (AcI, RMP).
The proposed system was tested and validated on a clinical dataset of 200 images (400 hips)."	The authors propose an automatic system for calculating the acetabular index (AcI) and Reimer's migration percentage (RMP) from paediatric hip radiographs. These two clinical measures are used for the diagnosis of developmental dysplasia (DDH) of the hip and monitoring hip migration for cerebral palsy. The approach uses the Random Forest Regression-Voting Constrained Local Models (RFRV-CLM) framework to automatically locate landmarks which are in turn used to automatically calculate the measures. They test their approach on a challenging dataset of pelvic radiographs of children containing cases of severe disease and occlusions. They report high conformation between the measures as automatically determined by their approach and those measured by clinical experts.	In this paper, the authors introduce a Random-forest-based method for measuring on coronal radiographs angular parameters of the pediatric hip that have clinical value.
064	BabyNet: Residual Transformer Module for Birth Weight Prediction on Fetal Ultrasound Video	"The authors propose an end-to-end method which called BabyNet for birth weight estimation based directly on fetal ultrasound video scans.
The authors design a novel residual transformer module by adding temporal position encoding."	The paper proposes a hybrid neural network called BabyNet, for automatically predicting fetal birth weight based on fetal ultrasound video scans.	The paper describes a method to estimate birth weight of fetus from ultrasound scans performed one day prior to delivery. The architecture (BabyNet) includes a residual transformer module in a 3D Resnet-based network (hybrid CNN and transformer) to analyze ultrasound videos. It is evaluated using 225 fetal ultrasound videos from 75 patients. It is compared with state-of-the-art methods ad human experts.
065	Bayesian dense inverse searching algorithm for real-time stereo matching in minimally invasive surgery	"This paper describes an approach to stereo reconstruction of surgical video building on Bayesian searching of correspondences as an extension to dense inverse searching.
The approach is tested on synthetic and clincal data set and evaluated with respect to computing requirements and performance. 
The evaluation is done quantitativelywith respect to a diffuse and non-Lambertian ilumination and qualitatively wrt the achieved 3D reconstructions."	This is paper introduces a stereo matching approach for minimally invasive surgical videos. The proposed approach includes a Bayesian Dense Inverse Searching method and a Spatial Gaussian Mixture Model to deal with textureless or no-Lambertian surfaces. The proposed approach runs fast in run-time and has been evaluated both synthetic and in-vivo dataset. The comparisons to state-of-the-art are also provided and results have shown the approach archives close performance to ELAS and has doubled run-time speed on processing same-sized images.	The authors tackle the problem of disparity estimation in stereoscopic pairs of surgery scene. Their intent is to have a computer efficient approach. The proposed algorithm is a modified version from standard patch-based matching. The key points of the modification are the introduction of a Bayesian computation to estimate posterior probability and to associate a confidence to the pixels.
066	Bayesian Pseudo Labels: Expectation Maximization for Robust and Efficient Semi-Supervised Segmentation	"In this paper, authors present semi supervised segmentation method based on psudo labels of the unlabelled images.

The authors present the  approach where the model and psudo labels are updated iteratively where in E step the psudo labels are generated and in M step the model is updated using both label and psudo label.

Dice loss used by authors need thresholding of psuolabels, so author variational inference based approach to compute the the threshold T."	This work presents a new formulation of pseudo-labelling as an Expecation-Maximization (EM) algorithm for clear statistical interpretation.	The paper proposes a novel semi-supervised segmentation method using pseudo-labels with an extension to variational inference. The method jointly trains a neural network on few labeled images and more unlabeled images in a two step approach. The authors link pseudo-labeling to the expectation-maximization framework. The extended method uses variational Bayesian inference to also estimate the label threshold used for generating pseudo-labels.
067	Benchmarking the Robustness of Deep Neural Networks to Common Corruptions in Digital Pathology	This paper propose to synthetically generate corruption to pathology images. Nine type of corruption was considered at five severity levels each. Ten CNNs are trained and their performance are tested on the regular validation set, the corrupted validation set, and a held-out test set. The authors found that 1) the corrupted data leads to higher error rate 2) the model confidence increase with level of corruption severity 3) different corruption affected the models differently 4) early stopping helps with robustness 5) error corrupted validation set is more predictive of generalizability of the model.	"This paper presents two new benchmarks to measure evaluate how deep neural
networks perform on corrupted pathology images. Specifically, corrupted
images are generated by injecting nine types of common corruptions into
validation images. Two classification and one ranking metrics
are designed to evaluate the prediction and confidence performance under corruptions. Furthermore, this paper validates the poor robustness of modern CNNs towards input corruptions."	"The paper builds an ensemble of corruption methods to be used as a standard suite for evaluating model robustness in histopathology.
It evaluates the methods on a pretty extensive list of standard architectures, including the more modern vision transformers."
068	BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis	The authors propose a transformer-based vision & language (V&L) model based on a recent image feature learning method named, PixelHop++ and BlueBERT which has been trained on biomedical and clinical datasets. The results show that the proposed method can better capture the associations between clinical notes and medical images, gaining higher classification results.	"The paper proposes a Vision and Language model for better capturing the associations between clinical notes and medical images.
In particular, PixelHop++ is used to extract features from images, that are then processed with a visual transformer together with language embedding, extracted from a text report.
The results demonstrate the validity of the method"	The paper proposes BERTHop, a transformer-based Vision and Language model that is applied to medical images. The visual encoder of the V&L architecture for BERTHop is implemented with PixelHop++. This is unsupervised and reduces the dependencies of labeled data.
069	Bi-directional Encoding for Explicit Centerline Segmentation by Fully-Convolutional Networks	A bi-directional endocing scheme without autoregressive blocks is proposed for various shapes and orientations of lines.	This paper proposed a encoding schema for representing/segmenting tube-shaped objects in 2D medical images. The representation can be directly infered by a neural network.	"The authors address the problem of centerline segmentation in 2-D images and propose a bi-directional point-based centerline encoding as target for a neural network (HRNet) which circumvents an ""implicit"" pixel-based segmentation. The authors evaluate their approach on three datasets (synthetic, semi-synthetic, CLIP) and show improvements compared to recently published segmentation-based methods for most investigated centerline types."
070	BiometryNet: Landmark-based Fetal Biometry Estimation from Standard Ultrasound Planes	The author proposed an end-to-end network BiometryNet for automatic fetal biometry estimation on the ultrasound images. It uses simple landmark annotations instead of complex mask annotations. Moreover, a dynamic orientation determination mechanism was proposed to reduce variabilities and improve landmarks' localization. The results on the two independent datasets demonstrated the effectiveness of proposed method.	This paper reports a contribution to a previously reported method for automatic detection of landmarks in medical images. The contribution allows the method for adaptation to rotating landmark pairs and was evaluated in 3 biometry tasks (biparietal diameter, occipito frontal diameter and femur legth) in two large data sets of fetal ultrasound images with accuracy errors within acceptable clinical values.	This paper introduces a landmark regression network for directly computing biometrics in US. Specifically, it modifies the original landmark class reassignment with a novel dynamic orientation determination to generalize it to multiple scenarios. This work validated the proposed method on a large dataset, and the results are sound and promising.
071	BMD-GAN: Bone mineral density estimation using x-ray image decomposition into projections of bone-segmented quantitative computed tomography using hierarchical learning	"This paper proposes a method to estimate BMD (Bone Mineral Density) from a plain X-Ray image. The proposed approach combines the QCT in training and decomposes an x-ray
image into a projection of a bone-segmented QCT."	The paper is focused on estimating bone mineral density using plane X-ray.  The main contributions are 1) the greatly improved method for estimating BMD from x-ray that is presented, 2) the method that allows combining QCT data, and segmentations using hierarchical learning to improve performance.	I congratulate the authors for this great work. The authors proposed a novel hierarchical learning approach to predict bone mineral density (BMD) from plain radiographs which provides opportunistic screening for osteoporosis.
072	Boundary-Enhanced Self-Supervised Learning for Brain Structure Segmentation	"This paper proposes Boundary-Enhanced Self-Supervised Learning (BE-SSL), leveraging supervoxel segmentation and registration as two related proxy tasks. The former task enables capture boundary information by reconstructing distance transform map transformed from supervoxels. The latter task further enhances the boundary with semantics by aligning tissues and organs in registration. Experiments
on CANDI and LPBA40 datasets have demonstrated that our method outperforms current SOTA methods by 0.89% and 0.47%, respectively."	This manuscript proposes two pretext tasks for self-supervised pretraining for the downstream task of brain structure segmentation, i.e., regressing unsigned distance maps defined with respect to supervoxel over-segmentation, and volumetric registration. The proposed pretext tasks are evaluated on two public datasets and demonstrate superior performance to several SOTA methods.	This paper proposes a boundary-enhanced self-supervision method that is able to learn from supervoxel segmentation and registration tasks. The supervoxel branch is refined for the main task to get the final segmentation. The experiments on CANDI and LPBA40 datasets show the efficiency of the proposed method.
073	BoxPolyp: Boost Generalized Polyp Segmentation using Extra Coarse Bounding Box Annotations	"The authors present a polyp segmentation framework. Their main goal is to achieve accurate polyp masks leveraging datasets with mainly polyp box annotations and few pixel level annotations. In particular, the paper proposes:

Fusion filter sampling (FFS) as a preprocessing module to (i) convert box annotations into pixel level annotations,  (ii) exclude difficult/wrong training samples, and (iii) ignore uncertain regions of the image during training. A pretrained model on a segmentation dataset is needed to perform this task.

Mixture of Annotated and Pseudo labels (MAP): it's a variation of Cutmix where regions of polyps with pixel level segmentations are pasted onto images with pseudo labels (arising from FFS). This is used to (i) suppress the negative effects caused by the errors in pseudo labels and (ii) to upsample the fully annotated polyps.

Inter-image consistency (IIC) loss"	This paper presented a polyp segmentation method, which leverages the cheap bounding box annotations to alleviate data shortage for a polyp segmentation task. The authors presented fusion filtering sample, mixture of annotations and pseudo, and Inter-image consistency loss to boost a generalized polyp segmentation model through extra bounding box annotations.	The authors propose to use leverage bounding box annotations for polyp segmentation task model. For Fusion filter sampling aimed at generating pseudo labels the authors used pertained SANet (previously proposed, [22]) to generate the coarse segmentation map prediction and compare with bounding boxes. They then use a similar technique to cut mix where they mix the patches with pseudo label on random images with true label. Inter-image consistency loss between different view predictions is also proposed. Authors did show some improvement over previous methods. An open question would be does these improvements comes from the use of large LDPolypVideo dataset for their coarse prediction or technique implemented that mimics more of a data augmentation techniques e.g. cut mix and loss function comparing different views. Also, is the preciseness of few more percent improvement clinically relevant.
074	Brain-Aware Replacements for Supervised Contrastive Learning in Detection of Alzheimer's Disease	"The paper introduces an augmentation technique along with a contrastive learning method for pretraining classifiers for Alzheimer's disease. The study uses augmented labels as ""soft labels"" for supervised contrastive objective."	The authors combine the advantages of relaxed contrastive learning and use case specific data augmentation operations (BAR and BAM) to solve the Alzheimer disease detection. The performance of the presented method is reported on the Alzheimer's Disease Neuroimaging Initiative dataset.	The authors propose a new data augmentation strategy for the contrastive learning framework to train a better pre-trained model. Their method produces a great variety of realistic-looking synthetic MRIs with higher local variability compared to other mix-based methods, such as CutMix.
075	Breaking with Fixed Set Pathology Recognition through Report-Guided Contrastive Training	"Existing frameworks for computer-aided diagnosis tools rely on a fixed set of predefined categories automatically that are extracted from medical reports. This paper proposes a framework to go beyond this assumption to make diagnosis more context aware.
Methodologically, they employ a contrastive global encoder-decoder designed to uncover latent concepts from unstructured medical reports, while still retaining the ability for free form classification. They also investigate properties of such free -form recognition and propose a method to employ weakly annotated data to improve training.
They evaluate on large-scale chest X-Ray datasets such as MIMIC-CXR, CheXpert, and ChestX-Ray14 to demonstrate the efficacy of their method in comparison to methods employing direct supervision."	The authors propose a method for training a framework to detect different diseases in chest X-ray images. The training is performed with report supervision using local (sentence) and global (full report) levels.	This paper aims to enable the neural networks used to medical images less reliant to label supervision. To this end, this work proposes a novel contrastive language-image pre-training method. The extensive experiments and analyses on four datasets, i.e., MIMIC-CXR, CheXpert, ChestX-ray14, and PadChest prove the effectiveness of the proposed approach.
076	Building Brains: Subvolume Recombination for Data Augmentation in Large Vessel Occlusion Detection	The authors propose a new augmentation method for training deep learning models to automatically classify large vessel occlusions by combining parts of relevant images from different patients.	"Propose ""recombination"" (generates artificial training samples by recombining vessel tree segmentations of the hemispheres or hemisphere subregions from different patients) as a simple but effective data augmentation strategy for large vessel occlusions classification. On a private dataset, the method is showing better performance than baseline augmentation methods."	The authors present an augmentation method for large vessel occlusion (LVO) classification that recombines subvolumes of vessel segmentations from different patients.
077	CACTUSS: Common Anatomical CT-US Space for US examinations	The authors propose a pipeline to segment the (healthy) aorta in US images without having to use labelled US data. They do so by training a contrastive generative network to translate between intermediate representation (from CT) to ultrasound images. Given that the CT scans are labelled, they can then train a network to segment the aorta in the IR.	This paper describes a way to bridge between CT and US to enable AAA screening using US.  This is done through an Intermediate Representation of the anatomy. Simulated US is generated from CT, and then trained with real US images unpaired. Also, a segmentation network is generated from the simulated US images.  This framework can then take real ultrasound image for segmentation for the purpose of AAA screening and diagnosis.	The authors demonstrate a framework for automatic aortic measurements on abdominal US doppler studies using a domain adaptation technique leveraging an intermediate representation space and deep learning models trained on labeled CT studies of the aorta. They then show favorable performance of their approach compared to a Unet model trained on a small number of labeled US studies alone using a Unet.
078	Calibrating Label Distribution for Class-Imbalanced Barely-Supervised Knee Segmentation	Novel proposed techniques to improve semi-supervised learning.  Specifically the techniques are 1) using weights for the loss that are dependent on the class, designed to address class imbalances that are common in segmentation problems. 2) patch selection that is dependent on the class. 3) sampling that is dependent on an estimate of uncertainty of the patch.	In this paper, the authors regard the MR knee bone and cartilage segmentation as a class imbalance problem with barely labeled data. In order to handle the segmentation under this situation, they utilize the cross pseudo supervision (CPS) to build a baseline of semi-supervised segmentation. Then the authors adjust the label distribution using the proposed probability-aware random cropping, class-aware weighted loss, and dual uncertainty-aware sampling supervision (i.e., the proposed CLD method). In the experimental part, the CLD obtains the best performance by comparing with other related approaches.	This paper focuses on a class imbalance problem in automatic deep-learning based multi-class knee structure segmentation and proposes a novel solution by combining class-aware weighted loss, probability-aware random cropping, and uncertainty-aware sampling supervision. The ablation study supports the addition of each approach.
079	Calibration of Medical Imaging Classification Systems with Weight Scaling	"The approach tackles the important problem of networks calibration. This is specially important when medical staff takes decisions based on networks confidences. The paper proposes Confidence based Weight Scaling (CWS), a technique for calibrating the outputs of deep learning classification networks.
The approach achieves state-of-the-art calibration with a guarantee that the classification accuracy is not altered"	A weight scaling calibration method that does not alter accuracy of a predictive model like the common post-hoc temperature scaling method often utilised, the approach achieves improved calibration when compared to current calibration methods and can be applied to any trained model.	The paper investigates calibration methods for DNNs trained for medical image classification systems and proposes a weight scaling methodology that helps calibrating models.
080	Camera Adaptation for Fundus-Image-Based CVD Risk Estimation	The manuscript proposes a novel method to adapt fundus images captured by two different fundus cameras to explore the domain discrepancy issue. First, the authors collect a dataset (FCP) containing pair-wise fundus images captured by two cameras with different image quality of the same patients. Second, the authors propose a cross-laterality feature alignment pre-training scheme and a self-attention camera adaptor module. I think the work is of importance for device adaption for fundus image analysis.	"This paper makes a fundus pair (left and right eyes) dataset with both high-precision and low-precision equipments.
The paper proposes a cross-laterality feature alignment method for model generalization in the task of cardiovascular disease risk estimation.
The paper design a self-attention camera adaptor module for domain adaptation, bridging the domain gap for data from different OCT cameras."	This paper proposed a cross-laterality feature learning training method and a camera adaptor module to improve a fundus image-base CVD risk predicting algorithm. In addition, they collected a Fundus Camera Paired (FCP) dataset containing pair-wise fundus images captured by the high-end Topcon retinal camera and the low-end Mediwork portable fundus camera of the same patients. This dataset is of great significance to the study of data in different domains for CVD risk prediction.
081	Capturing Shape Information with Multi-Scale Topological Loss Terms for 3D Reconstruction	This paper uses persistent homology, a popular approach in topological machine learning, to design a loss function for 3D reconstruction of 2D image slices.  The proposed loss function is suitable for neural networks (fully differentiable), and assesses the topological persistence (via persistence diagrams of image cubical complexes) of a predicted likelihood function measuring the probability that image voxels are part of the 3D object's shape.  This multi-scale loss incorporates novel shape information to help improve reconstruction, and is compared to other reconstruction method loss functions on cell shape prediction from 2D microscopy images.	This paper introduces a topological loss into a deep neural network for 3d reconstruction from 2d images. The purpose of introducing this additional loss term is to capture multi scale information about the general shape of an object in addition to the more standard geometric information. The new loss is fully differentiable and is added to the SHAPR model for image reconstruction. It is shown that this improves the accuracy of image reconstruction.	The submission focuses on a challenging task that aims to reconstruct the 3D objects from 2D images and masks. Upon the existing SHAPR framework that was optimized with a combination of Dice and BCE loss, this submission proposes a topology-aware loss (L_T) consisting of two terms: a Wasserstein distance between two persistence diagrams and a noise reduction term that incentivizes the model to reduce overall topological activity. The experiments are conducted on reconstructing 3D red bed cells and nuclei using the SHAPR framework with or without the proposed topology-aware loss. The topology-aware loss improves predictions in relevant metrics.
082	Carbon Footprint of Selecting and Training Deep Learning Models for Medical Image Analysis	The paper raises awareness and provides informative results about the carbon footprint of deep learning in medical image analysis.	The authors propose clearly defined guidelines for reducing carbon emissions during the development of machine learning models. They use a well-known segmentation framework and well-known datasets in the medical image analysis (MIA) community to estimate the energy consumption used by the community during training.	This paper presents carbon footprint of selecting and training deep learning models for medical image analysis, which seems to work from the test results.
083	CaRTS: Causality-driven Robot Tool Segmentation from Vision and Kinematics Data	The authors proposed to perform semantic segmentation via 3D pose estimation and rendering of surgical instruments. They propose that this makes the method robust to challenging image based situations such as smoke/blood.	This paper presents a novel framework for robot tool segmentation. The key novelty of the proposed model is that instead of assuming a causal relation between an image and its segmentation mask, it rather assumes a direct causal link between robot kinematics measurements and the segmentation mask. Removing the direct link between the image and its segmentation mask, that is the standard assumption in prior works, is hypothesized to render the segmentation model robust to image-domain shifts. The latter is experimentally validated on both real and simulated data captured under controlled settings using the dVRK platform.	The paper describes, CaRTS, a surgical instrument segmentation algorithm. CaRTS proposes a novel framework for estimating the segmentation of surgical instruments using images and kinematics. The results on binary segmentation seems to be well above other existing methods.
084	CASHformer: Cognition Aware SHape Transformer for Longitudinal Analysis	This paper proposed a  Cognition Aware Shape Transformer for longitudinal shape analysis.  The CASHformer uses a frozen pre-trained Transformer, where only LN layers are fine-tuned in small Alzheimer's dataset, to predict the mesh deformation along time. Congnitive embeddings and congnitive decline asare loss are also introduced as regularization.	This paper proposed a method named CASHformer, a transformer-based framework for the longitudinal modeling of neurodegenerative diseases. CASHformer consists of the mesh network, frozen pre-trained transformer, cognitive embedding, and cognitive decline aware loss. The results show CASHformer reduces the reconstruction error by 73% and increases AD disease detection by 3% to the baselines.	Authors propose CASHformer, a transformer based approach to model hippocampus deformations across time. MRI follow-ups of hippocampus are segmented using an already existing software (FIRST) and embedded using a mesh-based neural network encoder (SpiralResNet). A pretrained transformer is trained to predict hippocampus deformations embeddings (only fine-tuning the Layer Normalization blocks). Authors propose to incorporate clinical knowledge to the model by including a cognitive score embedding (similarly to positional encoding) to modulate the hippocampus latent representations, as well as a Cognitive Decline Aware Loss based on cosine similarity to enforce larger deformations for patients with a higher cognitive decline. Authors evaluate their model on three proposed longitudinal shape modeling tasks: interpolation, extrapolation and trajectory prediction. An ablation study on the proposed contributions and a discussion on the size of the models are also presented.
085	Censor-aware Semi-supervised Learning for Survival Time Prediction from Medical Images	"The paper presents a deep learning method for survival predictions based on images.
It presents a methodology to leverage the use of censored data which is often ignores or sub optimally used."	The paper addresses the challenge of survival time prediction with censored data, either by patients leaving the study or by patients living longer than the study ran. The authors suggest a pseudo-label approach to estimate labels for the missing data and establish different loss functions that can be used in this case. The proposed approach is evaluated on two datasets and compared to other methods.	This paper proposes a semi-supervised learning method for patient survival time regression with censorsed and uncensored pathology and x-ray images based on the lower-bound time to death and peudo labels. The proposed method is evaluated on two public datasets and achieve improved performance.
086	CephalFormer: Incorporating Global Structure Constraint into Visual Features for General Cephalometric Landmark Detection	The paper presents a two-stage framework for 2D and 3D landmark detection. It first detects the coarse landmark by a unet network inserted with CephalFormer Block and then refines the landmark by a sequence of CephalFormer Block, where the Transformer explicitly takes the global structure constraint. The method outperforms the state-of-the-art methods on two public cephalometric landmark detection datasets and a real-patient dataset.	The manuscript proposed a two-stage method with transformer-based neural networks for 2D/3D cephalometric landmark detection. The proposed method utilizes a transformer-based network for coarse predictions of landmarks, and uses self-attention layers to refine landmark prediction combining information of high-resolution image appearance and low-resolution predictions. Moreover, the experimental results validated model performance of the proposed method on three different data sets.	To adaptively encode the landmark's global structure constraint into the representation of visual concepts and avoid large biases in landmark localization. This paper proposed CephalFormer, which exploits the correlations between visual concepts and landmarks to provide meaningful guidance for accurate 2D and 3D cephalometric landmark detection. By evaluation on two public datasets, experiments show that CephalFormer significantly outperforms the state-of-the-art methods.
087	Cerebral Microbleeds Detection Using a 3D Feature Fused Region Proposal Network with Hard Sample Prototype Learning	This paper proposes a single-stage 3D deep learning method for automatic detection of cerebral microbleeds based on susceptibility-weighted imaging (SWI) and the phase images. Compared to the literature, the study removes the need of a second-stage learning for reducing false positives. Instead, it adds a feature fusion module (FFM), as well as a hard sample prototype learning (HSPL) approach. Collective strategies seem to outperform existing models.	The authors propose a novel single-stange deep convolutional neural network that combines a 3D-Unet with the Region proposal network (of Faster R-CNN) as well as a feature fusion module and a convolutional prototype learning-based loss term to detect cerebral microbleeds in SWI MRI.	This paper proposes a single-stage deep learning framework for the automatic detection of cerebral microbleeds. The structure of the net consists of an initial encoding based on the 3D U-Net while the decoding part is merged with a region detection network (YOLO-based).
088	CFDA: Collaborative Feature Disentanglement and Augmentation for Pulmonary Airway Tree Modeling of COVID-19 CTs	Authors propose to augment features in a siamese-like Unet between healthy and COVID-19 affected CT images. Specifically, healthy and COVID-19 image crops are passed into the neural network and their feature representations are permuted and concatenated at different resolution levels. This approach allows to learn the structure of the airway tree and improve segmentation quality for damaged lungs.	A collaborative feature disentanglement and augmentation framework is proposed for the segmentation of airway trees. This method can jointly exploit labelled clean CT scans and a small amount of labelled noisy CT scans to train a bias-discriminative encoder for the segmentation.	This paper utilizes a disentanglement way to tackle clean and noisy domains, aiming to synergistically learn intrinsic features and independently learn unique features for  airway segmentation of noisy COVID-19 CTs.
089	Characterization of brain activity patterns across states of consciousness based on variational auto-encoders	VAE applied to dFC	In this paper, the authors proposed a dense variational auto-encoder (dVAE) to generate low-dimensional representations which map dynamic functional connectivity to probably distributions. The dVAE model was validated on dataset with five rhesus macaques in different arousal states. A connection-wise receptive field (FR) analysis is then to visualized and interpret encoded trajectories between states of consciousness. The VAE-VIENT framework provides a complete definition of the latent space in terms of wakefulness status and dynamic brain trajectories.	This paper proposes characterization of brain activity patterns across states of consciousness based on variational auto-encoders, via analysis of the resulting low-dimensional latent feature space. The proposed method is experimented on a primate dataset and the results show that it can reconstruct the average pattern of each brain state with high accuracy, generate a latent feature space stratified into a base of brain states, and reconstruct new brain states coherently and stably.
090	CheXRelNet: An Anatomy-Aware Model for Tracking Longitudinal Relationships between Chest X-Rays	The authors present CheXRelNet, an anatomy-aware model for tracking longitudinal relationships between chest X-rays. The proposed approach allows the authors to perform diagnosis and monitoring of a patient through comparisons of sequential chest X-rays. The method takes 2 sequential chest X-ray images of a patient and evaluate disease change.	This paper works on monitoring the changes of pathological findings in Chest X-rays (CXRs), i.e., given a pair of two sequential CXRs, to predict whether a finding is improved or worsened. The authors propose to leverage both global information from the whole image and local information from the given anatomical region bounding boxes for the prediction. They use pathology co-occurrence to construct a graph and build CheXRelNet based on the graph neural network to merge information. Experiment results show that the proposed CheXRelNet outperforms the separate global and local baselines on the Chest ImaGenome dataset.	The study proposes using a graph attention neural network to learn the correlations between the follow-up CXRs to track the pathological change. The model considers both local and global visual features. The experiment compares the proposed approach (local+global) with the local-only model and global-only model.
091	ChrSNet: Chromosome Straightening using Self-attention Guided Networks	"The proposed method straightens images of curved chromosomes, to allow easier analysis of their properties.
It applies a DNN, self-attention layers, a U-Net refinement layer, and a loss function tailored to the use-case.
Ironically, a key finding (though not acknowledged as such) is that the extra architectures beyond the basic DNN have little-to-no effect (table 2). To the authors' credit, they do not obscure this finding."	"The paper proposes a novel chromosome straightening approach using
self-attention guided networks.
The method combines low-level details and global contexts to recover banding patterns.
This study creates mappings between straight and curved chromosomes for
chromosome straightening."	this method introduces a new neural network based machine learning method for chromosome straightening, with good contribution of its machine learning method and its biological impacts.
092	CIRDataset: A large-scale Dataset for Clinically-Interpretable lung nodule Radiomics and malignancy prediction	The authors propose an end-to-end trainable deep learning architecture for combined lung nodule malignancy classification as well as vertex-wise spiculation and lobulation classification from thoracic CT scans. The architecture is a slightly extended version of Voxel2Mesh. The extension mainly focuses on adding the classification heads. Moreover, the authors provide lung nodule segmentation masks, spiculation/lobulation annotations, and area distortion maps for the publicly available LIDC and LUNGx data sets. Those data sets are also used to quantitatively evaluate the proposed method.	"almost 1000 annotations of lung nodules for open datasets, including segmentation masks and classification w.r.t. spiculation
approach to segment lung nodules, classify speculations, and estimate malignancy in one network architecture"	The authors propose a method combining shape features and deep features (both based on Voxel2Mesh) in an end-to-end model for the automatic prediction of lung cancer malignancy. The motivation for the use of Voxel2Mesh is to extract spiculations on the lung nodule surface, which are predictive of malignancy, without smoothing the contours. The authors therefore extend the use of Voxel2Mesh to a multi-class problem to segment nodules, and classify vertices into 3 classes: nodule, spiculations and lobulation. Spiculations annotations are performed on the public LIDC-IDRI dataset for training/validation (annotations and code will be made publicly available upon acceptance). The models are evaluated on one internal and one external test set.
093	Class Impression for Data-free Incremental Learning	The author presents a data synthesis strategy using learned neural network parameters for data-free incremental learning. Multiple loss functions are introduced to mitigate the catastrophic forgetting problem. The proposed scheme is applied in echocardiogram view classification and demonstrates its efficacy.	The authors propose a data-free class Incremental learning method, and they show that the proposed framework which combines the pseudo images generation and three novel losses can provide the accuracy improvement for sequences of medical images classification tasks.	The authors propose Class Impression, a novel data-free class incremental learning framework. In Class Impression, instead of saving data from classes in the earlier tasks that are not available for training in the new task, they synthesize class-specific images from the frozen model trained in the last task.
094	Classification-aided High-quality PET Image Synthesis via Bidirectional Contrastive GAN with Shared Information Maximization	The paper proposed a framework for low-dose PET reconstruction. The method consists of three components: a domain alignment module to regularize the consistency of the shared information between low-dose and standard-dose PET, a contrastive learning strategy to enhance domain-independent information, and a classifier to ensure the accurate diagnosis-related features.	In this paper, the authors hypothesized that the abundant shared content and structure information between LPET and SPET can help improve image synthesis performance. Based on this, the authors proposed a BiC-GAN framework that contains a master network and an auxiliary network to extract shared information from LPET and SPET. Both networks implement intra-domain reconstruction and inter-domain synthesis tasks, aiming to extract shared information from LPET and SPET domains, respectively. Additional contrastive learning and classification tasks were also used to boost the performance. The proposed method achieved results comparable to the state-of-the-art methods.	The paper studies how to generate high-quality standard-dose PET synthesis from low-dose PET images. The authors propose a bi-directional contrastive generative adversarial network (BiC-GAN), including a master network and an auxiliary network, for intra-domain reconstruction and inter-domain synthesis tasks. Moreover, a domain alignment module is designed to maximize the mutual information from two domains. Also, the mild cognitive impairment (MCI) classification task is incorporated into PET image synthesis. The authors demonstrate the robustness of the method compared with the state-of-the-art qualitatively and quantitatively.
095	Clinical-realistic Annotation for Histopathology Images with Probabilistic Semi-supervision: A Worst-case Study	This paper proposes a new semi-supervised segmentation method for histopathological slides. The originality consists in annotating only a single polygon on the major tumor site and give a rough estimation of the tumor/tissue area ratio.	"This paper proposed a annotation strategy for histopathology images. A semi-supervised learning method with probabilistic week supervision is designed to verify its effectiveness on Camelyon 16 dataset under ""worst-case"" setting. The idea seems interesting and refreshing."	This paper studies an interesting topic in clinical-realistic annotation for histopathology images. It poses several key components that are neglected but could be critical in histopathology image annotation, including localization and boundary delineation. To address them, this paper proposes different annotation strategies for slides with different annotation burdens. Especially, this paper proposes a probabilistic weak-supervision training pipeline, which is novel to me. The overall results are promising. In particular, different baseline methods, e.g., MixMatch or SimCLR can be improved by the probabilistic ratio supervision with a considerable margin.
096	CLTS-GAN: Color-Lighting-Texture-Specular Reflection Augmentation for Colonoscopy	The paper presents a method for creating synthetic colonoscopy images using CT imaging and that the authors term a CLTS-GAN.  the CLTS-GAN is trained using an unsupervised approach, it allows texture and lighting to be disentangled.  The authors also demonstrate the utilty in using the CLTS-GAN to improve segmentation in colonoscopy images	This paper proposes a one-to-many image-to-image data augmentation model for colonoscopy whereby image attributes such as colour, lighting, texture and specular reflexion are controlled by means of 1D vectors and 2D matrices.	The authors propose a method for the augmentation of colonoscopy images by changing color, lightning, texture and specular reflections of the original images which is realized by controlling noise parameters for color/lightning and texture/specular, respectively. The framework maps optical colonoscopy images (OC) to virtual ones (VC), extracting color/lighting and texture/specular feature representations (G). A second generator (F) generates OC from VC using color/lighting and texture/specular noise. The framework is trained end-to-end using a combination of GAN loss, cycle consistency loss, and additional regularization losses. The authors evaluate their method in the context of data augmentation for three datasets.
097	Collaborative Quantization Embeddings for Intra-Subject Prostate MR Image Registration	This paper proposed a HiCo-Net for prostate MRI registration. The proposed HiCo-Net introduced a hierarchical quantizer with a collaborative dictionary to regularize the global and local feature maps of the CNN to generate a better deformation field. Experimental results showed that the proposed method can outperform other state-of-the-art methods in multiple evaluation metrics.	This paper describes an approach for (prostate) image registration. Conjecturing that deep networks for this task are overparameterized and that the feature space can be clustered into few groups, the authors devise a vector quantization approach improving performance.	This paper proposes a hierarchical collaborative quantization embedding for the image registration network to address the potential overparameterization problem. The authors also validate their proposed method on a private dataset.
098	Combining mixed-format labels for AI-based pathology detection pipeline in a large-scale knee MRI study	This paper proposes a method for training neural nets from positional-class pair labels. The authors develop and validate their idea on knee MRI datasets.	The paper presents a two-stage method for classification of 4 abnormalities from knee MRI. The first stage performs rough detect localization, the second - binary classification. The authors put focus on the data-centric aspects - heterogeneity of the available MR images and the corresponding annotations across institutions - and study the relative importance of positional (point location) and categorical (defect grade) labels in detection of knee abnormalities. The results are three-fold: (I) combining positional and categorical labels was shown to be beneficial for the overall performance, with the proposed automatic method reaching the level of inter-reader agreement, (II) data augmentation done also between the stages lead to further performance increase, (III) training with diverse multi-institutional data (25 locations) yielded high performance also on the unseen public dataset obtained with a different MR protocol, which support the importance of combining the datasets.	Interesting study exploring use of both text level global labels and pixel level annotations for anomaly detection on multiple tasks. The study is conducted on a large dataset making ablation results comprehensive. The validation of model with public dataset is notable.
099	Combining multiple atlases to estimate data-driven mappings between functional connectomes using optimal transport	This paper proposed a all-way optimal transport algorithm that combines information from multiple source atlases to estimate a connectome close to the target one. As an application, predicted connectome was used to predict IQs and yielded a equivalent performance as the target one.	"This paper addresses a problem when you have a large rsfMRI dataset processed to form a connectome using one atlas, and you want to compare with a connectome generated with another atlas. Normally, you would have to reprocess your dataset with the second atlas in order to make a comparison. This problem exists because there are several widely used atlases used in connectomics research. Previously it was proposed to use optimal transport algorithm to transform connectome based on a single atlas into a connectome based on a second atlas, using just a subset of ""training"" subjects processed with both atlases. Here, the authors show that a connectome can be predicted better if the training dataset is processed with multiple existing atlases."	The authors explore the optimal transport method to estimate the mapping of brain connectomics form multiple source atlases, unlike widely used single source atlas, to a target atlas improving better estimation. For this a paired time-series is taken from 'k' different source atlases with a linear combination of ns regions and compared to the target atlas distribution (as distance minimisation of two pdfs). An iterative Sinkhorn algorithm is used to solve the equation using existing Optimal Transport toolbox [11].
100	Computer-aided Tuberculosis Diagnosis with Attribute Reasoning Assistance	This paper introduces new large-scale TB dataset for attribute-assisted X-ray diagnosis and help models conduct weakly-supervised TB detection. This paper also proposes an multi-scale attention-based feature interaction module to enhance TB detection.	It proposes a new large scale tuberculosis (TB) chest X-ray dataset, namely tuberculosis chest Xray attribute dataset (TBX-Att), and establishes a attribute-assisted weakly supervised framework to classify and localize TB by leveraging the attribute information to overcome the insufficiency of supervision in WSL scenarios.	The paper describes a new chest X-ray (CXR) tuberculosis dataset that contains disease attributes in addition to TB labels. A novel multi-scale feature interaction model for TB attribute detection and classification is also described. Majority of existing TB CXR datasets contain only disease identifying labels (TB, healthy, sick/no TB). However, there are many other clinical features that may be of interest to clinicians during diagnosis. To address this, the paper presents a TB CXR dataset with attributes (e.g., fibrotic streaks, pulmonary cavitation etc.) to facilitate computational analysis and reasoning about different TB properties.
101	Conditional Generative Data Augmentation for Clinical Audio Datasets	The paper presents a GAN based method for augmentation of clinical audio data by synthesizing log-mel spectrograms. Furthermore, the paper demonstrates that the augmented data can help to improve the classification of various clinical actions flow by using a resnet-18 classification model.	The paper introduces a new clinical audio dataset, which records the sounds of different surgical phases during the Total Hip Arthroplasty (THA) procedures in the real-world operating room. A GAN-based model equipped with Wasserstein loss and Gradient Penalty is proposed to enlarge the dataset. Based on the augmented dataset, the method shows the improvement on the phase classification task, compared with other data augmentation strategies.	The authors present a Wasserstein GAN based method for augmentation of audio based classification tasks for medical applications.  The authors show an improvement in classification performance of a classifier trained with the data augmented with the GAN.
102	Conditional VAEs for confound removal and normative modelling of neurodegenerative diseases	"The authors aim to detect outliers (neurodegenerative diseases) from learning a distribution of atrophy patterns from healthy MRI.
Healthy Brain MRI from Biobank were processed using Freesurfer, resulting in gray matter volume of 16 subcortical nuclei and 66 neocortical areas (so presumably 82 features per scan). A variational autoencoder was used with a latent space of dimension 10. Additional variables are added as condition (input to encoder and concatenation of latent space).
The proposed criteria for detecting outliers is a z score over the latent space."	The paper proposes a normative modeling framework with confounder removal for Alzheimer's disease datasets.	"The authors proposed a latent deviation metric and use it to quantify deviations in individual subjects with neurological disorders. They claim model is able to identify these disease cohorts as deviations from the normal brain in such a way that
reflect disease severity."
103	Consistency-based Semi-supervised Evidential Active Learning for Diagnostic Radiograph Classification	A Consistency-based Semi-supervised Evidential Active Learning framework (CSEAL) is presented in this submission to mitigate the data annotation problem in supervised learning for radiological image classification, where consistency-based semi-supervised learning is combined with uncertainty-based active learning. The proposed CSEAL is applied to enhance four types of consistency-based semi-supervised learning methods. Evaluation on NIH-14 Chest X-Ray dataset is performed to demonstrate the effectiveness of the proposed method.	The paper proposes a method to leverage both semi-supervised and active learning for the task of X-ray classification. The proposed method, called CSEAL, can be applied to any consistency based semi-supervised learning method - the paper applies it to Pseudo-labelling, Virtual Adversarial Training, Mean Teacher and NoTeacher. Experiments on chest X-ray classification show that combining with active learning does improve performance compared to other semi-supervised + active learning methods.	The authors proposed a new method (CDSEAL) to enhance existing consistency-based semi-supervised learning methods. They compare it with existing semi-supervised active learning algorithm and show that their method improve over the baseline. On top of the semi-supervised learning, authors introduced an uncertainty estimation for active learning. The results show that it improved over random sampling.
104	Consistency-preserving Visual Question Answering in Medical Imaging	"*	The paper proposes a VQA model with focus on consistency across model replies, to ensure that the model doesn't contradict itself when answering multiple questions over same image."	This paper proposes a method that enforces VQA consistency specifically by regularizing the answers to perception questions and to reasoning questions. The authors demonstrate improvements on model consistency as well as model accuracy in diabetic macular edema staging.	"This paper proposes a novel loss function and corresponding training procedure that allows the inclusion of relations between questions into the training process. The proposed method is evaluated on  Diabetic Macular Edema
(DME) staging from fundus imaging and showed that proposed method outperforms state-of-the-art baselines, not only by improving model consistency, but also in terms of overall model accuracy."
105	Context-Aware Transformers For Spinal Cancer Detection and Radiological Grading	This paper presents spinal context transformer, a deep learning architecture considering context from multiple sequences and neighboring vertebrae, for spinal cancer detection and radiological grading. In this study, the training labels of the spinal cancer detection task was obtained from free-text radiological reports, avoiding the necessity of annotating the images.	The paper describes a method for vertebrae analysis using an algorithm relying on transformers. The authors focus in particular on vertebrae classification using multiple MRI sequences. Particular attention is drawn to weak supervision, as the labels are extracted from clinical reports. The authors perform the evaluation on the Genodisc dataset and compare the method to some state-of-the-art works. Moreover, some ablation is performed regarding the contribution of the sequences being used.	The paper proposes a Spinal Context Transformer (SCT) for a variety of spine-related tasks in multi-series spinal MR scans. It also proposes strategies to use annotations derived from reports. Experiments on two datasets show improved accuracy.
106	Context-aware Voxel-wise Contrastive Learning for Label Efficient Multi-organ Segmentation	This paper develops a voxel-wise contrastive learning (CL) method to utilize both labeled and unlabeled data in partially labeled dataset to improve the multi-organ segmentation.	"1) A novel loss function that can be used to train a multi-organ segmentation network based on both labeled and unlabeled information in partially labeled datasets.
2) A contrastive learning method is proposed to learn better feature representation.
3) Comprehensive study for the proposed method."	The authors proposed a context-aware voxel-wise contrastive learning method to train a network on partially labeled dataset.
107	ConTrans: Improving Transformer with Convolutional Attention for Medical Image Segmentation	The paper introduces the Swin Transformer to medical image segmentation and develops a hybrid network leveraging CNN's local information extraction ability and Transformer's long-range dependencies. This model outperforms both CNN and Transformer's previous SOTA methods.	This manuscript proposes a hybrid architecture termed ConTrans for medical segmentation. It not only exploits CNN's capacity in capturing detailed local information, but also leverages Transformer to build long-range dependencies and global contexts. Extensive experiments on four typical medical segmentation tasks across ten public datasets demonstrate its effectiveness.	The authors propose a model that combines features from Swin Transformer and a well-designed CNN to perform medical image segmentation. A feature integration module named spatial-reduction-cross-attention (SRCA) module are also proposed for effectively fusing the two-style features. Extensive experiments are performed on various datasets to show the effectiveness of the proposed methods.
108	ContraReg: Contrastive Learning of Multi-modality Unsupervised Deformable Image Registration	The authors propose a new approach for multi-modal image registration that uses patch-wise features to learn a multi-scale multi-modality embedding space for the loss function.	"In this work, the author introduces a new contrastive loss for deep learning multimodality registration. Three networks are used : a registration network, a T1 auto-encoder and a T2 autoencoder. The deformed image and the reference image pass through the two auto-encoder and the loss is calculated between their projection.
The author also used a hypernetwork to choose the regularisation parameter lambda."	The authors present a new approach for unsupervised Deep Learning-based multimodal image registration. Their approach builds on contrastive learning techniques and is validated on the registration of brain image data from the Human Connectom Project and compared to other current approaches and variants of the proposed method.
109	Contrast-free Liver Tumor Detection using Ternary Knowledge Transferred Teacher-student Deep Reinforcement Learning	A ternary knowledge transferred teacher-student DRL (Ts-DRL) for liver tumor detection that is contrast-free (without the use of chemical injection) which is safe, speedy, and inexpensive technology.	This paper presents contrast-free liver tumor detection using ternary knowledge transferred teacher-student deep reinforcement learning. The test results are also provided.	This paper enhance the previous work WSTS by integrating additive teacher model features into the teacher-student based DRL framework with a novel P-strategy. Experiments show that the proposed method outperforms previous baseline methods.
110	Contrastive Functional Connectivity Graph Learning for Population-based fMRI Classification	The paper proposes a method to encode functional connectome features by using contrastive learning to obtain embeddings that are then used as inputs to graph convolutional networks for disease classification	The authors proposed a contrastive learning framework for population-based fMRI classification. Th proposed framework contains two parts: 1) constrastive graph learning and 2) dynamic graph classification. By employing both of the two parts, the proposed framework is able to outperform all the other benchmarks.	"In this paper, the authors propose contrastive learning of functional connectivity graph for population-based fMRI classification. In addition, a population graph is constructed for dynamic graph classification.
They perform experiments on ADHD datasets. The results show that the proposed method outperforms baseline methods."
111	Contrastive learning for echocardiographic view integration	In this work they fuse two Echo views (A2C and A4C) to estimate the LV volume. The main contributions are the intra-subject contrastive loss and inter-subject contrastive loss which are proven to improve the performance of the model.	This paper proposed a contrastive learning method for view fusion to estimate LV volume in echocardiographic examination. Results on CAMUS dataset illustrate the effectiveness of the proposed approach.	"This work presents a volume contrastive network used to derive the left ventricle volume (a 3D measurement) from Apical-2-Chamber and Apical-4-Chamber 2D echocardiographic views.
The main contributions are tackling the 2D fusion information to generate 3D measuements and introducing intra and inter volume contrastive losses to improve this fusion"
112	Contrastive Masked Transformers for Forecasting Renal Transplant Function	"They propose the use of contrastive schemes, generating informative manifolds of DCE MRI exams of patients undergoing renal transplantation. Different self-supervised and weakly-supervised clinical pertinent tasks are explored to generate relevant features using the cosine similarity.
They introduce a transformer-based architecture for forecasting of serum creatinine score, while proposing a tailored method to deal with missing data. In particular, Their method is using a key mask tensor that highlights the missing data and does not take them into account for the training of the sequential architecture. Such a design is very robust with respect to the position and number of missing data, while it provides better performance than other popular data imputation strategies."	"They have twofolds in thier contributions:-

They propose the use of contrastive schemes, generating informative manifolds of DCE MRI exams of patients undergoing renal transplantation. Different self-supervised and weakly-supervised clinical pertinent tasks are explored to generate relevant features using the cosine similarity.

They present a transformer-based architecture for forecasting of serum creatinine score, while proposing a tailored method to deal with missing
data."	"Contrastive Masked Transformers for Forecasting Renal Transplant Function
This paper presents a methodology for forecasting renal transplant function based on contrastive masked transfoms. Overall, the problem is interesting. However, the paper needs more work to be presented in the prestigious conference."
113	Contrastive Re-localization and History Distillation in Federated CMR Segmentation	The manuscript proposes an approach for the cross-center and cross-sequence cardiac segmentation problem following a federated learning framework. To deal with the distribution shift problem between clients and the server, a contrastive re-localization (CRL) module is applied which is facilitated by a cross-attention transformer. The optimization of the local client models are assisted by a momentum distillation module which stores the its own training history. An ablation study and a comparison with other federated learning approaches are conducted using Dice similarity index as the metric for accuracy.	Authors have proposed a federated learning framework, specifically suited for datasets with imbalanced distributions, where some datasets are more heterogeneous than the rest of the clients. Their method reduces representation bias in the model fusion and overcomes optimization stop in the model replacing. Their method FedCRLD uses a contrastive difference metric for the former purpose and uses a momentum distillation strategy for the latter.	A CRL module that corrects the server bias in federated learning is proposed and supposedly validated.
114	Contrastive Transformer-based Multiple Instance Learning for Weakly Supervised Polyp Frame Detection	The paper introduce a novel robust anomaly video classification method to detect polyp frames in colonoscopy videos.	This paper proposes a weakly-supervised framework based on transformers and a contrastive snippet mining approach to identify frames with abnormality (eg. Polyps) from colonoscopy video frames. An imbalanced dataset is collected from publicly available colonoscopy data and used in this work. The method is compared against some SOTA work and the results indicate better performance in abnormality detection.	The authors propose to use I3D to extract features from colonoscopy videos for the convolutional transformer to achieve Polyp Frame Detection. The authors utilize multiple instance learning (MIL) and contrastive snippet mining (CSM) to further improve the performance of the model. Experiment results show that their proposed method can outperform some SOTA methods for Polyp Frame Detection on a new dataset.
115	Coronary R-CNN: Vessel-wise Method for Coronary Artery Lesion Detection and Analysis in Coronary CT Angiography	The paper discuss a two stage cascade neural network to detect and classify abnormal regions in a coronary artery. The first neural network is used for detection and the second neural network is used for classification of the abnormal regions into plaque type and degree of stenosis. The authors discuss their results and compare them with other existing methods.	This paper presents a deep learning based method for coronary artery lesion detection and analysis. It incorporates Faster R-CNN and a multi-task network for lesion detection, plaque classification and stenosis degree regression.	"(1) This paper proposed a novel vessel-wise detection architecture inspired by Faster R-CNN To the best of our knowledge, it is the first application of this type of method on coronary artery lesion detection.
(2) This paper proposed a multi-head analysis module that can predict not only plaque types but also the exact stenosis degree, rather than just significant stenosis classification.
(3) This paper achieved an outstanding performance on a dataset consisting of 1031 CCTA images with 7961 vessels."
116	CorticalFlow++: Boosting Cortical Surface Reconstruction Accuracy, Regularity, and Interoperability	In this paper, the authors propose an upgraded cortical surface reconstruction pipeline upon CorticalFlow. The efforts exist in three perspectives: a more accurate ODE solver, a sommther template generation routine, and a deformation process from white surface to pial surface.	"This paper improves the cortical flow method in the following 3 aspects:

Using the Runge-Kutta method to replace the forward Euler method to improve computation efficiency and the approximation accuracy.
Using a genus zero smooth mesh templates to replace the convex-hull template in the cortical flow method.
Using the predicted white surface to further predict the pial surface, which can build the vertex-wise correspondence between white and pial surface."	The paper presents cortical surface reconstruction using neural nets. The underlying architecture follows what was originally proposed in CorticalFlow. The authors propose the RK4 ODE solver, cortical shape-like template, and pial reconstruction from the WM surfaces. The experimental results show improved performance over the original CorticalFlow and also compare with a single baseline method (PialNN).
117	CRISP - Reliable Uncertainty Estimation for Medical Image Segmentation	The paper aims to integrate anatomical prior knowledge into uncertainty estimation via a novel method called CRISP via contrastive learning where the valid segmentations to the corresponding images are defined as positive samples.	The authors introduced the nearest neighborhood ensemble in the latent space as an uncertainty estimation. For that, the authors leveraged contrastive training between image and segmentation. The final uncertainty map is obtained from a weighted sum of error between the predicted mask and the k-nearest ground truth masks from the training data.	"The paper proposes a method for uncertainty estimation for image segmentation.
The proposed architecture consists of a segmentation (shape) encoder, segmentation decoder, and image encoder.
The architecture is trained such that image and corresponding shape representations are mapped to a similar location in the latent space while at the same time segmentation autoencoder is trained to reconstruct shapes.
In test time, an image is encoded and M shape representations from the training set closest to the encoded image representation are found. Also, the most similar M images are reconstructed in the shape decoder.
Uncertainty map is obtained as the weighted sum of the differences between the predicted segmentation and the reconstructed M shapes.
Experiments are performed on 4 different datasets and the results are compared LCE, ConfidNet and MC_Dropout which shows improvement in many cases."
118	CS2: A Controllable and Simultaneous Synthesizer of Images and Annotations with Minimal Human Intervention	This paper presents a method to synthesize images and labels for medical image segmentation. The method is technically sound. It is compared with three strong baseline methods on both in-house and public datasets and delivers promising results.	The paper describes a novel approach for synthetic CT generation. There are two key ideas. First, it is important to combine both masks and noise vectors into the generation process, that on one hand, allows controllable synthesis, and on the other, can learn a large variability of images. Second, by using modified Hounsfield unit (HU) maps as a replacement for traditional binary/class maps, more structural information is encoded into the model. Experiments demonstrate that the proposed method creates more anatomically correct CTs and demonstrates competitive results with respect to semantic segmentation.	"The authors propose a new medical image synthesis method based on AdaIn GAN and average HU value assignment.
With their contribution, the authors claim that less number of annotated images are required to produce more realistic synthetic images that can aid final segmentation output."
119	Curvature-enhanced Implicit Function Network for High-quality Tooth Model Generation from CBCT Images	The paper presents a method for generating high quality tooth reconstructions from CBCT scans using superresolution ideas based on implicit function networks and a curvature enhancement for the tooth crown surface based on k-NN based features and a CNN regression.	"The paper presents a method for 3D tooth model construction from CBCT and intra-oral images with implicit function networks (ICT). The motivation of the paper is to combine the intra-oral scans and CBCT images for better root and crowns due to limited resolution of CBCT images.
The method is validated on a dataset of 50 subjects where 20 of them are test data. The method outperforms the compared methods."	"key idea is to combine the commonly used CNN-based segmentation
network with an implicit function network to generate 3D tooth models
with fine-grained geometric details"
120	DA-Net: Dual Branch Transformer and Adaptive Strip Upsampling for Retinal Vessels Segmentation	The authors of this paper propose a novel architecture for retinal vessel segmentation by combining image and patch level information in a joint encoder-decoder model. Their approach combines regional and global features from the encoder and introduce them to a transformer module. The transformer output is then decoded with an adaptive, line like, stip upsampling block. Compared to the existing work, they introduce the transformer module to fuse features from two different scales and they modify the standard decoding part of the existing architectures to take into account more context from the regions along the length of the vessels. The authors validate their approach on 2 widely used public databases. Compared to existing methods, the method outperforms existing work in the literature.	The paper proposes DA-Net for retinal vessel segmentation. The design of the network addresses limitations of image-wise and patch-wise approaches by combining them in a single network with a dual branch transformer. Also, the paper presents an adaptive strip upsampling method to better mimic tubularity of vessels. The proposed method is validated on two fundus images datasets; Drive and CASE-DB1 and shown to outperform previous methods	The paper proposes a patch and non-patch combination retinal vessel segmentation network, including a shared-weights U-net like encoder and decoder for patch and non-patch training and a transformer module for combining them in the latent space.
121	D'ARTAGNAN: Counterfactual Video Generation	The paper introduced an approach to generate counterfactual images. The approach built upon Deep Twin networks and proposed a new architecture. The model has been assed on two datasets.	D'ARTAGNAN (Deep ARtificial Twin-Architecture GeNerAtive Networks) answers the question what would this echocardiogram look like if the patient had a different ejection fraction?	This paper focuses on computing counterfactual queries for echocardiograms. The authors proposed a method called D'ARTGNAN that combines deep neural networks, twin causal networks, and generative adversarial learning. The model is tested on a synthetic dataset and a real-world echocardiogram dataset.
122	Data-Driven Deep Supervision for Skin Lesion Classification	Authors present a Class Activation map based deep supervision method for training skin image classification model. They highlight that due to absence of object-level labels, the models are deemed to the restricted to image level information and feedback for most classification problems. They propose the use of effective receptive fields as a deep supervision mechanism to solve this problem to some extend and boost the classifier performance. The also present a layerwise effective receptive field determination strategy to make the mode in variant to the size of the object within the field of view.  The resulting  model is tested on several skin image datasets	The paper shows that adding deep supervision to the layer whose effective receptive field size approximately matches the average object size, improves the performance of a skin lesion classification model.	This paper proposed a supervision generation method for skin lesion classification, where the total framework composes a LERF module, morphological object size approximation, and deep supervision. The experimental results on several skin lesion datasets have shown the better performances.
123	Data-driven Multi-Modal Partial Medical Image Preregistration by Template Space Patch Mapping	Presents a method for partial image registration of 3D rotational angiography (3DA) and CT angiography of the head. Their model combines several blocks to predict the location of patches in the template space and a transformation. They demonstrate improvement over 4 baseline method in measuring distance from ground truth anchor points.	The authors propose a deep learning-based method to perform the initial rigid registration of two images (especially when one image has a much smaller field of view) in order to provide an accurate starting point (based on translation only) for a second registration refinement. This effectively gets the second refinement registration out of many local minima. The proposed method utilizes a common template space with multiple sub-patches from the moving image to infer the initial transformation and then utilizes a standard registration approach for refinement. Experiments rigidly registering multi-modal 3D rotational angiography and CT angiography demonstrate the approach.	The paper introduces a method that aims to improve the initialization for other local-search registration in rigid multi-modal partial image registration. Instead of doing a direct matching, the 2 images are matched to a common template space. The method works for images of diverse sizes, and for partial volumes
124	DDPNet: A novel dual-domain parallel network for low-dose CT reconstruction	The paper provides a novel dual-domain parallel network for low-dose CT reconstruction. The network is composed of a dual-domain parallel architecture, a unified fusion block and a pair of coupled patch-discriminators. The proposed method achieved good noise reduction and structure maintenance.	The authors proposed a Dual-domain parallel network (DDPNet) for low-dose CT (LDCT) reconstruction. A parallel structure is proposed to make parallel optimization between sinogram and image domains streams to reduce the cumulative error caused by the process of the sinogram domain denoising. The dual-domain information is used complementarily by Interactive Information Flow (IIF) mechanism. Then the authors design a triple-cross attention block to fuse features from two domains.	The authors propose a novel DDPNet for low-dose CT denoising. They design special modules for DDPNet, including dual-domain parallel architecture, a unified fusion block using multi-head attention and coupled patch-discriminators. Extensive experiments prove the effectiveness of each module and the best performance of DDPNet.
125	Decoding Task Sub-type States with Group Deep Bidirectional Recurrent Neural Network	This paper uses a single classification model to simultaneously complete multiple brain function network decoding tasks under different external stimuli. The authors proposed a multi-scale random segment preprocessing and multi-task interaction layer to realize a single model's perception of varying brain functional states.	"1.The authors proposed a group-wise brain function state classification network by capturing the temporal-spatial-wise context information. 
2.The proposed multi-task interaction layer can help the classification network to learn the temporal-task-wise context information between multiple brain activation states. 
3.The proposed method improves the performance of classifying the brain activation states of multiple subtasks."	"This manuscript proposed a two layers-bidirectional GRU network to extract time-series features and the inter-class association features.
The proposed method improves the classification performance of deep neural networks for functional brain activation states decoding."
126	Decoupling Predictions in Distributed Learning for Multi-Center Left Atrial MRI Segmentation	"In this paper, the authors present a technique for performing image segmentation with federated learning while combining the two diverging tasks of global and local optimisation. Their approach draws inspiration from the probabilistic U-net, and consists of a VAE architecture and a ""DA net"", which in combination allow to tune the network's prediction to the specific local distributions. The approach is evaluated for atrial image segmentation from MRI and seems to reliably outperform the implemented baselines."	"The manuscript proposes a method extended the ideas from [1] for distributed Learning for Multi-Center Left Atrial MRI segmentation. 
The authors used the ""conditional VAE [18]"" to model the latent representation of the joint data distribution, and proposed a ""distribution adaptation network"" to generate an adaptation matrices conditioned on the joint data distribution. This is used to decouple the global and local predictions and adapts the prediction to be consistent with local distribution during testing. 
The proposed method evaluated on the constructed dataset, collected from three centers, and the results shows substantial performance improvement for global and local tasks over its competitors."	
127	Deep filter bank regression for super-resolution of anisotropic MR brain images	This paper perfect reconstruction filter banks to perform MR super resolution in the out-of-plane axis. The pipeline is split into 2 stages; stage1 randomly samples 1D row/columns from in-plane slices to train analysis and synthesis filter banks (apart from H_0 that's fixed to the PSF), and stage2 where 2D training pairs of y (output of H_0) and { d_1 to d_(M-1) } are trained with pix2pix.	"The paper does super-resolution (SR) of thick-sliced MR single-modality images by a training-free method (""self-super-resolution""), which casts recovering the unknown high-resolution (HR) image in the context of perfect reconstruction filter banks. They fit the parameters of the filter bank from 1D rows and columns from in-plane slices using gradient descent, and the detail coefficients using a regression CNN on 2D patches extracted from in-plane slices. Finally, the HR image is recovered by encoding the input image with the first set of filters, regressing the detail coefficients from the encoded image, and then decoding the coefficients with the last set of filters. The method is compared to simple resampling, which it outperforms, as well as another self-super-resolution technique where it performs favorably for larger slice thicknesses."	"(1)	This paper proposed a novel filter bank formwork for super-resolution of anisotropic MR brain images based on filter bank theory. 
(2)	The structure of the network is interpretable.
(3)	Network training does not require extra training data."
128	Deep Geometric Supervision Improves Spatial Generalization in Orthopedic Surgery Planning	"The authurs proposed an automatic landmark detection framework to identify an anatomic landmark point inside the distal femoral head called ""the Schoettle Point"". The accurate calculation of this point is of great importance for patellofemoral ligament (MPFL) reconstruction surgery. In the common practice, first relevant anatomical structures, for example, the tangent line to the posterior femur shaft cortex, are detected by optimimising a proxy objective function. Next, the Schoettle Point is calculated based on geometrical properties of the detected structures. This paper proposed a framework called 'Deep Geometric Supervision' to merge these two separate steps into one."	The authors develop a novel method to accurately identify the graft fixation site for MPFL surgery, from both diagnostic and intraop X-rays. Their method combines anatomical landmark extraction together with a model that learns the geometric relationship between landmarks to infer the fixation site.	This study jointly optimized anatomical feature extractor and the planning target in an effort to automate the surgical planning for reconstructive orthopedics.
129	Deep is a Luxury We Don't Have	This paper proposes a high resolution transformer based model HCT, in particular the attention convolution (AC) block.	Transformer has limited application in analyzing large-size medical images due to its huge computation requirements of the self-attention block. This work adopts the recent proposed Performer with reduced computing consumption to power the shallow layer of the neural network, providing a possible way to explore efficient learning for other research.	In this paper, the authors address this complexity of high-pixel medical image recognition by exploiting a linear self-attention approximation. With this approximation, the authors propose an efficient vision model called HCT, which stands for High Resolution Convolutional Transformer. Extensive case studies validate the effectiveness of the proposed HCT.
130	Deep Laparoscopic Stereo Matching with Transformers	"The paper presents a deep-learning-based method to solve the stereo matching problem involving laparoscopic images. An existing framework (reference [4]) is modified to achieve superior performance for laparoscopic applications. The authors main contributions are the following:

Use of Transformer networks in place of Convolutional NN in cost-aggregation. The authors justify this architectural change in terms of loss landscape, learning trajectory and accuracy

The proposed architecture is compared to the state-of-the-art using publicly available datasets"	This paper targets the task of stereo matching between two rectified images. Authors try to replace CNN with Transformer for learnable components of a cost-volume-based network architecture from the prior work named LEAStereo. Various visualizations have been done for loss landscape upon convergence. Experiments on SceneFlow, SCARED2019, and dVPN datasets have been conducted and the authors claim that the proposed model performs better than some of the prior works. They claim that by replacing the CNN with Transformer for feature extraction, the model results in faster convergence, higher accuracy, and better generalization.	This paper introduces a stereo matching architecture, consisting of a feature extraction network using a transformer and a matching network using a CNN. It performed extensive experiments on ablation, learning behaviours and comparisons to other methods.
131	Deep Learning based Modality-Independent Intracranial Aneurysm Detection	The authors present a novel modality agnostic aneurysm detection method	The manuscript proposes a deep learning-based, modality-independent method for intracranial aneurysm detection based on a previous extraction of the vascular surface mesh. The method was demonstrated in cross-modality and mixed-modality experiments based on 500 datasets and achieved 96% sensitivity and 0.81 false positive detections per image.	The primary contribution of this manuscript is a deep learning system to detect intracranial aneurysms, tested in both MRA and CTCA imaging. This approach shows good results compared to the state of the art and does seems robust to changes in training data, at least between MRA and CTA.
132	Deep Learning-based Facial Appearance Simulation Driven by Surgically Planned Craniomaxillofacial Bony Movement	The paper describes a method for predicting facial appearance after osteotomy.  The method uses the pre-operative bone and soft tissue surfaces of the skull and face, as well as the planned revised bony surfaces as input to a pointnet based network.	A deep Learning-based method was presented to predict the facial appearance following bony movement in this paper. The PointNet++ network was adopted to extract the point-wise features of facial and bony model. And, a novel cross point-set attention module was proposed to explicitly calculate the correspondence matrix between each bony-facial point pair. The calculated matrix was then used to predict the postoperative facial change. The proposed method was evaluated on 40 sets of CT data.	This paper describes Attentive Correspondence assisted Movement Transformation network (ACMT-Net), a method to predict post-operative facial appearance after orthognathic surgery leveraging on movements of corresponding bony segments. This is achieved by exploiting point-to-point correspondences between facial and bony points, which are estimated thanks to a novel module called Cross Point set Attention (CPSA). The proposed method is evaluated on models extracted from real CTs and it achieves comparable performance to related works in terms of accuracy, while outperforming their computational performance.
133	Deep learning-based Head and Neck Radiotherapy Planning Dose Prediction via Beam-wise Dose Decomposition	The presented work introduces a new strategy for deep-learning-based radiotherapy dose prediction. The proposed method includes two main innovations: 1) A neural network is used to predict the radiation dose along the paths of the individual radiation beams before averaging the obtained dose maps. Explicitly encoding the prior knowledge of beam-wise radiation delivery has the goal of improving accuracy along the beam paths. 2) The authors introduce two loss functions, value-based DVH loss and criteria-based DVH loss, with the aim of placing more emphasis on the dose prediction in the regions containing the tumor and critical organs. In extensive benchmarking experiments using the publicly available OpenKBP dataset, the authors show that their method outperforms seven other algorithms.	"This paper proposes a deep-learning based dose prediction method. It generates beam mask to represent an irradiation boundary as a prior knowledge, and applies ""disassembling-then-assembling"" strategy for the dose prediction."	This paper presents a framework for head and neck radiotherapy planning dose prediction, including global coarse dose prediction and beam-wise dose prediction based on decomposition and multibeam voting mechanism. Some experimental results on the public OpenKBP challenge dataset are provided.
134	Deep Motion Network for Freehand 3D Ultrasound Reconstruction	Authors proposed a new deep learning model MoNet for integration of US images. They used data from IMU for training of the MoNet.	Conventional Freehand ultrasound is utilized as tomographic imaging modality by utilizing IMU sensors together with a novel deep motion network (denoted as MoNet by the authors) for almost seamless 3D reconstruction. Thus, no exterior devices are needed anymore. Both key contributions of this paper address the IMU, on the one hand getting the elevation displacement of the planes and further to reduce the sensor drift. So this work addresses the current main challenges of Freehand ultrasound reconstruction, namely elevational displacement estimation and the cumulated drift.	"This paper describes a method to reconstruct 3D ultrasound volumes from 2D video clips and IMU signals with a deep learning-based approach.
In particular, two ideas related to the usage of the IMU information are investigasted: 
(1) the network uses the orientation but also the acceleration signal from the IMU (which is a challenge since it is very noisy)
(2) an online refinement of the prediction by trying to match the IMU signal
The method is evaluated on two datasets (carotid and arm) and yields better estimate than 3 baselines."
135	Deep Multimodal Guidance for Medical Image Classification	"The paper proposed a student-teacher method that distills knowledge learned from a better-performing (superior) modality to guide a more-feasible yet under-performing
(inferior) modality and steer it towards improved performance in two clinical tasks."	"The authors propose a method to guide a neural network with an ""inferior"" input modality based on a network trained on a superior input. The method is tested on two datasets with two different target tasks and demonstrate, that their method is even able to outperform the model trained on the superior modality."	The paper describes a multimodal / student-teacher learning approach for training classifiers to do a task based on inferior (cheaper, more accessible, more convenient, etc) medical data vs. superior (expensive, exotic, invasive, etc) medical data, and transferring information from the superior to inferior classifier to improve the performance of the inferior classifier.
136	Deep Regression with Spatial-Frequency Feature Coupling and Image Synthesis for Robot-Assisted Endomicroscopy	X	"The first approach is proposed to automatically regress the distance between a pCLE probe and the tissue surface during robotic tissue scanning.
The first pCLE regression dataset (PRD) was generated which includes ex-vivo images with corresponding probe-tissue distance.
A novel FT module to synthesise pCLE images between fine distance intervals to incorporate image level supervision into the training process."	This paper presents a network, called the spatial-frequency feature coupling network (SFFC-Net), for pCLE probe to tissue surface distance estimation. The proposed network use both the image and frequency information for distance estimation. The author also proposed a feedback training strategy to boost the training. The experimental results show successful application on pCLE,
137	Deep Reinforcement Learning for Detection of Inner Ear Abnormal Anatomy in Computed Tomography	"This paper proposes a method for inner ear abnormality detection based on a deep reinforcement learning model for landmark detection trained in normative data only.
The method is based on multiple landmark locations in CT scans using communicative and standard multiple agent reinforcement learning (C-MARL and MARL).
After landmark location, two different metrics for measuring abnormalities were defined: Variability across agents within a PCA subspace and Q-values."	The authors describe a deep reinforcement learning framework for inner ear abnormality detection that leverages landmark detection. The abnormality detection is expressed through 2 proposed methods. One approach uses a projection of proposed landmark configurations into PCA space and analyses the variability using a norm (Procrustes distance) defined in that space. The other uses the distribution of Q-values of the last ten states before landmarks are located (i.e. measurement of uncertainty of final landmark location) as a measure. They entire approach is based on using normative data and does not require learning representations of the anomalies. They conduct  tests on artificial and clinical data and the results indicate good performance.	The authors presented a framework to detect inner ear abnormality using deep reinforcement learning-based landmark localization. They used a score that combined the PCA shape distance and the Q-value history distribution to detect the abnormality.
138	Deep Reinforcement Learning for Small Bowel Path Tracking using Different Types of Annotations	The paper introduces a RL based method to extract the path of the small intestine from ct images	A reinforcement learning framework has been setup that utilises ground truth segmentation data and optionally ground truth path data to learn path tracking. The reward is computable even without the ground truth path, thus making this optional during training. Experiments were performed using CT data and ground truth labelled by a human observer. The results show improvements compared to other techniques, however, the lack of statistical tests limits the conclusions that may be drawn.	This paper presents a DRL framework to extract the centerline of the small bowel. The proposed framework can be trained on different annotations, i.e., bowel segmentation and bowel path.
139	Deep treatment response assessment and prediction of colorectal cancer liver metastases	The paper proposes a longitudinal approach to treatment response assessment via siamese networks as well as treatment response prediction from baseline image.	Authors have proposed a method to predict and assess treatment response using pre-treatment and post-treatment CT scans and deep learning. The problem is of clinical importance and the method achieved a good performance	This paper proposed a model to assess the treatment response from pre- and post-treatment 3D CT volumes. The same network architecture was also used for predicting treatment response from pre-treatment scans only. The models were trained/tested on a dataset of 102 patients with liver metastasis treated by chemotherapy.
140	DeepCRC: Colorectum and Colorectal Cancer Segmentation in CT Scans via Deep Colorectal Coordinate Transform	The paper presents DeepCRS, a method to segment colorectal cancer (CRS). DeepCRS guides the tumor segmentation using a surrogate task to locate the colorectum, allowing the model to better differentiate the target organ from the rest. The results show that the proposed approach obtains superior performance than nnUNet.	"The authors propose an extension of a UNet like method to improve segmentation of the colo-rectum and colorectal tumours.

Addition of a colorectal coordinate transform to capture positioning with the addition of a regression loss
Addition of attention to the network
This accounts for the relatively unusual shape characteristics of the colo-rectum compared to other organs."	This paper studies a segmentation problem of the colorectum (colon and rectum) and CRC in routine abdominal CT scans. The task is interesting and valuable. The idea of adopting topology information to enhance the segmentation performance is rational and novel.
141	Deep-learning Based T1 and T2 Quantification from Undersampled Magnetic Resonance Fingerprinting Data to Track Tracer Kinetics in Small Laboratory Animals	A deep learning based MRF parameter mapping method is proposed for preclinical MRF data, achieving 4-fold further acceleration compared to the baseline MRF method.	This paper presents a deep learning method to compute T1 and T2 map by MR fingerprinting in Mice that have been injected with a Mn2+ tracer. The method mostly replicates blocks that have been applied in Human before, but trained on Mouse data. An ablation study was performed.	The manuscripts presents a deep learning-based method to generate T1 and T2 maps from undersampled MRF data acquired in mouse brain pre and post Mn2+ administration. Specifically, the developed pipeline involves sliding-window cascaded modules, a U-Net to infer T1 and T2 maps, a network to generate back MRF from the inferred T1 and T2 maps, and a data-consistency module to suppress estimated errors. The performance was evaluated by means of MAPE, PSNR and SSIM and proven to be higher with the dedicated components. The approach to solve the limitations from MRF is novel and well addressed.
142	DeepMIF: Deep learning based cell profiling for multispectral immunofluorescence images with graphical user interface	"The authors develop a deep learning based framework to identify cell phenotypes for M-IF images.
The authors develop a whole slide M-IF viewer to visualize the M-IF images as well as cell detection and phenotytes."	The author proposed DeepMIF, a novel deep learning method for detecting and quantifying cell phenotypes on M-IF images. DeepMIF also includes a GUI, making it accessible to researchers with less programming background. The authors also demonstrated that DeepMIF was able to achieve effective cell classification performance.	This paper proposes a graphical user interface based on deep learning for the profiling of cells in multispectral  immunofluorescence. The paper is well writen and described and a graphical user interface would be attractive for researchers who are not interested in running scripts from the command line. As such it is an interesting contribution.
143	DeepPyramid: Enabling Pyramid View and Deformable Pyramid Reception for Semantic Segmentation in Cataract Surgery Videos	The authors proposed a U-Net based model for semantic segmentation in cataract surgery called DeepPyram. The main contribution is the inclusion of two blocks: Pyramid View Fusion and Deformable Pyramid Reception. The former is in charge of recognizing the relative information between the object and its surroundings, whereas the latter performs shape-wise feature extraction. Ablation studies and comparisons to twelve models are also presented.	This paper proposes a semantic segmentation network, which contains three modules. The main novelties of this method is a varying-angle surrounding view, shape-wise feature extraction and multi-scale semantic feature maps.	In this paper, a network, called DeepPyram, was proposed.  DeepPyram can deal with challenges posed by transparency, deformability, scalability, and blunt edges in objects. It has three novelties: a Pyramid View Fusion module, a Deformable Pyramid Reception module and a dedicated Pyramid Loss module. The authors showed that the proposed approach outperforms existing methods without imposing additional parameters.
144	DeepRecon: Joint 2D Cardiac Segmentation and 3D Volume Reconstruction via A Structure-Specific Generative Method	The contribution of the paper is a method for synthesizing 2D cardiac MR images by interpolating an optimized latent embedding, which has been obtained by an encoding-generating network architecture. A segmentation network is furthermore trained, using the synthesized MRIs as input. The interpolation technique allows for reconstructing (super-resolving) 3D images and segmentation, as well as transferring information from subjects with longitudinal data, to subjects without such data. The method is validated on the tasks of: segmentation, 3D volume reconstruction, and motion pattern adaptation.	This paper presents an end-to-end latent-space-based framework, DeepRecon, that generates multiple outcomes, including image segmentation, 3D reconstructed volume, and motion adaptation. Some cardiac datasets have been used for evaluation.	In this paper a 2D cardiac segmentation  and a 3D volume reconstruction tool is shown, and after this they obtain the 4D motion pattern shown in volume flow graphics, to probe the correct segmentation and reconstruction.
145	Deformer: Towards Displacement Field Learning for Unsupervised Medical Image Registration	This paper proposes a new deformer-based multi-scale registration method (DMR) for medical deformable image registration. The proposed Deformer module leverages the multi-head attention strategy to capture the long-range dependency between high-level features. The multi-scale architectural design and auxiliary loss from different levels further improve the registration performance. The method is evaluated on two public brain MRI datasets (LPBA40 and OASIS). Extensive quantitative and qualitative evaluations demonstrate that the DMR performs favourably against state-of-the-art methods (2 conventional methods, 2 CNN-based methods and 1 CNN+Transformer based method).	The paper propose one deep learning network to perform deformable registration. Instead of convolution operations, transformer module is used in the framework. Experiment is performed over the two public brain MR image datasets.	It proposes a novel Deformer module along with a multi-scale framework for the deformable image registration task. The Deformer module is designed to facilitate the mapping from image representation to spatial transformation by formulating the displacement vector prediction as the weighted summation of several bases. With the multi-scale framework to predict the displacement fields in a coarse-to-fine manner, superior performance can be achieved compared with traditional and learning-based approaches.
146	Degradation-invariant Enhancement of Fundus Images via Pyramid Constraint Network	The paper proposed a network architecture and loss functions to enhance the fundus images. It contains three modules, one for augmentation, one for Laplacian pyramid extraction and one for autoencoding.	The authors proposed PCE-Net for the enhancement of fundus images.  Moreover, a Laplacian pyramid is introduced to exploit the retinal structure in PCE-Net.	This manuscript proposes a pyramid constraint to develop a novel model called PCE-Net for fundus image enhancement. The work is of interest. The experimental results verifies the effectiveness of the model. I think it would be a good enhancement approach for fundus image analysis.
147	Delving into Local Features for Open-Set Domain Adaptation in Fundus Image Analysis	This paper describes a method for unsupervised domain adaptation with unknown/new classes in target domain, i.e. OSDA problem. The paper proposes a collaborative regional clustering approach to identify feature clusters, then a contrastive loss for better cluster boundary shaping.	This paper proposes a collaborative regional clustering and alignment method to explore the open-set domain adaptation (OSDA) issues in the domain of medical images. The experiments show that the proposed model can achieve consistent improvements over the state-of-the-art methods.	This manuscript proposes an open-set domain adaptation (OSDA) method for fundus image classification. The proposed method employs contrastive learning based on clusteredl assigned by k-means to align source and target features, as well as to identify private classes. This paper can be interpreted as a sensible multi-scale version of to Domain Consensus Clustering (DCC, CVPR'21).
148	Denoising for Relaxing: Unsupervised Domain Adaptive Fundus Image Segmentation without Source Data	This paper presents a method for unsupervised domain adaptative segmentation via a coarse-to-fine label denoising scheme. With pseudo labeling and uncertainty-rectified label soft self-correction, the model trained on the source domain labeled data can be further finetuned without the access to the source data. Extensive experiments demonstrate its effectiveness.	"To address the source free domain adaptation (SFDA) problem, authors present a novel uncertainty-rectified denoising-for-relaxing (U-D4R) framework. Contributions can be summarized into three aspects:
C1: Considering the unreliable pseduo labels of target data generated from source model, authors present an adaptive class-dependent threshold strategy as the coarse denoising process to generate the pseudo labels.
C2: Authors introduce the uncertainty-rectified label soft correction for fine denoising by taking advantage of estimating the joint distribution matrix between the observed and latent labels.
C3: Extensive experiments on cross-domain fundus image segmentation showed that the proposed approach outperforms SOTA SFDA methods and achieves comparable performances with source-dependent methods."	"This paper suggests a method for unsupervised domain adaptation for a scenario where  the source data is not available. Pseudo labels are generated on the target domain via an adaptive class-dependent threshold
strategy. Then, uncertainty-rectified label soft correction is introduced for fine
denoising.
They apply their approach on  multi-site retinal fundus images for the optic disc and cup segmentation, and show that they outperform existing models.
Various ablation studies are performed."
149	Denoising of 3D MR images using a voxel-wise hybrid residual MLP-CNN model to improve small lesion diagnostic confidence	"Authors propose a voxel-wise hybrid residual MLP-CNN model to denoise 3D MR images with small lesions.
The proposed method shows a good performance (SSIM and PSNR) compared to some state-of-the-art methods.
-The diagnosis confidence for small lesions is confirmed by radiologists."	The authors proposed a method for image denoising of 3D (multislice) MRI using an MLP-CNN architecture. The method processed each image patch with MLPs followed by an encoder-decoder CNN with residual connections. Results show that the proposed method outperforms other methods in terms of recovery of small lesions.	Authors propose a MLP-CNN structure for 3D MRI denoising. Compared with some other denoising methods, the proposed method shows superior results by presenting clear small lesions.
150	DentalPointNet: Landmark Localization on High-Resolution 3D Digital Dental Models	The paper presents an end-to-end deep learning-based method for the localization of dental landmarks. The method follows a coarse-to-fine strategy that generates proposals with RPN and refines them with DLLNet.  The presented method is an extension of DLLNet that first finds the candidate landmarks with RPN, then refines them with DLLNet. The method is evaluated on a dataset containing 77 patients and outperforms the state-of-the-art methods.	This paper proposes a coarse-to-fine framework to automatically localize landmarks on dental surface models. In the coarse stage, it addresses the issue of foreground/background imbalance problem by a balanced focal loss and uses the curvature as a threshold for filter predictions. In the fine stage, a DLLNet is trained to further improve the results. The proposed method achieves promising performance.	This papers presents a deep learning framework to automatically localize landmarks on dental surface models. The main contributions on the paper are the two sub-networks (Region Proposal Network and Bounding Box Refinement Network) proposed to precisely localize 3D landmarks on high-resolution 3D digital dental models. Other relevant points are the comparison of the proposed methods with other published methods using the same dataset and the possibility of applying the method to edentulous patients.
151	DeSD: Self-Supervised Learning with Deep Self-Distillation for 3D Medical Image Segmentation	This paper proposes a non-contrastive self-supervised learning method and validates it on different 3D datasets.	This paper proposes a new design for self-supervised learning (SSL) and shows its effectiveness in medical image segmentation. The proposed SSL method is based on DINO (a well-established SSL approach), where the loss is only computed at the last layer. This paper shows that it is beneficial to have supervisions (self-supervised) at intermediate layers.	This manuscript introduced a new self-supervised learning method, referred to as DeSD, by introducing deep supervision into single self-distillation. DeSD was pretrained on the DeepLesion dataset and evaluated on 7 segmentation tasks from 3 datasets. DeSD showed higher or comparable performance compared with 3 SSL methods, including SimSiam, BYOL, and DINO.
152	DeStripe: A Self2Self Spatio-Spectral Graph Neural Network with Unfolded Hessian for Stripe Artifact Removal in Light-sheet Microscopy	The proposed method removes stripe artifacts from LSFM images. It leverages domain specific information including fourier domain behaviors, and uses a graph NN to fill in suspected corrupted datapoints in the fourier domain. It combines this with an optimization in the spatial domain to encourage spatial continuity.	This paper tackles the problem of removing stripe artifacts in light-sheet fluorescence microscope images. The method models stripes as a combination of a  graph neural network on the Fourier coefficients connected in a polar coordinate structure, a spatial domain Hessian based regularization scheme. and an energy minimization scheme to seek the optimal noise reduced image. The method is analyzed on a single noise-free image-volume with repeatedly artificially added stripe noise and compared with several existing algorithms. The results are assessed wrt. peak signal to noise ratio and structure similarity measure and performs better than the existing methods. The method is also applied to a real image with favorable result.	This paper contributes a new method to remove stripe artifacts from light-sheet microscopy data. The approach is based on self-supervised learning with a graph neural network and a Hessian regularization and thus, combines both frequency and spatial domain features.
153	Detecting Aortic Valve Pathology from the 3-Chamber Cine Cardiac MRI View	The authors describe a multi-stage machine learning approach to detect pathologies of the aortic valve from Cine MRI imageing sequences. This is intended to support medical staff in determining which other types of imaging are required for the specific patient, potentially improving the imaging duration and quality.	Overall paper describes an approach for aortic valve disease classification based on cardiac MR. Using deep learning based heat map regression, features are derived from anatomical landmarks & contours (aortic hinges & leaflets) and pathophysiological dynamics (stenotic and regurgitant jets). Based on these features random forests are trained to obtain an estimate of whether or not aortic valve disease is present.	This works presents a multi-stage deep/machine learning strategy for aortic valve abnormalities classification from a single cine CMR view (3-chamber). The authors propose to regress heatmaps with the location of the aortic valve hinge points, followed by regression of curves representing the valve leaflets and pathological blood jets. By applying a ridge detection method on these curves, several handcrafted features are extracted per frame, later aggregated in a per-video feature set, and use for classification using a random forest (RF) classifier. The approach was validated in data from 3 centers, with interesting results.
154	DEUE: Delta Ensemble Uncertainty Estimation for a More Robust Estimation of Ejection Fraction	This work makes several interesting contributions in form of an epistemic uncertainty estimation method for deep learning regression tasks applied to cardiac echo,  including agnostic to neural  network architectures, real-time and deterministic; memory-efficient, scalable and computationally fast for large models, and provides high-quality uncertainty estimation.	The authors present a method for estimating the uncertainty in a Deep Learning estimate of a real valued prediction. The method computes the empirical variance of the parameters over 5 trained versions of the same network model. The authors explain how such an estimate can be used as an approximation to the network covariance which would be used as part of a Taylor expansion of the expected squared predictive error. The approach is applied to the estimation of ejection fraction from apical 4-chamber ultrasound views from a publicly available database.	In this paper, the author mainly proposes an epistemic uncertainty estimation method for Deep regression networks in the context of EF learning. Compared to other methods, this method only requires one forward-pass at the inference time.
155	DGMIL: Distribution Guided Multiple Instance Learning for Whole Slide Image Classification	This paper proposed a feature distribution guided deep MIL framework for WSI classification and positive patch localization. Specifically, The authors proposed a cluster-conditioned feature distribution modeling method and a pseudo label-based iterative feature space refinement strategy. This framework achieves a new SOTA on the CAMELYON16 dataset.	This paper focuses on improving the learning of feature extractor for multiple instance learning for WSI classification. The authors initialize the feature extractor via self-supervised learning (i.e., MAE) and perform clustering, instance selection, and refinement iteratively. Validations and ablation studies on Camelyon16 show its effectiveness.	This paper proposes a distribution guided multiple instance learning framework for whole slide image classification. The proposed method refines the instance representation in the latent space, by using a cluster-conditioned feature distribution modeling method and a pseudo label-based iterative feature space refinement strategy. It outperformance some state-of-the-art methods on CAMELYON16 dataset.
156	Did You Get What You Paid For? Rethinking Annotation Cost of Deep Learning Based Computer Aided Detection in Chest Radiographs	A large-scale analysis with 120K chest X-rays is conducted to analyze how annotation cost impacts CAD systems for classification and segmentation. Useful conclusions include: 1. bounding box annotations are as useful as the accurate contours when provided as additional supervision to the classification model. 2. Relatively small improvements to the label extracting algorithms lead to gains in classification performance. 3. We can achieve strong segmentation performance by mixing image-level labels with only small amounts of pixel-level contour labels.	This is quite a good paper that analyze the cost of annotations for two tasks of chest X-ray analysis: classification and segmentation, from three dimensions: annotation granularity, annotation quality, and annotation quantity. The experiments are extensive and convincing with several interesting findings that could inspire further studies on the same field.	This paper investigates the role of quantity vs. quality of annotations for medical image classification. The authors have collected an impressive private dataset of Chest X-rays which is close in size to CheXPert (120K vs. 224K images), but is manually annotated by radiologists. In addition, pixel-level annotations are provided. Specifically, different architectures are trained for chest X-ray classification and segmentation with different ground truths: expert labels (gold standard), expert labels + random noise, expert labels + segmentation, expert labels + bounding boxes. Their key take-away points are that i) noisy labels affect performance especially when training on smaller dataset, ii) providing lesion-level annotations improves performance at all scales and iii) mixing a small number of gold standard annotations with a larger dataset of imprecise annotations can improve.
157	Diffusion Deformable Model for 4D Temporal Medical Image Generation	This paper proposed a novel 4D image generation framework by adapting the denoising diffusion probabilistic model (DDPM) to the deformable registration model. The proposed method learns the distribution of the source and target and estimates the latent code to generate deformed images along the continuous trajectory. Experimental results on 4D cardiac MR image generation verify that the proposed method produces dynamic deformations from the end diastolic to systolic phase volumes, and outperforms the existing registration-based models.	"This paper proposed a novel deep learning based model to generate the intermediate temporal 3D+t cardiac MRI image.
This model is a combination of diffusion probabilistic module and deformation module which both are implemented with 3D U-Net.
Their implementation is adopted from a PyTorch version of these two modules from [10] and [3]."	This paper proposes a method for 4D cardiac image interpolation. The method uses a generative model based on denoising diffusion probabilistic models. The loss function combines a loss based on the diffusion model with a loss based on the deformable model. The model learns a code in the latent space that can provide the interpolation path between the source and the target images by a scaling sampling of interval [0,1]. The method has been evaluated in th ACDC dataset. The evaluation shows that the method provides plausible interpolation between the diastolic and systolic phases.
158	Diffusion Models for Medical Anomaly Detection	"This paper introduces a a novel weakly supervised anomaly detection
method based on denoising diffusion implicit models. Experiments are conducted on BRATS2020 dataset for brain tumor detection and the CheXpert
dataset for detecting pleural effusions."	The paper proposed an anomaly detection method using Denoising Diffusion Implicit Models (DDIM). The key idea is to iteratively add noise and learn to subtract it from input images using DDIM. During the anomaly detection stage, the anomaly image is treated as the noisy image and the learned network is used to generate a healthy image. Finally, their difference is used to calculate the anomaly map.	The paper proposes to use diffusion models trained on healthy patient scans to restore a 'pseudo-healthy' scan for scans with anomalies and use the residual between the original image and the 'pseudo-healthy' image as anomaly localization.
159	Digestive Organ Recognition in Video Capsule Endoscopy based on Temporal Segmentation Network	This paper proposes an automated organ recognition method in VCE based on a temporal segmentation network. MS-TCN++ model is used for temporal locating and classifying organs including the stomach, small bowel, and colon in long untrimmed videos	The authors propose to solve the important issue of automatically identifying anatomic transition points in video capsule endoscopy (VCE). To solve this, the authors propose to combine features from a timeSformer and I3D model combined in a MS-TCN++ model to automatically identify organs.	"This paper proposes a temporal segmentation network to to recognise three different digestive organs throughout a capsule endoscopy video. The method is based on the concatenation of two feature extractors (TimeSformer, I3D) that are fed into a temporal model (MS-TCN). Given the low number, and long duration of the 3 classes, a smoothing term is included to remove any noisy predictions.
The method is trained and tested on a large dataset of 200 videos that includes both normal and abnormal cases. An ablation is performed comparing different feature extractor options."
160	Discrepancy and Gradient-guided Multi-Modal Knowledge Distillation for Pathological Glioma Grading	This paper address the clinically relevant problem where paired pathology-genomic data are available during training, while only pathology slides are accessible for inference. To ensure effective knowledge transfer, a DC-Distill module is proposed to allow the teacher to provide knowledge via reliable contrastive samples with teacher-student discrepancy. A GK-Refine scheme is proposed to allow the student to selectively absorb the beneficial knowledge according to the gradient-based agreement.	The authors propose a novel multimodal model using genomic+histopathology information for glioma grading. The model jointly uses three components: 1) State-of-the-art knowledge distillation techniques 2) Contrastive loss over teacher-student model features and 3) gradient-guided knowledge refinement. The model is compared with current multimodal models and outperforms them using the image modality, reaching   92.35% of AUC.	"Authors propose a two-stage knowledge distillation framework for pathological glioma grading. At stage I, a multi-modal network is trained with both histopathological images and genomic data as inputs. At stage II, the privileged knowledge of the trained multi-model network is distilled to a unimodal model which only takes histopathological images as inputs. Authors further propose the discrepancy-induced contrastive distillation and the gradient-guided knowledge refinement to improve the performance of knowledge distillation.
According to experimental results, the performance of the learned unimodal model can be very close to the multi-modal upper bound."
161	Discrepancy-based Active Learning for Weakly Supervised Bleeding Segmentation in Wireless Capsule Endoscopy Images	This paper presents an active learning method to reduce annotation cost for medical image segmentation. The method uses novel criterions for image selection. On a public dataset, it outperforms many baseline approaches from the literature.	This paper proposes an activate learning framework for weakly supervised bleeding segmentation. It proposes a new scheme to select pseudo labels or ground truth for training images effectively based on the reliability of the generated labels.	This paper propose an active learning pipeline that incorporates CAM-based weakly-supervised method and pseudo-label-based semi-supervised method. Experiments demonstrate that the proposed method has considerable advantages over prior works in the 10% data regime.
162	Disentangle then Calibrate: Selective Treasure Sharing for Generalized Rare Disease Diagnosis	The paper proposes a generalized network for rare disease diagnosis, which simultaneously diagnose common and rare diseases. The network includes a gradient-based disentanglement (GID) module that separates common-disease features into disease-shared channels and disease specific channels. Also, it includes a distribution-targeted calibration (DTC) module that uses disease-shared channels to enrich rare-disease features via distribution calibration.	The paper proposes two modules to i) disentangle common disease features into disease-specific and disease-agnostic channels based upon gradient agreement, ii) use disease-shared channels to enrich rare disease features via distributon calibration.  With a WideResNet backbone, the authors compare the method against six recent approaches, producing improved results on two medical image classification tasks.	The paper approaches the problem of computer-aided-diagnosis by framing it into a few-shot-learning problem. The most occurring classes are used to learn shared and class specific features. The distinction between those categories relies on the gradient consistency across classes. Rare diseases  produce  increments to the shared features that are class specific. To avoid biases induces by the class  imbalance and  normal/lesion areas, the authors  learn to calibrate the distributions via an attention mechanism.
163	DisQ: Disentangling Quantitative MRI Mapping of the Heart	This work proposed a novel disentanglement framework for learning latent space of cardiac Quantitative MRI (qMRI) for contrast and anatomy separately, to benefit the downstream image registration and quantitative mapping.	The manuscript presents an unsupervised pair-wise registration pipeline with disentangled latent space of contrast and anatomy for a sequence of MOLLI T1-weighted images with inherent varied contrast and residual motion. Specifically, the developed neural network architecture decomposes the input pair into synthetic representations with same contrast, preserving anatomy, and same anatomy, preserving contrast, using U-Nets, for an easier pair-wise registration with Voxelmorph. The performance was evaluated by means of the reconstructed T1 fitting error map in the myocardial region and proven to be higher than the vanilla Voxelmorph approach. The application of disentangled representations for motion correction in T1 maps is novel.	This paper addresses the issue of improving cardiac quantitative MRI (qMRI) such as T1 mapping by proposing an image disentanglement method, called DisQ (Disentangling Quantitative MRI), to discompose cardiac qMRI images into their anatomical representation and contrast representation in the latent space.
164	Distilling Knowledge from Topological Representations for Pathological Complete Response Prediction	"The authors use topological information and a student/teacher network
to improve pathological Complete Response (pCR) for breat cancer
diagnosis based on MRI."	This paper proposes a deep learning method with topological priors for pCR predictions. The authors use DenseNet as the backbone prediction network, and extract Betti curves as topological priors. They incorporate the extracted topological features into a linear layer and distill them into DenseNet. Compared with previous method (TopoTxR), the key difference is 1) the distillation makes it possible to avoid computing topological features at inference time; 2) the usage of Betti curve is different from persistent homology. Betti curve is a weaker feature (less expressive) than persistent homology. But it seems sufficient for this task.	In this paper, the authors study the neoadjuvant chemotherapy treatment response in patients with breast cancer named pathological Complete Response (pCR). Their main contribution is this paper is 1) Extracting persistent homology-based features from breast DCE-MRI images using Betti-curves which is allegedly less time-consuming. 2) Using a response-based knowledge distillation approach, they designed a network to fuse features from a DenseNet network and topological based feature extraction block based on a teacher-student model 3) Outperforming the state-of-the-art by 5% margin, thanks to the topological feature fusion.
165	Domain Adaptive Mitochondria Segmentation via Enforcing Inter-Section Consistency	The authors propose to conduct domain adaptive mitochondria segmentation by  enforcing inter-section consistency. They  align both segmentation results and intersection residuals predicted from source and target volumes via adversarial learning. The validations show that their method outperforms leading methods on several datasets.	The authors present a method for successfully applying a model trained on one EM dataset to another EM dataset. This domain transfer allows the reuse of existing ground truth annotations. The authors compare their results with previously published methods for the same task and other UDA methods.	"A new method is proposed for unsupervised domain adaptation (UDA) of 3D mitochondria segmentation in EM images.  The inter-domain alignment design leverages adversarial training to align segmentation output space. The authors designed residual decoder and discriminator, where ""residual"" refers to the differences between the prediction maps from two sections of the same volume, which enforces simultaneous alignment between the prediction maps of two sections from the same 3D volume as well as the residual prediction maps from the target domain with the corresponding masks from paired source domain sections. For intra-domain alignment, they designed inter-section consistency loss for the target domain to penalize differences between the prediction map of each section and their corresponding pseudo-label generated by subtracting the residual prediction map from the prediction map of the paired section of the target same volume. The method is validated on four mitochondria datasets."
166	Domain Adaptive Nuclei Instance Segmentation and Classification via Category-aware Feature Alignment and Pseudo-labelling	In this paper, the authors propose a class-aware feature alignment method in domain adaptation for nuclei segmentation and classification. They also propose to select a certain branch to generate pesudo labels to reduce the negative effects of incorrect prediction in pseudo labels. Experiments show the effectiveness of the method.	"Proposes a new unsupervised domain adaptation approach for nuclei instance segmentation and classification.
The approach uses class-level feature alignment with class-specific adversarial discriminators and self-supervised learning from pseudo-labels predicted by the model.
The proposed approach outperforms the baseline methods on segmentation and classification."	Revise the class-awre feature alignment compared with Ref.12
167	Domain Specific Convolution and High Frequency Reconstruction based Unsupervised Domain Adaptation for Medical Image Segmentation	This paper presents an unsupervised domain adaptation method for medical image segmentation, introducing a novel domain-specific convolution (DSC) module to dynamically extract domain invariant features, and an auxiliary high frequency reconstruction (HFR) branch for filtering out task-irrelevant low-frequency features. The effectiveness of each module has been validated in the ablation study. Comparison study with several competitive unsupervised domain adaptation methods on the multi-domain RIGA dataset verifies the superiority of the proposed method. Yet, I have concerns regarding the applicability of the HFR component for noisy image segmentation. See below.	The authors have considered an important problem of domain adaptation in medical image segmentation. They have proposed domain specific convolution module to get appropriate features and an additional high frequency task to guide the domain adaptation process. They have has evaluated the method on relevant datasets.	This work presents a multi-source-domain UDA method called Domain specific Convolution and high frequency Reconstruction (DoCR) for medical image segmentation, where an auxiliary high frequency reconstruction (HFR) task is proposed to facilitate UDA and the domain specific convolution (DSC) module is constructed to boost the segmentation model's ability to domain-invariant features extraction. The experimental evaluation on a benchmark fundus image dataset demonstrated the superior performance of the proposed DoCR over other UDA methods in multi-domain joint optic cup and optic disc segmentation.
168	Domain-Adaptive 3D Medical Image Synthesis: An Efficient Unsupervised Approach	This paper proposed an unsupervised domain adaptation method based on 2D VAE approximating 3D distributions. The proposed domain adaptation approach is applied to image synthesis problem and the authors demonstrated the effectiveness of 2D VAE method.	This paper presents an unsupervised domain adaptation strategy for image translation/synthesis. A VAE is pre-trained on output domain of the paired training set and used to approximate its distribution. The synthesis network is trained on the paired training domain (S) (in a supervised fashion) and on the unpaired shifted domain (T) (KL between the output domain of S and output domain of T, under the VAE). In order to work with small training set, a 2D VAE - rather than a 3D one - is used. The latent code of a 3D volume is obtained by concatenating the latent code of all its 2D slices.	The authors explore a new topic of unsupervised domain adaptation (UDA) for image synthesis. The key difference from the previously well-researched UDA classification and segmentation tasks is the discrepancy between objectives. Here, the authors suggest an approach based on two existing ideas: image synthesis, and domain distributions (generated by VAE) matching. Besides, the ideas are combined in a novel way and used in a new setup.
169	Domain-Prior-Induced Structural MRI Adaptation for Clinical Progression Prediction of Subjective Cognitive Decline	This paper introduces a domain adaptation method for MRI-based Subjective Cognitive Decline (SCD) classification. Specifically, they devised a two-path framework and jointly trained them with activation-averaged attention and maximum mean discrepancy loss. Taking a relatively large ADNI dataset as a source domain, the proposed network was trained to reduce distribution gap to a target AAA dataset. The experimental results showed improved performance with their method.	This paper modifies the transfer learning methods using feature adaptation, and propose a domain-prior-induced structural MRI adaptation (DSMA) method for automated SCD progression prediction. Experimental results on 795 subjects from the public ADNI dataset and a small-scale SCD dataset demonstrate the superiority of the proposed DSMA method.	In this work, the authors propose a method to predict the progression of Subjective Cognitive Decline (SCD) by accounting for the distribution gap between Alzheimer's Disease and SCD datasets.
170	DOMINO: Domain-aware Model Calibration in Medical Image Segmentation	This paper proposes that deep-learning models calibrated with domain aware model calibration (DOMINO), are more accurate than models not tuned with DOMINO. To test this medical image segmentation algorithms were chosen for this analysis. Specifically, algorithms that perform head segmentation. The DOMINO framework that uses the confusion matrix (UNETR-CM) outperforms both hierarchical class-based (UNETR-HC) and non-calibrated UNETR (UNETR-Base), in most instances, however both UNETR-CM and UNETR-HC outperform UNETR-Base. Calibrated models also outperform Headreco on all tissue classes except for gray matter and csf.	The authors put forward a sensible domain-aware loss function which leverages class similarity and hierarchy.	
171	Double-Uncertainty Guided Spatial and Temporal Consistency Regularization Weighting for Learning-based Abdominal Registration	The authors investigated deformation regularization weighting in context of Voxelmorph based non-rigid abdominal CT-MRI registration. They proposed to use a mean teacher approach to adjust dynamically the weights of the spatial and temporal consistency regularization based on the transformation uncertainty and appearance uncertainty. Experiments involving 10 intra-patient test CT-MRI scans showed that the proposed approach seemingly outperformed state-of-the-art SyN, Deeds and DIF-VM methods according to organ-wise Dice, average surface distance, deformation Jacobian evaluation metrics.	This paper presented a double-uncertainty guided spatial and temporal consistency regularization weighting strategy for the Mean-Teacher (MT) based registration framework, avoiding the grid searching for the optimal regularization weight.	This paper proposes a student-teacher model for image registration, a typically ill-posed problem.  Separate student and teacher models are implemented; the former is a typical registration network which features spatial regularization to improve the ill-posed nature of the model.  The novelty is in the teacher model (and its interaction with the student model), which imposes temporal regularization for consistency with the student model, and allows tuning of weights for spatial regularization in the student model.  Their method is evaluated on CT-MRI images of the abdomen from a partner hospital.
172	DRGen: Domain Generalization in Diabetic Retinopathy Classification	"The paper explores domain generalisation for the task of classifying grading (0 to 4) of diabetic retinopathy from retinal fundus scan.
The proposed method is to average model weights identified at particular iterations of the training. An additional loss is added to reduce the covariance of the gradient across datasets.
4 datasets are used, with a leave one dataset out for testing."	In this paper, the authors address the problem of domain generalization in Diabetic Retinopathy (DR) classification. The baseline for comparison is set as joint training on different datasets, followed by testing on each dataset individually. The authors therefore introduce a method that encourages seeking a flatter minima during training while imposing a regularization.	The authors address the problem of domain generalization applied to retinopathy classification. The proposed method is build on Fishr regularization and the generalization capability is shown using 4 dataset with different dimensions. The averaged results show an improvement vs. SOTA of ~1%. The authors plan to share the github repository containing the source code for reproducibility.
173	DS3-Net: Difficulty-perceived Common-to-T1ce Semi-Supervised Multimodal MRI Synthesis Network	This paper presents a Difficulty-perceived common-to-T1ce Semi-Supervised multimodal MRI Synthesis network (DS3-Net), which promotes the synthesis task by predicting a difficulty map. The predicted difficulty map can guide a pixelwise constraint and a patchwise contrastive constrain. Experiments on BraTS2020 dataset have been performed to investigate the effectiveness of DS3-Net.	1) To the best of our knowledge, this is the first semi-supervised framework applied to multimodal MRI synthesis for gliomas. 2) In light of the teacher-student network, we make full use of unpaired multimodal MRI data through maintaining consistency in spaces of both high and low dimensions. 3)They innovatively estimate a difficulty-perceived map and adopt it to dynamically weigh both pixelwise and patchwise constraints according to the difficulty of model learning, and thus the model can assign the difficult-to-learn parts (such as the glioma region) more attention. 4) Extensive comparison experiments are conducted, both quantitatively and qualitatively.	This paper introduce an multimodal MRI synthesis network to generate T1ce based on given modalities. By introducing an attention map, the proposed method can flexibly focus on the important area in the generation, and through a distillation procedure, the method incorporate more unpaired data to help this synthesis task.
174	DSP-Net: Deeply-Supervised Pseudo-Siamese Network for Dynamic Angiographic Image Matching	The authors proposed a novel framework DSP-Net to automatically match the intra-operative X-ray fluoroscopic images to the dynamic angiographic images, which can provide doctors with dynamic reference images in PCI.	"To solve a series of problems caused by cardiac motion during PCI treatment:

DSP-Net realizes automatic matching of dynamic angiography images;
The PSAD block is designed to successfully distinguish subtle frames, overcome the noise background, and enhance generality."	"the first automatic approach exploring the task of dynamic angiographic image matching problem
DSP-Net processes X-ray fluoroscopic and angiographic images parallelly in a proposed dataset."
175	DSR: Direct Simultaneous Registration for Multiple 3D Images	A method for simultaneous mono-modal rigid registration of multiple volumes is proposed, based on a bundle adjustment mathematical formulation. The properties of the presented algorithm are demonstrated on simulated and real TEE ultrasound data from six patients, and compared against a number of other related algorithms.	The paper proposes a novel simultaneous registration of 3D image data without requiring a reference image or features, specifically for Transesophageal Echocardiography. A predefined panoramic image is used to optimise the global poses of local image frames. The method shows promising results on both simulated and in-vivo datasets.	DSR (Direct Simultaneous Registration) approach is able to match 3D images without using the definition of keypoints. It is adapted to object (here organs) that have no easy keypoints to detect. The framework of the direct bundle adjustment is used. The first contribution DBA (Direct Bundle Adjustment) consists in redefining BA that jointly optimizes the poses of local frames and the intensities of the panoramic image (instead of 3D point positions in BA) and the second contribution is the proof that the optimization of poses is independent of the image intensities.
176	Dual-Branch Squeeze-Fusion-Excitation Module for Cross-Modality Registration of Cardiac SPECT and CT	The paper proposed a rigid multi-modality DL-based registration algorithm with application to SPECT and CT images. The SE block (Squeeze Excitation) is utilized in between the feature extraction for each of the SPECT and CT feature extraction pipeline. The dataset includes in-house 450 aligned pairs, which have been artificially deformed with a random rigid transformation for the evaluation. The proposed method is compared with a conventional method and several multi-modality DL-based registrations.	The paper proposes a potentially novel, dual-branch squeeze-fusion-excitation (DuSFE) attention module for feature fusion between cardiac SPECT and CT. The proposed attention module aims to explicitly model the feature fusion process between the two modalities. The proposed framework aims to directly utilize the spatial and channel re-weighting property of the squeeze-and-excitation networks (SENets) to better fuse multimodal information for image registration. The authors motivate the need for such a task specific feature fusion module due to a lack of cross-modal feature integration models.	"This paper is well-organized, clearly written, and easy to follow.
The novelty of increasing cross-modal registration accuracy by squeeze-fuse-exci both the channel and spatial dimensions is intuitive and interesting.
The main motivation is well-supported by strong experimental evaluations."
177	Dual-Distribution Discrepancy for Anomaly Detection in Chest X-Rays	In this manuscript, the author proposed a dual-distribution discrepancy for anomaly detection. This paper is the first work that includes the unlabeled normal and abnormal images in training to improve abnormal detection. The abnormality is evaluated by two evaluation metrics: intra- and inter-discrepancy. The experiments on two benchmarks show state-of-the-art results and observed the increasing AUC by including more abnormal data in training.	This paper proposes a new strategy method for anomaly detection based on labeled and unlabeled data, which is a novel idea. Experiments show the effectiveness of the method. This will change the traditional way of thinking about anomaly detection.	Previous anomaly detection papers often consider the problem as one-class classification using only normal images. The authors in this work propose to leverage both normal and unlabelled images containing anomalies for training to perform more accurate anomaly detections.
178	Dual-graph Learning Convolutional Networks for Interpretable Alzheimer's Disease Diagnosis	This paper proposed a dual-graph interpretable GCN to classify AD-NC and related MCI. And further, the proposed method could identify AD-related biomarkers.	"In this paper, dual-graph learning framework is proposed in the GCN context which has mainly three components  including graph construction, dual-graph
learning and graph fusion. Proposed framework is being utilized for the early AD diagnosis"	The article proposes to derive interpretable deep learning classifier (for Alzheimer's disease) by jointly investigating subject and feature (structural ROIs) diversity. The model relies on jointly performing subject graph learning and feature graph learning within a graph convolutional network. The proposed method is more accurate than several baselines when applied to the cortical scores extracted from MRIs acquired by the Alzheimer's disease neuroimaging initiative (ADNI) datasets.
179	Dual-HINet: Dual Hierarchical Integration Network of Multigraphs for Connectional Brain Template Learning	In this study, a dual graph convolutional network architecture is proposed to learn connectional brain templates of brain multigraphs, which learns multigraph representations at node-level and module-level simultaneously.	In this paper, the authors propose a novel method, namely Dual-HINet, for dealing with brain multi-graphs while considering the hierarchical structure of neural interactions. The framework consists of several major steps, from which they seem to firstly construct node-level and cluster-level embeddings simultaneously, which are fused together for final analysis. They also use 4 large-scale connectomic datasets (ABIDE I) to validate the performance.	This paper proposed a Dual Hierarchical Integration Network (Dual-HINet) to simultaneously learn the node-level and hierarchical cluster-level integrations for the connectional brain template (CBT). Through the proposed dual GCN block, the proposed method can group the nodes through hierarchical layers based on their multi-edge interactions. The subject-specific CBT is derived from the concatenated node-level and cluster-level embeddings. Finally, the population CBT is generated by taking the median of all the subject-specific CBTs in the training set.
180	DuDoCAF: Dual-Domain Cross-Attention Fusion with Recurrent Transformer for Fast Multi-contrast MR Imaging	Towards better multi-contrast MRI reconstruction, this manuscript proposes a dual-domain cross-attention fusion mechanism to make full use of a reference image, and a recurrent transformer to remove the non-local aliasing artifacts.	The authors present a novel dual-domain cross-attention fusion network with recurrent transformer for fast multi-contrast MR imaging. The cross-attention fusion scheme enables deep and effective fusion of features extracted from two modalities. The dual-domain recurrent learning allows the proposed model to restore signals in both k-space and image domains by removing the artifacts effectively. The recurrent transformers can capture long-range dependencies from the fused feature maps for improving reconstruction performance.	This paper proposes a dual domain deep learning framework for MRI multi-contrast super-resolution. According to the results, the proposed method can generate superior results when compared with some other methods.
181	Dynamic Bank Learning for Semi-supervised Federated Image Diagnosis with Class Imbalance	This paper aims to address the challenging problem of class imbalanced semi-supervised FL. It proposes a  dynamic bank learning scheme consisting of the dynamic bank construction and the sub-bank classification. Expensive experiments on two benchmark datasets demonstrate the superior performance of the proposed method.	This work proposes a dynamic bank learning scheme to address the class imbalance in the semi-supervised FL. This scheme consists of two parts at the client side, including the dynamic bank construction to distill various class proportions for each client, and the sub-bank classification to guide the local model to learn different class proportions. On two public datasets, the method achieves remarkable improvements.	This paper aims to achieve effective class-imbalanced semi-supervised federated learning, where the server has labeled data and the clients have only unlabeled data. To this end, this paper proposes a dynamic bank learning method to leverage the class proportion information. The dynamic bank construction distill class proportions for each client, and a sub-bank classification task is used for local training. The proposed methods are evaluated on two datasets and show improved performance over existing works.
182	EchoCoTr: Estimation of the Left Ventricular Ejection Fraction from Spatiotemporal Echocardiography	This paper aims to estimate the left ventricular ejection fraction (LVEF) from 2D echo sequences. To do so, the authors adapt the existing UniFormer architecture with the objective of overcoming the limitations of CNNs and vision transformers for this type of task, therefore leading to a convolutional transformer. They demonstrate their methods on 10.000+ sequences from the EchoNet public database, focusing on 4CH views. Extensive comparisons with state-of-the-art methods and architectural choices are performed, demonstrating improved performance in terms of MAE and correlation.	In this article, a-convolutional transformer (EchoCoTr) is proposed as a method that combinies vision and CNN transformers to analyze echocardiogram video sequences and generate LVEF prediction. Deep learning networks require a fixed number of video samples, to obtain them they are taken at uniform frequencies, and authors proposed to use images from the end of systole and diastole images. The EchoCoTr architecture learns local features without avoiding redundancy in adjacent images while capturing global information through video. The results show that EchoCoTr can train with little information and give better or comparable results to other models such as EchoNet-Dynamic, BERT, DistilBERT and ViT although they also show that the model results are affected by the way the samples are taken in the model. video.	The authors present an application of the UniFormer network to the task of LVEF prediction. The results outperform existing approaches by a very small margin.
183	EchoGNN: Explainable Ejection Fraction Estimation with Graph Neural Networks	The authors describe a computational framework to automate EF calculation using ultrasound cines. This is achieved by mainly 3 steps - a video encoder, an attention encoder and a regressor, with embedded neural networks at different stages. For testing and training purposes, a large sample of echo cines is used (10,000+) containing 'ground truth' data. Comparison and validation with other methods is also provided, showing relatively good agreement with ground truth for some EF sub-cohorts, and with computational complexity superiority.	"In this work, the authors integrate an attention encoder, which learns the adjacency matrix describing the relationship between video frames, and a GNN after that, which leverages the learned attention matrix, to predict ejection fraction (EF), from AP4/AP2 Ultrasound images. The particular formulation of the attention encoder and the GNN is perhaps unique and interesting as it offers some explainability - which the authors claim is lacking in many works in this domain.
They offer very good results and explainability as well, which is good to see."	The authors propose a Graph Neural Network for explainable ejection fraction (EF) estimation from cardiac US imaging (echo) which they call EchoGNN. The weakly-supervised training pipeline does not directly rely on ES/ED ground truth annotations and benefits from a low number of parameters, hence reducing computational requirements. EchoGNN consists of three main components which are explained in detail: a video encoder, an attention encoder and a graph regressor. The authors show that their framework is able to accurately predict EF while also correctly identify end systole and end diastole. They tested their method on a large data set of AP4 echo cines.
184	Edge-oriented Point-cloud Transformer for 3D Intracranial Aneurysm Segmentation	The authors present a novel point-based 3D aneurysm segmentation using transformer. The proposed method consists of three major components: 1) dual stream transformer for both semantic segmentation and edge classification, 2) edge context dissimilation achieved by graph convolution and 3) hard sample mining of edge points by constructive learning. The proposed method is evaluated on a public dataset. Experiments show that the presented method provides promising results.	This paper propose a new framework to segment intracranial aneurysm from point clouds containing both aneurysm and blood vessels, and emphasis is placed on how to segment the aneurysm edge accurately. To this end, the proposed framework consists of three parts, a dual transformer to segment the aneurysm and the edge separately, and a graph convolution part and a contrastive learning part to further enhance edge segmentation. Experiments are done on a public intracranial vessel and aneurysm dataset consisting of 116 annotated aneurysm. Better performance than baselines are achieved on aneurysm segmentation .	Point cloud processing and analysis have been a popular topic in the community of 3D computer vision, however, medical point cloud studies are still in demand towards clinical applications of practical significance, such as clipping surgery and Intra identification. This is an interesting topic, which has not been well-explored yet. It is thus encouraging to see studies proposed to tackle geometric processing problems for medical usage.
185	Effective Opportunistic Esophageal Cancer Screening using Noncontrast CT Imaging	In this work, authors proposed a novel, non-invasive, low-cost, and highly accurate tool for opportunistic screening of esophageal cancer based on nonconstract CT scan, including esophageal tumor detection and classification (cancer or benign) task. The model achieves a sensitivity of 93.0% and specificity of 97.5% for the detection of esophageal tumors on a holdout testing set with 180 patients, which outperforms the mean doctors by absolute margins of 17%, 31%, and 14% for cancer, benign tumor, and normal, respectively. It is even more sensitive for early-stage cancer and benign tumor, compared with established state-of-the-art esophageal cancer screening methods, e.g., blood testing and endoscopy AI system.	"This paper presents a deep learning method to classify esophageal tumors 
from non-contrast CT. The deep learning method is based on a baseline nnUNet model (ref 8 in the paper) but incorporates position-sensitive full-attention layers. 
The authors claim improved performance of their method compared with doctors' reading of non-contrast CT (which is not the gold-standard screening method for esophageal cancer), and a performance comparable to established state-of-the-art esophageal cancer screening methods."	The work provided a self-attention-based nnUnet model for screening esophageal cancer, as a non-invasive, low-cost, ready-to-distribute, and highly accurate tool, which showed strong performance compared with doctors and other AI tools.
186	Efficient Bayesian Uncertainty Estimation for nnU-Net	This paper proposes a method to estimate the nnU-Net uncertainty for medical image segmentation.	"This paper leads to several nice contributions:
* it provides a novel VI approximation method,
* it provides an uncertainty estimation scheme for nnU-net architecture
* it boosts this same architecture in the context of biomedical image segmentation"	This paper presents an uncertainty estimation method that employs the posterior sampling of weight space and validates it in two public datasets under the nnU-Net framework. The uncertainty is estimated by ensembling multiple snapshots (checkpoints) during one model training but under a cyclic learning rate schedule. The obtained results outperform three commonly used baseline methods.
187	Efficient Biomedical Instance Segmentation via Knowledge Distillation	This paper introduces a knowledge distillation method for biomedical instance segmentation.Specifically, the authors proposed two schemes: graph distillation and pixel affinity distillation to transfer the knowledge.	Submission 368 proposes a novel knowledge distillation approach which is suitable to distill networks trained to do very difficult tasks, i.e. networks where one would expect a large number of parameters is necessary. Through the use of both instance- and pixel-level consistency between teacher and student networks, the authors achieve excellent distillation results, as evaluated on 3D EM segmentation data (CREMI challenge) and 2D natural image data (CVPPP challenge).	"This paper presents a knowledge distillation method targeting on medical image segmentation task. This method can transfer the knowledge learned in a large teacher network to a lightweight student network using two distillation schemes, i.e. instance graph distillation and pixel affinity distillation.
The experiments show the potential of improvement on student models trained with the proposed distillation method."
188	Efficient population based hyperparameter scheduling for medical image segmentation	Authors propose a hyperparameter optimization method that performs local search by using best performing checkpoints from an initial training run and then, in parallel, retraining the model from the checkpoint using  multiple hyperparameter sets sampled using Tree-Parzen Estimators. The method does not require expensive retraining (from scratch)  every time a different hyperparameter setting is explored. The method was tested using several datasets from the MSD challenge.	This paper presents a hyperparameter optimization technique, based on population based training (PBT), that reduces the training cost of original PBT, to make it feasible for large 3D medical images. They key idea is to start from a set of default parameters (chosen due to prior knowledge) instead of random parameters, which reduces the number of workers needed for PBT to converge. The method is evaluated on 4 tasks of the medical segmentation decathlon, and on 2 network architectures. It shows slight improvement in Dice Score (1-3%).	This paper utilizes Population based training (PBT) for hyperparameter tuning for medical image segmentation models. From a default setting, the tuning is able to achieve performance improvements and save 90%~97% computation cost of training from scratch compared to the original PBT.
189	Electron Microscope Image Registration using Laplacian Sharpening Transformer U-Net	This paper puts together a Cascaded Laplacian-sharpening Swin Transformer U-Net (LST-UNet) for deformable image registration of data slices from the MICCAI Challenge on (neural) Circuit Reconstruction from Electron Microscopy Images (CREMI). As these are preregistered data, synthetic deformations are applied for later recovery of motion.	"The authors propose a Swin Trasnformer UNet with Laplacian sharpening in the skip connections to register TEM images by infering the displacement map rather than the registered image. The sharpening filters seem appropriate for connectomics in TEM to preserve the semantic and structural information in the image.
They also propose applying the model inference two times, one after the other one (cascade processing).
They compare their approach with other existing methodologies in the field, showing a better performance of their proposed architecture and the cascade approach."	The authors investigate the use of a Swin Transformer based U-Net (Swin-UNet) for registration of serial electromicroscopy (EM) image slices. They further incorporate ideas from Sharp U-Net and cascaded registration approaches (see for example Quicksilver by Yang et al. 2017 and Recursive Cascaded Networks by Zhao et al. 2019) to further improve the registration. In addition, a similarity term consisting of two loss terms is utilized.
190	Embedding Gradient-based Optimization in Image Registration Networks	"In this paper, the author deals with the problem of medical image registration. They introduced a two step scheme to connect tradionnal approaches and network based approaches. To do so they have two levels of optimisation : a deep learning based optimisation (looking for the best networks parameters) and a iterative optimisation using gradient descent (looking for the best transformations).
The proposed scheme is independant from the network architecture or the registration formulation. Authors compared with deep learning and non deep learning approaches using two datasets with cardiac and brain MRI."	The authors present a combination of deep-learning-based and conventional registration.	In this paper, the authors present a deep learning based method for image registration. It is based on the interleaving of a learned gradient based forward step during a multiresolution based learned optimization. The authors present the individual building blocks of the algorithm and show the applicability of the method on 2d and 3d medical data, combined with a comparison to other published methods.
191	Embedding Human Brain Function via Transformer	They adoptted a transformer-based framework that encoded the human brain function measured by fMRI data into vectors of latent layer in transformer.Then they  evaluated the proposed framework in brain state prediction downstream task, and found that the embedding vectors are relevant to the response of task stimulus.	In this submission, the authors propose a transformer-based learning model for analyzing human brain functions, specifically, they focus on learning a canonical embedding for better predicting human brain states through fMRI inputs. They address the issue of regularity and variability of different instances, and choose transformer as the backbone to solve this issue.	"DL method is proposed based on transformers for building a compact representation of human brain functions from fMRI. 3D volume of fMRI data can be embedded as a dense vector which profiles the functional brain activities at the corresponding time point. Regularity and variability of brain functions at different time points and across individual brains can be measured by the distance in the embedding space.
The method is evaluated on the Human Connectome Project task fMRI dataset for brain state prediction. A comparison with various baselines is reported, demonstrating the increase in performance of the proposed method, with a neglectable computational cost increase as compared to a standard auto-encoder."
192	End-to-End cell recognition by point annotation	This paper proposes  an end-to-end framework that applies direct regression and classification for preset anchor points. The pyramidal features aggregation module provides low-level and high-level features for multi-task learning framework.	This paper proposes a neural network structure that predicts the anchor point for each cell without generating the density map. Two main components introduced in this framework are the pyramidal features aggregation and the optimized cost function.	The authors proposed a novel framework for dense cell recognition by using multi-task learning and one-to-one matching strategy. The experiment results demonstrate the effectiveness of proposed modules.
193	End-to-End Evidential-Efficient Net for Radiomics Analysis of Brain MRI to Predict Oncogene Expression and Overall Survival	This study attempts to predict the oncogene status of MGMT in glioblastoma patients using multiparametric MRI scans. This prediction has been previously investigated with mixed results. Using data from a prior challenge, the authors show that their evidential deep learning (EDL)-based approach achieve highest performance compared to other state-of-the-art.	Evidential deep learning for classification and regression is employed to predict the methylation status of MGMT and overall survival (OS) of GBM patients.	This paper proposed a deep learning-based framework for the tasks of Overall Survival (OS) prediction as well as prediction of methylation status of  MGMT for patients diagnosed with Glioblastoma from multimodal MR images. The status of  MGMT that is of vital importance for both diagnosis and prognosis purposes and its accurate prediction is of great interest for the communities. The main contributions of this work can be summarized as: Uncertainty information was integrated to the final prediction through Evidential-Regression approach, and Integration of a Gaussian distribution to characterize the final predicted values. The proposed pipeline was based on a tiny version of EfficientNet followed by some modifications. This model was tested on two standard challenge dataset that include multiomodal MR scans of subjects diagnosed with Glioblastoma. Performance of the model for both tasks of MGMT status prediction and OS prediction shows outstanding accuracy.
194	End-to-end Learning for Image-based Detection of Molecular Alterations in Digital Pathology	This paper describes a method that uses k-siamese networks with an EfficientNet backbone to solve digital pathology tasks using one model instead of a typical two-staged approach (stage 1 being some method to identify which regions are important, either manual or using deep learning, and stage 2 being the actual classification task. The k-siamese network samples k tiles randomly from the original image, encodes them and then combines them to make a prediction.	The paper introduces an end-to-end trainable k-siamese network with random tile selection for predicting molecular alterations. The method is shown to be better than the two stage pipeline which requires auxiliary annotations for region-of-interest in the first stage and dense tessellation and aggregation in the second to make the slide-level prediction.	A CNN is proposed by combining k number of well known Siamese CNNs to predict molecular alterations for a number of different use-cases, such as microsatellite instability in colorectal tumors and specific mutations for colon, lung, and breast cancer.
195	End-to-end Multi-Slice-to-Volume Concurrent Registration and Multimodal Generation	A multi-modal deformable registration algorithm is proposed, based on a combination of modern deep learning techniques, including both modality synthesis with CycleGANs, and DL-based deformable registration. It is evaluated on a large dataset of radiation therapy cases, with intra-session MRI with large slice spacing being registered to pre-operative CT scans.	The work presents a contribution to image generation by modality transfer accompanied by slice-to-volume deformable registration. Authors introduce end-to-end DL-based approach including CycleGAN-based synthesis, 2-D to 3-D registration and improvement of the generation by MIND-based supervision using the registration output.	"The paper proposes MSV-RegSyn-Net, a novel, unsupervised, concurrent framework for modality transfer synthesis and MSV mapping in an end-to-end pipeline. The method is evaluated on two clinical datasets. The evaluation shows the mutual benefits triggered by the joint architecture, leading to better performance than state-of-the-art methods.
The model is a methodological concept that is theoretically applicable to images of different modalities and quality, but also of different slice spacing, slice thickness or orientation. This has not yet been evaluated by the authors."
196	End-to-End Segmentation of Medical Images via Patch-wise Polygons Prediction	The paper proposes using patch wise polygons and neural renderers as the decoding branch of encoder-decoder deep architectures for segmentation purposes. This allows using an arbitrary resolution before rendering segmentation masks on the initial input size. The approach is evaluated on several medical and non-medical benchmark datasets and achieves top results.	This paper presents an image segmentation method in which the object edges are modeled as a polygon with vertices. The method obtains multiple stage-of-the-art results in several public datasets.	"The main contribution of the paper is the novel way to model the edge of segmentation boundaries using polygons with multiple vertices.
These polygons will then generate a raster image via neural renderer."
197	Enforcing connectivity of 3D linear structures using their 2D projections	The paper proposes a novel method to improve continuity in the segmentation of 3D elongated structures by minimizing a 2D connectivity loss in multiple 2D projections. The 2D connectivity loss itself was recently proposed, but has not been used in medical imaging (not extensively or not at all) and its application for 3D segmentation is a neat idea.	"better segmentation of 3D linear structures (e.g. vessels) by using 2D topological aware loss on projections
ground truth can be annotated on projections for higher efficiency"	The authors used an existing 2D loss function on three 2D projections of 3D datasets. In addition, they have performed experiments on multiple 3D datasets, which showed improved topology-aware scores.
198	Enhancing model generalization for substantia nigra segmentation using a test-time normalization-based method	The authors use two 3D U-Net vanilla models in a sequential manner to segment substantia nigra in MRI. This model represents a coarse-to-fine cascaded network. The first network generates a ROI that is used by the subsequent network to segment substantia nigra. Furthermore, during inference stage, the authors propose a test-time normalization to boost segmentation accuracy. The final segmentation is the average probability among the input images from the time-test normalization. Validation is performed using an atlas-based metric.	This paper introduces substantia nigra segmentation from T2-weighted imaging since these scans tend to be more readily available in large open-source datasets. The authors show that using a test-time normalization (TTN) method can help increase segmentation of substantia nigra (SN) accuracy. The same model was used on several different combinations of preprocessed data, such as using histogram matching and an asymmetric loss (ASL) function on the training set, to test which procedures worked best for getting the best SN segmentation. Ultimately, TTN with ASL, was shown to be the best method.	This paper presents a test time normalization method using an affine registration and histogram matching to improve the model generalization of substantial nigra segmentation during the inference time. It is said to be resulting in increased segmentation accuracy and the estimation of model uncertainty. Proposed results tend to perform better than the SOTA in terms of mean Dice score and in unseen datasets.
199	Ensembled Prediction of Rheumatic Heart Disease from Ungated Doppler Echocardiography Acquired in Low-Resource Settings	The paper describes a deep learning pipeline for automatic processing of colour Doppler images for the purpose of detecting and grading rheumatic heart disease. The pipeline works with non-ECG-gated data and is intended for use in low resource settings.	This work presents and evaluates a deep learning method for diagnosing rheumatic heart disease (RHD) from Doppler echocardiography. It starts with data homogenization to identify two specific echo acquisition planes and identifies the left atrium during ventricular systole. Then an ensemble model is used to predict RHD. The ensemble includes a 3D multi-view CNN that analyzes all frames during systole as volume data, and a multi-view Transformer that evaluates the images frame-by-frame. The results demonstrate the benefit of combining these networks into an ensemble.	"The authors propose a pipeline for RHD diagnosis with color doppler echocardiograms (CDE) in a low-cost setting. The authors preprocess the ungated CDEs with deep-network-based view selection, frames of interest selection, and left atrium (ROI) localization to generate video clips in ROI with A4CC and PLAXC views. Then the authors use a 2-view 3DCNN network and a 2-view 2DCNN+Transformer network to predict the RHD probability simultaneously, and use a maximum voting result of these two probabilities as the final prediction. The authors validate their method on a 591-patient dataset, and achieve a better result than a previous RHD prediction method.
This study focuses on CDE obtained by hand-held ultrasound devices, which are low priced and easy to deploy in low- and middle-income countries."
200	Estimating Model Performance under Domain Shifts with Class-Specific Confidence Scores	The manuscript describes a method for DL model output probability calibration, which is to add parameters for class-specific tunings.	This paper addresses the problem of estimating the predictive performance of a machine learning model on unseen data, where no ground truth labels are available. The authors adopt the concept of average confidence scores and state that the confidence is especially miscalibrated on imbalanced datasets. The main contributions are class-wise confidence calibration methods that greatly improve the performance estimation.	Various methods have been developed to estimate how well a trained model will perform on out-of-distribution data. These methods do not account for class imbalances. The authors propose new class-aware modifications to such methods to take rare classes into account when estimating a model's confidence. They carry out a thorough evaluation for both image classification and segmentation on different distribution shifts.
201	Evidence fusion with contextual discounting for multi-modality medical image segmentation	The paper proposes a method to process multi-MRI image separately and merge the segmentation results using the formalism of Dempster-Shafer theory. The merging part is learnable.	Authors propose  a DST and deep learning-based multi modal evidence fusion framework with contextual discounting. the method was evaluated on the BraTs 2021 dataset. In particular, they claim their method is able to take into account the uncertainty of the different sources of information compared to probabilistic approaches.	The authors propose a novel evidence fusion framework with contextual discounting for multi-modality brain tumor medical image segmentation. For the first time, the authors proposed  an evidence discounting mechanism. The experiment demonstrates that their method outperforms the best previously published results for this task.
202	Evolutionary Multi-objective Architecture Search Framework: Application to COVID-19 3D CT Classification	The author pays attention to the problem of searching the neural architecture problem. By proposing an objective, which is called potential, the author balances the exploitation and exploration operation on finding out promising models and reducing the search space during weight training.	"The paper proposes a neural architecture search based on ""potential"", a regression parameter fitted to the history of model accuracy. Higher values of ""potential"" indicate more promising architectures (subnets of a supernet) which are then more likely to be further exploited by a evolutionary algorithm. The method is evaluated on three separate COVID classification tasks (all 3D CT chest images) and shows promise of previous methods."	This paper proposes a more stable neural architecture search (NAS) approach for three COVID-19 prediction from 3D CT data. Based on the observation that weight-sharing (WS) strategy in NAS   incurs search instability, the author proposed a new objective called potential, which is used to explore more 'potential' or promising sub-nets.  Combined with accuracy, the proposed method can get more compact model with better performance on three public COVID-19 3D CT datasets.
203	Explainable Contrastive Multiview Graph Representation of Brain, Mind, and Behavior	This paper proposed a model to coupling the structure and function activity of brain on graph representation.	This paper used GCN for contrastive learning of structural and functional multimodal data and used the model results to analyze the strength of the structure-function coupling patterns between functional connectivity, structural connectivity and behavioral performance.	The paper mainly proposed a novel heterogeneous contrast subgraphs representation learning based method to exploit the coupling of structural and functional connectivity from different brain modality.
204	Explaining Chest X-ray Pathologies in Natural Language	The paper proposes an approach for extracting natural language explanations for conclusions from radiology reports.  The approach is used to generate and publish a new dataset, MIMIC-NLE.  The paper establishes performance baselines on this dataset.	"This paper introduce the task of generating natural language explanations (NLEs) to justify predictions made on medical images. As a first step, authors created
MIMIC-NLE, the first, large-scale, medical imaging dataset with radiological
NLEs and contains over 38,000 NLEs, which explain the presence of
various thoracic pathologies and chest X-ray findings. In addition, authors proposed a general approach to solve the task and evaluate several architectures
on this dataset, including via clinician assessment."	The paper introduced the first dataset of natural language explanations (NLEs) to justify predictions made on medical images. The authors validated a novel approach to generate NLEs for multi-label classification. It automatically distilled NLEs from radiology reports from the MIMIC-CXR dataset and created a new dataset called MIMIC-NLE. The paper also proposed self-explaining models that learn to detect lung conditions and explain their reasoning in natural language.
205	Exploring Smoothness and Class-Separation for Semi-supervised Medical Image Segmentation	This paper proposes a modified semi-supervised method for image segmentation. They design two losses to separately promote model regularization and inter-class separation. They also conduct comprehensive experiments to show the effectiveness of the proposed method.	This paper proposes the SS-Net for semi-supervised medical image segmentation via exploring the pixel-level Smoothness and inter-class Separation at the same time. The pixel-level smoothness forces the model to generate invariant results under adversarial perturbations. Meanwhile, the inter-class separation constrains individual class features should approach their corresponding high-quality prototypes, in order to make each class distribution compact and separate different classes. The methods are evaluated on two public benchmarks.	The authors proposed a deep learning framework for semi-supervised medical image segmentation. Pixel-level smoothness and inter-class separation are explored in the proposed framework. In the experiment, two public datasets are used for evaluation.
206	Extended Electrophysiological Source Imaging with Spatial Graph Filters	This paper addresses the ill-posed problem of source reconstruction in EEG or MEG. The idea of the method is to be less sensitive to spatial high frequency activation. The method proposes a law rank representation to estimate the different parameters on a projected subspace spanned by a low-frequency graph basis.	The authors provide a novel method for estimation of both source location and extents . They provide a new that exploits the graph structure defined in the 3D mesh of the brain by separating the graph signal into different frequency subspaces, where they project the signal.	This paper investigates extended electrophysiological source imaging with spatial graph filters. The simulation tests have been carried out in detail.
207	FairPrune: Achieving Fairness Through Pruning for Dermatological Disease Diagnosis	The paper introduces a method for modifying a pre-trained classifier to achieve fairness with respect to certain sensitive attributes. The method is based on identifying network parameters (nodes) with high saliency difference between different demographic groups and then pruning those nodes. This is a novel way of pursuing fairness compared to the traditional adversarial-training-based strategies.	The paper proposed a pruning approach to remove the bias of models to sensitive features, specifically skin tone and gender. The approach operates on a pre-trained model and has the added benefit of reducing the model size. Each parameter of the model has different importance for different groups' accuracy scores, therefore pruning the parameters based on their importance removes the effect of the sensitive parameter and bridges the accuracy gap between the two groups.	The paper describes a method for increasing the fairness of machine learning models whilst minimising the drop-off in accuracy for protected groups. The method is based on the idea of 'pruning', which is an approach normally used for reducing model complexity. The authors propose a novel metric of parameter saliency that enables the pruning operation to act to address lack of fairness in the model.
208	Fast Automatic Liver Tumor Radiofrequency Ablation Planning via Learned Physics Model	This paper proposes a surrogate model for liver tumour radiofrequency ablation using a non-autoregressive operator learning	Previous studies on automatic planning for Radiofrequency ablation commonly neglected the underlying physiology and used simplified spherical or ellipsoidal ablation estimates. The main contribution of this work was speeding-up biophysical simulations by using non-autoregressive operator learning, so that the proposed planning method could consider the biophysical effects of thermal ablation.	This work proposes the use of non-autoregressive operator learning approach for a very fast automatic RF liver ablation planning method.
209	Fast FF-to-FFPE Whole Slide Image Translation via Laplacian Pyramid and Contrastive Learning	The paper presents a GAN based model to synthetize FFPE image from FF samples. It proposes to use Laplacian Pyramids to increase computational performance.	The authors proposed a GAN-based model using Laplacian Pyramid frequency decomposition and Contrastive Learning via a memory bank to translate low-resolution FF into high-resolution FFPE-style slides.	This manuscripts describes a methodology that translates  one type of histological staining process (frozen, FF) to another (Parafin FFPE) as the frozen is much quicker to acquire but has lower resolutions and quality that the FFPE. The rationale behind this is good as the FF can be acquired quickly and then translated to a higher quality for further investigations.
210	Fast Spherical Mapping of Cortical Surface Meshes using Deep Unsupervised Learning	This paper proposes a spherical mapping of cortical surfaces using spherical convolution [29]. The proposed method infers a deformation field to adjust triangles on the unit sphere to minimize the mapping distortions. Three distortion metrics are used for computing deformation fields, and L2 regularity is introduced for a smooth velocity field. The experimental results show that the proposed method achieves a fast spherical mapping compared to the baseline methods.	"Proposes a very efficient method to obtain deformation field to map between spherical mesh and brain mesh.
The method achieves results with less distortion.
The method works in an end-to-end manner in an unsupervised way."	In this paper, the authors proposed a novel framework based on Spherical U-Net for spherical mapping of cortical surface meshes. Compared with FreeSurfer, which is the most popular tools for brain images, the proposed method have fewer distortions and achieve a speedup for more than 200 folds.
211	Fast Unsupervised Brain Anomaly Detection and Segmentation with Diffusion Models	This papers introduce latent DDPM (Denoising Diffusion Probabilistic Model) into medical image analysis and proposes a new method for unsupervised brain anomaly detection and segmentation. DDPM as a new generative model has the potential to model the data distribution with high image quality. Based on the observation that if the input image is from a healthy subject, the reverse process will only remove the added Gaussian noise,  while if the image contains an anomaly, the reverse process removes part of the signal of the original anomalous regions, the authors proposed to compute a mask from the sampling, thus detecting and performing segmentation from brain imaging in an unsupervised fashion.	This paper proposed a novel unsupervised pipeline, based on vector quantized variational autoencoder (VQ-VAE) and denoising diffusion probabilistic models (DDPM), for brain anomaly detection and image healing. It achieves comparable performance with state-of-the-art algorithms while having the advantage of fast inference time, which may increase its value in clinical applications.	"The paper proposes a novel method combining a variational autoencoder with a codebook to encode images into a latent space with a denoising diffusion model to ""heal"" pathological images. This unsupervised model is then used to restore anomalies without the need for manual annotations and then use the residual between the restored and original image to segment anomalies."
212	Feature Re-calibration based Multiple Instance Learning for Whole Slide Image Classification	The authors present a method for WSI classification using Multiple instance learning. They exploit the assumption that the features from positive instances have larger magnitude, and by recalibrating with the predicted highest magnitude instance (critical) they produce better separable groups.	"This paper proposes a method built using the positional encoding (PEM) [26] followed by a single pooling multi-head self-attention block (PMSA) [19] modules for WSI classification.
The main contribution is exploring the effectiveness of the feature re-calibration idea (which is used in few-shot learning) to produce balanced bags of +/- instances and, as a result, improve WSI classification.
Two ideas are used for feature re-calibration:
1- max-critical instance embedding
2-  feature magnitude loss"	The authors worked on multiple instance learning for whole slide image classification. The authors re-calibrated the distribution of a WSI bag (instances) by using the statistics of the max-instance (critical) feature.  The authors of this manuscript also proposed a balanced-batch sampling method to effectively use the feature loss and a position encoding module to model spatial/morphological information and perform pooling by multi-head self-attention with a Transformer encoder.
213	Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer's disease detection	The author proposed to evaluate the robustness of automatic feature extraction method based on a 3D CNN compared to a logistic regression method for Alzheimer's disease classification. Authors showed that	In this paper, the authors analyze the robustness of two different MRI volume-based classifiers to distribution shifts. Both classifiers are trained to detect Alzheimer's disease, based on different feature representations. The first is a logistic regression model that uses manually selected volumetric features as inputs, which are obtained using FreeSurfer and SPM. The second is a CNN using the full 3D MRI volumes as inputs. They analyze the effect of differing training dataset sex compositions on the performance for male and female test subjects.	In this work the authors evaluate the effects of sex imbalances on the performance of two classifiers (logistic regression and CNN) in the context of Alzheimer's disease diagnosis/prognosis. They trained the two classifiers with several training sets more or less imbalanced and showed that, in contrast with other domains such as lung disease diagnosis from x-ray, sex differences do not seem to affect the results.
214	Federated Medical Image Analysis with Virtual Sample Synthesis	This paper aims to solve a realistic problem that the local data from different clients are likely non-i.i.d distributed. To deal with this problem, authors propose a method named FedVSS, which uses Virtual Adversarial Training (VAT) for data generation/synthesis to align the local models with the global model.	In this paper, the authors propose to utilize virtual adversarial sample synthesis to improve the performance of federated medical image analysis on heterogeneous data. On one hand, the local synthesized samples can smooth the local model, on the other hand, the global synthesized sample can help align local models. The combination of the two types of samples reduces the negative effect of heterogenous data in local sites.	This paper proposes the virtual samples synthesis to help tackle the data heterogeneity issue. The proposed method is validated on five public datasets with significant performance improvements and additional study is performed.
215	Federated Stain Normalization for Computational Pathology	"The paper proposes a method to account for stain heterogeneity across different sites whilst training using Federated Learning. 
The method includes a generative model, known as BottleGAN,"	This paper proposed BottleGAN for stain normalization in an unsupervised way, and further integrated BottleGAN into WA-based FL. The experiments outperform on conventional FL algorithms.	This paper presents a BottleGAN generative model for computational alignment of staining styles of many laboratories. The purpose is to apply deep federated learning in computational pathology for creation of datasets that reflect diversities of many laboratories. That is expected to provide a vast amount of training data for deep networks, and that is prerequisite for computer-aided diagnosis, prognostication and assessment.
216	FedHarmony: Unlearning Scanner Bias with Distributed Data	The work presented in this paper is aimed at simultaneously handling issues related to both scanner/ acquisition differences and data privacy concerns when combining datasets across different site to form large, integrated medical imaging databases. The authors propose a strategy termed based on federated learning to address these issues and experimentally evaluate it using multi-site data from the ABIDE resting state fMRI publicly available database. Ultimately they show that only the mean and standard deviation of learned features need to be shared to address the scanner-specific effects.	The paper describes a federated learning approach that requires minimal information sharing, specifically just the mean and standard deviation of each feature from each site. Experiments show the method outperforms baselines on a single multi-site data set.	The paper proposes a federated learning approach for multisite MR image harmonization. Experiments on age prediction using the ABIDE dataset show promising performance of the proposed FedHarmony on removing scanner-specific information.
217	Few-shot Generation of Personalized Neural Surrogates for Cardiac Simulation via Bayesian Meta-Learning	This paper presents a new concept to achieve personalized neural surrogate in an end-to-end meta-learning framework, the proposed method shows a good performance on cardiac simulation.	The paper uses Bayesian meta-learning for neural cardiac simulation. Specifically, the paper uses graph CNN to model the 3D geometry of heart, and uses Gated Recurrent Units for temporal modeling, which are optimized through amortized variational inference.	In this paper, a Byesian Meta-Learning based method is proposed for few-shot cardiac simulation is proposed. The generative GCNN model is conditioned on specific input data and the output is personalized cardiac simulation results. GRU model is used for temporal modeling.
218	Few-shot Medical Image Segmentation Regularized with Self-reference and Contrastive Learning	Authors propose a regularization method to improve prototype-based few-shot segmentation model for abdominal organs. Their contributions consist of self-reference and contrastive learning. Self-reference regularizes a class prototype to be representative of entire organ in support image. Contrastive learning helps learning similarity between foreground and background features.	The paper proposes a novel method for few-shot semantic segmentation using class prototypes. These prototypes are locally created. The authors incorporate self-reference regularization, contrastive learning, and self supervision in order to train their models. To evaluate, they use two public available abdominal datasets.	This work applied self-supervision and contrastive learning to semantic segmentation, where the support image is used as a query image and the model is asked to segment on the support image itself. The proposed methods outperformed the SOTAs on two datasets of 30 and 20 3D images.
219	FFCNet: Fourier Transform-Based Frequency Learning and Complex Convolutional Network for Colon Disease Classification	This paper presents a Fourier based method to classify colonoscopy images, the proposed framework dices input images and calculates the DFT for each dice and then applies complex conv/rel/bn on them to perform the classification. Images are divided into four classes normal, polyps, adenomas, and cancers.  The results show superior performances in comparison to SOTA works in the colonoscopy domain.	This paper presents a frequency learning method for automatic colon disease classification, featured the Patching Shuffling Module and complex network.	The authors propose a frequency-domain complex number CNN for colon disease classification in colonoscopy images. By splitting the data into real and complex parts, the proposed approach can alleviating the effects of uneven brightness by decoupling image content and brightness.
220	Fine-grained Correlation Loss for Regression	"1.This paper proposes two correlation-based loss functions for medical image
regression tasks, where  two complementary correlation indexes are explored as learnable losses. 
2.The experimental results show that the simple network equipped with our proposed loss functions are effective on various medical image regression tasks."	The authors proposed training networks for regression tasks using two loss functions based on Pearson linear correlation (PLC) and Spearman rank correlation (SRC). Since using a pure PLC is highly sensitive to outliers, the defined loss function splits normal samples and outliers and calculates PLC only on normal ones while calculating the L2 norm on outliers. In addition, they introduced a Coarse-to-Fine optimization strategy to ease the rank learning using SRC. The proposed method has been evaluated on image quality assessment and bio-metric measurement tasks using ultrasound images.	The authors propose a method using their fine-grained correlation loss for regression tasks. The method contains two parts: Pearson linear correlation (PLC) training and ranking order training. In the first part, different from using L2 loss in ordinary regression, the authors use PLC, mean, variance as loss for normal samples, and L2 loss for auto-identified outliers. In the second part, the authors propose a ranking constraint on the similarity of features. The authors use the ratio of regression label as supervision information: 1) force the similarity close to the ratio,  2) force the difference of the similarity close to the difference of the ratio. The method is validated on image quality assessment (IQA) and bio-metric measurement(BMM) tasks on ultrasound images, achieving promising results.
221	Flat-aware Cross-stage Distilled Framework for Imbalanced Medical Image Classification	In this paper, the authors propose a two-stage framework for imbalanced medical image classification. The proposed method sequentially learns the representative and discriminating features from the imbalanced data distribution and re-balancing strategies, respectively. In details, the method flattens the local minima to form a common optimal region and further employs the cross-stage distillation to facilitate the network optimization within this region.	In this paper, the authors address imbalanced medical image classification with a flat-aware cross-stage distilled framework (FCD). FCD combines two-stage learning, flatten local minima and cross-stage distillation to re-balance classes while avoiding knowledge forgetting. FCD achieved good performance in two large imbalanced medical image calssification datasets.	This paper proposed to adopt a flat-aware cross-stage distilled framework for imbalanced medical images classification. Extensive experiments have been done on two widely-used pubic datasets. The results demonstrate the effectiveness of the proposed methods.
222	Flexible Sampling for Long-tailed Skin Lesion Classification	The authors present a cirriculum learning based sampling strategy to improve the performance in classification of dermoscopy images. They initially train a embedding representation model and determine anchor samples within each class. These anchor samples are then used to train a classification model which will then be used to select the next set of samples that can be added the training set for further training. Authors show that iteratively training a model with such curriculum can help in boosting the classification performance.	Authors proposed a class re-sampling method for learning from the long-tailed distribution. The idea is to first use SSL to learn balanced representations, and then filter out an anchor dataset with balanced difficulty. Finally, using this anchor dataset to initialize a model, the evaluated difficulty/uncertainty samples of the model is sampled to train it in a recurrent manner. Experiments are conducted on skin lesion classification comparing with a wide range of long-tailed distrubution learning methods.	"This paper presents a curriculum sampling-based method to improve automatic skin lesion classification on imbalanced datasets. The paper introduces a strategy to mitigate class imbalance in several stages, such as pre-training a CNN backbone with a self-supervised loss, sampling anchor points to highlight the ""key"" elements on the dataset per class, and curriculum sampling to incorporate unsampled elements on the fly in the rest of the training."
223	fMRI Neurofeedback Learning Patterns are Predictive of Personal and Clinical Traits	This paper claims that neurofeedback data can also predict individual behavioral and clinical traits, in addition to instead existing generic resting-state data.	This interesting piece of work describes a self-modulation task guided by fMRI. Classifications are based on the fMRI signal and set to various personal and clinical indications. The individual learning pattern based in the amygdala can be used as a diagnostic tool perhaps.	the authors developed a method for extraction of information from rs-fMRI data, which better predict personal traits
224	Free Lunch for Surgical Video Understanding by Distilling Self-Supervisions	"The work presented in this paper considers the task of surgical phase recognition on videos and tackles specifically one of its challenges: the lack of annotated data. In response, the paper proposes a two-fold strategy: a self-supervision approach (teacher/student models) and the use of publicly available models trained on large generic datasets to train the teacher model.
To do so, the presented method has three main characteristics. (1) it follows a contrastive learning approach, as training an encoder for a dictionary look-up task. (2) it enables to preserve semantics extracted from the model trained with large datasets, by fixing its backbone and updating its head projection. (3) it operates a self-training of the student model with a specific distillation strategy where the similarity matrices of the teacher and student models are constrained to resemble.
Experiments with cholecystectomy videos reveal that (2) and (3) are effective strategies, leading to a general improvement."	"The paper investigated use of self-supervised training for surgical video analysis tasks. This is an important topic for the community given scarce amount of labeled datasets available.
The paper proposed methodology to leverage large-scale publicly available datasets to enhance performance on surgical video analysis tasks. Semantic-preserving training (via contrastive learning) for teacher network and a distillation objective function for student network are interesting and impactful techniques.
Authors have done experiments on two publicly available datasets and compared their method with a few other self-supervised approaches."	"This manuscript presents an approach to adapt a self-supervised method (MoCo-V2) from a general computer vision domain to a surgical domain. They propose a two-stage self-supervised training approach: in the first stage, they propose ""semantic-preserving training scheme"" by training just the projection-head of the self-supervised model on the surgical video; in the second stage, the trained model from the first stage, called teacher mode, is used to guide a student model using distillation and contrastive loss. They show the improved results using their training approach on the Cholec80 and MI2CAI16 datasets."
225	Frequency-Aware Inverse-Consistent Deep Learning for OCT-Angiogram Super-Resolution	"This paper proposes an inverse-consistent deep learning based method to enhance the unpaired OCTA images.
To enhance the OCTA image, Fast Fourier Transformation, Gaussian filters and Discrete Wavelet Transform are used to decompose frequency information.
The proposed method outperforms the compared methods."	This paper proposes inverse-consistent generative adversarial networks (GAN) for unpaired OCTA image restoration and degradation. In the proposed framework, a frequency domain decomposition module is introduced to enhance high-frequency information at the frequency domain level.	The authors proposed an inverse-consistent generative adversarial network with frequency awareness for unpaired image enhancement of low-resolution optical coherence tomography angiography. In this work, the authors regarded the enhancement task as the mapping from low resolution domain to high resolution domain. Furthermore, frequency domain information including low- and high-frequency components was integrated into the proposed network. Qualitive and quantitative results demonstrate that their approach outperforms other methods, especially in terms of the balance between low- and high-frequency information.
226	From Images to Probabilistic Anatomical Shapes: A Deep Variational Bottleneck Approach	A novel framework was proposed for predicting probabilistic anatomical shapes from 3D images based on the variational information bottleneck theory.	This paper proposes to use the variational network to parameterize the statistical shape modeling. It leverages the information bottle neck to enable the learning framework.	This paper proposes a new method for generating probabilistic shapes from 3D image inputs using a variational information bottleneck (VIB) approach. The claimed advantages are higher accuracy and better uncertainty estimation compared to previous DeepSSM methods. Experiments were performed using a large MRI dataset (1001 scans), with paired ground-truth shape annotations with point correspondence.
227	FSE Compensated Motion Correction for MRI Using Data Driven Methods	The paper presented a method for simulating synthetic motion artifacts accounting for k-space acquisition ordering and T2-signal decay in FSE acquisition and showed improved motion correction	In this work, the authors propose a FSE motion-corrupted data generation method that takes into account the intra-echo signal decay.	This paper proposes a new method for simulating motion corrupt data in FSE sequence, which can be used for training deep learning model for retrospective motion correction. The method considers the key effects of FSE sequence such as signal decay and sample ordering and can simulate more realistic motion corrupted data. Experiment results showed that by training with data simulated by the proposed method, a significant improvement can be achieved in motion correction results.
228	Fusing Modalities by Multiplexed Graph Neural Networks for Outcome Prediction in Tuberculosis	This paper presents a framework for multi-modal fusion of medical data based on multiplexed graph neural networks for multi-class classification for the prediction of clinical outcomes in tuberculosis. The authors applied the framework to a large cohort of TB patients with imaging (CT), genomic, treatment, demographic, and clinical data modalities. Comparisons are made to the class fusion schemes (early, intermediate, and late fusion), as well as several methods based on graph convolutional networks.	In this paper, authors adapt Multiplex-GNN theory for the purpose of multimodal/multi-omics latent fusion. They demonstrate their method on a multimodal dataset for Tuberculosis (TB) treatment outcome prediction. The dataset features 5 input modalities (Chect CT, genomics, demographics, clinical data, regimen data). The proposed Multiplex-GNN method is compared against various baselines and ablations, and has the highest and most consistent AUC values across the 5 output classes.	This paper proposes a multiplex graph based representation for fusion of 5 clinically relevant types of data (drug regimen, chest x-ray, demographic, clinical, genomic) and a Graph Neural Network based learning algorithm performing multi-class outcome prediction for Tuberculosis disease
229	FUSSNet: Fusing Two Sources of Uncertainty for Semi-Supervised Medical Image Segmentation	"The paper describes a framework for semi-supervised deep learning-based segmentation that incorporates both aleatoric and epistemic uncertainty. Epistemic uncertainty is used to divide the image into ""certain"" and ""uncertain"" areas, which are handled differently in the semi-supervised learning approach. The aleatoric uncertainty is used in the supervised part of the loss."	This paper is built on a joint training regime of epistemic and aleatoric uncertainty. Particularly, the authors computed the epistemic uncertainty from four different classifiers on top of a shared embedding and used the thresholded uncertainty as a mask for computing loss between student and mean-teacher networks. They have shown two dataset experiments that showed marginal performance gain over previous methods.	"The paper proposes an iterative multi-step training strategy called ""FUSSNet"" for medical image segmentation tasks consisting of unsupervised and supervised learning aspects. In different steps, epistemic and aleatoric uncertainty is exploited to boost segmentation performance according to multiple metrics (pixel-level and global-level). The authors claim superiority to other recent semi-supervised methods on two challenging segmentation tasks (on MRI and CT) in the small data regime (only 12 or 16 labeled datasets used per task)."
230	GaitForeMer: Self-Supervised Pre-Training of Transformers via Human Motion Forecasting for Few-Shot Gait Impairment Severity Estimation	This paper proposed a novel method GaitForeMer that forecasts motion and gait (pretext task) while estimating impairment severity (downstream task). By pre-training on NTU dataset, it can improve performance of early diagnosis of Parkinson's disease (PD) on a small dataset.	"This paper presents a method to predict Movement Disorder Society Unified Parkinson's Disease Rating Scale (MDS-UPDRS) scores. To this end, the authors propose Gait Forecasting and impairment estimation transformer (GaitForeMer), a transformer model using motion forecasting as a self-supervised pre-training task. The proposed system achieves an F-1 of 0.76, which is 0.18 higher than OF-DDNet [1].
[1] Lu,M.,Poston,K.,Pfefferbaum,A.,Sullivan,E.V.,Fei-Fei,L.,Pohl,K.M.,Niebles, J.C., Adeli, E.: Vision-based estimation of mds-updrs gait scores for assessing parkinson's disease motor severity. In: Medical Image Computing and Computer Assisted Intervention (2020)"	It is an interesting paper. The paper develops models to predict MDS-UPDRS gait impairment severity and these models are first pre-trained on public datasets to forecast gait movements.
231	GazeRadar: A Gaze and Radiomics-guided Disease Localization Framework	The paper combines basic radiomic features and visual attention from gaze maps to localize disease.	A novel architecture to fuse radiomics and visual attention is proposed for classification and localization tasks. A novel loss is proposed to calculate the distance between the student block attention distribution, and the joint representation. Experiments demonstrate the effectivenesss of the proposed method.	The authors present GazeRadar, a novel global-focal student-teacher architecture for disease localization based on radiomics information and visual attention features. The representation is used to train a student block for downstream classification and localization tasks. The authors develop novel Radiomics Attention Fusion and Gaze Attention Fusion strategies to fuse radiomics features and gaze features.
232	Geometric Constraints for Self-supervised Monocular Depth Estimation on Laparoscopic Images with Dual-task Consistency	A self-supervised monocular depth estimation framework is presented for surgical video datasets. This framework has included a scene coordinate prediction branch in addition to depth and pose estimation branches. The pose estimation branch has also been added with an additional Siamese optimization process. A weighting mask is used based on the dual-consistency test to reduce the effect of unreliable predictions.	"A self-supervised approach to monocular depth estimation with a promising results
Depth prediction and pixel 3d coordinate prediction are handled as two distinct tasks whose results support each other via a consistency loss"	This work proposed a self-supervised framework for laparoscopic depth estimation. The authors used the multi-task training strategy, adding scene coordinate prediction to train the network with dual-task consistency. The confident mask is also computed from the scene coordinate prediction. The authors also updated the pose estimation with the siamese process, which improved the pose rotation prediction.
233	Gigapixel Whole-Slide Images Classification using Locally Supervised Learning	In this work, the idea of training a network block by block (locally supervised networks) has been adopted to feed Whole Slide Images to the network. Random feature reconstruction has been proposed to improve the last layer feature quality rather than the whole slide reconstruction. Results have been discussed in three microscopic WSI datasets.	This paper proposes to employ the locally supervised learning scheme [24] for bypassing the memory bottleneck that exists in end-to-end WSI representation learning. To further deal with the memory issue, the authors replace the reconstruction loss in the original locally supervised learning scheme [24] with a random feature reconstruction unit.	To overcome the spatial relations loss of conventional multiple instances learning for WSIs classification, this paper proposed locally supervised learning by splitting deep network into multiple gradient-isolated modules.
234	Global Multi-modal 2D/3D Registration via Local Descriptors Learning	"The authors propose a rigid-registration neural network based on descriptors (local features) extracted from 2D US and 3D MR images.
The method is adapted from LoFTR (Local Feature matching with Transformers). Each image is processed with separate U-net like neural networks to produce feature maps. A similarity matrix is filled with the dot products of pairs of descriptors, then filtered with a ""double softmax"" to isolate significant ""matching"" features. This matrix is the basis of the loss function of an end-to-end registration network. The pose is finally estimated from the matches with RANSAC.
The method is evaluated on MR + US liver images of 16 patients. Several versions of the method are compared, and overperform a baseline method from ImFusion with statistical significance. While the registration error remains relatively large (on a difficult task), the proposed method is interesting at least as an initialization for more accurate methods which require a close initial pose."	This paper presents an automated 2D/3D registration between US and MR images for ultrasound-guided interventional applications. The algorithm follows a classical feature/landmark matching approach but with features learnt from 2 Unet architectures for US and MR images.	The main contribution is the adaptation of the LoFTR algorithm to multi-modal data and by considering imprecise ground truth.
235	GradMix for nuclei segmentation and classification in imbalanced pathology image datasets	The authors propose a data augmentation technqiue, termed as GradMix, to improve nuclei segmentation and classification performance, particularly for imbalanced pathology image datasets.	The paper describes a synthetic data generation method to increase training dataset size and address class imbalance to train more robust and accurate nucleus segmentation and classification models.	The paper introduces a data augmentation technique (GradMix) for nuclei segmentation and classification when cells between classes are imbalanced. The proposed method generates patches showing both major-class nuclei and rare-class nuclei. The proposed method is tested on two public datasets and the results show an improvement in classifying rare-class nuclei.
236	Graph convolutional network with probabilistic spatial regression: application to craniofacial landmark detection from 3D photogrammetry	A graph NN based approach to locating landmarks on photogrammetric images.  Takes account of specific nature of data and includes a regression method to deal with landmarks which don't coincide with a mesh node.	The authors describe a novel method for automated landmark placement on 3D point clouds of faces that leverages a graph convolutional neural network architecture. The clinical motivation for automated landmark placement is for enabling automatic and reproducible analysis for 3D photogrammetric data. In and of itself, the spectral model approach used here is an adaptation of the well known Chebnet (Defferrard, M., Bresson, X., & Vandergheynst, P. (2016)).  The authors demonstrate the landmark placement accuracy of their framework through an analysis of a large dataset (982) of 3D paediatric faces and they compare their approach, plus variants thereof, to Pointnet++. The results quantitatively indicate the improvement gains in landmark placement accuracy of their approach.	This paper introduces a graph-based convolutional neural network to pediatric craniofacial landmarks from 3D photographs (i.e., surface meshes). Three strategies are adopted in the proposed method: 1) Multi-resolution spatial features at every vertex are extracted with Chebyshev polynomials; 2) A novel weighting scheme dependent on the local data density at every surface location to aggregate the spatial features; 3) A new probabilistic regression framework that uses the aggregated spatial features to calculate landmark locations. The authors evaluated the proposed method by detecting 13 landmarks from a set of patients' 3D craniofacial surfaces. Generally, the three strategies are actually not new, similar ideas are commonly applied by the related methods in the field of geometrical/point-cloud deep learning. In addition, the landmark detection accuracy of the proposed method is too low to meet clinical requirements.
237	Graph Emotion Decoding from Visually Evoked Neural Responses	This paper introduces a novel method, Graph Emotion Decoding (GED), to decode emotions by integrating emotion scores of the video stimulus and brain responses from brain regions. By stacking layers of the GED, the model uses the relationships of the brain regions and neighboring emotions to decode. The model showed reasonable performance by comparing with other models and gradually improved by staking the layer of the model.	The authors proposed a neural network to predict scores of individual emotions for presented videos from fMRI recordings. The network architecture is simple but the results are better than some of the state-of-the-arts methods. Overall this paper is interesting and clearly written.	The Neural Decoding framework is proposed to find the association between Emotion and brain regions via a bipartite graph structure.
238	Graph-based Compression of Incomplete 3D Photoacoustic Data	In this paper, a graph-based compression scheme is proposed for incomplete 3D photoacoustic data. Both objective and subjective evaluations are provided to demonstrate the compression quality.	The work proposes a tailored compression approach for photoacoustic data. The compression mode is locally adaptive, depending on present features and in the advanced mode uses graphs to encode features.	The paper approaches the problem of incomplete 3D PA in a graph-based encoding scheme. A reliability-aware rate-distortion optimization (RDO) is proposed to enable adaptive compression PA observations based on different reliability levels.
239	Greedy Optimization of Electrode Arrangement for Epiretinal Prostheses	This paper presents a greedy optimization approach to selection of optimal electrode sites for a retinal prosthesis design. The approach uses a phosphene shape model to optimize the arrangement of electrodes to maximize predicted coverage of the visual field, as predicted by the model.	This paper is in a very specialized field of electrode placement for epiretinal prothesis. The paper defines the problem and proposes a disctionary learning based optimization for arrangement of such electrode for getting the desired outcome.	This paper describes a novel approach to determine the distribution and number of retinal implant electrodes to maximize / optimize the resulting visual perception.
240	Hand Hygiene Quality Assessment using Image-to-Image Translation	The authors propose an AI system to evaluate and document the effect of hand hygiene procedures, using fluorescent hand disinfectants and Ultraviolet (UV) images of the hand. Aim of the proposed method is to generate standardized hand template images which display the amount and location of the hand disinfectants.	This paper describes a deep learning-based segmentation and image-to-image translation approach to standardize hand hygiene documentation from images of hands with different amounts of skin coverage (with desinfectans) taken under standardized UV lighting conditions. The models in the paper are based on a U-net architecture augmented with attention gates in the generator path. The authors use a self-generated dataset to train and validate their models.	The paper describes a deep learning approach for hand hygiene analysis. After applying a fluorescent hand disinfectant, pictures of hands are analyzed using a segmentation network and mapped onto a common template. Results are reported on synthetic and real images.
241	Harnessing Deep Bladder Tumor Segmentation with Logical Clinical Knowledge	"1.This paper proposes a novel bladder tumor segmentation method by fusing clinical logic rules of bladder tumor and wall,the rules can guide the DCNN to produce precise segmentation results
2.This paper validate that fusing the logical clinical knowledge is helpful to reduce the data dependency of DCNNs for image segmentation."	The authors propose a novel bladder tumor segmentation method in which the logic rules of clinical knowledge are incorporated into DCNNs.	The main idea of this paper is to merge the clinical logic rules with Deep Convolutional Neural Networks (DCNN) to enhance the segmentation of the bladder tumor. The clinical logic rules depend on the appearance view of a bladder tumor must rely on the bladder wall. While the standard U-net is used for DCNN to create semantic segmentation.
242	Hierarchical Brain Networks Decomposition via Prior Knowledge Guided Deep Belief Network	This work proposed a novel method to incorporate prior knowledge to DBN for hierarchical brain network decomposition. Sufficient experiments suggest the proposed method can converge faster than the traditional DBN models. In addition, the proposed method can identify better task and intrinsic functional brain networks compared with the traditional DBN models. This work contributes a novel idea on how to introduce prior knowledge to unsupervised deep models for fMRI data analysis.	The authors proposed a prior knowledge-guided version of deep belief network to infer brain networks with the task labels used as prior information. The inferred networks are more aligned with the ground truth resting-state network	In this paper, the authors propose a novel prior knowledge guided DBN (PKG-DBN) model hierarchical brain network decomposition. By incorporating such constraints in the learning process, the proposed method can simultaneously leverage the advantages of data-driven approaches and the prior knowledge of task design.
243	Histogram-based unsupervised domain adaptation for medical image classification	This paper describes a domain adaptation method base on histograms rather than images and applies it to disease detection from chest x-ray images.	In this paper, the authors work on the hypothesis that most domain shifts in medical images are variations of global intensity changes which can be captured by transforming histograms along with individual pixel intensities.	This paper propses a simple and straightforward yet effective for the unsupervised domian adaptation for medical images, which only operate on the high level of the input images via learnable gama transformation. The proposed method also achieves the best results compared with the most poplar image translation based methods.
244	How Much to Aggregate: Learning Adaptive Node-wise Scales on Graphs for Brain Networks	A novel dynamic aggregation mechanism for graph convolutional networks, exploiting Heat Kernel equation.	In this paper, the authors proposes a flexible GCN model that learns adaptive scales of neighborhood for individual nodes of a graph to incorporate broader information from appropriate range. Extensive experiments on various datatsets show that the proposed method outperforms the state-of-the-arts methods.	This paper proposes a flexible model that learns adaptive scales of the neighborhood for individual nodes of a graph to incorporate broader information from the appropriate range. The authors derive a parameterized formulation to perform gradient-based learning on the local receptive field of nodes using a diffusion kernel.
245	Hybrid Graph Transformer for Tissue Microstructure Estimation with Undersampled Diffusion MRI Data	This paper introduced a hybrid graph transformer (HGT) method to estimate tissue microstructure measures by using a graph neural network (GNN) for q-space modeling and a residual dense transformer (RDT) for spatial modeling. The proposed method was compared with several state-of-the-art methods and showed better performance for estimating NODDI parameters with reduced samples. Moreover, an extensive ablation study was performed to examine the effectiveness of the learning modules.	Deep learning techniques allow prediction of high-quality diffusion microstructural indices from sparsely sampled data. Existing methods are either agnostic to the data geometry in the q-space or limited to leveraging information from only local neighborhoods in the spatial domain. This paper proposes a hybrid graph transformer (HGT) that combines a graph neural network (GNN) and a novel residual dense transformer (RDT), so that the q-space geometric structure and spatial information are fully exploited. Experiments were performed on the HCP dataset for evaluation, where the proposed method has achieved promising results. Overall, this is an interesting paper with proper validation.	This paper proposed a deep learning approach for estimation of tissue microstructure parameters from sparse diffusion MRI data.  They specifically investigate a hybrid graph transformer network that uses both q-space and spatial information.
246	Hybrid Spatio-Temporal Transformer Network for Predicting Ischemic Stroke Lesion Outcomes from 4D CT Perfusion Imaging	In this paper, the authors propose to predict acute ischemic stroke (AIS) lesions 2-7 days after the stroke onset from Spatio-temporal Computed Tomography Perfusion (CTP). Instead of using estimated perfusion maps, the authors utilize the raw temporal CTP acquisitions, by proposing a new hybrid Convolutional Neural Network (CNN) and Transformer model. CNN encoders extract features from each time step, then the Transformer learns the temporal relations, and finally, a CNN decoder estimates the final lesion. The method is evaluated in an in-house dataset and improves over perfusion maps-based CNN and CNN-based temporal methods.	The authors proposed to use spatio-temporal transformer to predict stroke lesion outcomes directly using 4D CTP images as input.	This paper proposes to segment the ischemic stroke lesions directly from 4D CT perfusion images, rather than from perfusion parameter maps. They used transformer for fusing the temporal information and use a CNN to extract spatial features.
247	Ideal Midsagittal Plane Detection using Deep Hough Plane Network for Brain Surgical Planning	This paper deals with automated detection of the midsagittal plane (MSP) for brain surgical planning. The MSP bisects the human brain into two cerebral hemispheres. The detection of optimal MSP is based on a deep Hough plane network which combines the idea of Hough Transform based object detection with deep convolutional neural networks.	"In the sagittal plane localization task of 3DCT human brain image:

Make full use of image space and Hough space features to locate the sagittal plane.
The use of DHT increases feature sparsity and reduces computational cost."	"Following are the contribution of the paper:

Application of deep hough transform (DHT) and inverse deep hough transform (IDHT) which simplifies the plane detection problem into image space.
Combination of Hough transform along with CNN features to detect the MSP properly."
248	Identification of vascular cognitive impairment in adult moyamoya disease via integrated graph convolutional network	In this paper, the authors intend to propose a novel graph-based method of diagnosing VCI using two modalities (fMRI and DTI). The main contribution in methodology is two-fold: one is the dual-modal GCN to firstly process the two-modality images independently (graph construction and convolution) and fuses them together for the diagnosis, the other is the node-based normalization and constrain mechanism to resolve the over-smoothing issue in GCN and incorporation of the non-imaging information. Experiments such as ablation studies, SOTA comparisons and biomarker interpretations also demonstrate the effectiveness of their works.	This paper proposed a dual-modal GCN framwork to integrate imaging and nonimaging information for VCI identification in adult MMDs.	"This paper designs different ways to extract complementary information from
rs-fMRI and DTI when constructing graphs, which maximizes the utilization of
characteristics of different modalities.
Node-based normalization and similarity constraint item are proposed to improve performance by solving the problem of over-smoothing and integrating non-imaging information, respectively. 
3) Some salient biomarkers for VCI identification are selected by introducing self-attention pooling mechanism which combines node features and graph topology,
showing the clinical value of the proposed model."
249	Identify Consistent Imaging Genomic Biomarkers for Characterizing the Survival-associated Interactions between Tumor-infiltrating Lymphocytes and Tumors	The paper presents a multi-modal framework that fuses the interactions between TILs and tumors with a graph attention network and the genomic data by concrete autoencoders for prognosis predictions of breast cancer.	This paper analyses the role of immune cells, lymphocytes, in their role in survival of cases with tumours	Fusing imaging features with the genomic features has been used for the prognosis prediction of breast cancer in existing previous works. The contribution of this work is to use an attention mechanism for fusing imaging features with the genomic features.
250	Identifying and Combating Bias in Segmentation Networks by leveraging multiple resolutions	This paper described the analysis for resolution-bias in the segmentation network and explored the way to reduce the bias. In order to analyze the problem of the limitation of the segmentation network performance due to the resolution of the training data, a comparison experiment was performed using four approaches. This paper shows that the single resolution network fails to generalize across resolutions, but scale augmentation and network with resolution independence structure are helpful to reduce the bias.	This work illustrates how the resolution bias in the data distribution propagates to the output prediction. Their compare how different strategies such as input resampling, scaling augmentation perform in comparison with resolution-aware architectures, and demonstrate that the later approaches reduce such bias more effectively.	The authors present an analysis of volumetric bias from networks trained on image data acquired at one resolution influencing segmentation results on data acquired at a second resolution. To measure the volume bias, a normalized volume difference is computed between the ground truth segmentation and the predicted segmentation mask. For models and data, the authors test Unets, and voxel size independent neural networks (VNNs) trained with a variety of resampling on MRI images acquired from adults and children to provide a resolution challenge, and hippocampal volume segmentation. Volume bias is examined by looking at the distribution of volumes segmented, Dice similarity, and the volume bias of the predictions. Overall, the authors found that building scale-invariant networks, or using resolution augmentation can reduce volume biases.
251	Identifying Phenotypic Concepts Discriminating Molecular Breast Cancer Sub-Types	The authors propose a method to predict the molecular sub- types of breast cancer, and to identify the associated shared and discriminative visual traits from simultaneously acquired MRI and PET data.	This paper performed image classification on molecular sub-type classification for breast cancer patients. The proposed pipeline consisted of the classification using ResNet-18 pre-trained on ImageNet, the latent features were then extracted from the intermediate layers and clustered using k-means. Phenotypic Concepts were formed and weighting on these was calculated for each sub-type category.	This paper proposes an application of testing with Concept Activation Vectors (CAV) by Ghorbani et al., on breast cancer imaging, showing that the proposed methods provide interesting insights on visual features characterising breast cancer sub-types. The main contribution added to the state of the art method is the identification of patient-specific concepts in the latent space, rather than concepts that generalise to the entire pool of data.
252	Implicit Neural Representations for Generative Modeling of Living Cell Shapes	"The paper proposes a new cell shape representation method.
The paper proposes a deep learning framework for spatio-temporal cell representation and synthesis.
The proposed method allows for shape synthesis with virtually unlimited spatial and temporal resolution."	The paper addresses the use-case of generating synthetic datasets of cell shapes. It trains a NN to generate sequences of cell shapes from a signed distance function.	This paper proposes a approach to segmentation of living cells in 3d+t using a generative neural architecture. The paper is based on a level-set represented with a MLP that learns an implicit shape model from annotated images and is able to generate accurate boundary models of cells in fluorescence images.
253	Implicit Neural Representations for Medical Imaging Segmentation	This paper adopts a continuous implicit neural representations for medical image segmentation.	This paper propose a new segmentation method via using implicit neural representation.	This paper proposed a novel implicit organ segmentation network (IOSNet) that utilizes continuous implicit neural representations (INRs) to achieve memory-efficient and high-resolution medical image segmentation. Benefiting from the introduction of INRs, the presented IOSNet showed significantly smaller memory footprints and much faster convergence speed than the conventional fully convolutional networks. Experimental results on a clinical head and neck CT dataset demonstrated the superior performance and effectiveness of the proposed method in dealing with the 3D organ segmentation task, especially for small targets.
254	Improved Domain Generalization for Cell Detection in Histopathology Images via Test-Time Stain Augmentation	This paper proposes a test-time stain augmentation (TTSA) method for cell detection in histopathology images, which transforms the test image based on stain mix-up, and then the detection results from different augmented images are fused to produce the final output. The main contribution of this paper is the fusing parts, but an existing method (stain mix-up) [4] is used for stain augmentation. The fusing method is mostly based on the existing test-time ensemble method [3]. Therefore, the contribution is minor.	The authors propose a test-time stain augmentation method for cell detection under stain-varying conditions between source and target. The method uses conventional decomposition in the OD domain to decompose RGB images into the stain color matrix and stain density map. Multiple augmented test images are generated by mixing their stain color with the source domain through different weighting factors. The method is validated for cell detection on a publicly available dataset on which it outperforms the existing similar approaches	This paper is concerned with development of stain normalization method aimed for improving performance of cell counting in histopathology images. Thereby, the emphasis is to achieve robustness to domain variation (training set and target set do not come from the same staining protocol). In particular, the authors adopt test-time stain augmentation approach to domain generalization problem. The concept is based on generating mixtures of stain colors of source domain and target domain images. Given detection models fuses mixed images with the property to be less likely affected by the improperly mixed stains. Detection model is not required to be retrained, because it is applied during a test time only. The concept is validated on public dataset related to mitosis detection. In principle, proposed method improved counting performance in terms of A_50 metric (as well as F1 score).
255	Improving Trustworthiness of AI Disease Severity Rating in Medical Imaging with Ordinal Conformal Prediction Sets	This paper propose a distribution-free method of estimating uncertainty of ordinal predictions, with a simple approximate algorithm.An experiment is carried out on an stenosis grading task from MRI. The result is high-performing in comparison to the competing method, and the uncertainty score is able to select problematic examples as revealed by manual radiology review.	Th paper proposes an ordinal prediction set method that is guaranteed to contain the reported severity with a chosen probability in the context of automatic disease severity rating. It also shows a method to quantify the uncertainty in this setting.	Authors evaluate the usage of conformal prediction sets for uncertainty prediction in clinical settings.
256	Incorporating intratumoral heterogeneity into weakly-supervised deep learning models via variance pooling	The authors propose an attention variance pooling method to aggregate patch-level features into a WSI-level representation, which explicitly considers intratumoral heterogeneity. Experimental results show that adding this pooling method into existing multi-instance learning frameworks improves survival prediction in five WSI datasets of different cancer types.	In this paper, the authors propose an attention variance pooling module, that helps multiple instance learning (MIL) frameworks learn  intratumoral heterogeneity (ITH) information from encoded patch features of whole slide images (WSIs). This module can be incorporated into existing MIL frameworks for survival prediction tasks. Authors also provide two metric scores for interoperability. Experiments on five datasets from The Cancer Genome Atlas (TCGA) demonstrate the effectiveness of the proposed method.	Intratumoral heterogeneity in WSIs have been extensively studied in the past and ongoing efforts are focused towards characterizing the structural/appearance differences across different diagnostic subtypes. This paper addresses a key challenge of modeling complex fetaures of the tumor microenvironment. The authors have developed a novel variance pooling architecture that enables an MIL model to empower the inherent intratumoral heterogeneity into deep learning models. The authors also provide two interpretability tools to investigate the biological signals captured by the models.
257	INSightR-Net: Interpretable Neural Network for Regression using Similarity-based Comparisons to Prototypical Examples	"In this work, the authors propose an inherently interpretable CNN for regression using similarity-based comparisons (INSightR-Net).
Experiments were performed using a dataset of diabetic retinopathy grading.
The proposed network is able to achieve performances in line with the baseline while being inherently interpretable."	This work proposes propose an inherently interpretable CNN for regression tasks applied in the field of medical imaging, which utilizes the information of similarity-based comparisons. Specifically, the authors incorporate a prototype layer into the model architecture to visualize the areas in the image that are most similar to learned prototypes. The final prediction is then modeled as a mean of prototype labels. Extensive experiments conducted on the task of diabetic retinopathy grading demonstrating the effectiveness of the proposed method.	In this paper, the authors propose a INSightR-Net deep neural network for retinopathy grading. It relies on a CNN architecture with a prototype layer. Such protypes help for better explanation while achieving a good accuracy.
258	InsMix: Towards Realistic Generative Data Augmentation for Nuclei Instance Segmentation	Submission 807 proposes a new method for generating data augmentations to aid the task of instance segmentation of nuclei in histology images. The method contains 3 major components, each of which contributes into the final improvement. Extensive evaluation is made available, including a comparison to state-of-the-art. The proposed method clearly aids the segmentation network in all datasets shown.	The paper describes a novel image augmentation method, that is similar to Mix-based methods.	"This paper proposed InsMix which is a realistic data augmentation approach follows a Copy-Smooth-Paste principle. Compared with previous Copy-Paste methods, the InsMix mainly has three different components: 1. Morphology constraints (scale, shape, distance) to maintain nuclei's morphology characteristics. 2. Background perturbation is used for exploit effective use of the background information. 3. Smooth-GAN with triplet loss is designed for generate realistic augmented nuclei images.
The experiments were done in two public datasets. Ablation studies on each component were also provided."
259	Instrument-tissue Interaction Quintuple Detection in Surgery Videos	This paper proposes a neural network architecture to jointly localize and classify the instruments, tissues interacting with the instruments, and classify the action type. To enhance instrument and tissue detection performances, the anthers have employed joint spatio-temporal information via a spatiotemporal attention layer (STAL). A graph convolutional network is adopted to boost quintuple detection via reasoning relations between the instruments and tissues.	"The authors propose to represent instrument-tissue interaction as instrument
bounding box, tissue bounding box, instrument class, tissue class, action
classquintuples by extending the earlier works that represent them as triplets. Moreover, they localize these quintuples. They propose QDNet which aggregates spatial and temporal information through the use of a spatiotemporal attention layer (STAL) and a graph-based quintuple prediction layer (GQPL) which is able to infer tool-tissue relationships.
As part as QDNet, they propose a spatiotemporal attention layer (STAL) to aggregate spatial and temporal information of the regions of interest between adjacent frames, and a graph-based quintuple prediction layer (GQPL) to infer the relationship between instruments and tissues.
They build a cataract surgery video dataset with annotations named Cataract Quintuple Dataset. According to what is stated in the Reproducibility checkbox list, the authors intend to share this dataset."	The paper presents an approach for instrument-tissue interaction detection in surgery videos. In doing so, the authors use a Quintuple detection network (QDNet) and apply it to cataract surgery videos.
260	Interaction-Oriented Feature Decomposition for Medical Image Lesion Detection	This paper introduces the whole image context embedding to enhance the classification branch of the Faster RCNN solution for the lesion detection task. The main idea is to encode the whole image as a fixed size embedding and leverage the self-attention mechanism to interact with the RoI align features before the final classifier. Evaluated on two different datasets, the proposed approach can consistently improve performance.	This paper aims at improving the classification accuracy in lesion detection problems. In some problems, classifying different lesion types is closely related to the relative location and size of the lesion in the image. Therefore, the authors propose to use attention-weighted global features to do classification, instead of ROI features. They designed the Global Context Embedding module and the Global Context Cross Attention module for this goal. On a private OCT dataset and a public MRI dataset, 6% and 3% improvement were observed in the classification accuracy, compared to Faster RCNN.	This paper proposes a new framework to fuse global context features into local lesion features for better lesion detection. Specifically, a global context embedding (GCE) module and a global context cross attention (GCCA) module are introduced to combine global and local features for classification. Experiments are conducted on an inhouse OCT dataset and a public brain MRI dataset. Results indicate the proposed method achieves state-of-the-art performance. Ablation study proves the effectiveness of the GCE and GCCA modules.
261	Interpretable differential diagnosis for Alzheimer's disease and Frontotemporal dementia	The paper describes creating a tool to differentiate between cognitively normal (CN), Alzheimer's disease (AD), and Frontotemporal disease (FTD) since this is a tough task to do by just using cognitive tests or observing symptomatology. It describes using a deep grading (DG) framework with a support vector machine (SVM) to classify whether to assign a diagnosis of CN, AD, or FTD. Different groupings of data were also tested (AD+FTD+CN vs CN+FTD vs AD+CN vs AD+FTD) in order to test the best classification model.	In this paper, the authors propose a new method to perform specific-disease diag- nosis (i.e., AD vs. CN and FTD vs. CN) and differential diagnosis (i.e., AD vs. FTD and AD vs. FTD vs. CN). Their purpose is to expand the knowledge about dementia sub-types and to offer an accurate diagnosis tool in a real clinical scenario. They extend the recently proposed Deep Grading (DG) framework by training it with multiple types of dementia (i.e., AD and FTD).  Furthermore they propose an ensemble of the graph convolutional network and an SVM.	This paper aims at developing a machine-learning algorithm to classify multiple sub-types of dementia (e.g., Alzheimer's disease and Frontotemporal dementia) based on T1-weighted MR images.  The authors combine the classification results from a deep-learning-based grading framework that performs disease classification according to the structure-wised evaluation of the tissue abnormality, and an SVM algorithm that classifies the disease type by exploiting volumetric atrophy in dementia patients.  The proposed method reveals the abnormal brain structures that are characteristic of each dementia sub-type and allows improved classification results over existing methods.
262	Interpretable Graph Neural Networks for Connectome-Based Brain Disorder Analysis	This paper proposed an interpretable GNN to find the group-wise-specific connectome-level features. The authors provided clear descriptions for the algorithm, which could contribute to the future work.	The article proposes an interpretable deep learning framework to predict disease and identify disorder-specific salient regions of interest and important connections driving predictions. The method is applied to data set consisting of HIV positive subjects, one containing subjects diagnosed with bipolar disorder, and the publicly available data set of the Parkinson's Progression Marker Initiative. The method reveals much higher accuracy scores than several baseline methods	The authors proposed an interpretable brain network-oriented framework, in which a GNN is used to extract embeddings of ROIs from the brain MRI images and an explanation generator is used to learn a disease-specific masking matrix. Their experiments showed that the proposed method achieved superior prediction performance and interpretations derived from the learned masking matrix aligned with existing clinical understandings.
263	Interpretable Modeling and Reduction of Unknown Errors in Mechanistic Operators	The paper extends the DAECGI method to improve the reconstruction of the forward operator when errors are present in the initial estimation. The method cyclically updates the estimated corrected forward operator by generating a latent vector z based on the initial forward operator and the current estimated forward operator. By using an SOM, the types of errors can be revealed by examining the latent vector z for a set of initial and final forward operators.	Use prior knowledge to improve the performance.	The paper described a physics-inspired neural method for  the inverse problem of ECG. The method shows advantages over a pure physics-driven method (fully data-driven) or a pure neural network-based method (requires less training samples and has more interpretability).
264	Interpretable signature of consciousness in resting-state functional network brain activity	The Modular Hierarchical Analysis (MHA) linear latent variable model was used to differentiate the various conditions of consciousness using resting-state fMRI. The statistical analysis showed the signature of consciousness from 5 monkey data.	This paper proposed a four-stage strategy and used a constraint linear latent variable model to define the spatial pattern of different consciousness states.	This paper introduces a novel method for states of consciousness by understanding ROI connectivity patterns, proposing a new spatial biomarker for determining levels of consciousness.
265	Intervention & Interaction Federated Abnormality Detection with Noisy Clients	This paper proposed an approach based in Federated learning (FL) for abnormality detection with noisy clients. The novelty of the work lies in way of addressing the noisy input given by local model. It is very much desired in practice.  Experimental results are shown to show the improvement in the results.	"This paper presents a causality-inspired method for federated abnormality detection
with noisy clients and  designs a debiasing solution namely Intervention & Interaction FL framework  to alleviate the client confounder effect. 
The experiments on class-conditional noise and instance-dependant noise demonstrate the efficacy of the proposed method"	The paper presents a framework for abnormality detection in the setting of federated learning where a centralized global model is trained using decentralized, local data. The paper addresses the scenario where such a modeling scheme suffers from noisy labels across distributed clients, by using structural causal modeling (SCM) to identify the clients causing confounding bias. To resolve the bias, intervention and interaction approaches are used. Interaction adaptively estimates appropriate weights that balance local training status with global noise levels. Intervention uses these weights to shuffle and mix features from the local client and the global model to gradually reduce the detrimental effect of local noise.
266	Intra-class Contrastive Learning Improves Computer Aided Diagnosis of Breast Cancer in Mammography	The paper describes an extension of the contrastive learning approach for cancer detection from multi-view mammography images. They propose using contrastive learning with a triplet loss within normal and lesion classes to improve the separability of the embedding space. Comparison experiments demonstrate the benefits of their proposed approach.	This paper proposed novel loss functions that consider the contrastive properties among lesion and normal cases. The proposed methods can effectively work with various latest multi-task learning frameworks.	In this paper, authors introduced a contrastive learning framework involving Lesion Contrastive Loss (LCL) and Normal Contrastive Loss (NCL) to improve the overall accuracy.
267	Invertible Sharpening Network for MRI Reconstruction Enhancement	This paper proposed an invertible sharpening network (InvSharpNet) that adapts a backward training streategy that learns a blurring transform from the fully-sampled MR images to the underssampled images to improve the visual quality of MR image reconstruction.	"(1)	This paper proposed an invertible network for MRI reconstruction enhancement to make the image sharper.
(2)	The experiments demonstrate that the proposed InvSharpNet can improve reconstruction sharpness."	An invertible sharpening network (InvSharpNet) is proposed to improve visual quality of reconstructed MRI images. The authors propose a backward training strategy to train InvSharpNet from the ground truth image to the reconstructed image, and the inference is in the opposite direction.
268	Is a PET all you need? A multi-modal study for Alzheimer's disease using 3D CNNs	This paper proposes a framework for the systematic evaluation of multi-modal DNNs and critically re-evaluate single- and multi-modal DNNs based on FDG-PET and sMRI for binary healthy vs. AD, and three-way healthy/mild cognitive impairment/AD classification.	The author proposed to investigate the utility of multi-modal MRI + FDG PET for Alzheimer's disease classification using deep-learning. They conducted a robust comparison of this two modality and different fusion schemes.	This paper designs a framework for the systematic evaluation of multi-modal DNNs and critically re-evaluate single- and multi-modal DNNs based on FDG-PET and sMRI for binary healthy vs. AD, and three-way healthy/mild cognitive impairment/AD classification. This study conforms with the established clinical knowledge on AD biomarkers, but raises questions about the true benefit of multi-modal DNNs.
269	iSegFormer: Interactive Segmentation via Transformers with Application to 3D Knee MR Images	The paper shows how to use a pretrained Transformer model for interactive image segmentation. It obtains a model that uses a small number of clicks to segment knee cartilage MRI images.	"This paper presents a novel deep learning architecture based on a vision transformer (ViT) to solve interactive MR image segmentation. Interactive image segmentation takes in user input in addition to the image itself: the user may click on the image with a ""positive click"" to indicate a region that should be segmented as foreground and with a ""negative click"" to indicate a region that should be segmented as background. While ViTs have been applied to non-interactive image segmentation a number of times in the literature, this is the first use of ViTs in interactive image segmentation as far as I can tell (this is also what the authors claim). The authors compare their model to state-of-the-art CNN-based architectures (known for lighter memory requirements than ViTs) on 2D MRI knee cartilage segmentation. The authors make efforts to design their ViT-based architecture in a memory-friendly way with a Swin Transformer encoder and a lightweight MLP-based decoder."	The authors proposed an interactive segmentation method using a memory-efficient method combining a Swin transformer with a lightweight multilayer perceptron decoder. They applied their method to interactive 2D medical image segmentation on the public OAI-ZIB dataset for the segmentation of knee cartilage on MRI. The authors claim their method's performance is superior to its CNN counterparts while achieving comparable computational efficiency. They further extended their transformer model to 3D interactive knee cartilage segmentation borrowing techniques from video analysis to extend 2D slice-based segmentations into 3D within the other previously unsegmented image slices.
270	Joint Class-Affinity Loss Correction for Robust Medical Image Segmentation with Noisy Labels	The paper addresses medical image segmentation with noisy labels. It introduces a joint class-affinity segmentation model to consider both pixel-wise label correction and pair-wise pixel relations to reduce the label noise rate. A DAR is proposed for affinity reasoning and an affinity-based loss function is designed for regularization.	This paper introduces a new method for robust medical image segmentation under noisy labels. The core of the proposed method is a novel Joint Class-Affinity Segmentation (JCAS) framework, which takes into account both pixel-wise class and pairwise affinity supersivions. Specifically, to rectify the pixel-wise segmentation mask, a differentiated affinity reasoning (DAR) module is developed. To effectively train JCAS, a class-affinity loss correction (CALC) strategy is introduced to correct supervision signals. Experimental results show that the proposed method outperforms the previous works under both synthetic and real-world noisy labels on one dataset.	This paper presents a novel segmentation framework using noise labels in the surgical instrument dataset. The proposed method is constructed by the affinity representation learning in the inter-class and intra-class manners. Extensive experiments demonstrated the effectiveness of the proposed method by outperforming comparison methods under various types of noisy labels.
271	Joint Graph Convolution for Analyzing Brain Structural and Functional Connectome	This paper proposes a joint graph convolution for both structural and functional brain connectomes.	The authors proposed a graph convolutional networks (GCN) based model to represent the nodal coupling strength between brain structural and functional network by adding learnable inter-network edges between corresponding brain regions. By employing individual MRI data of 662 participants with 5-fold cross-validation strategy, they showed that this model performs better in age and sex prediction task than previous SVM or GCN methods.	This paper proposes a joint graph convolutional neural network to combine brain structural and functional connectome for further application, such as age prediction or gender classification.
272	Joint Modeling of Image and Label Statistics for Enhancing Model Generalizability of Medical Image Segmentation	The paper proposes a method referred to as Bayesian segmentation, or BayeSeg, for probabilistic image segmentation with the purpose of improving method generalizability. The method uses a probabilistic autoregressive model consisting of a combination of ResNets and UNet to decompose the input image into a basis and a contour. The contour is used to infer the segmentation, as it is argued to be more site and modality independent. The approach is tested for cross-sequence and site cardiac MRI segmentation with superior results to U-Net and the probabilistic U-Net.	"A deep learning based segmentation algorithm that decomposes shape (""contour"") and appearance (""basis"") in order to better generalize across imaging protocols, centers and population bias.
A dedicated analysis on cardiac MRI data shows substantial improvements in terms of transfer learning (e.g. training on LGE MRI, testing on T2 MRI etc.) compared to vanilla u-nets and related state-of-the-art.
While the overall idea may not be brand new (e.g. tested for multimodal registration https://arxiv.org/pdf/1903.09331.pdf), the detailed model appears to be novel and seems to provide a thorough derivation and convincing results."	"The author proposed a  deep learning-based Bayesian segmentation framework that decomposes an input image into components of contour and basis. The segmentation label is then inferred from the contour component, which varies less across different MRI sequences.
Unlike conventional Bayesian methods, the framework is implemented with neural networks, where three CNNs were trained to infer the posterior distributions.
The author evaluated the proposed solution on public databases, significant improvement in segmentation accuracy was observed."
273	Joint Prediction of Meningioma Grade and Brain Invasion via Task-Aware Contrastive Learning	The authors developed and implemented a network to simultaneously predict two binary clinical values from MR image data. Those values were meningioma grade (low or high) and brain invasion (no or yes). The input was the image data from three types of MR acquisitions (T1 with contrast, FLAIR with contrast, and ADC calculated from MR DWI). Using MR images collected retrospectively from 800 studies, the authors trained and tested their proposed network and compared the results with other networks they also implemented using quantified metrics such as sensitivity, specificity and AUC. The proposed method had highest values for most measures, and if not highest it was second highest.	The authors develop an approach for multimodal multitask learning for meningioma grade and brain invasion classification. The proposed architecture accepts multimodal inputs to produce a common feature representation that is then deconvolved into common and task specific feature vectors. Furthermore, a contrastive loss module is imposed to improve task-specific feature representations and model predictions.	"The goal of this paper is to present a novel model for joint prediction of meningioma grade and brain invasion from multi-model MRIs. A multi-task learning approach is proposed that derives task-common and task-specific features from a shared encoder. A contrastive learning strategy is used to align the task-common features for each task and enforce similarity between feature embeddings contributing to the same task.
The method is evaluated on a private database of 800 multi-modal MRIs (T1, Flair, ADC). Dataset is imbalanced with most meningioma being low grade. Results are promising with some interesting AUC for both task although a bit lower for meningioma grade prediction."
274	Joint Region-Attention and Multi-Scale Transformer for Microsatellite Instability Detection from Whole Slide Images in Gastrointestinal Cancer	In this paper, the author proposed a new transformer based approach for MSI detection, which is a WSI MIL problem.	The paper describes a method to detect Microsatellite Instability from whole slide images stained with HE, as well as from regions. The method uses an attention map to sample patches to get more predictive power and uses a transformer architecture to combine two levels of infomation, region level and patch level in forms of extracted features. The region level architecture is leveraged to build a slide level architecture by aggregation regions in a modified architecture.	A transformer based model was proposed to detect microsatellite instability status from while slide images, which outperforms existing patch-supervision methods on the gastrointestinal cancer data set from TCGA. To preserve representative features and remove noisy and redundant data, a feature weight sampling method was proposed.
275	Kernel Attention Transformer (KAT) for Histopathology Whole Slide Image Classification	This paper presents a novel framework for WSI classification. Its main contribution comes from: 1) leverage the spatial relationship of the patches and kernels, some representative points,  2) introducing a novel module of ViT.	This paper proposed a kernel attention transformer (KAT) for WSI classification. The information transmission of the tokens is achieved by cross-attention between tokens and a set of kernels related to the spatial relationship of the tokens on the WSI. KAT was evaluated on a gastric dataset with 2k WSIs and an endometrial dataset with 2.5K WSIs. Results have shown the proposed KAT is effective and efficient in the WSI classification and is superior to the state-of-the-art methods.	The paper proposes the Kernel Attention Transformer for classification of WSIs, which builds on the promise of ViTs whilst addressing some of the issues they face when confronted with WSIs. It also provided details on the pipeline into which this network fits.
276	Key-frame Guided Network for Thyroid Nodule Recognition using Ultrasound Videos	"The paper investigates akey-frame guided video classification model for thyroid nodule recognition and diagnosis. The overall framework contains two parts, the first part is for key-frame localization. In this part, a detection-localization network (based on Faster-RCNN) is trained to localize the frames with clinically typical thyroid nodules in dynamic ultrasound videos. The second part is a ultrasound video classification network (based on lightweight 3D convNet) for thyroid nodule classification/diagnosis. By making use of the adjacent N(N=32) frames of a ultrasound video, the video classification network can take the advantage of temporal information for a more precise classification.
The authors have collected over 3000 clinical thyroid ultrasound videos labelled by three radiologists for the experiments."	The manuscript represents an automated localization approach for the key frame identification in thyroid US videos combined with a motion attention module in order to have a more focus on the significant frame.	The paper first proposes a detection-localization framework to automatically identify the clinical key-frames with typical nodules in each ultrasound video. Based on the localized key-frames, the authors develop a keyframe guided video classification model for thyroid nodule recognition. Besides, the authors introduce motion attention module to help network focus on significant frames in an ultrasound video, which is consistent with clinical diagnosis.
277	Knowledge Distillation to Ensemble Global and Interpretable Prototype-based Mammogram Classification Models	This work proposes and describes network that adds interpretability to a global model by assembling it with a prototype-based model. The proposed approach was tested in their own database and in a public available database. Results are similar to state-of-the art approach with the advantage of interpretability results.	To integrate the advantages of accurate global models and interpretable prototype-based models, the proposed ProtoPNet++ distills the knowledge from the global model to the prototype-based model. The performance and interpretability of the proposed ProtoPNet++ are valiated on private and public datasets.	This paper proposed ProtoPNet++, which ensemble a global model with a prototype-based model for mammogram classification tasks (cancer/no cancer). Such combination is claimed to be both more accurate than the baselines and can provide more interpretability.
278	Landmark-free Statistical Shape Modeling via Neural Flow Deformations	This paper propose a novel shape model based on continuous neural flows, which produce natural shape deformations without relying on dense correspondence between training shapes	This paper proposes a novel shape space representation based on diffeomorphic deformation of templates parameterized by the PCA codes of the latent space of a MLP. The authors show on 3 examples that this shape space is expressive and is suitable to discriminate between healthy and pathological cases. The representation generalizes the shapeflow approach by considering multiscale deformations through the addition of  a local latent representation	Authors present a novel method for shape modeling based on neural flow deformations.
279	Layer Ensembles: A Single-Pass Uncertainty Estimation in Deep Learning for Segmentation	The authors proposed an uncertainty quantification method that could estimate the segmentation uncertainty in a single pass. They conducted experiments on two datasets and compared the proposed algorithm with the deep ensemble method.	The paper proposes a method for lowering the cost of uncertainty estimation methods that are based on network weight sampling by introducing layer ensembles. Therefore, instead of individual networks an ensemble can be built from a single networks' different depths. Given the high sampling cost of state of the art uncertainty method of standard ensembles, the work is very valuable.	This paper proposed a new measure of uncertainty to evaluate segmentation on image level.
280	Learn to Ignore: Domain Adaptation for Multi-Site MRI Analysis	This paper proposes a supervised domain adaptation approach for classification of Multiple sclerosis patients and healthy controls on MRI scans. The target dataset contains images from one scanner type only, whereas the source data contains different scanner types. The authors propose to learn cluster centers based on the target data, and force latent vectors from the target and source data to be close to those centers. The approach outperforms several domain adaptation and contrastive learning approaches on the target domain and keeps good performance on the source domain.	The authors formulate a new domain adaptation paradigm where diseased and healthy participants come from different studies in the source domain. They propose a method to enforce the latent codes from different classes to be far from each other whereas the codes within each category close to each other by introducing a center point loss and a latent loss. Essentially, the losses are controlled by two parameters: the radius of each class sphere and the distance between the clusters. In an experiment of multiple sclerosis classification, the proposed method outperforms the other domain adaptation methods on target domain when training on both source and target domains.	The authors propose a novel domain adaptation/harmonization method for MRI acquired by different scanners. Adaptation is facilitated by adding specific constraints on the latent space of the MRIs to reduce the domain shift caused by scanner differences. Experiments on several MR datasets demonstrate the effectiveness of the proposed method.
281	Learning Incrementally to Segment Multiple Organs in a CT Image	"The authors propose a method to perform incremental learning (IL) of segmentation models using datasets with disjoint, potentially non overlapping annotations throughout the dataset. The authors propose to use a ""light memory module"" to make the location and approximate shape of previously seen anatomies persistent persistent during model training and a loss function that prevents the effects of conflicting labels for certain regions."	In this paper, the authors aimed to tackle the partially labeled datasets training problem using incremental learning. The paper is clearly written and easy to follow. The general idea of combining multiple datasets in multi-organ segmentation drives its novelty. Evaluated using five public datasets and multiple backbone networks, the proposed method demonstrates its effectiveness.	This paper introduces an incremental learning mechanism to learn a single multi-organ segmentation model from partially labelled, sequentially constructed datasets. Able to deal with the catastrophic forgetting issue, the developed method includes a light memory module to stabilize the incremental learning process as well as new loss functions to restrain the representation of different categories in feature space. The experiments performed on organ segmentation from CT scans using five publicly-available datasets reveal the effectiveness of the proposed contributions.
282	Learning iterative optimisation for deformable image registration of lung CT with recurrent convolutional networks	The authors propose a deep learning-based approach called learn to optimize (L2O), that aims to emulate the structure of gradient-based optimization used in conventional registration. The proposed architecture consists of recurrent updates on a convolutional network with deep supervision. It uses a dynamic sampling of the cost function, hidden states to imitate information flow during optimization and incremental displacements for multiple iterations.	This paper proposes a novel recurrent framework to emulate instance optimization for deformable image registration, using an iterative dynamic cost sampling step.	The authors present a deep learning based approach to emulate the structure of gradient based optimization (Adam optimizer).
283	Learning Robust Representation for Joint Grading of Ophthalmic Diseases via Adaptive Curriculum and Feature Disentanglement	"The manuscript describes a method that addresses diabetic retinopathy and its associated diabetic macular
edema together in a single framework.
The main purpose of the work is to design an automatic grading system with good generalization for DR and DME.
To avoid ignoring potential generalization issues, the authors proposed a dynamic difficulty-adaptive
weight (YAW) and the dual-stream disentangled learning architecture (DETACH), in order to learn way different features with curriculum learning, and separates features of grading to avoid potential emphasis on bias, respectively.
Experiments are conducted on three well-known datasets, either intra and cross."	The paper proposes a network for joint grading of diabetic retinopathy (DR) and diabetic macular edema (DME). The proposed network uses a dynamic difficulty-adaptive weight for weighting samples gradually, and two encoders with a detached shared features to model the correlation between the two tasks and find a disentangled representation of the features.	The authors proposed a CANet for automated DR and DME diagnosis and grading. The YAW is used to specifically dealwith hard samples, while the DETACH is used for disentanglement of DR and DME for more robust diagnosis.
284	Learning self-calibrated optic disc and cup segmentation from multi-rater annotations	"This paper describes a self-calibrated optic disc (OD) and cup (OC) segmentation model from multi-rater annotations. The major contributions are:

A recurrent learning framework is proposed for the self-calibrated segmentation using multi-rater annotations.
In the proposed framework, two models are designed for recurrently learning the multi-rater expertness maps, and separating multi-rater annotations from the estimated segmentation masks."	The authors propose a new method for calibrating multi-rater annotation for optic disc and cup segmentation. Unlike previous studies, the proposed approach leverages recurrent attention network and self calibration to simultaneously calibrate segmentation and learn the consensus between the annotations from multi-raters. The design was guided by half-quadratic optimization. They provided extensive experimental validations that outperformed state of the art.	The work proposes a novel method to learn a segmentation from multi-rater annotations and show the usefulness of the method on the segmentation task of optic disc and optic cup in fundus images. The segmentation output is produced through an iterative optimization of multi-rater expertness estimation and unified segmentation based on expertness.
285	Learning shape distributions from large databases of healthy organs: applications to zero-shot and few-shot abnormal pancreas detection	This paper proposes a scalable and data-driven approach to learn shape distributions from large databases of healthy organs, in order to learn normative shape models from collections of healthy organs for anomaly detection.	"They propose a scalable and data-driven approach to learn
shape distributions from large databases of healthy organs"	The authors aim to learn a shape atlas using a U-Net architecture with the ultimate goal to obtain a reference atlas for possible normal shapes. The approach is evaluated on a dataset with approx. 2600 images of healthy pancreas. The obtained shape model is then evaluated using images of a pathological and healthy pancreas and classifying them using a one-shot/few-shot learning approach.
286	Learning towards Synchronous Network Memorizability and Generalizability for Continual Segmentation across Multiple Sites	Authors propose a new Synchronous Gradient Alignment objective and associated dual meta objective. The paper also provides some technical and heuristic details on replay buffers in order to reduce redundancy and improve model generalisability.	The paper proposes a continual learning + domain generalization framework for a series of multi-site prostate segmentation datasets. A dual-meta algorithm aligns the gradients between the previous and new sites, and also between the train and test sites (for the given sites). A seven-site dataset on prostate segmentation was used for evaluations.	The authors in their study delivered a learning technique (SMG-Learning) which tries to deliver memorability and generalizability of a network in domain shifted datasets. They utilised a Synchronous Gradient Alignment (SGA) objective, a Dual-Meta algorithm to deliver the SGA objective without expensive computation overhead, and a replay buffer to verify the efficient rehearsal and to reduce redundancy.
287	Learning Tumor-Induced Deformations to Improve Tumor-Bearing Brain MR Segmentation	The authors aim to segment the brain despite the presence of large tumors. Given a brain tumor segmentation, the proposed method uses synthesized images with accompanying ground truth deformation fields of mass-effect and infiltration to learn the tumor-induced deformation to the rest of the brain with a point cloud network. During inference, a tumor is injected into an atlas (including both a new tumor label plus deformation of the rest of the brain), and this new patient-specific atlas is used in atlas-based segmentation. The main experimental results include an improvement of about ~4 Dice over SAMSEG for subcortical labels on the tumor side in simulated images, plus qualitative results on real images from BraTS.	The authors have proposed a method to learn brain deformation induced by tumors to improve brain MR segmentation. To this end, they have trained a point-cloud deep learning network to learn deformation caused by the growth of the tumor and used it to warp a healthy brain atlas so that it can be used for pathological images. They have mainly used synthetic data for the validation of the proposed method and real dataset is only used for qualitative evaluation.	"The paper proposes a novel whole brain segmentation method in the presence of pathology (tumours). The method first predicts the displacement field induced by the tumour using a point based deep network trained from synthetic data. Next, an atlas is deformed with the predicted deformation field to account for the tumour growth. Finally this atlas is matched with the current image to produce the final brain segmentation.
The regression deformation network uses two models - (1) a direct displacement field and (2) a diffeomorphism represented using a SVF. The network is trained using synthetic data - simulated tumours using TumorSim [ref 26]
The method is evaluated in 3 ways: (1) by testing the brain symmetry after reversing the computed deformation field; (2) using data that synthesize pathological ground-truth by fusing well-labelled health brain images (MindBoggle-101) and tumor scans (BraTS) (3) using real tumour data from BRATs (only qualitative evaluation)"
288	Learning Underrepresented Classes from Decentralized Partially Labeled Medical Images	This paper proposed 'an under-explored problem' federated partially supervised learning. And they also proposed a framework to solve the problem with federated self-supervised learning, energy-based loss and a prototype based inference. Ablation study showed better results than some baselines.	The paper proposes a federated learning framework for learning underrepresented classes under partial label scenarios. The framework contains a self-supervised learning for warmup, an energy-based partial label learning for differentiating common classes and underrepresented classes, and a prototype-based inference stage for final testing. The results showed good improvement compared with baselines.	This paper studies a new problem, where underrepresented classes only have few labeled instances available and only exist in a few clients of the federated system. They proposed a novel FL framework FedFew, which consists of three stages and show good results on multi-label classification tasks.
289	Learning with Context Encoding for Single-Stage Cranial Bone Labeling and Landmark Localization	The paper proposes a method for cranial bone segmentation and landmark localization based upon the well known unet architecture.	This paper proposes a context encoding-constrained neural network for single-stage skull bone segmentation and landmark detection from cranial CT images. The authors designed a context encoding module based on U-Net for feature learning that considers the global image context, .and introduced an auxiliary regression task that models the relative spatial configuration of the anatomical landmarks to promote the landmark detection. The method was evaluated on pediatric 3D CT images, showing superior performance compared with the related methods	In this study, the authors developed a novel method for a single-step segmentation and landmark localization of the cranial bones. The authors achieved this by incorporating a context encoding network into the U-net architecture. This context encoding mechanism helped capture image related feature information in order to avoid isolating  pixel level prediction from the global image context. At the same time, the authors have added an auxiliary task of modeling the relative relationships of different anatomical landmarks spatially.
290	Learning-based and unrolled motion-compensated reconstruction for cardiac MR CINE imaging	"The authors propose an end-to-end  reconstruction and registration network for MR  image reconstructionn.
Their proposed approach, effectively iterates reconstruction and  registration steps within the same network, which allows them to train and  execute them jointly."	The authors propose a learningbased self-supervised framework for MCMR, to efficiently deal with nonrigid motion corruption in cardiac MR imaging. A dynamic motion estimation was embed into the unrolled optimization, which can deliver more precise and deailed estimation.	The proposed work solves an important problem related to dynamic MRI data of accounting for motion compensation while reconstructing undersampled data. This method provides a framework to perform motion compensated and high quality MRI data acquired in low scan times.
291	Learning-based US-MR Liver Image Registration with Spatial Priors	The paper proposed a registration framework for preoperative alignment of 3D ultrasound and MRI liver images. The initial alignment was achieved by using the right intercostal spaces from MRI as spatial priors for ultrasound positioning.	This paper develops a pipeline for within-subject in-vivo 3D ultrasound/MR liver image registration based on right rib segmentation, probe-orientation estimation, learning-based point-cloud registration, and refinement using image similarity. The method was evaluated on 18 subjects.	"The paper presents a method to perform liver image registration using patient-specific magnetic resonance and intercostal ultrasound images.
Clinically, alignment of pre-interventional magnetic resonance imaging and ultrasound images is frequently required and represents an interesting topic.
An initial alignment between the MR and US images is estimated based on the spatial priors.
A learning-based approach is considered for the rigid image alignment. Accuracy is improved by using the LC2-based non-rigid method.
A detailed description of the workflow is presented with an assessment of performance and validation using 18 clinical cases."
292	Lesion Guided Explainable Few Weak-shot Medical Report Generation	"This paper proposed a multi-view lesion guided few weak-shot learning for explainable medical report generation, which is the first model in such a complex task.
Different from existing report generation frameworks that use the global features of images for the generation, this method uses regional lesion features by jointly learning with a lesion region detection task. 
for weak-shot learning, this method builds a soft label for exploiting the semantic relationship between seen and novel diseases."	This paper proposes to leverage the few weak-shot learning for medical report generation. The few short setting lies in potential unseen lesion types in the testing cases.  The report generation is coupled with the lesion detection task and uses the detection results for guidance. To better improve the model, the authors further propose a soft target of lexical embeddings training. Lexical features and visual features are combined before being fed to the generative model. Experiments on the Fundus Fluorescein Angiography Images and Reports dataset (FFA-IR) demonstrated the superiority of the proposed method.	The paper uses weak ZSL to transfer knowledge from a model trained on seen to unseen lesions/classes using images and pixels. It is a novel approach to reduce human annotation requirement for retraining models on new diseases using multi view embeddings.
293	Lesion-Aware Contrastive Representation Learning for Histopathology Whole Slide Images Analysis	"The paper proposed a novel weakly supervised representations learning method with
a designed lesion queue under the setting of contrastive learning."	The authors propose a weakly supervised contrastive learning framework called LACL, where WSI labels are introduced to relief the class collision problem. Specifically,  LACL builds a queue for each WSI class, thus negative samples are selected from different classes. To effectively update the queue, the authors select the representative samples based on the similarity distribution.  The authors validate LACL on two WSI benchmarks and achieves incremental performance gain.	Authors propose a novel class-aware semi-supervised contrastive learning framework LACL for histopathological images. LACL replaces the memory bank of MoCo with several class-specific queues. Negative samples are generated from these queues to alleviate class collision problem. To guarantee the queue purity, a queue refinement strategy is proposed for queue updating. Authors validate the proposed method on two WSI-level classification datasets.
294	Lesion-aware Dynamic Kernel for Polyp Segmentation	The paper proposes a method for endoscopic polyp segmentation that uses an adaptive/dynamic kernel for optimizing features relevant to a polyp; the method also utilized two new attention modules ESA and LCA. Rigorous evaluation on public data provides experimental support.	This manuscript proposes the lesion-aware dynamic kernel (LDNet) for polyp segmentation, which is generated conditioned on the global information and updated by the multi-level lesion features. The dynamic kernel endows LDNet with more flexibility to attend to diverse polyps' regions. Besides, LDNet use two tailored attention modules (ESA and LCA) to improve the feature representation and enhance the context contrast. Extensive experiments and ablation studies demonstrate the effectiveness of LDNet.	This paper describes a method for polyp segmentation that combines a U-net segmentation architecture with dynamic kernel update as well as self-attention and cross-attention modules. These components are brought together to produce accurate lesion segmentations validated across various datasets.
295	Less is More: Adaptive Curriculum Learning for Thyroid Nodule Diagnosis	This paper aims at improving the accuracy of the thyroid nodule classification. The existed methods can't fit well with the inconsistent information between the label obtained by the cytological biopsy and the ultrasound imaging TI-RADS criteria, so the author propose an adaptive curriculum learning framework, which adaptively discovers and discards the samples with inconsistent labels. Moreover, the authors contribute a new thyroid nodule classification dataset to facilitate future related research on the thyroid nodule.	This paper presents a model for adaptive curriculum learning that can adaptively eliminate the samples with label uncertainty from the prediction function. The paper contributes a dataset to evaluate the model on.	This paper proposed an adaptive curriculum learning for thyroid nodule classification based on ultrasound images. The proposed confidence queue and certainty queue can help the model pick out hard samples. Moerover, the authors provide a new dataset for thyroid nodule classification. The experimental results show the superiority of the proposed method against SOTA methods.
296	Leveraging Labeling Representations in Uncertainty-based Semi-supervised Segmentation	"This paper proposes an uncertainty-based method for semi-supervised segmentation. Based on a common teacher-student framework, it introduces a labeling representation module, which is a pre-trained denoising autoencoder (DAE), in order to estimate a ""perfect"" segmentation map from the current prediction. The uncertainty map is estimated by the pixel-wise difference between the teacher and DAE predictions to guide the training of the student model. Experiments show the SOTA segmentation accuracy on the Left Atrium dataset."	This paper proposes a labeling representation-based uncertainty estimation algorithm for semi-supervised segmentation. It obtains better performance than SOTAs on left atrium segmentation from 3D MR volumes in two different settings.	The paper proposed a novel labeling representation-based uncertainty estimation method for  the semi-supervised segmentation, which requires only single inference. Specifically, a pre-trained denoising autoencoder is used to maps the predictions of the segmentation into set of plausible masks. Then the uncertainty is calculated based on the difference between the predicted mask and the reconstructed mask. The experiments show that the proposed network achieves the state-of-the-art results.
297	LIDP: A Lung Image Dataset with Pathological Information for Lung Cancer Screening	"The authors present a database of CT images suitable for the development and evaluation of pulmonary nodule classification algorithms, of clinical relevance, specially in lung cancer screening.
The main contribution of the paper is that, to the authors claim and to my understanding too, this is the first lung cancer screening dataset that has pathological gold standard for its nodules. Previous databases use radiological interpretation of the type of nodule by experienced radiologists, however, there is an inherent likely interpretation error by such label. The well accepted gold standard for nodule classification is biopsy and pathology assessment. All the patients underwent surgery post their CTs and the nodules were analysed pathologically.
The database is relatively large (990 CT scans), from a plurality of institutions (8) .
The authors further show the poor performance of state of the art algorithms train on other databases on the new database."	The paper introduces a new Chest CT dataset consisting of labeled nodules (location and segmentation) with pathology-based ground truth and demonstrates its importance in comparison to limitations identified in the LIDC_IDRI dataset. Models trained on both datasets are used to demonstrate these findings.	This paper presents a new dataset for lung cancer screening with pathological information, called LIDP. It is emphasized that the LIDC-IDRI lung nodule dataset has been over-studied and has crucial generalization problems.
298	LifeLonger: A Benchmark for Continual Disease Classification	The authors propose a benchmark for different continual learning scenarios (task incremental, class incremental and cross-domain incremental) base on the MedMNIST dataset. They provide the setup of the benchmark and run multiple state-of-the-art continual learning methods as baselines.	This paper presents a benchmark for continual learning algorithms on 4 datasets from the MedicalMNIST collection, for multi-class classification. They evaluate state of the art continual learning algorithms in task-, class- and domain- incremental learning settings. The cross-domain incremental learning setting is newly defined in this paper, where each domain is a different dataset, with different classification task.	"Similar to the ""SplitMNIST"" and ""PermutedMNIST"" benchmarks commonly used in continual learning literature, the authors propose using ""MedMNIST"" as a simple, computationally inexpensive benchmark dataset for continual disease classification. They evaluate five different methods in three (or four, depending on how these are viewed) settings and report the average accuracy and forgetting scores."
299	LiftReg: Limited Angle 2D/3D Deformable Registration	This paper proposes a new network for performing 2D/3D registration from limited view x-ray. Feasibility is demonstrated using CT + DRRs	This paper provides a deformable 2D-3D registration algorithm based on an artificial intelligence algorithm capable of regressing deformation field vector between the source and the target images. A unique aspect of this algorithm is the back projection of 2D projections into a 3D space and regressing the transformation between the back-projected 3D space and the source 3D space. The performance of the developed method has been evaluated on two a publicly available dataset and according to target registration error and dice coefficient metrics. As a core contribution, the training loss is calculated in a 3D space allowing for better representation of the deformation parameters in all directions (specifically along the projection direction).	The manuscript describes a method to predict deformation vector fields between a 3D source image and 2D limited-sampled projections.
300	Light-weight spatio-temporal graphs for segmentation and ejection fraction prediction in cardiac ultrasound	The paper proposes a graph convolutional network (GCN) for segmenting the myocardial border of the left ventricle in single-frame echo. They also propose a ulti-frame model with a GCN branch for ED/ES segmentation and other branches for EF regression and ED/ES frame classification.	"In this work, the authors propose a CNN + GCN based approach for joint LV segmentation and EF estimation, from cardiac Ultrasound images. The segmentation is done via keypoint regression, as opposed to semantic segmentation. This seems to be the key novelty here. Spiral Net, a type of GCN, is used for the keypoint regression.
They train a single frame model for keypoint regression. They also train a multi-frame model, which does both keypoint regression + EF estimation. EF can be estimated from either the keypoints, or the direct estimation. The direct regression based estimation seems more accurate. 
The keypoints that are outputted help enhance explainability."	The authors propose a DL model for the segmentation of the LV in four-chamber-view using echocardiography. Thanks to the combination with graph neural-networks, they are able to recover 2D contours instead of just a segmentation mask. The model is fast thanks to the use of light architectures, and is evaluated against the SOA.
301	Local Attention Graph-based Transformer for Multi-target Genetic Alteration Prediction	The paper presents a local attention graph-based Transformer for multiple instance learning with an efficiently adapted loss function to learn expressive WSI embeddings for the joint analysis of microsatellite instability and mutation prediction.	The authors proposed LA-MIL, a local attention-graph based transformer for multiple instance learning in whole slide images. The authors demonstrated LA-MIL could effectively predict microsatellite instability and tumor mutational burden jointly with genetic alterations in gastrointestinal cancer.	A local-attention graph-based transformer model is proposed to restrict self-attention calculations which improves the performance of mutation prediction comparing with the state-of-the-art methods in many cases.
302	Local Graph Fusion of Multi-View MR Images for Knee Osteoarthritis Diagnosis	This paper proposed a local graph fusion network (LGF-Net) to extract features from multi-view MR images for knee osteoarthritis (OA) diagnosis. Specifically, a knee graph is first constructed based on the segmentation of sagittal-view MR images and the intersection of the multi-view MR images. After that, a local graph fusion (LGF) module is devised for the fusion of multi-view patches. Moreover, a graph transformer network (GTN) is developed to aggregate the features among different patches and to predict the grading of OA. Experimental results demonstrate the effectiveness of the proposed LGF-Net.	In this work, the authors propose a graph fusion network to fuse local patch information from multi-view MR images for knee OA classification. The proposed framework includes a knee graph construction step using knee segmentation labels and interpolation points of multi-view slices, and a local fusion network (LFN) to encode each vertex's local patch information, and then a graph transformer network (GTN) to aggregate multi-view patch features along the edges of generated graph in the first module. The proposed framework has obtained higher performance by comparing with some related papers.	The authors used multi-contrast MR images of the knee to identify WORMS of the knee for osteoarthritis.  Unlike previous approaches of fusing the information from multi-contrast/multiview images at later stages of a network, the authors proposed to use a local fusion using a graph transformer network. The paper demonstrated that the local fusion with registered MR images using bone segmentation and a graph construction.
303	Localizing the Recurrent Laryngeal Nerve via Ultrasound with a Bayesian Shape Framework	This paper presented a  learning-based framework to identify the RLN from a US image for pre-operative assessment of contraindication for robotic thyroidectomy, which introduces Bayesian shape alignment and Locate-Net for geometrical constraints and localization result refinement, respectively.	Clinically, this paper helps clinicians to find the recurrent laryngeal nerve with ultrasound images. Technically, it puts forward a coarse-to-fine method to find the nerves in a segmentation network.	The authThis paper proposed a recurrent laryngeal nerve (RLN) localization method in ultrasound images. The Bayesian shape alignment is applied to obtain the ROI center according to the surrounding organ segmentation results. Small and large ROI patches are cropped from the ultrasound image and then fed into a coordinates regression network.
304	Local-Region and Cross-Dataset Contrastive Learning for Retinal Vessel Segmentation	The authors present a novel segmentation network for the retina vessel segmentation task. The main idea of the paper is to apply contrastive learning into the vessel segmentation network. The contrastive learning approaches are studied in the paper. One is the local region contrastive learning by selecting hard samples in a local region manner. The second one is the generalization of local regions to batches inside the whole dataset. Experiments show that incorporating contrastive learning to standard segmentation networks boosts the segmentation results.	The paper introduces a contrastive learning based algorithm for retinal vessel segmentation. The algorithm consists of a local intra-region contrastive learning strategy and a global cross-dataset contrastive learning strategy.	This paper proposes a framework to improve retinal vessel segmentation performance on some challenging pixels via the local-region and cross-dataset contrastive learning. In specific, the authors use a quality-aware anchor sampler to select the challenging pixels of false predictions and then construct contrastive loss in both the local area (with pixels from the same cropped patch) and global region (the other patches stored in the memory bank). The authors have verified the proposed method on DRIVE and CHASEDB1 datasets.
305	Longitudinal Infant Functional Connectivity Prediction via Conditional Intensive Triplet Network	The authors present a new Deep Learning architecture for longitudinal Functional Connectivity prediction in infants. Besides describing in detail new ideas for architecture design, they show the superiority of theirs with respect to other state of the art models.	The authors proposed a conditional intensive triplet network (CITN) for longitudinal prediction of the dynamic development of infant FC. This model is predicable for the common maturation pattern of FC and also maintains individual uniqueness. This model showed better performance than MLP and MWGAN methods.	A novel conditional intensive triplet network was proposed to longitudinal predict infant FC.
306	Long-tailed Multi-label Retinal Diseases Recognition via Relational Learning and Knowledge Distillation	"This paper focuses on mitigating the long-tailed effect in the multi-label classification of eye images. The proposed method first divides multiple diseases into several groups. A teacher model is trained for each group. Then a student learns from all the teacher models through knowledge distillation.
The basic idea of this paper is similar to [16], with several refinements, e.g., mutli-task backbone pretraining, region-based attention, automatical relational subsets generation, and class-balanced distillation loss."	The authors proposed a framework that contains multi-task relation, feature relation, and region relation in a knowledge distillation manner to recognize ocular diseases. The framework uses lesion segmentation and grading information from subjects with diabetic retinopathy to perform an initial classification task. The authors tested the proposed method with one dataset and reported performance metrics and class activation maps.	In this paper, the authors propose a novel knowledge distillation framework for long-tailed multi-label retinal disease recognition. First, a network is pretrained with classification and segmentation tasks on a well-labeled public dataset. Second, the long-tailed dataset is automatically divided into three subsets to train multiple teacher networks, which can help reduce the label co-occurrence and class imbalance. Besides, an spatial attention mechanism and a class-balanced distillation loss is introduced. The superiority of the proposed method is evaluated on a public dateset.
307	Low-Dose CT Reconstruction via Dual-Domain Learning and Controllable Modulation	The paper proposes a dual-domain end-to-end deep-learning network that predicts CT images from degraded CT images and sinogram data. To enhance the adjustability of the reconstruction process, the authors also propose integrating a controllable modulation module that gives the user room to do a trade-off between denoising and detail preservation. Experiments demonstrate that sinogram data work in the proposed network, and its controllable modulation module can control the degree of denoising.	The authors propose a neural network strategy to denoise low-CT images that considers a dual-domain approach (images + sinograms) and also allows to control the level of noise with an additional parameter.	design an end-to-end dual-domain deep network to achieve accurate the adjusted low-dose CT recon.
308	Low-Resource Adversarial Domain Adaptation for Cross-Modality Nucleus Detection	This paper presents a generative adverserial network (GAN) based unsupervised domain adaptation strategy for limited target training data case. The main contribution is achieved by a stochastic data augmentation module integrated to the GAN network. Unsupervised domain adaptation performance is increased.	"The authors propose a domain adaptation workflow to enable nuclei detection across different microscopy image modalities. Although the approach is not new, the authors propose a workflow that can provide accurate results using small annotated datasets.
They contribute a differentiable data module that could be connected to different approaches as it is agnostic to the architecture and the loss function.
The accuracy of the proposed approach is compared with other existing approaches showing that it can outperform them in the situation of having a few target training images."	This manuscripts presents a method for domain adaptation for the task of nucleus detection from microscopy data, for the case of small amount of labelled target data. The authors present several improvements for state-of-the-art, including usage of task-specific model to support target-domain discriminator, stochastic data augmentation, and targeted consistency constraint. This results in superior performance with respect state-of-the-art domain adaptation methods.
309	LSSANet: A Long Short Slice-Aware Network for Pulmonary Nodule Detection	The paper proposed a long short slice-aware network for pulmonary nodule detection, which have the ability to capture long-range dependencies. This is a relatively painful problem in this field, and it is very valuable.	This paper proposes a LSSANet, which has the ability to capture long-range dependencies for pulmonary nodule detection. This network not only reduces the computational burden, but also keeps long-range dependencies among CT slices. Experimental results show that this network has convincing performance.	
310	MAL: Multi-modal attention learning for tumor diagnosis based on bipartite graph and multiple branches	Authors proposed a multi-modal attention learning method for patient-level tumor benign and malignant diagnosis using a bipartite graph structure to model the correlation of different modality data. They also proposed a modal similarity loss function and intra-type similarity loss function PiTSLoss at patient-level.	The paper proposes a multi-modal attention learning framework MAL for tumor diagnosis. A bipartite graph structure is used to model the correlation of different modality data and the edges of the graph are predicted through the attention learning and multi-branch network. The modal similarity and intra-type similarity loss are calculated from the feature similarity matrix to extract better high-level semantic features. The multi-instance learning is used to obtained final diagnosis results of patients.	This paper proposes a multi-modal attention learning framework for patient level tumor malignancy classification. The results show the effectiveness of the proposed method, comparable and in some cases exceeding doctor performance.
311	MaNi: Maximizing Mutual Information for Nuclei Cross-Domain Unsupervised Segmentation	This paper addresses an interesting topic of unsupervised domain adaptation applied in Nuclei segmentation. The core idea of this paper is to use a lower bound based on Jensen-Shannon Divergence (JSD) to optimize Mutual information between different classes of source and target images, using the ground truth segmentation masks and pseudo-labels. Two series of experiments are made to show the effectiveness of the proposed method.	In this work, the authors proposed a domain adaptive nuclei instance segmentation method based on a two-stage training strategy. The proposed method facilitates the target feature generation by mutual information maximization mechanism. Extensive experiments on UDA nuclei semantic and instance segmentation benchmarks have indicated the effectiveness of the proposed method by achieving state-of-the-art performance.	"The paper proposes to use a contrastive learning based mutual information maximization approach to maximize the mutual information between source and target domains
The proposed approach is empirically validated on using different architectures on various datasets: TNBC -> KIRC/TCIA, TCIA -> KIRC/TNBC, CoNSep -> PanNuke."
312	Mapping in Cycles: Dual-Domain PET-CT Synthesis Framework with Cycle-Consistent Constraints	To obtain high-quality CT images while reducing the risk of radiation exposure, this paper proposed a novel framework that exploits dual-domain information to synthesize CT images from PET images. Specifically, the authors designed a main PET-to-CT synthesis task and a secondary CT-to-PET synthesis task, employing four networks to jointly learn both image and projection domain information. The FP and FBP are employed to connect the image domain and projection domain, thereby constructing a bidirectional synthesis framework with several closed cycles. Furthermore, a two-stage training strategy with dual-domain consistency and cycle consistency is adopted to facilitate network training for superior synthesis performance. The experimental results demonstrate that the proposed method significantly outperforms other state-of-the-art medical image synthesis methods in PET-CT synthesis.	The authors propose a novel dual-domain PET-CT synthesis framework. They design training strategy learning PET-to-CT mapping jointly in both projection and image domains. Additional CT-to-PET mapping is also learned to help the main PET-to-CT task. Extensive experiments show the new framework outperforms the SOTA methods.	In this paper, the authors proposed a novel dual-domain (image domain and projection domain) PET-CT synthesis framework. With using forward and backward projection to connect image and projection domain, the proposed two-stage training strategy with dual domain consistency and cycle consistency achieved better synthesis performance. The proposed method outperformed the SOTA methods through extensive validation on clinical PET-CT data.
313	Mask Rearranging Data Augmentation for 3D Mitochondria Segmentation	"The authors propose a novel data augmentation method to improve the segmentation of mitochondria in 3D electron microscopy (EM) images. The method is based on (1) a pix2pix-like network to generate realistic 3D EM images from mask (label) images which is trained in an adversarial fashion, and (2) a 3D mask generator that produces realistic mitochondria labels using size, distance and morphological priors from the training set.
The presented method boosts the performance of state-of-the-art segmentation networks (that use traditional data augmentation) on a public dataset, especially when training data is scarce."	The authors propose to boost 3D mitochondria segmentation by synthesizing images from synthetic instance layouts. It uses  one publicly available dataset for validation and shows the benifit  of the proposed data augmentation strategy.	In this paper the authors propose a generative adversarial modeling approach to augment data for 3D mitochondria segmentation in EM images. They first trained a pix2pix GAN model to synthesize realistic mitochondria EM images with instance masks. To increase the diversity of appearance for the synthesized mitochondria images, they design a pipeline to rearrange instances of mitochondria in the 3D masks and then feed these rearranged masks as input to the image synthesis network. The generated images are mixed with real images and used for training the segmentation network. The authors validate the method on one public dataset under the conditions of fully accessing all training data as well as reduced numbers of training examples, outperforming several baseline methods.
314	MaxStyle: Adversarial Style Composition for Robust Medical Image Segmentation	The manuscript describes a method for training a model that is more robust to domain shifts with only single domain data. The authors do so by building two more things on top the MixStyle method: 1) positioning the MixStyle layers in the decoder instead of the encoder, and 2) introducing adversarial noise in MixStyle layers to encourage more robust feature extraction.	This paper propose a style augmentation method with adversarial training scheme.	This paper proposes a data augmentation framework which achieves out-of-domain robustness using a single-domain dataset. Proposed method maximizes the effectiveness of style augmentation by producing worst-case style composition via adversarial training. Experimental results shows proposed model can achieve little better performance than baselines in terms of dice score.
315	MCP-Net: Inter-frame Motion Correction with Patlak Regularization for Whole-body Dynamic PET	This work seems like an extension of the work in [10]. Full text of [10] is not accessible. The difference from [10] might be that, Patlak fitting error, which accounts for the tracer kinetics in dynamic PET imaging, is added into the cost function when training a neural network based model to learn the motion displacement fields for motion correction.	The authors propose an inter-frame motion correction framework called MCP-Net with Patlak regularization and a Patlak loss term to register whole body dynamic PET scans. The framework consists of: 1. a 3D UNet based motion estimation module, 2. a spatial transformation module to warps images, and 3. an analytical Patlak module to estimate Patlak fitting. This paper uses tracer dynamics to improve network performance for image registration, and it performed better than traditional non-rigid and other deep learning based algorithms in correcting spatial mismatch, reducing normalized fitting error, and improving spatial alignment of K_i and V_b images.	This paper proposed a way to correct inter-frame motion during the acquisition of a whole-body dynamic PET scan.  The proposed MCP-Net takes tracer kinetics into account, as opposed to other methods that treated motion correction as a registration problem.  Qualitative and quantitative analysis showed that this framework is promising for improving the accuracy of dynamic PET.
316	Measurement-conditioned Denoising Diffusion Probabilistic Model for Under-sampled Medical Image Reconstruction	This paper proposes a denoising diffusion probabilistic model based approach for under-sampled medical image reconstruction. A measurement-conditioned DDPM method is proposed in measurement domain. Promising results on MRI reconstruction are demonstrated in the experiments.	This paper presents a novel and unified mathematical framework-MCDDPM, for medical image reconstruction using  under-sampled reconstruction. It is very meaningful.	"-This paper applies DDPM to undersampled MRI reconstruction. 
-The condition is on under-sampling, which inherent the data consistency in the recon pipeline. 
-The proposed method allows uncertainty quantification."
317	Mesh-based 3D Motion Tracking in Cardiac MRI using Deep Learning	This paper proposes an image-based mesh motion estimation network for 3D myocardial motion tracking, which estimates 3D mesh displacements from the intensity information of 2D CMR images in an end-to-end manner.	The authors propose a deep learning method for 3D cardiac motion tracking from 2D MRI. Rather than computing a dense displacement field, the proposed method learns to predict the vertex displacements of a 3D mesh from the 2D input images. This requires a novel mesh-to-image rasterizer to translate the motion estimates to 2D. This allows cardiac motion estimation and mesh-based segmentation.	"The authors claimed 3 innovations:
1) Achieved cardiac motion tracking on a geometric mesh using a deep network. 2) Used a mesh-to-image rasterizer to summarize related 2D information into 3D motion
estimation. 3) Can achieve both motion estimation and image segmentation."
318	Meta-hallucinator: Towards few-shot cross-modality cardiac image segmentation	This paper presents a method for few-shot cross-modality domain adaptation, with the goal of training a model on a label-scare source domain and then adapting the model to an unlabeled target domain. The method leverages meta-learning, mean-teacher based semi-supervised learning, and image-and-spatial transformation. The effectiveness of method is validated on a popular cross-modality domain adaptation dataset for cardiac segmentation, showing improved performance over prior works on this challenging scenario.	This paper proposed a novel method of learning cardiac image segmentation from few-shot cross-modality dataset. The core idea is using meta-learning to train a transformation-consistent meta-hallucination framework for unsupervised domain adaptation with a few labels.	To achieve efficient few-shot crossmodality segmentation, this work proposes a novel transformation-consistent meta-hallucination framework, meta-hallucinator, with the goal of learning to diversify data distributions and generate useful examples for enhancing cross-modality performance.
319	MIRST-DM: Multi-Instance RST with Drop-Max Layer for Robust Classification of Breast Cancer	The authors propose the Multi-instance RST with drop-max layer which includes a sequence of iteratively generated adversarial instances during training to learn smoother decision boundaries on small datasets.	The authors investigate the hot research topic of adversarial learning on robust self-training for image classification purposes. The generalizability and reproduction of the existing adversarial robustness on small medical image sets are considered to make some improvements. The authors proposed a multi-instance robust self-training with a drop-max layer to learn smoother decision boundaries on small datasets.	The paper proposes a method to defend against adversarial attacks for the task of breast tumor classification on ultrasound B-mode images. The method extends Robust Self Training by adding multiple instances of adversarial examples with gradually increasing perturbation during training and a dropmax layer to smooth the decision boundaries and achieve higher adversarial robustness.
320	Mixed Reality and Deep Learning for External Ventricular Drainage Placement: a Fast and Automatic Workflow for Emergency Treatments	The paper presents an augmented reality(AR) guidance system for ventriculostomy procedures. The system automatically registers the patient with a preoperative ct by aligning a model of the skin (segmented from CT) with the output of the depth sensor of the AR head-mounted display. Once registered, the segmented ventricules and sugical target (also derived from CT) are displayed in AR.	This study proposes a fully automatic MR and deep learning-based workflow to support emergency EVD placement. It provides a tool to automatically segment essential anatomies and register holograms on the patient's head via a marker-less approach.	"A complete workflow for augmented-reality-guided external ventricular drain
A deep-learning-based segmentation technique for ventricle segmentation"
321	mmFormer: Multimodal Medical Transformer for Incomplete Multimodal Learning of Brain Tumor Segmentation	The paper has presented tranformer network for multimodal medical data like Brain MRI dataset. The presented approach is capable to handle incomplete information in the dataset. The same is validated with the experimental results with BRATS dataset.	The authors propose a hybrid network that combines CNNs and transformers for segmentation of brain tumors from multimodal MRI inputs with missing sequences. The network is well designed, the authors motivate the need and provide a good description of the various modules. The network was trained and evaluated on a standard dataset enabling easy comparison with SOTA models. However some implementation details are lacking. Model size, training duration and inference speed are not provided. Dice coefficient was the only metric used for evaluation. Though the splits similar to that in ref 21 were used, comparison with the results in [21] is not provided.	In this paper, authors exploit Transformer, named Multimodal Medical Transformer (mmFormer), to build a unified model for incomplete multimodal learning of brain tumor segmentation. Experimental results demonstrate the effectiveness and robustness of the proposed method. The paper is good, and the figures are clearly drawn.
322	Modality-adaptive Feature Interaction for Brain Tumor Segmentation with Missing Modalities	The authors address the brain tumor segmentation with missing modalities by modeling feature interaction among modalities. To learn and interact complementary features between modalities, graph structure and attention mechanism are used.	This paper proposed a modality adaptive feature interaction (MFI) with multi-modality code to adaptively interact features among modalities in different modality missing situations. The proposed MFI was incorporated with U-Net for segmenting brain tumors. Experimental results had compared with other state-of-the-art brain tumor segmentation methods and achieved superior segmentation performance.	The authors propose a modality adaptive feature interaction network (Net-MFI) based on graph structure for brain tumor segmentation with missing modalities. Compared to other approaches, Net-MFI focuses on learning the complementary information using an attention mechanism for adaptively missing modalities. Validation on the BraTS 2018 shows that Net-MFI enhances the tumor segmentation in different missing modalities situations outperforming other existing methods.
323	ModDrop++: A Dynamic Filter Network with Intra-subject Co-training for Multiple Sclerosis Lesion Segmentation with Missing Modalities	This paper demonstrates a deep-learning based dynamic filter network for Multiple Sclerosis (MS) lesion segmentation. The authors proposes dynamic head with filter scaling and intra-subject co-training for the scenario that some modalities might be unavailable during training and testing in the clinical practice. The proposed method can be adapted to any arbitary number of MRI input modalities for automatic MS lesion segmentation task.	The authors introduce a novel framework named ModDrop++ to train a segmentation netowork with missing input MRI sequences. This approach can easily be integrated in any existing convolutional neural network, and, compared to the state-of-the-art method ModDrop, shows improved performance for multiple sclerosis lesion segmentation on two publicly available datasets.	The paper proposes an improvisation to the Modality Dropout (ModDrop)  technique by adapting that the training technique for multimodal image segmentation and adding dynamic filter convolutional layer (head) coupled with a modality-specific weighting strategy and further incorporating intra-subject co-training  (fill modality vs missing modality) .
324	Modelling Cycles in Brain Networks with the Hodge Laplacian	"This paper proposes a novel method to identify 1-cycles in brain networks. The algorithm starts with decomposing the network into MST and non-MST. Then a 1-skeleton with only one cycle is composed by adding one edge from the non-MST into MST. The unique 1-cycle can be identified by the zero eigenvalue of the Hodge Laplacian. The number of 1-cycles is the same as the non-MST edge number. The authors then propose that these 1-cycles forms a basis system over the collection of all possible 1-cycles, and thus can be used to discriminate networks with different topology. The authors validate the proposed method on simulated networks, against geometric measures 1-norm, 2-norm, infinity-norm and Gromov-Hausdorff distance.
Contribution:
The authors provide a new mathematical framework to extract cycles using the Hodge Laplacian over simplicial complexes."	"The quantitative analysis of structural and functional brain connectivity by network
(graph-based) measures helped to understand their complex properties. This submission proposes to extend current methods by including loops in the analytic assessment of networks. Authors introduce the Hodge Laplacian as a generalization of the graph Laplacian in order to identify and quantify 1-cycles (loops) in functional connectivity. Functional MRI data acquired in the resting state were used here, from a large, publicly available data base."	In this paper, the authors propose a 1-cycle basis in brain network analysis of fMRI-based graphs. The 1-cycle basis is extracted based on Hodge Laplacian using persistent homology framework. The authors first prove (Theorem 1) that the collection of 1-cycles (the maximum homology group for a graph is 1) spans the kernel L1 or the 1-th Hodge Laplacian of the graph. Then using this theorem, they extract the coefficients of 1-cycles across all graphs in the between-subject study. In the end, they also introduce an alternative to GH and other distance measures to compute the difference between brain networks, named statistics T. To validate the efficacy, they analyze the common 1-cycles between females and males in the brain network of normal subjects.
325	Momentum Contrastive Voxel-wise Representation Learning for Semi-supervised Volumetric Medical Image Segmentation	This paper introduces an approach to learn semi-supervised 3D medical image segmentation networks by leveraging four key objectives - (1) a simple voxel-wise contrastive learning objective against an EMA target network contrasting along the feature dimension, (2) a dimensional contrastive objective that contrasts along the batch-dimension, (3) a consistency loss which encourages to directly match the output of the EMA target, and a (4) supervised objective built around a cross-entropy and dice loss.	"This paper proposes a contrastive semi-supervised learning scheme for 3D image segmentation. The contrastive objective is taken along the feature and the batch dimension, and the optimization is performed at low-level and high-level.
The method is evaluated on a dataset for atrial segmentation, and a dataset for pancreas segmentation. The results for comparison to state-of-the art and for an ablation study are shown."	The contributions of this paper is to use a voxel-wise contrastive learning approach that leverage the contrastive loss in both the bottleneck feature space and in the segmentation space.
326	Morphology-Aware Interactive Keypoint Estimation	An interactive X-ray image keypoint estimation method is presented in this submission. The proposed approach aims to reduce the manual correction cost, instead of fixing each of the wrongly predicted keypoint, a user only needs to correct one point, all other keypoints would be updated as the user's modification to one keypoint is propagated to other points. The proposed approach is evaluated on multiple datasets (AASCE and others).	The herein paper presents an X-ray landmark detection algorithm with the possibility of interactive corrections that can be made by the end user. Taking into account the morphological information of the anatomy, the revised landmark detection adheres to the structural constraints of the desired object (e.g., cervical spine). Although interactive segmentation networks have been previously proposed, to the best of my knowledge this algorithm is one of the first efforts on the use of artificial intelligence for interactive landmark detection in X-ray imagery. Although not directly translatable, a comparison to the state-of-the art methods for interactive segmentation algorithms is also provided.	"The authors present an approach for interactive landmark estimation refinement. They utilize iterative user input similar to attention weights resp. as gating mechanism for the main network and additional regularize the prediction of the network using a ""morphology-based loss"" that is derived from dataset statistics. The authors evaluate their approach on one public and one private data set with synthetic user interaction and demonstrate improvements compared to three (+1) frameworks originally developed for interactive segmentation."
327	Moving from 2D to 3D: volumetric medical image classification for rectal cancer staging	In this paper, the authors proposed a volumetric convolutional neural network to discriminate T2 from T3 stage rectal cancer with rectal MR volume. A variety ways for combining 2D slice-level features into 3D volume-level features were compared. The authors selected the best performing model through extensive experiments in an in-house dataset of 567 patients.	Using a volumetric convolutional neural network, the authors developed an automatic CAD system to differentiate between T2- and T3-stage rectal cancer. The network contains a CNN feature extractor that maps medical volume to frame-wise features. As well as, a depth aggregation function summarizes the frame-wise features into a volume-wise feature.	"1, a hybrid convolution model is introduced to extract rectal tumor features.
2, a bilinear scheme is employed to conduct pooling for every layer.
3, the classification performance is carried out over 3D MRI rectal volumes."
328	MRI Reconstruction by Completing Under-sampled K-space Data with Learnable Fourier Interpolation	"In this paper, the authors propose a learnable method for k-space data completion and filtering. The missing Fourier coefficient are interpolated using a weighted summation of its neighbors with adaptive weights. Two CNNS are applied to regularize the data in both k-space and image space. 
The proposed methodology solves the under sampling problem in MRI reconstruction. The authors claim that the accuracy of the proposed method compared to other learning based algorithms is computationally efficient for both training and reconstruction processes."	The main contribution of this paper is to improve MRI reconstruction via an interpolation strategy. The authors use a k-nn strategy along with two CNNs as means of regularisation. Whilst the paper has a strong motivation the technical description is limited as well as the intuition.	The authors proposed a novel deep learning framework to perform MRI reconstruction. This framework was decomposed into three parts: the first part aimed to interpolate the under-sampled k-space using a k-near neighbor method (where the interpolation weights are learned by a deep learning method); the second part aimed to denoise the obtained interpolated k-space using a convolutional neural network; the last part aimed to denoise the reconstructed image (the image obtained from the inverse Fourier transform applied to the denoised interpolated k-space) using a convolutional neural network. The authors evaluated their method on one clinical dataset (brains MR images from ADNI). They compared the performance of their method to those of six state-of-the-art reconstruction algorithms.
329	mulEEG: A Multi-View Representation Learning on EEG Signals	To combine the temporal and spectral information for representation learning.	"The proposed method is significant in EEG Domain for training with mult-view self-supervision approach.
The experiment setup is good and the evaluation process.
The training aspect is novel by utilizing two views."	The authors propose a multi-view self-supervised method (mulEEG) for unsupervised EEG representation learning. The results show that the proposed method has higher performance.
330	Multidimensional Hypergraph on Delineated Retinal Features for Pathological Myopia Task.	In this work, the authors developed a multimodal hypergraph learning approach for identifying pathological myopia using features from different retinal structures of fundus images and utilizing the associations between the hidden features. The authors have demonstrated that the combination of these features provide better prediction performance than other approaches, which focus, at most, on only one target structure.	The authors introduced a novel multimodal hypergraph learning technique to learn higher-order associations and modulate delineated retinal features. Their experimental results demonstrate the potential of the model to improve prediction performance, in addition, an intensity thresholding approach was proposed to extract choroid tubular patterns.	The authors develop an algorithm to classify pathological myopia (PM) from retinal fundus images, based on hypergraph learning.  Specifically, the authors extract multiple anatomical features from retinal fundus images (including choroid tessellation, for which they present a sub-algorithm in the manuscript), and build a hypergraph where each node is an image, and images with similar retinal features are connected by an edge (the edge weight is the similarity score).  They argue that this approach can learn to associate multiple interpretable features, and they compare the predictive performance of this model against a hypergraph trained on a reduced set of anatomical features, and a traditional CNN-based approach.  Overall, they demonstrate that the hypergraph trained on multiple anatomical features slightly outperforms the other two approaches, on a range of different inputs.
331	Multi-head Attention-based Masked Sequence Model for Mapping Functional Brain Networks	This paper proposed a new deep learning model, Multi-head Attention-based Masked Sequence Model (MAMSM), to extract functional brain networks in task fMRI data. They adopted many state-of-the-art deep learning methods in the natural language processing (NLP) field such as Transformer based on attention mechanism and Masked Language Modeling (MLM) used in BERT. Their approach considering fMRI time-series as one of the sequence data like NLP is reasonable and the application of current deep learning models is interesting. Compared to other methods to extract functional brain networks such as sparse dictionary learning and independent component analysis, MAMSM utilized a state-of-the-art deep learning method showing advanced results in extracting functional brain networks and some resting-state functional networks.	This paper proposed a Multi-head Attention-based Masked Sequence Model (MAMSM) similar to BERT model, aiming to learn the different states/tasks or meanings of the same signal values at different time points in a fMRI time series. Quantitative evaluation demonstrates that the learned feature has better interpretability. The authors also design a novel loss function that combine MSE loss and cosine similarity error to extract FBNs. The experiment results demonstrate the new loss function is more suitable for tfMRI than MSE only and can be used to extract more meaningful brain networks.	This work proposes a self-supervised a Multi-head Attention-based Masked Sequence Model (MAMSM) as an embedding technique to identify the task-evoked brain networks and temporal features
332	Multi-institutional Investigation of Model Generalizability for Virtual Contrast-enhanced MRI Synthesis	This paper proposes a deep learning framework to investigate the generalizability of the proposed method through comparing MRI contrast synthesis results from some single-institutional models and a joint-institutional model. According to the results, joint-institutional model outperformed single-institutional models in both internal and external testing sets.	In this study, the authors evaluated the performance of a deep learning method (multimodality-guided synergistic neural network) for generating virtual contrast-enhanced MRIs from T1 and T2 MRIs. They explored the generalizability of the proposed method using multi-centric brain MR images. The images were acquired from patients having ongoing radiotherapy. The authors found that the model trained with multi-centric MRIs had better generalizability and accuracy than those trained with images from a single clinical center.	"The purpose of this study is to investigate the model generalizability
using multi-institutional data for virtual contrast-enhanced MRI (VCE-MRI)
synthesis. This study presented a retrospective analysis of contrast-free T1-
weighted (T1w), T2-weighted (T2w), and gadolinium-based contrast-enhanced
T1w MRI (CE-MRI) images of 231 NPC patients enrolled from four institutions."
333	Multimodal Brain Tumor Segmentation Using Contrastive Learning based Feature Comparison with Monomodal Normal Brain Images	This paper presents the brain tumor segmentation framework by adopting normal brain images as a reference to compare with tumor brain images in the learned feature space. The main contribution of the proposed method is to use monomodal normal brain images as a reference to improve the segmentation performance and the contrastive learning-based feature comparison (CLFC) module that is designed to solve the incomparable issue between features learned from multimodal tumor brain images and monomodal normal brain images. The proposed method has been validated on two datasets which include the in-house dataset and the publicly available Multimodal Brain Tumor Segmentation (BraTS2019) dataset.	In this paper, the authors tackle the task of brain tumor segmentation from multimodal Magnetic Resonance Imaging (MRI) using Convolutional Neural Networks (CNNs). The main contribution is in utilizing MRI images of normal brains to help the network in contrasting the tumor to the normal region. The normal images are generated at runtime by reconstruction from IntroVAE. To further enhance learning, the authors propose that the features of normal regions are aligned between the features of the brain with tumors and features of normal brains. Finally, an attention map is generated to enhance tumor features. The method is evaluated in the publicly available Brain Tumor Segmentation (BraTS) Challenge 2019 dataset and in an in-house dataset. Results of the proposed method improve over the baselines.	This paper proposed a novel deep learning segmentation model to deal with brain tumor segmentation in multimodal MR images. The novelty of the proposed model is to integrate the appearance of healthy brain MRI in order to localize the anomalies that is further used to strengthen the segmentation accuracy. In specific, capturing the appearance of normal-looking brains does not necessarily require all four MR sequences as the model relies only on T1 MR sequence of the subjects. The normal-looking T1 images are synthesized from the original pathological T1 sequences through an IntroVAE model. To tackle the inconsistency between the multimodal image data and the mono-modal normal appearance data, a contrastive learning-based module was designed as well. The model was developed and tested on 2D orthogonal views of the BraTS19 dataset and compared against one standard segmentation model in which the superiority of the model is highlighted in terms of segmentation accuracy.
334	Multimodal Contrastive Learning for Prospective Personalized Estimation of CT Organ Dose	"This paper provides an interesting approach to estimate the tube current modulation (TCM) map from scout images and patient size. The approach includes a novel contrast learning technique to include information from different sources (images and size profiles).
The contributions are clearly stated:

Contrastive learning technique to include information from images and patient profiles.
Estimation of TCM maps.
Real time CT organ dose estimation from scout images and TCM maps."	"This paper proposes a method to predict patient specific organ dose in CT acquisition.  The method takes as inputs both image-like information : 2 orthogonal 2D scout CT images, the scan z range in form of a binary 2D image, a tube current modulation map and 1D patient size profiles derived from the two scout images (Dw profiles).
The objective is thus to be able to estimate dose from only scout images for tubes with TCM capability, alleviating for the need of a CT scan, which would be a major step towards dose personalization in CT imaging, which is of great clinical importance. 
The authors contributions are :

multimodality : both image-space and profile-space are embedded into compressed latent representation and combined for dose prediction
contrastive learning is used to correlate learned features of both encoders from orthogonal views of the same patient while disentangling them from views of other patients
generate a TCM map, a part I did not fully catch"	This paper proposes a deep learning approach for CT dose estimation from scout images and size profile. It is based on multi-modal self-supervised learning (with contrastive-learning (CL)), followed by dose learning from the deep self-supervised representations. A Tube Current Modulation (TCM) modeling is also proposed as an intermediate step to improve the dose estimation.
335	Multi-Modal Hypergraph Diffusion Network with Dual Prior for Alzheimer Classification	In this paper, the authors propose a novel semi-supervised hypergraph learning framework for Alzheimer's disease diagnosis. Besides,the framework allows for higher-order relations among multi-modal imaging and non-imaging data whilst requiring a tiny labelled set. The experimental results show that the proposed approach is able to outperform current techniques for Alzheimer's disease diagnosis.	This paper proposed a novel self-supervised dual multi-modal embedding strategy aiming at Alzheimer's disease diagnosis. It utilized the imaging data and the space of the hypergraph structure. Moreover, the paper introduces a diffusion model to hypergraph learning. The experimental results show the method's good performance.	"This paper proposes a novel semi-supervised hypergraph framework for Alzheimer's
disease diagnosis. It introduces a dual embedding strategy for constructing a robust hypergraph and a better diffusion model for hypergraph learning.  Experimental results demonstrate that it outperforms other hypergraph techniques."
336	Multi-Modal Masked Autoencoders for Medical Vision-and-Language Pre-Training	This paper integrated vision with language together using masked autoencoders for joint pre-training. Several important technical modifications and explorations were made upon the original masked autoencoders, such as masking ratios, reconstruction features, and decoder designs. The pre-trained vision-and-language model yields significant improvement over random initialization and other competitive baseline methods on three representative vision-language tasks, covering five public datasets. Ablation study was presented to demonstrate the efficacy of both vision (MIM) and language (MLM) parts of the model.	This paper presents a multi-modal masked autoencoder (M^3AE), which is based on the Transformer, for medical vision-and-language pre-training. Given a pair of image and text, this paper introduces a simple training strategy that trains the model by predicting the masked regions of the image and the masked words of text. The experimental results show that the proposed method outperforms the baseline methods on three downstream tasks including medical visual question answering, medical image-text classification, and medical image-caption retrieval.	This paper presents a multimodal pretraining method in a self-supervised manner for the medical field. Reconstruction takes advantage of different levels of visual and textual features to deal with different levels of visual and language abstraction. The evaluation was performed on multiple multimodal downstream tasks.
337	Multi-modal Retinal Image Registration Using a Keypoint-Based Vessel Structure Aligning Network	The paper proposed a self-supervised learning method for multi-modal retinal image registration. The proposed method consists of feature detection using RetinaCraquelureNet and feature matching using SuperGlue.	The authors present an end-to-end method that combines RetinaCraquelureNet and SuperGlue networks into a single system to perform multimodal retinal image registration. Training is performed with a synthetically generated multimodal dataset of retinal images, in which warpings and noise is dynamically introduced into the images. to represent image acquisition variances.	"The authors proposed to extract convolutional features from the vessel structure for keypoint detection and description and used a graph neural network for feature
matching to achieve the multi-modal retinal image registration."
338	Multi-Modal Unsupervised Pre-Training for Surgical Operating Room Workflow Analysis	The authors describe a method for pretraining a CNN to aid in workflow analysis tasks (Activity recognition and semantic segmentation) from the room camera in an operating room. The method is evaluated on two public datasets and compared against 2 other methods from the state of the art.	This work proposes to use unsupervised clustering method, i.e., SwAV to pretrain the image encoder with multi-modal images. It takes two modalities as two different views of the same image, intensity and depth images from TOF cameras and train the encoder to predict the other modality's pseudo code. Compared to the offline clustering method, the SwAV fits the large-scale setting and achieves a superior result compared to the other self-supervised methods, especially on few-shot settings.	This paper relies on multimodal data to pretrain models. The model enforces generating similar prototypes from different modalities. The model has been evaluated on two task, where the proposed model achieved superior performance.
339	Multimodal-GuideNet: Gaze-Probe Bidirectional Guidance in Obstetric Ultrasound Scanning	"The authors propose a multimodal neural network to jointly predict the change in gaze position on the ultrasound image and the movement applied on the probe by a human operator to reach each of the many standard planes during a routine obstetric sonographic scan.
The aim is to use gaze information to suggest probe motion, and viceversa, during training of new specialists.
The performance improvement of the method over single-task networks is consistently shown by the experimental evaluation, which was performed on a dataset which is not mentioned to be public. The methodology used for data collection is however very well explained, such that replication should be feasible."	This paper explores a completely new paradigm to use Ai techniques to assist less experienced operators of obstetric  ultrasound to obtain high quality results. It achieves its goal through the novel combination of probe and the gaze of the sonographer,  and results demonstrate that such a joint approach outperforms single-task learning for both probe motion guidance and gaze movement prediction. This is a very tangible and practical first step towards making ultrasound more universally available as a diagnostic imaging tool, even in the hands of non experts. For me, this paper embodies the spirit and raison d'etre of the MICCAI Society perfectly.	This paper presents a multi-task learning framework to predict gaze position and US probe rotation for guiding obstetric US scanning, which is a novel approach to tackle this kind of problems.
340	Multiple Instance Learning with Mixed Supervision in Gleason Grading	A mixed supervision Transformer is proposed based on the MIL framework for WSI classification/grading. The proposed framework suggest a novel manner to take advantage of both slide-level label and limited pixel-level labels. And a random masking strategy is proposed to avoid the performance loss caused by the inaccurate instance-level labels.	"Propose a mixed supervision scheme for an improved gleason grading in pathology images.
Propose a mixed supervision Transformer that utilizes the recent advances in NLP.
Obtain superior results to other competing models."	Aiming at the Gleason Grading of WSI, authors propose a Transformer framework to utilize the slide-level labels and limited pixel-level labels under the MIL scheme. In particular, authors employ the superpixel techniques to convert the pixel-level labels into instance-level labels with improved quality. The random masking strategy and sinusoidal position encoding are also adopted to promote the Gleason classification.
341	Multi-scale Super-resolution Magnetic Resonance Spectroscopic Imaging with Adjustable Sharpness	To achieve multi-scale super-resolution, the author adopted a Filter Scaling strategy to obtain resolved results with different upscaling factors. The proposed network was conditioned on the weight of GAN loss and instance normalization to adjust the sharpness of the image. The experiments were evaluated on various metabolite types of 3D brain images from 15 high-grade glioma patients. And, given methods could achieve the best performance and have flexible operations in sharpness of the image.	This work develop  a multi-conditional module to incorporate multiple conditions into a MRSI super-resolution network that can avoid training a separate network for each combination of hyperparameters.	This paper proposed a blind super-resolution method for Magnetic Resonance Spectroscopic Imaging. It applied the filter scaling strategy based on the upscaling factor to realize the multi-scale super-resolution within a single network. Extensive experimental results demonstrated that the performance of the proposed model was comparable to the single SR model.
342	Multiscale Unsupervised Retinal Edema Area Segmentation in OCT Images	The authors present a novel Multiscale Unsupervised Image Segmentation (MUIS) framework for the Retinal Edema Area (REA) segmentation task. It has two steps. 1: the image-level clustering groups the images in two categories. This provides guidance for the downstream segmentation task. 2: The pixel-level segmentation yields pixel-wise labels for each image. Results are very good and approach the supervised approach.	In the manuscript, the authors have proposed a novel Multiscale Unsupervised Image Segmentation (MUIS) framework for the Retinal Edema Area segmentation task. Based on the observation that smaller lesions are more obvious on large scale images with detail texture information and larger lesions are easier to capture on small scale images for the large field-of-view, they introduced multiscale information into both stages through a scale-invariant regularization and a multiscale Class Activation Map fusing strategy, respectively.	The authors proposed a 2-stage network architecture for unsupervised segmentation of retinal edema. In the first stage images are classified as normal/edema using DCCS. In the second stage, multiscale CAM fusing strategy is applied to guide segmentation for an encoder-decoder network.
343	Multi-site Normative Modeling of Diffusion Tensor Imaging Metrics Using Hierarchical Bayesian Regression	This paper evaluated, under the normative modeling Hierarchical Bayesian Regression framework, three model fitting strategies for the age effects on brain white matter microstructure across the lifespan. Using multi-site diffusion tensor imaging data, the authors found that compared to the linear fit, the polynomial and b-spline fits were better for modeling age trajectory. The authors further found that compared to the linear model, the b-spline model resulted in fewer ROIs with significant effect of a rare neurogenetic syndrome on microstructural brain differences, suggesting modeling complexity can impact statistical findings and therefore must be determined with caution.	This work aims to the comparison of three harmonization models, linear, polynomial, and b-spline in a large-scale dataset.	"The authors test the usage of Hierarchical Bayesian Regression for multi-site imaging data, to adjust for site. They experiment with linear, spline and polynomial models for age and sex, since the distribution of these can be confounded by site.
They compare the models in terms of associations that they can find, where they compare micro brain structure measures of controls and carriers of a rare deletion on chromosome 16 (16p11.2)."
344	Multi-Task Lung Nodule Detection in Chest Radiographs with a Dual Head Network	The paper proposes an improved architecture for nodule detection. The implementation of multi-task in the architecture improves both performance on classification and detection. The dual head structure is reflected in both the overall architecture and a data augmentation approach.	A multi task pulmonary nodule detection algorithm for chest X-ray analysis is proposed.	The authors propose a multi-task lung nodule detection algorithm to reduce the false-negative rate in this manuscript. The dual-head network (DHN) is proposed to predict the global-level label of nodule presences as image-level prediction and the local-level label of precise locations. A dual-head augmentation is proposed for DHN training. The experiments on the NIH dataset demonstrate the effectiveness of the proposed model.
345	Multi-task video enhancement for dental interventions	This manuscript presents a multi-task network architecture that handles three tasks related to dental interventions, which are video enhancement, binary teeth segmentation, and homography estimation. Authors show that these tasks are correlated with each other and the overall performance of the proposed architecture on multiple tasks is comparable to that of state-of-the-art methods designed for a single task.	In this paper, a new dental video enhancement dataset is proposed, accompanied with a strong benchmark model. The dataset are tailored for 3 tasks: video restoration, segmentation and homography estimation. The proposed multi-task model is evaluated on all 3 tasks and compared with other methods.	The authors propose a novel deep network for multi-task video enhancement that works in near real- time for macro-visualization of dental scenes. The authors also release a new dataset of dental videos with multi-task labels for facilitating further research in video processing applications.
346	Multi-TransSP: Multimodal Transformer for Survival Prediction of Nasopharyngeal Carcinoma Patients	"Use multimodal network to combine CT image data and text data to predict patients' overall survival.
Demonstrate the effectiveness of Transformer model in this task"	The authors apply a transformer and CNN to predict the overall survival from nasopharyngeal carcinoma patients from CT images. The proposed method is compared to competing techniques on a private dataset. The benchmarked method also include non-imaging methods based on clinical reports (text).	This paper tackles the task of predicting survival in nasopharyngeal carcinoma patients, by effectively utilizing the information from the CT images and the clinical text data. To do so, the authors propose a novel multi-modal architecture which leverages the feature extraction power of convolutional neural networks and the the feature fusion ability of transformers. The authors demonstrate the efficacy of their proposed model on a small in-house dataset.
347	Multi-view Local Co-occurrence and Global Consistency Learning Improve Mammogram Classification Generalisation	The paper cover multi-view detection of mammographic abnormalities. The method uses local and global information based on standard radiology assessment. Evaluation is based on three different datasets and uses global labels.	The paper introduces the Multi-View local Co-occurrence and global Consistency Learning (MVCCL) to consider features from ipsilateral mammographic views. The authors introduced Global Consistency module penalizing the differences in feature representation from the two views and also local co-occurrence learning module that uses multi-head attention to produce a representation based on the estimation of the relationship between local regions from the two views.	This paper presents a multi-view local co-occurrence and global consistency learning for mammogram classification generalization. It proposes global consistency module and multi-view local co-occurrence module to aggregate the information from two views of a breast. The generalization of the proposed approach was evaluated on four datasets, including 1) testing subset of ANON 1, 2) ANON 2, 3) CMMD, and 4) InBreast, and the results demonstrate the promising performance.
348	MUSCLE: Multi-task Self-supervised Continual Learning to Pre-train Deep Models for X-ray Images of Multiple Body Parts	From the title of this paper, we can imagine the topic of this paper is to make self-supervised learning, continual learning and multi-task learning for deep X-ray image classification. The proposed method aggregates Xray images collected from different body parts for MoCo-based representation learning with continual learning (CL) procedure for X-ray analysis tasks.	"This paper proposes a self-supervised training method of pre-train models for X-ray images, which is named MUSCLE. The method consists of pre-processing, pre-training, continuous learning and fine-tuning steps. MUSCLE adopts MoCo method to train the backbone network from multiple data sets and continuous learning to avoid over-fitting and ""catastrophic forgetting"". In the results section, detailed experiments demonstrate the effectiveness of the training method."	"MUSCLE is proposed to pre-train DNNs for X-ray images of multiple body parts for multiple tasks (classification, segmentation, detection) using self-supervised(SSL) and Continual Learning (CL) techniques. The pipeline has 3 stages : 
1) MD-MOCO uses 9 xray datasets to modify MoCo-CXR to SSL pretrain a backbone DNN after preprocessing the data, 
2) Continual learning is applied to further pretrain the backbone with task specific heads in a cyclic fashion across 4 tasks. Only 4/9 datasets are used from this stage onwards, 
3) Independent task-specific fine tuning with 4 datasets is done by having both the backbone and 4 task specific heads.
The experiments have 4 baselines named - Scratch, ImageNet, MD-MoCo, and MUSCLE- , to compare against MUSCLE. Task specific performance metrics are used for the comparison. MUSCLE is shown to have better numbers on many of the metrics."
349	NAF: Neural Attenuation Fields for Sparse-View CBCT Reconstruction	This work adapts the Neural Radiance Fields idea for 3D reconstruction to the clinically relevant CBCT modality. A key element is a recently proposed network architecture which includes a learning-based encoder. Overall, the strategy resembles an iterative CT reconstruction, where the reconstructed 3D function is represented as a neural network. The method is evaluated on both simulated patient data and measured phantom data. It is compared against multiple state-of-the-art methods and performs competitively.	This paper proposes to learn attenuation coefficients in CBCT via an implicit function parameterized by a fully-connected deep neural network. A learning based hash coding method is utilized to help the network capture high-frequency and edge details of human organs.	A self-supervised model for sparse CBCT reconstruction is proposed.
350	NerveFormer: A Cross-Sample Aggregation Network for Corneal Nerve Segmentation	The authors propose a method for segmenting corneal nerves in CCM images. The method consists of encoder (pre-trainied ResNet34), two attention modules, and a CNN-based decoder. Experiments show that method performs better than a number of other methods.	The paper presents a transformer based network for nerve fibre segmentation in CCM images. The proposed transformer based part contains an intra-image local spatial attention and inter-image attention.	This paper presented a new transformer design for corneal nerve segmentation. The proposed method achieves state-of-the-art performance in two CCM dataset by learning features from single CCM image and common properties from multiple samples.
351	NestedFormer: Nested Modality-Aware Transformer for Brain Tumor Segmentation	The paper has presented transformer network for multimodal medical data like Brain MRI dataset. The presented Nested Modality Aware Transformer (NestedFormer) approach is capable to handle multimodal information in the dataset. The same is validated with the experimental results with BRATS and Meniseg dataset.	This paper proposes a model, termed NestedFormer, to fuse multi-modal information based the architecture of transformer. The multi-model information is firstly embedded separately using Global Poolformer. The core module of NestedFormer, called Nested Modality-aware Feature Aggregation (NMaFA), is proposed to fuse long-range dependencies of different modalities. A modality-sensitive gating (MSG) is proposed to utilize modality-aware low-resolution features by decomposing in three orientations.	In this paper, the authors propose NestedFormer that combines U-Net and Transformer for brain tumor segmentation. The effectiveness of NestedFormer is demonstrated through performance evaluation experiments using the BraTS2020 dataset.
352	Neural Annotation Refinement: Development of a New 3D Dataset for Adrenal Gland Analysis	The paper proposes a method to refine mask annotations to get better segmentation/classification results.	"3D segmentation masks of medical images are often noisy. 
The authors proposed an appearance-aware implicit function-based method to refine the human annotations of a 3D adrenal gland dataset. 
The shape modeling method with a modified implicit function is technically sound. 
The new dataset reduces label noise for downstream image analysis."	"This paper proposes a novel appreace-aware implict surface model for ground truth repairments.
This paper also contributes a new data set for adrenal gland analysis."
353	Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in Robotic Surgery	This paper adopts a leading edge deep learning 3D rendering algorithm  called neural rendering  to reconstruct 3D surfaces of surgical scenes in the context of robot-assisted procedures that employ a stereo endoscopic cameras. It  seeks to provide an improved  rendering of the visualized surface based on a known depth model from the stereo-camera. As distinct from the   traditional 3D rendering approach, where the 3D surface is approximated using polygons and projected back to the camera using physical optical principles, the neural rendering technique is trained to create a predictor as a function of camera position and it is able to directly predict  the r,g,b, alpha(transparency) value for all camera rays.  In the paper, the authors use an existing stereo-matching algorithm STTR-light to obtain a coarse depth map for surface reconstruction, and then proposes an improved method based on the existing D-NeRF model for neural rendering.	In this work, the authors newly adopt neural radiance fields (NeRF) to reconstruct dynamic surgical scenes from single-view (left view) stereo endoscope videos. The proposed framework is based on D-NeRF, and applies STTR-light to estimate depth maps as the prior knowledge for 3D scenes reconstruction. Results indicate that this method is promising, and provides good dynamic scenes recontraction models even non-rigid deformation and tool occlusion exists.	This paper proposed a NeRF-based 3D reconstruction framework for deformable tissues during robot-assisted surgery. The framework uses neural implicit field for dynamic scene representation and incorporates mask-guided ray casting for occlusion issue as well as depth-cueing ray marching and depth-supervised optimization scheme. The method was evaluated on clinical dataset from DaVinci surgical robot and compared against the most recent SOTA method E-DSSR and outperformed significantly.
354	Neuro-RDM: An Explainable Neural Network Landscape of Reaction-Diffusion Model for Cognitive Task Recognition	"This paper introduces a new method for extracting brain states from fMRI via a dynamical systems model. The authors blend model-based and data-driven strategies by using neural networks to implicitly learn the parameters of a reaction-diffusion equation. The ""reaction"" component is implemented using an ANN, and the ""diffusion"" component is mapped onto a graph convolutional network for joint training. The authors evaluate their model on simulated data and task-based fMRI from the Human Connectome Project. The results demonstrate improved recognition accuracy compared to recurrent architectures."	The article rewrites the reaction-diffusion  model originally expressed in partial differential equations in terms of a deep neural network. The new network is used to study changes in brain states from BOLD fMRIs.	"This work examines the problem of modeling regional fMRI BOLD signals as a dynamical system governed by reaction-diffusion process which is formulated as a set of trainable PDEs. They introduce a reaction-diffusion model (RDM) which characterizes evolution of brain states across the connectome and captures the interplay between brain states and neural activity. This in turn is formulated as a graph neural network optimization which is guided by the cognitive task being performed.
They evaluate their framework on simulated and real HCP data against baselines on the basis of the ability to identify the latent generating states and identify the cognitive task being performed respectively"
355	Noise transfer for unsupervised domain adaptation of retinal OCT images	This paper proposes to transfer device-specific noise to OCT images taken with different device(s), thus mitigating the domain gap that often affects performance with models trained on one device source, but used on another device source. The transfer is done by singular value decomposition-based noise adaptation (SVDNA), which adds the reconstructed noise signal from some target domain, to a source image. With the SVDNA method, noise from various (known) domains can be included as part of the data augmentation in training a UNet++ segmentation model. It is claimed that this improves OCT image layer segmentation performance over state of the art unsupervised domain methods.	The paper proposes a new domain adaptation technique, named SVDNA, for improving the performance of segmentation models when trained in a source domain and tested on a different/target domain. The paper is validated when domains are images generated by different camera devices for the task of Optical Coherence Tomography (OCT).	In order to to bridge the domain gap between different retinal OCT imaging devices, the authors proposed a minimal noise adaptation method based on a singular value decomposition (SVDNA), without modifying the basic model architecture or training an extra style transfer model.
356	Noise2SR: Learning to Denoise from Super-Resolved Single Noisy Fluorescence Image	"Authors proposed a self-supervised image denoising method to train a image denoising model based on single noisy fluorescence image.
The propose technique consists of a sub-sampler module that generates sub-sampled noisy images from the original one; and an image SR module that improves the sub-sampled noisy image resolution to that of the original one.
Quantitative and qualitative experiments are presented comparing the proposed technique and some state-of-the-art methods.
The results show a good performance (PSNR, SSIM)."	This paper aims to denoise a set of noisy images with the same noise distribution with only one observation per image. It cleverly improves Noise2Self idea by creating training image pairs through image subsampling and randomizing subsampling mask. In experiments, the proposed method achieves competitive results and outperforms Noise2Self.	The authors propose a self-supervised image demonising model using U-Net. Here, the authors used a single noisy observation for self supervision. During the main task the authors used paired noisy images of different dimensions. While the model takes advantage of well-known noise2noise, unlike this method the use of sub-sampling module allows to authors to train image pairs at different resolutions. The experimental results showed competitive results on fluorescence microscopy datasets.
357	Non-iterative Coarse-to-fine Registration based on Single-pass Deep Cumulative Learning	This paper proposed a one-shot DL-based registration method to address image registration tasks with large displacements. In the decoder, the displacement vector field is predicted at several resolutions, and at each scale, the wrapped moving image is injected. The evaluation is performed on public Brain MR datasets, in which the displacements are relatively small. The proposed method is compared with two conventional registration methods as well as six DL-based methods, which are retrained in this study.	This paper proposed a Non-Iterative Coarse-to-finE registration Network (NICE-Net) for deformable image registration. Unlike the existing iterative deep registration methods, the proposed NICE-Net can perform coarse-to-fine registration with a single network in a single iteration.	"The authors propose an unsupervised non-iterative coarse-to-fine registration network (NICE-Net) for
deformable registration using cumulative learning. This includes a single pass deep cumulative learning (SDCL) decoder, a selectively propagated feature learning (SFL) encoder, and an enhanced loss function.
Compared to other iterative deep registration methods, NICE-Net can perform more accurate registration with a single network in a single iteration.
Validation on two public datasets shows that NICE-Net outperforms the existing deep iterative registration methods."
358	Nonlinear Conditional Time-varying Granger Causality of Task fMRI via Deep Stacking Networks and Adaptive Convolutional Kernels	The paper focus on effective brain causality. More specifically on some issues related to Granger causality which are the limit of linearity and poor performance with task-based fMRI data. The non-linearity is addressed by estimating the regressive coefficient by deep stacking networks. The idea is tested on a synthetic dataset and on a real dataset.	The manuscript proposes a nonlinear Granger Causality estimation model by reconstructing the target time series based on the nonlinear modeling of source time series by a neural network. In addition, potential temporal lags between the source and target time series are modeled by the adaptive convolutional kernels (ACK) for identifying the real time lag. The proposed model was evaluated on both synthetic and real fMRI data.	The paper proposes an extension to the conditional time-varying granger causality to the nonlinear setting. The target signal Y_t is modeled as a time varying kernel (learned by a neural network) convolved with X_t after accounting for covariates Z_t. Results are shown on synthetically generated data, fMRI simulated data showing that the method can recover the true lagged GC coefficients. Results on real-world task fMRI are also presented identifying an additional causal relationship from fusiform gyrus to occipital gyrus.
359	Nonlinear Regression of Remaining Surgical Duration via Bayesian LSTM-based Deep Negative Correlation Learning	This paper introduced a multi-task hybrid model, named BD-Net, for remaining surgical duration (RSD) estimation. In particular, multiple sub-models of the Bayesian LSTM with forced feature diversity were incorporated to estimate both RSD and uncertainty. In the end, the network achieved state-of-the-art results with RSD estimation on cataract-101 dataset.	The authors propose a novel model for predicting remaining surgery duration in cataract surgeries. By using deep negative correlation learning, the model can estimate uncertainty in a single inference step. The proposed method outperforms state of the art and the authors show promising plots which indicate effective uncertainty estimation. Uncertainty estimation is especially important in this task due to the inherent ambiguity of future events.	This paper proposes a novel BD-Net for residual surgical duration prediction, which ensembles multiple Bayesian LSTMs via deep negative correlation learning.
360	NVUM: Non-Volatile Unbiased Memory for Robust Medical Image Classification	This paper proposes a novel training module, non-volatile unbiased memory (NVUM),  which non-volatility stores running average of model logits for a new regularization loss on noisy multi-label problem. Experiments on multi-label chest X-ray  images demonstrate the superior performance of the proposed method.	This work proposes a new regularisation loss to address multi-label medical image classification with label noise and class  imbalance. The proposed loss aims to penalise differences between current and early-learning model logits. Besides, the proposed method leverages the logit adjustment technique to unbias the classification predictions arisen by the class-imbalance issue.	The paper focuses on a real-world robust learning problem, classification on noisy multi-labelled imbalanced dataset, and proposed a novel NVUM method based on non-volatile memory module paired with a new regularization loss to alleviate noisy label effect and introduce class prior knowledge in model update to unbias the classification. Experiments show that the method outperforms other SOTA methods.
361	On Surgical Planning of Percutaneous Nephrolithotomy with Patient-Specific CTRs	This paper proposes an optimization algorithm that approximates the ellipsoidal geometry and orientation of kidney stones for patient-specific surgical planning in Percutaneous nephrolithotomy (PCNL) using concentric-tube robots (CTRs). The paper evaluates the algorithm using 7 sets of CT data which are segmented to construct point clouds of kidney stones for these cases. Some of the results show promise with respect to positional error generated.	This work proposes a method to design a patient-specific concentric-tube robot for percutaneous nephrolithotomy. Access to kidney stones is difficult and often requires multiple insertions. This work proposes a three-tube CTR to access difficult-to-reach stones, where the first one is straight, and the second two are both straight and curved. The stone is modeled as an ellipsoidal, the principal directions of the ellipsoidal are used to guide the CTR design.	A nested optimization-driven scheme for determining a single tract surgical plan along which a patient-specific concentric-tube robot (CTR) is deployed to enhance manipulability along with the most dominant directions of the stone presentations.
362	On the Dataset Quality Control for Image Registration Evaluation	"The paper identifies the very important issue of quality control for landmark points in public data sets used for the evaluation of the registration algorithms that underpin much of MICCAI. The paper describes a methodology to evaluate landmark point quality and demonstrates feasibility on two public data sets. 
The basic hypothesis is that variograms can be used to quickly identify suspect landmark points in the data."	This paper presents a new efficient approach to test the quality of image fiducials in (medical) image data sets. The approach is quick, reliable and easy to use and interpret by applying the variogram from the geosciences.	"The authors propose a method to assess the quality of paired landmarks that were manually labeled in corresponding images of registration datasets. Variograms, an existing statistical tool, are used to create 2D representations of 3D landmarks distributions. These 2D variograms can be easily checked by an operator to identify potentially problematic landmark pairs, as these cases with localization errors yield specific patterns. The method is applied to two open-sources datasets of MR and intraoperative US images of the brain. Among more than 700 landmark pairs, 29 were identify as potentially problematic. After a review by third-party clinicians, the poor quality of these landmark pairs was indeed confirmed.
The proposed method is thus an interesting tool to check/improve the annotations of publicly available datasets."
363	On the Uncertain Single-View Depths in Colonoscopies	The paper introduces bayesian neural networks to single-view depth estimation in colonscopy. Furthermore, the paper discusses synthetic-to-real domain challenges, self-supervised methods and introduce a new student-teacher model that considers the teachers uncertainty. These introduced methods and the results described in the paper can be valuable over a wide variety of endoscopic image analysis applications.	This paper applied Bayesian deep networks for estimating depth maps with uncertainty for colonoscopic images. The additional teacher-student model taking into account teacher's uncertainty further improves the depth estimation accuracy. The proposed approaches were validated on both synthetic dataset and real colonoscopic dataset.	This paper presents a method to estimate both depth and uncertainty in the depth estimates using a teacher-student model architecture and the method is able to generalize to real data even when trained on synthetic datasets.
364	One-Shot Segmentation of Novel White Matter Tracts via Extensive Data Augmentation	In this paper, the authors intend to implement one-shot segmentation of white-matter tracts by a novel data augmentation method. This work is extended from [10] (namely IFT) by borrowing its pretraining and fine-tuning framework, and the data augmentation is implemented by its proposed random cutout and tract cutout strategies. Then the augmented training images are used in constructing WM tract segmentation model (using TractSeg as the backbone). They demonstrate their segmentation performance using the downsampled HCP dataset (CQ) and the in-house dataset (IH).	The authors propose a method for segmenting novel white matter pathways with only a single annotated image by extensive data augmentation. Data augmentation is based on different types of masking out image regions. While the compared state of the art performs indeed well for images with few-shot annotations using a transfer learning framework, which relies on a fine tuning strategy, the segmentation based on one-shot annotations is challenging. In their experiments, the authors train segmentation models for each augmentation strategy separately and then ensemble the results of these models for the final segmentation.	This is an interesting paper about using transfer learning to predict white matter tracts in dMRI data.
365	Online Easy Example Mining for Weakly-supervised Gland Segmentation from Histology Images	This paper proposes an online easy example mining (OEEM) method for weakly-supervised gland segmentation, which can distinguish easy and confusion pixels in the pseudo labels. In training, the proposed metrics are used for weighting the loss functions, where an easy pixel has a higher weight, and a confusion pixel has a lower weight. In the experiments, the proposed method was better than the compared method.	The paper proposes a method for weakly-supervised gland segmentation from histology images. The method can mine the credible supervision signals in pseudo-mask and mitigate the damage of noisy regions.	This paper introduces a technique for weakly supervised semantic segmentation (WSSS) of glandular structures in histopathology images with image-level labels. To address the challenge of segmenting glands with similar/confusing homogeneity and low contrast, Online Easy Example Mining (OEEM) is proposed to mine confident regions in the pseudo-masks and reduce noise by suppressing ambiguous regions via a novel normalized loss.   Extensive experiments on a public glandular dataset validate the effectiveness of their method over prior state-of-the-art; including several ablations on the variants of the OEEM losses.
366	Online Reflective Learning for Robust Medical Image Segmentation	This paper proposes a test-time adaptation method for segmentation. The authors propose to synthesise the images based on the segmentation prediction and the sketch of the input image. By iteratively improving the quality or the similarity of the synthesised image and the input image, the segmentation performance improves. Due to the domain shift, the authors propose to use two similarity losses and the GAN losses to train the model.	The paper proposes a segmentation framework with test-time adaptation to adjust the model for each test image (before inference), which can be useful if the test image is from a slightly different domain.	This paper introduces a novel approach for test time adaptation, employing a cGAN-based image synthesis network to guide the segmentation network finetuning. Specifically, at test time, the segmentor is finetuned to minimize a structure similarity loss computed on the input image and the synthesised image generated by the cGAN (conditioned on the network output and an auxiliary canny map).
367	OnlyCaps-Net, a capsule only based neural network for 2D and 3D semantic segmentation	"Authors propose OnlyCaps-Net for 2D and 3D multi labels semantic segmentation for improving accuracy and inference speed by replacing the squashing function with  Softsquash and Unitsquash function with introducing unit routing, paramter free single pass routing mechanism. Authors also propose a new convolutional capsule, depthwise convolutional capsule. Authors evaluate proposed method on  public datasets using Dice Similarity score.
Contibutions are as follows:
-Implementing two novels squashing functions softsquash and unitsquash.
-Introduce unit routing, a parameter-free single pass routing mechanism
-Comparing with sota public method on public dataset
-New convolutional capsule, depthwise convolutional capsule."	"The contribution of this paper is 3-fold:
* the authors combine separable depthwise convolution to reduce the complexity of capsule networks,
* they provide two new squashing functions,
* they introduce a parameter free single pass routing mechanism which does ""normalization""."	"The proposed method proposes an optimized capsule network architecture from state of the art for 2D and 3D segmentation.
The authors implemented some efficiency strategies, such as Separable Convolutions and approximation of the Squash-Softmax functions for Dynamic Routing, to speed up the training process and limit the model memory footprint and could be of interest for the community.  The method was tested on different datasets for 2D and 3D image segmentation, and the results were validated with 3-fold cross-validation."
368	Only-Train-Once MR Fingerprinting for Magnetization Transfer Contrast Quantification	"OTOM can be applied to any MRF schedules unlike the previous deep learning based studies dedicated to only a single fixed MRF schedule.
It enables transfer learning of the pre-trained OTOM on each dataset of new MRF schedules to further improve the accuracy while significantly reducing data preparation and network training time."	The authors propose a model that can sustain changes in the MRF schedule and yet produce consistent tissue parametric maps.	The authors propose a recurrent neural network-based (RNN) approach that is able to estimate MTC tissue parameters from MR fingerprints acquired with various MRF schedules, avoiding the time-consuming process of generation of training dataset and network training for different MRF schedules. The proposed method shows similar accuracy to the conventional fully connected neural network (FCNN) method.
369	Opinions Vary? Diagnosis First!	This paper proposes an idea for improvement of Optic and Cup Discs (OD-CD) segmentation in eye fundus images in a multilabel by various experts scenario. The idea is based on rating expertness of the different experts by analyzing contribution to the diagnosis using a diagnosis network trained for glaucoma diagnosis.	The paper proposed a method to segment the cup/disc of fundus images and also use these masks as the auxiliary input to increase the glaucoma detection accuracy. For this reason, a multi-rater fusion and expertness map are also proposed along with a smoothing method.	"The authors propose a novel OD/OC expertness map generation method called DiagFirstGT. 
2.The authors developed the ExpG is developed to improve the performance of DiagFirstGT
The experimental results show that the method has achieved comparable results with the state-of-the-art methods."
370	Opportunistic Incidence Prediction of Multiple Chronic Diseases from Abdominal CT Imaging Using Multi-Task Learning	The authors present a method to predict the incidence of a set of chronic diseases in the five years post abdominal CT acquisition. CT input is sliced in an axial, a coronal and a sagittal plane using landmarks to homogenise them. Outcome data is obtained from the medical records by analysing the ICD codes. A neural network (ResNet-18) is used to predict outcomes, either one at a time or all together. Results are presented for the network having only one slice, having multiple slices or having multiple slices and multi-task learning. Results with respect to the number of training samples are also presented. All measured as AUC of ROC curves. The dataset used for training and evaluation is large (>14,000 CT scans from >9,000 patients).	This paper designed a multi-task low-label learning method for opportunistic incidence prediction of multiple chronic diseases from abdominal CT imaging. A multi-planar 2D CT processing method is designed to extract useful information for five diseases, which reduces the dimensionality of the volumetric 3D data and outperforms 2D single-plane approaches. The proposed method achieve outperformance in 5-year incidence prediction of CKD, DM, HT, IHD and OST.	Development of a multi-task DL model, levarging on reanalysed CT scans for a 5-year multiple chronic disease detection tool.
371	Optimal MRI Undersampling Patterns for Pathology Localization	"A new iterative gradient sampling algorithm was employed for finding optimal
undersampling patterns in different medical tasks and applications."	In the manuscript, the authors investigated MRI acceleration strategies for the benefit of downstream image analysis tasks. They proposed to optimize the k-space undersampling patterns and studied the effect of the proposed paradigm on the segmentation task using two classical labeled medical datasets, and fastMRI+ annotations. They demonstrated an improvement of the target metrics when the sampling pattern is optimized.	The authors propose a novel way to find the optimal MRI under sampling pattern based on the downstream image processing tasks such as segmentation and pathology detection. They provide the convincing validation on large public dataset such as BRATS and fastMRI.
372	Optimal Transport based Ordinal Pattern Tree Kernel for Brain Disease Diagnosis	The authors propose an approach to tackle the problem of brain network connection pattern estimation. they use a new graph kernel called optimal transport based ordinal pattern tree kernel. Experimental evaluation shows significant improvement.	The paper presented a novel method called Optimal Transport (OT for short) based Ordinal pattern tree (OPT for short), for achieving better performance on classification and regression tasks in brain disease classification. This method is achieved by extracting OPT from brain network generated by fMRI, and measuring optimal transport distance in different OPT levels. Experiments from 4 datasets are reported and compared with other graph kernel classification methods.	In this submission, the authors introduce a new data structure to transform a graph to a tree structure. An advantage of doing so is that the proposed tree structure contains hierarchical relationships. An optimal transport distance between two trees is computed and used to build a kernel. Based on this kernel, a series of learning tasks can be applied.
373	ORF-Net: Deep Omni-supervised Rib Fracture Detection from Chest CT Scans	"This paper proposed to adopt an Omni-supervised learning strategy to better leverage heterogeneous annotations when training Rib Fracture detectors.
In addition to the Omni-supervised strategy, the authors further incorporate the ""aggregated"" confidence from different heads into the final loss calculation to strengthen the ""focal"" idea introduced by focal loss. Extensive experimental results confirm the effectiveness of each technical component."	The author proposed a label assigning strategy for training a rib fraction detection framework using data with three different levels of annotations, i.e., boxes, centers of objects, and none. Data with different types of annotations will be used to train their dedicated classification branch. All annotations are utilized as pixel-level supervision (in or out of the object box) during the training. Inter-guided maps (IGM) for each branch (using predictions from the other two branches) are computed and used as the GT(after thresholding) whenever annotations are not available. A private dataset of CT images is employed for the experiments and evaluation. Superior results of the proposed method are reported in comparison to previous Omni-supervised methods and other label assigning strategies, i.e., self-guided maps (SGM).	This paper presents an omni-supervised learning framework to train a CT-based rib fracture detection model. The proposed framework features a shared feature pyramid network backbone and an omni-supervised detection head, which supports supervision from box-annotated, dot-annotated data, and unlabeled data. A dynamic label assignment strategy is introduced to combine multiple branch outputs and guide the model training. Experiments are conducted on a new rib fracture dataset of 2239 images. Results demonstrated the proposed method's efficacy.
374	Orientation-guided Graph Convolutional Network for Bone Surface Segmentation	This study proposes a method to segment bone structures from ultrasound imaging. In contrast to widely used pixel-wise prediction, the proposed method relies on an orientation-guided graph neural network to perform the segmentation of bone surface. The proposed method was compared against a few other neural net based methods such as UNet and MFG-CNN. The proposed study uses 1042 images and 20% of the images were designated for testing the algorithms.	A method for bone surface segmentation which addresses segmentation discontinuity is proposed, based on orientation-guided graph convolution network.	This paper describes a graph convolutional network approach to segmenting bone surfaces in ultrasound images, using orientation information to improve the performance and quantifying the connectivity of the resulting segmentations to ensure realistic results are produced. The paper compares results to three other existing approaches to this problem, showing improvements in connectivity and traditional Dice score.
375	Orientation-Shared Convolution Representation for CT Metal Artifact Learning	The authors propose a method for a deep-learning-based metal artifact reduction algorithm using the orientation-shared convolution representation.	Improve the DICDNet by integrating rotationally symmetrical streaking (RSS) property and filter parameterization. Contribution is incremental.	"This work introduces a new image-based neural network architecture for metal artifact reduction in X-ray CT. The architecture is built around an additive artifact reduction model which aims to predict an artifact layer which is to be subtracted from the input image. The artifact layer is estimated by using a formulation of steerable convolutional filters to represent rotationally symmetric streaking artifacts. Those filters are learned together with networks interpreted in this work as proximal operators which together predict the decomposition in artifact layer and artifact-free image.
The method is evaluated on simulated data against multiple state-of-the-art methods."
376	Out-of-Distribution Detection for Long-tailed and Fine-grained Skin Lesion Images	The authors present a mixup augmentation and prototypical learning based OOD detection method for skin lesion images. They first group the classes into 3 main groups (Head, middle and tail) according to their occurrences in the dataset. They show that mixing up samples from middle and tail classes helps in learning better representations for the purpose of OOD detection. They integrate their mixup strategy into prototypical learning to enhance the capability of their model.	"The paper proposes an out of distribution (OOD) detection method with application on long-tailed skin lesion datasets. The method consists of two parts: i) an augmentation strategy (mixup) targeted to middle and tail classes in the dataset (classes are categorized according to number of samples in the dataset); and ii) prototype learning integrated with the augmentation strategy.
The authors experiment with mixup augmentation targeted to different parts in the dataset and concluded that targeting the middle and tail classes yielded the best performance. They've done experiments on ISIC 2019 and an in-house dataset to evaluate the ability of the proposed method to detect out-of-distribution samples."	The paper describes a method combining the Mixup method with prototype learning aiming to improve out-of-distribution detection in the context of dermatology imaging. The authors propose several mixup strategies and report a comparison to a baseline as well as several state-of-the-art methods demonstrating the superiority of the proposed method in the context of unknown data of the same nature (i.e., unknown classes). The paper uses both, private and public (ISIC2019) datasets.
377	Overlooked Trustworthiness of Saliency Maps	Paper attempts to quantify the trustworthiness using the resilience and resistance of saliency maps. Inspired by adversarial attack methods, they propose a formulation to study how saliency maps change if the adversarial attack changes the classes (relevance) and if the adversarial attack changes the saliency map but maintains the same class (resistance). A comparison with six different saliency maps empirically highlights the drawbacks of current methods.	"This work focus on evaluating the robustness and trustworthiness of common interpretability saliency maps.
The authors propose two fundamental properties to evaluate the trustworthiness of interpretability saliency maps: relevance (if a model's prediction change due to alterations in the input, the saliency map should also change) and resistance (if the model's prediction does not change with alterations in the input, the saliency map should also remain the same).
In the experiments, the authors show in a Chest X-ray application, that several common interpretability saliency maps demonstrate both a lack of relevance and a lack of resistance."	This work investigates the problem of trustworthiness of the saliency maps in the medical imaging research domain via proposing quantitative criteria (relevance and resistance). Experimental studies demonstrate the effectiveness of the criteria in revealing the problems of the overlooked trustworthiness of saliency maps.
378	Parameter-free latent space transformer for zero-shot bidirectional cross-modality liver segmentation	This paper addresses the problem of cross modality learning from the perspective of abdominal MR/CT segmentation. A nominal intensity model for MRI and CT seeks to create an invariant latent space. The target is for zero shot cross-modality learning.	The authors propose a zero-shot bidirectional cross-modality liver segmentation method by investigating a parameter-free latent space through the prior knowledge from CT and MR images,which address the domain shift in cross CT-MR liver segmentation task. The evaluation is done on a variety of datasets. The structure of the manuscript is clear. This is an interesting and good paper.	"1.This work provides a new paradigm for the task of cross-modality liver segmentation: solving the problem of modality transfer and domain shift through parameter-free latent feature space.
2.Based on the prior knowledge of liver intensity information, a bidirectional cross modalities latent feature converter is proposed to project CT and MR images into a common space."
379	Patcher: Patch Transformers with Mixture of Experts for Precise Medical Image Segmentation	This work presents a new transformer-based network with three branches to predict a Gauss map, a boundary map, and a contour map. Then, a MoE-based decoder is presented to disentangle features. Experimental results on stroke lesion segmentation dataset and polyp segmentation dataset show that the developed network outperforms state-of-the-art methods.	"The paper proposes a novel transformer-based model that is composed of multi-scale Patcher blocks and a Mixture-of-Experts module.
The methods achieves SOTA results compared with existing methods."	The authors present a new Neural Network Architecture for image segmentation, combining ideas from convolutions and transformers for the feature extraction and a Mixture of Model approach for the reconstruction. They show that their model beats SOTA on two medical imaging segmentation tasks.
380	Patch-wise Deep Metric Learning for Unsupervised Low-Dose CT Denoising	The paper proposed a novel unsupervised learning approach for low-dose CT reconstruction using patch-wise deep metric learning. Experiments confirmed that the deep metric learning plays a critical role in producing high quality denoised images without CT number shift.	"In this work, the author applied a patch-wise deep metric learning method to the hidden embedding space in the mid-layer feature map of GAN's generator to maintain the structural information and suppress the noise.
The method achieves better PSNR and SSIM with less CT numbers shift compared with existing unsupervised Low-Dose CT denoising methods."	This paper introduces deep learning in a deep feature space. This is combined with an adversarial loss to preserve feature consistency. This improves the denoising performance, while maintaining greater CT number accuracy.
381	PD-DWI: Predicting response to neoadjuvant chemotherapy in invasive breast cancer with Physiologically-Decomposed Diffusion-Weighted MRI machine-learning model	This study proposes a method for prediction of pathological complete response (pCR) to neoadjuvant chemotherapy for breast cancer. The method exploits diffusion weighted MRI data, taking into account both pseudo-diffusion and pure diffusion, using an approximation of the bi-exponentional IVIM model fitting. Machine learning is performed using a radiomics approach, using XGBoost classifier to combine all features (including some clinical features). On the BMMR2 challenge dataset, the method shows improved performance compared to other DWI and DCE MRI based methods.	The study introduces a physiologically decomposed diffusion-weighted MRI (PD-DWI) machine learning model to predict the pathological complete response (pCR) from DWI and clinical data. The proposed model improved the performance of predicting pCR when applied to a public breast data challenge (BMMR2).	This work provided a PD-DWI method for the breast cancer pCR prediction, which could decompose DWI data into an ADC 0-100 map and an F map. And the new maps-based radiomics model could get the optimal performance that goes beyond the top performance in the BMMR2 challenge.
382	Personalized Diagnostic Tool for Thyroid Cancer Classification using Multi-view Ultrasound	The manuscript presents a new framwork for thyroid nodule classification using double view US images.	The authors propose a new multi-view thyroid tumor classification network. It is mainly composed of three parts: a swin-Transformer for feature extraction, a personalized weighting allocation network that customizes the multi-view weighting for different patients, a self-supervised view-aware contrastive loss that considers intra-class variation inside patient groups and can further improve the model performance.	"This paper proposes a personalized diagnostic tool for thyroid cancer diagnosis, consisting of  a multi-view classification module for feature extraction and a personalized weighting allocation network that generates optimal weighting for
different views. Experiment results showed that the trained model outperform state-of-the-art approaches in thyroid cancer diagnosis."
383	Personalized dMRI Harmonization on Cortical Surface	Harmonizing site-dependent effects on diffusion MRI is critical in multi-site clinical studies. Most methods take a volume-space-based approach to harmonize the imaging measures in a reference space. But these methods are not optimal to study cortical gray matters because of the heterogeneous structures of cortical surfaces. This work introduces a method to harmonize diffusion MRI measures at the cortical surface for individual subjects. The method is based on a distance measure to find corresponding vertices on the surface. The performance of the method is evaluated based on the HCP and HCPD data sets.	The paper introduces a surface-based harmonization method to reduce inter-site variation in diffusion-weighted images.	dMRI harmonization method that personalizes inter-site mappings
384	PET denoising and uncertainty estimation based on NVAE model using quantile regression loss	The authors present an approach to denoise PET images that relies on a VAE using quantile regression loss, which enables uncertainty estimation.	"This manuscript, ""PET denoising and uncertainty estimation based on NVAE model using quantile regression loss"", reports an improved PET denoising method by applying a NVAE model using quantile regression loss method (NVAE-QR) compared to a Unet-based and another NVAE model using Monte Carlo sampling (NVAE-MC). The proposed framework evolves from the NVAE model by minimizing quantile regression loss and Kullback-Leibler (KL) divergence term. The proposed model was tested using the real 11C-DASB dataset. The authors first generated a low-quality PET image by down-sampling the full list-mode data by a quarter, and 20 subjects were used for training, 3 for validation, and 3 for testing. By comparing the original image to a denoised PET image from each model, the authors evaluated the performance based on the peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM)."	The paper proposes a deep learning model for simultaneous PET image denoising and uncertainty estimation. It uses the NVAE Variational Autoencoder which is trained  with the quantile regression loss.
385	PHTrans: Parallelly Aggregating Global and Local Representations for Medical Image Segmentation	This paper presents a mixed network architecture that combines convolution and transformer for better performance.	propose a novel hybrid architecture for medical image segmentation called PHTrans, which parallelly hybridizes Transformer and CNN in main building blocks to produce hierarchical representations from global and local features and adaptively aggregate them, aiming to fully exploit their strengths to obtain better segmentation performance.	This work looked at a popular and important problem in medical image segmentation - how to efficiently hybrid CNN and ViT. To this end, the authors proposed a hybrid architecture, in which convolution and self-attention (from ViT) are performed simultaneously at each downsampled and upsampled scale in U-shaped architecture. The manuscript is well written with extensive experiments demonstrating the benefits of the proposed method on two datasets.
386	Physically Inspired Constraint for Unsupervised Regularized Ultrasound Elastography	This paper tackles the problem of displacement estimation from beamformed RF data in ultrasound elastography. The contribution is a physics-based regularization - in particular, using the fact that human tissue has a relatively small range of Poisson's ratio close to 0.5. This allows the lateral and axial displacements to be correlated.	The paper proposes a new loss function to regularise the training of Ultrasound Elastography. It is based on physical properties that need to be present in a pysically correct estimate of Ultrasound Elastography. In terms of network architecture MPWC-Net++ is employed to conduct the experiments. Experimental results demonstrate significant improvements over the state of the art.	"The authors propose a physically inspired constraint (PICTURE) to improve lateral displacement estimation on ultrasound elastography.
The experiment results on phantom and in vivo data show that PICTURE substantially improves the quality of the lateral displacement estimation."
387	Physiological Model based Deep Learning Framework for Cardiac TMP Recovery	The authors introduce a deep-learning method to perform inverse solutions in ECG. The network the authors use, emulates  the general approach of  a Kalman filter with the non-linear  model provided by the deep-learning model. They test  this  method on  synthetic  data.	The paper presents a novel framework for predicting TMP from BSP using data-driven Kalman filtering network. The paper introduced a novel method and compares its results to various recent methods with favorable results for the presented method.	Authors propose an ECGI framework that combines deep learning with the physiological model of TMP dynamics. They argue that they address the limitation in the related works where they consider ECGI as an static mapping at each time step and ignore the temporal pattern of this problem. Considering the ECGI problem as state-space model they introduce a Kalman Filtering network consisting of a transition network and a kalman gain network.
388	Physiology-based simulation of the retinal vasculature enables annotation-free segmentation of OCT angiographs	This paper proposes a novel method for the synthesis of OCTA 3D tomographies with associated vascular segmentation ground truths, that are used to pre-train  segmentation networks over OCTA images. The experiments presents promising results.	Segmentation of vessels from OCTA images is a clinically relevant problem, but a large amount of publicly available datasets is not available to train a deep learning based segmentation method. The paper proposed a pipeline for physics-based simulation of OCTA images with corresponding ground truth labels for segmentation. Low amount of annotated data is a typical problem in medical imaging, this paper tries to address this issue by generating synthetic images. It also followed physics-based methods for augmenting datasets and introducing several artifacts generally introduced in OCTA image acquisition.	In this work, the authors present a method to generate highly realistic, synthetic OCTA images with intrinsically matched ground truth labels. To some extent, it solves the problem that deep learning methods need time-consuming and labor-intensive manual annotations to train blood vessel segmentation models on OCTA images. The quantitative and qualitative performance show that this method could be a versatile tool to advance OCTA analysis. In addition, they quantify the intrinsic scalability of the proposed approach and investigate how it can facilitate segmentation of the retinal vasculature in three-dimensional OCTA images.
389	Point Beyond Class: A Benchmark for Weakly Semi-Supervised Abnormality Localization in Chest X-Rays	The paper follows the framework of Point DETR and tries to introduce it into the field of abnormality localization with chest X-rays. In my opinion, the main contribution of the paper lies in the proposal of the two regularization terms (multi-point consistency and symmetric consistency) with the Point DETR framework, which seem novel and are proved to be efficient.	In this paper, the author improves the existing abnormality localization pipeline with self-supervised learning. More specifically, they emphasize the importance of multi-point consistency and symmetric consistency to improve the model robustness.	Abnormality detection in chest X-rays (CXR) is notoriously hard as the boundaries of lesions in CXR images are not clear. Training a model with full supervision i.e. pixel annotation is the gold standard, but producing these masks is really time expensive. On the other hand, models trained using only image annotation perform poorly. A middle ground can be reached at limited time-cost by providing point based annotation for lesions. The authors propose a new regularization-based method to improve the results using the latter annotation and propose ablation studies to evaluate the impact of their regularization terms.
390	Poisson2Sparse: Self-Supervised Poisson Denoising From a Single Image	This paper proposed a novel approach to denoise given noisy image. The considered approach  in this paper is  very relevant in the domain of medical image processing. Self supervised de-noising approach does not require ground truth image to learn the de-noising model. The objective is achieved by using sparse representation based approach. Here the dictionary, to obtain the sparse representation, is learned using convolution sparse coding network. A framework is worked to denoise image, where it is assumed the noise has poisson distribution. The experimental results show that the proposed approach is performing better in comparison with the existing approaches.	The paper has introduced a modification of the ISTA iterative optimisation dictionary learning algorithm which uses a recurrent neural network. The authors demonstrate this shows improved denoising performance compared to stat of the art self supervised methods.	This paper presents a self-supervised approach for single image denoising for Poisson corrupted images, which requires only one noisy image to generate the clean version. The method is extremely practical in situations where the acquisition of clean data can be difficult. Meanwhile, embedding deep neural networks into the framework of traditional iterative optimization methods provides a new inspiration for related research.
391	Pose-based Tremor Classification for Parkinson's Disease Diagnosis from Video	"This paper presents a method to classify Parkinson's tremors in videos. To this end, the authors propose an attention module with a pyramidal channel-squeezing-fusion architecture (Spatial Pyramidal Attention Parkinson's tremor classification Network, SPAPNet). The proposed system shows an accuracy of 90.9 %, which is 3.2% higher than ST-GCN [1].
[1] Yan, S., Xiong, Y., Lin, D.: Spatial temporal graph convolutional networks for skeleton-based action recognition. In: AAAI Conference on Artificial Intelligence. (2018)."	The authors propose a strategy to classify different tremor classes using postural inputs and a graph neural representation (GNN). Also, the proposed architecture includes an attention mechanism to enhance relationships among joint distances. The authors validate the strategy over a public dataset with some tremor patients diagnosed with Parkinson's disease. The authors report promising results with around 90.9 % in the classification task of Parkinson's tremor vs Parkinson's no tremor.	The authors propose a binary classification (and an extension to multi-class) framework to diagnose Parkinson's disease in video recordings of subjects using the seven upper body joints of a 2D skeleton extracted with OpenPose as input to their framework. The body joints are used to build a graph with intra-skeleton and inter-frame connections which are fed to a GNN with Spatial Attention and a novel Pyramidal Channel-Squeezing Fusion Block. The presented results show that the proposed method consistently outperforms prior work.
392	Position-prior Clustering-based Self-attention Module for Knee Cartilage Segmentation	In this work, the authors propose a self-attention module based on a computational process on class centers, and they call it as the position-prior clustering-based self-attention module (PCAM). The PCAM is a plug-in module, which could be integrated into an up-sampling layer of the decoding half in a UNet/VNet-like network structure. From the experimental part, the proposed method could achieve the best overall results by comparing with other existing approaches.	"This paper proposes a position-prior clustering-based self-attention module (PCAM) for automatic knee cartilage segmentation in MR images: 
1). lightweight PCAM that can be plugged in to networks
2). Application of clustering-based self-attention module on knee cartilage segmentation.
3). The proposed method outperforms State-of-The-Art methods."	The paper present a self-attention module with clustering to improve the possible discontinuous segmentations of cartilage from knee MR images. Proposed module can be added to different upsampling layers of U-net type segmentation models.
393	Predicting molecular traits from tissue morphology through self-interactive multi-instance learning	"In order to bridge the divide of usually two separate steps, i.e. tile embedding and feature integration, the paper proposes an alternative optimization method to fine-tune the CNN encoder and to learn attention pooling.
The CNN encoder is fine-tuned on three sets of tiles from the decomposition of WSI tiles into (1) attention, (2) supplementary, and (3) negative tiles with respect to their attention scores."	The authors propose a self-interactive multi-instance learning framework for predicting molecular trait. Specifically, the backbone and aggregation network are optimized alternately for fine-grained and global feature, respectively, where an instance selection strategy and adversarial optimisation are further proposed. The authors validate their methods on multiple genetic and molecular analyses and achieve promising results.	The authors of this paper present a method for the prediction of molecular traits or biological types from WSIs. In particular, they present a multi-stage method that iteratively fine-tunes a WSI-tile attention module and a feature extraction one. The authors present results on four classification endpoints and report better AUC scores to a number of competing methodologies from the literature.
394	Predicting Spatio-Temporal Human Brain Response Using fMRI	This paper proposed a method to predict high resolution brain response in space and time using fMRI data.	"In this paper, a recurrent memory optimization method for predicting the behavioral state of spatio-temporal brain activity is proposed. The proposed method uses Optimal Polynomial Projections to capture the long temporal history with robust online compression, and predicted the recurrent brain states through a Siamese network based on fMRI data and MEG data in the training phase.
During the testing phase, using only fMRI data to predict the spatiotemporal corresponding neural response of each voxel within the brain, millisecond and millimeter-scale brain responses were predicted."	This work proposed a novel framework to predict the brain response with high spatial and temporal resolution only based on fMRI data. In the training stage, the proposed method uses Optimal Polynomial Projections with robust online compression to take the fMRI and MEG data as inputs and uses a Siamese network to predict the brain state. In the testing stage, only the fMRI data is used.
395	Privacy Preserving Image Registration	The authors describe a distributed image registration, where two parties provide a fixed an moving image, without wanting to share their actual image data; they show that some established image registration algorithms can be approximated using full encryption, with significant performance loss, but comparable accuracy.	The paper shows how to perform image registration while preserving privacy using cryptographic tools.	The authors present a privacy preserving image registration algorithm using cryptographic tools such as secure multi-party computation and homomorphic encryption.
396	ProCo: Prototype-aware Contrastive Learning for Long-tailed Medical Image Classification	"This paper studies the long-tailed imbalance problem in medical image classification. Typically, the authors adopt
contrastive learning to tackle such an imbalance problem. The category prototype and adversarial proto-instance are used for generating representative contrastive pairs with the prototype recalibration strategy. The authors apply such a learning scheme in highly imbalanced data for medical image classification. Experiments vandalized their claims on different datasets."	The paper proposes a prototype-based contrastive learning framework  for long-tailed medical image classification. A mixup-style sythesis is adopted to generate adversarial instance, a prototype recalibration strategy is proposed, and a proto-loss is proposed. The reported numbers show outperforming performance over baselines.	"To address the long-tailed dataset problem, the authors propose a novel end-to-end framework using prototype learning and contrastive learning, namely prototype-aware contrastive learning (ProCo). 
Specifically, adversial proto-instance is generated from the combination of learnable category prototype and feature of representative instance to enhance the robustness of contrastive learning over all classes on the long-tailed dataset. A prototype recalibration strategy is adopted to alleviate the prototype bias. Two long-tailed medical datasets are adopted to evaluate the proposed framework, and the experimental results support the effectiveness of ProCo."
397	Prognostic Imaging Biomarker Discovery in Survival Analysis for Idiopathic Pulmonary Fibrosis	The paper proposed a framework for prognostic imaging biomarker discovery and survival analysis based on contrastive learning and ViT, and exemplified its application in IPF.	The document aims to derive a method for survival prediction from lung CT scans. Patch representations are learnt by a modified contrastive learning method. Next, these patch representations are clustered using spherical L-Means. The final survival prediction is made by a clustering Vision Transformer (ViT) using the patch representations and their cluster assignments.	The authors propose a two-stage approach to predict survival of CT images from patients with idiopathic pulmonary fibrosis. In the first stage, the authors learn descriptors of image patches via self-supervised learning. In the second stage, the authors group patch-descriptors via K-means and and pass that information to a ViT to predict survival risk scores. Evaluation is performed based on internal cross-validation and a separate hold-out dataset.
398	Progression models for imaging data with Longitudinal Variational Auto Encoders	The authors proposed to endow the latent space of a VAE with a linear mixed-effect longitudinal model to generate MRI or PET images of elderlies that progress with time. The latent representation, including patient onset time, acceleration factor, and individual space shifting, can be applied to characterize Alzheimer's disease progression.	This paper proposes a method for the generation of images following a disease progression model. The method combines a variational autoencoder with a temporal linear mixed-effect model that allows learning from the data a latent representation that is able to disentangle age from disease effects in image generation. The ability of the method to correctly generate the images has been demonstrated in a simulated experiment. In addition, the authors show how the method is able to generate images with well known patterns in Alzheimer's Disease progression from MRI and PET data.	The submission works on longitudinal image regression by integrating the variational autoencoder with mixed-effects model in the latent space. The method is evaluated on a synthetic dataset and the ADNI dataset.
399	Progressive Deep Segmentation of Coronary Artery via Hierarchical Topology Learning	"-Proposal of novel segmentation framework of coronary artery region.
-SAD that consider relationships between large and small (artery) anatomical structures for segmentation was proposed.
-HTL that effectively models topological characteristics of artery structure was proposed."	This paper proposed a progressive learning-based framework, a spatial anatomical dependency module and a hierarchical topology learning module to realize the accurate coronary artery segmentation.	This paper proposes a two-stage coronary artery segmentation task framework. The framework consists of a spatial anatomical dependency module and a hierarchical topology learning module. The former provides rough spatial localization and introduces cardiac anatomical information, while the latter emphasizes topological information by using multi-task CNN networks, which helps to maintain thin vessel continuity.
400	Progressive Subsampling for Oversampled Data - Application to Quantitative MRI	"The paper addresses the joint problem of sampling scheme optimization and signal reconstruction/q-space superresolution posed in the MUDI 2019 Challenge.
The authors present a method improving upon and comparing with the challenge winner (SARDUNet). Similar to SARDUNet, they use two MLPs (one for subsampling and one for superresolution) and introduce two changes: 1. an improved iterative method to build the subsampling mask leaning on RFE and 2. a hyperparameter optimization scheme which (presumably) at its core increases the network capacity (i.e. the number of parameters).
In a quantitative signal evaluation (MSE) the method achieves better results than the baseline. Additionally, several qualitative downstream analyzes reaffirm the improved reconstruction quality."	"This work introduces an improved neural-network based method for solving the MUDI2019 challenge task of recovering a large set of volumes from different parameter combinations of diffusion MRI measurements from a smaller set of volumes. 
Two neural networks are used in this method, where one is tasked with choosing the smaller set of measurements and another one is tasked with reconstructing the large set from the chosen set.
The improvements over previous algorithms are in the training scheme especially for the network choosing the smaller set. Here, a exponential moving average is used to gradually select the smaller set and a learning schedule to gradually decrease the cardinality of the set. In addition the training is embedded in a neural architecture search component. The method is evaluated on the MUDI2019 challenge data against versions of the winner of this challenge."	The authors propose a method to recursively eliminate features to know the limits of subsampling
401	Prostate Cancer Histology Synthesis using StyleGAN Latent Space Annotation	This work trained and tested StyleGAN2 on prostate histology dataset to generate new prostate cancer images. These images were draw from the GAN latent spaces, and the author demonstrate that the latent space learned by GAN can accurately disentangle and model prostate cancer features without exposure to labels in the training process.	A GAN network was trained and then the network accurately modelled Prostate Cancer features without exposure to labels in the training process.	This papers describes an experiment showing that the latent space of a deep generative model (StyleGAN2) can contain structures that reflect clinically relevant information (here, Gleason score grading). The model was trained in an unsupervised manner on image tiles (digital pathology). Random samples from the learned latent space were generated and annotated in a first round. From these landmarks, cluster regions in latent space are estimated via PCA. To validate the approach, the authors then generated samples from the latent clusters and let a pathologist annotate them. They found a considerable agreement in the respective grades (exact match or neighboring category).
402	PRO-TIP: Phantom for RObust automatic ultrasound calibration by TIP detection	The author designs a phantom consisting of nine cones with different heights for ultrasound calibration. In addition, with the tip detection, the probe can be calibrated without requiring a tracking target on the phantom.	The authors present a novel calibration technique that allows feature and intensity-based calibration. Their proposed method is fully automatic that extracts the locations of cones in their proposed phantom and using segmentation they can track them across the sweep.	This paper presents a procedure for combining phantom-based and CNN image-based calibration methods to provide accurate, automatic calibration of tracked ultrasound probes. The proposed method was also tested on a dataset using an ultrasound probe not used in development, demonstrating generalizability.
403	Prototype Learning of Inter-network Connectivity for ASD Diagnosis and Personalized Analysis	The paper combines prototype learning and topological relational learning to learn high-order inter-network functional connectivity (FC). Empirical results are reported on the ABIDE dataset.	The authors propose a transformer based deep learning framework for topological relational learning to model higher-order characteristics of inter-network functional connectivity. They combine this with prototype learning to uncover differences between patients and controls, while simultaneously modeling individual characteristics. They experiment on ABIDE and examine diagnosis of ASD/controls and ability to generate neuroscientific explanations for intra-class variations and inter-class variations.	This paper proposes a method for analyzing functional connectivity (FC) data for interpretable classification. The proposed neural network uses multi-head attention to learn global inter-network relationships for FC reconstruction. The pretrained model is then finetuned in the classification task, where prototypes of each class in the embedded space are learned. The prototypes can then be used along with an individual's FC representation to explain inter- and intra-class differences for a subject. The methods were tested on classification of autism spectrum disorder (ASD) vs control subjects using the ABIDE dataset.
404	Pseudo Bias-Balanced Learning for Debiased Chest X-ray Classification	"A pseudo bias-balanced learning algorithm, which first captures and predicts per-sample bias labels via generalized
cross entropy loss and then trains a debiased model using pseudo
bias labels and bias-balanced softmax function."	The paper proposes a novel model to learn prediction using biased dataset. The methodology is two folder. The first part is to estimate a Pseudo Bias label from the sensitivity and specificity on the training set. The second part is considering this bias label into the Bias-Balanced softmax function at which a generalized cross entropy is used to capture the discrepancy between biased training and non-biased testing set.	This paper proposed a novel algorithm, pseudo bias-balanced learning (PBBL), to tackle the dataset bias problems in medical images. The underlying method first estimate the bias level for each case, then use this pseudo bias label to train a debiased model which avoids the shortcuts and directly learns from the intended information.
405	Radiological Reports Improve Pre-Training for Localized Imaging Tasks on Chest X-Rays	The authors propose a downstream evaluation framework with 18 localized tasks on chest X-rays, including object detection and semantic segmentation on five public datasets. The authors conduct a comparative study of pre-training methods, including text-supervised and image-only contrastive methods. The authors pre-train their models on MIMIC-CXR and evaluate the studied methods on their localized chest X-ray evaluation framework.	The authors propose a evaluation framework consisting of 18 localized tasks, including semantic segmentation and object detection, on five public chest radiography datasets. They test many different SOTA self- or text-supervised methods in many downstream tasks.	This paper studies the performance of different self-supervised pre-training methods on localized imaging tasks on chest x-rays. In this paper, two types of self-supervised pre-training methods are studied, including contrastive visual representation learning and text-supervied learning. Three evaluation protocols including fine-tuning, backbone frozen, and linear evaluation are employed. Extensive experiments on five datasets show the advantages of text-supervised learning over contrastive learning methods.
406	RandStainNA: Learning Stain-Agnostic Features from Histology Slides by Bridging Stain Augmentation and Normalization	The authors propose a pre-processing method to perform joint stain augmentation and stain normalization (SA & SN) in computational pathology. The SN process generates color templates using the LAB space intensities averages and standard deviations. The SA generates only synthetic images within the ranges of the generated SN templates. The approach is evaluated on the downstream tasks of colorectal cancer image classification and nuclei segmentation outperforming (outdated) SA and SN approaches separately.	The article proposes an image augmentation metod that combined stain normalization and stain augmentation. At first they use Lab color space and then increase the number of color-spaces used during processing to 3. The method seems to work regardless of the task (segmentation/classification).	This paper proposed RandStainNA which unifies stain normalization (SN) and stain augmentation (SA) for histology image analysis. Specifically, randomness is introduced in the conventional SN process to generate more realistic stain variations, i.e., random virtual templates from pre-estimated stain style distributions are generated and incorporated into the SN process. Additionally, random color space selection scheme is also introduced in the framework.
407	Real-Time 3D Reconstruction of Human Vocal Folds via High-Speed Laser-Endoscopy	The paper presents a method for extracting a 3D mesh of the vocal folds using laser endoscopy as well as a dataset of such laser endoscopy images.	Motivation for the study is examination for vocal folds for diagnosis if laryngeal and voice related disorders. The study proposes a new framework for real-time (~25 fps) reconstruction of 3D geometry of (vibrating) human vocal folds. The framework uses laser projection unit (LPU) connected to a high-speed camera to acquire information about the vocal folds geometry and well-established methods of parametric reinterpretation of the M5 vocal fold model as a tensor product surface for geometry reconstruction.	"This paper presents a structured light-based method to reconstruct human vocal folds. A symmetric laser grid pattern is projected on the surface of interests and their 3D locations are estimated after a localizing them in the endoscopic image and correspondence between the camera and the projector is established. Using a parametric model of the vocal folds and the estimated 3D locations of the projected dots, the authors obtain a dense reconstruction of the projected surface. The major contributions are:

An automated method for dense reconstruction of the human vocal folds using a monocular laparoscopic camera system augmented with a laser dot projector.
The quality of the reconstruction is compared to the state-of-the-art using in-vivo datasets. The dataset will be released upon acceptance."
408	Recurrent Implicit Neural Graph for Deformable Tracking in Endoscopic Videos	"The authors present a novel graph based method to track an arbitrary number of key points through a video sequence. It is designed to cope as different obstacles are introduced into the scene, and to track foreground and background objects without requiring explicit segmentation steps.
The method appears to be accurate and fast."	"The paper presents a self-supervised method for estimating dense pixel flow in endoscopic videos.
The main contribution compared to prior work is the addition of a temporal component which tracks deformation over time inside a recurrent neural network."	The paper proposes a deformable tracking method on endoscopic videos using a recurrent implicit neural graph (RING). It extends a previous method by accommodating temporal information using a RNN. Its inference is quite fast enough to be used for real-time application.
409	Reducing Positional Variance in Cross-sectional Abdominal CT Slices with Deep Conditional Generative Models	This paper is dealing with a novel application, which is to reduce positional variance in cross-sectional abdominal CT slices by generating subject-specific target vertebral level slice given an arbitrary abdominal slice as input. This paper proposes C-SliceGen to capture positional variance in the same subject with conditional generative models. Experiments show the effectiveness of the proposed method.	"The paper aims to reduce the positional variance in cross-sectional abdominal CT scans by extending the conditional generative models to C-SliceGen that
takes an arbitrary axial slice in the abdominal region as the condition
and generates a vertebral level slice. Experiments are performed on 1170 subjects from an in-house dataset and 50 subjects from BTCV MICCAI Challenge 2015 dataset."	"Authors propose conditional SliceGen (C-sliceGen) to synthesizing slices to target vertebral level (axial position) to reduce the positional variance problem. Authors extend classic conditional generative generative method and input random axial slices.
They use one private dataset for generating images and  two dataset such as   BTCV MICCAI Challenge 2015) and  BLSA dataset for external validation. They also report their results with SSIM, PSNR and LPIPS GAN metrics."
410	RefineNet: An Automated Framework to Generate Task and Subject-Specific Brain Parcellations for Resting-State fMRI Analysis	"In this paper, the authors introduce RefineNet, a Bayesian-inspired deep network architecture that adjusts region boundaries based on individual functional connectivity profiles. RefineNet uses an iterative voxel reassignment procedure that considers neighborhood information while balancing temporal coherence
of the refined parcellation."	The authors developed a novel network architecture that can update parcellation scheme based on resting state information.	This paper proposed a framework for task-specific individualized functional brain parcellation.
411	Region Proposal Rectification Towards Robust Instance Segmentation of Biological Images	"This paper proposes a region proposal rectification (RPR) module which involves two components: a progressive ROIAlign and an attentive feed-forward network (FFN).
RPR shows improvement in region proposal location rectification and achieves favorable performances in instance segmentation for both anchor-based and anchor-free approaches (e.g., Mask R-CNN and CenterMask) in three different biological image datasets."	This work tackles the incomplete instance segmentation using existing methods such as Mask RCNN by proposing a novel region proposal rectification (RPR) module that rectifies the region proposal locations with an expanded view.	The authors propose a region proposal rectification module, which includes a progressive ROIAlign module and a self-similarity attention based feed forward network module, to address the issue of bounding box not enclosing the entire object in object detection.
412	Region-guided CycleGANs for Stain Transfer in Whole Slide Images	This paper introduces a GAN-based stain style transfer method for WSI. The method adopts Cycle-GAN as baseline and introduce a ROI-based discriminator in GAN.	"The authors extend the CycleGANs with the proposed ""region of interest discriminator"", naming it Region-guided cycleGAN. The proposed discriminator performs a soft segmentation on the generated stain transferred image. This leads to performance improvement in stain localization. Results are validated on one public (Camelyon16) and one private dataset on which it outperforms the existing methods. The qualitative results are presented on the private dataset, while qualitative and quantitative results are provided for both datasets. The generated binary mask from synthesized DAB stain is compared with the GT mask for qualitative performance evaluation."	This paper proposes a method to transform H&E stains to IHC stains for histopathology images under an unpaired setting. The idea is based on CycleGAN, but instead of using a patchGAN discriminator (from the original CycleGAN approach), it proposes a region-based discriminator. The discriminator takes cell bounding boxes as additional inputs so that the GAN loss is computed on the RoIs, and thus better generation could potentially be achieved.
413	Regression Metric Loss: Learning a Semantic Representation Space for Medical Images	This paper considers learning semantic representation space for medical image regression tasks. The authors propose a novel regression metric as loss function and use it to low-dimensional manifold that matches high-dimensional labels feature space. The experiment section demonstrates that the proposed loss is better than existing state-of-the-art metrics.	In this paper, the authors present a new metric loss specifically adapted to regression. The specificity of this loss is that it takes into account a semantic aspect related to the data. Results are obtained on two regression tasks based on medical images, propose by the  RSNA Bone Age Assesment Dataset and the NLST CAC score  estimation dataset.	The main contribution of this paper is proposing a novel loss for medical image regression tasks that is the Regression Metric Loss (RM-Loss). This loss could decrease MAE and other indicators to make DNN more robust.
414	Reinforcement Learning Driven Intra-modal and Inter-modal Representation Learning for 3D Medical Image Classification	The paper presents a novel Reinforcement Learning (RL) driven approach to get semantic, meaningful inter-modality features and complentory inter modality features. This is achieved using dynamic weighting using RNNS.	This paper introduces RL into the intra-modality learning and inter-modality learning and proposes a novel hierarchic feature enhancement framework for multi-modality learning. The results demonstrate its effectiveness.	This paper presents a novel Reinforcement Learning (RL) driven approach to comprehensively address these challenges, where an independent learning mechanism is proposed to choose reliable and informative features within modality and explore complementary representations across modalities with the guidance of dynamic weights.
415	Reinforcement learning for active modality selection during diagnosis	The paper introduces an RL based method to select modalities and input information given a constrained budget	This paper works on active modality selection for clinical diagnosis and proposes a reinforcement learning (RL) formulation to maximize the accuracy/ cost balance. The proposed Q value-based RL algorithm can actively select the next modality or end the examination to get the diagnosis for a specific patient. Experiments are conducted on a heart disease dataset and an echocardiographic hypertension dataset and show that the proposed RL algorithm is better than the population-based selection method.	This works presents a reinforcement learning (RL) strategy for modality selection during diagnosis, which accounts for both diagnosis accuracy and modality-specific acquisition cost. The authors have shown the validity of the proposed approach in two datasets (one public and one private), demonstrating the clinical utility of RL over population-wise feature selection.
416	Reliability of quantification estimates in MR Spectroscopy: CNNs vs. traditional model fitting	This paper does a systematic comparison between CNNs and traditional model fitting for MR spectroscopy quantification, and identifies major concerns about the CNN approach.	This is a simulation study highlighting bias in the estimation of model parameters and uncertainties when using neural networks with MR spectroscopy data.	The main contribution of this paper is to conduct a synthetic study of the robustness, in terms of bias and variance (due to aleatoric and epistemic causes), of a CNN trained for metabolite quantification for MR spectroscopy. The main conclusion is that the CNN displays significant bias and variance (in both noisy and noiseless data) which depends on the parameter value; predictions for parameter values near the bounds of the generated data display more bias/variance. In contrast, they find that traditional model fitting shows no parameter value dependence with respect to bias/variance of estimates.
417	Reliability-aware Contrastive Self-ensembling for Semi-supervised Medical Image Classification	The paper describes a semi-supervised classification method based on reliability analysis. MT method is used to contrastively analysis the reliability of the classification results, which is then used as the fake-label for fine training. The proposed method achieves the SOTA performances.	The manuscript presents a novel reliability-aware contrastive self-ensembling framework, which can leverage the reliable unlabeled data selectively. The authors introduce a weight function to the mean teacher paradigm for mapping the probability predictions of unlabeled data to corresponding weights that reflect their reliability and also design a novel reliable contrastive loss to achieve better intra-class compactness and inter-class separability for the normalized embeddings derived from related unlabeled data. Extensive experiments are conducted on two public datasets to verify the effectiveness of the proposed method.	This paper aims to effectively use unlabeled data for semi-supervised medical image classification. The challenge in using the unlabeled data is that they can be acquired from different populations or equipment, which may result in difference between these data. To address this challenge, this paper proposes to assign different unlabeled data with difference weights, instead of assigning equal weights. The weight function is learned together with the consistency loss and contrastive loss. Experimental results on two datasets show improved accuracy over other semi-supervised learning methods.
418	ReMix: A General and Efficient Framework for Multiple Instance Learning based Whole Slide Image Classification	This work introduces a novel framework coined 'ReMix' for whole slide image (WSI) classification that leverages latent space augmentation (LA) on WSI instance cluster prototypes under the multiple instance learning (MIL) paradigm. WSI bags are reduced by replacing instances with cluster prototypes, enabling MIL parallelization, with several LA augmentation strategies applied to the prototypes facilitating generalization. The work is well motivated and provides extensive experiments on two public datasets showing very competitive results. Also, the introduced framework is agnostic to existing state-of-the-art MIL models - highly scalable and has plug-and-play functionality.	This paper propose ReMix, a general and efficient framework for WSI classification, which has two steps, reduce and mix. ReMix is evaluated on two public datasets and experimental results have shown its effectiveness and efficiency.	To address the WSI classification with high resource consumption, authors propose a simple yet effective MIL framework with two steps. In the first reduce step, the centroids at the feature space serve as instances for MIL, instead of original patches. Then, the mix step augments the reduced instances to regularize the training of the whole MIL framework. With the help of advanced pretraining for high-quality instances, the proposed ReMix framework can complete the WSI classification efficiently.
419	RemixFormer: A Transformer Model for Precision Skin Tumor Differential Diagnosis via Multi-modal Imaging and Non-imaging Data	This paper proposed a transformer based multi-modality classification framework for skin tumors to simulate the diagnostic process of dermatologists in realistic situations. The proposed method achieved SOTA results.	The paper proposes a disease- wise pairing of all accessible patient data. Further a cross-modal fusion module is also proposed and integrated with a transformer based multi-modality fusion module.	A cross-modality-fusion module integrated with transformer-based multi-modality deep classification framework that can fuse multi-source data (i.e., clinical images, dermoscopic images and accompanied with clinical patient-wise metadata) for skin tumors. Validation on 1011 cases.
420	Removal of Confounders via Invariant Risk Minimization for Medical Diagnosis	In this work, the Authors propose a variant to the framework of Invariant Risk Minimization (IRM) to reduce/remove the effect of confounders in an X-ray classification task with binary class labels. Specifically, the Authors create ad-hoc IRM environments, based on confounders values, to reduce their effect. The main contribution of this work is the use of the IRM framework to remove confounders; a second contribution is the application to a medical imaging task of X-ray classification. Differently from IRM, the proposed method (ReConfirm) introduces class-conditional penalties to improve stability of features across class and promote feature diversity. Experiments are presented to support the claims.	The paper presents a modified invariant risk minimization (IRM) , namely ReConfirm to remove the effect of the confounders.  The proposed method were applied to NIH chest X-ray classification tasks where sex and age are confounders. The experimental results outperforms baseline CNN models trained under the traditional empirical risk minimization framework.	"A learning strategy based on the invariant risk minimization framework [4] is proposed for medical image classification, such that the classification can be done without reliance on confounding variables such as age or sex.

The main idea from [7] is used to define training environments, based on agreement between the known confounding variable and the class label.

The original loss function of [4] is extended to include class-conditional penalties. This potentially allows the model to learn different environment-invariant representations for each class."
421	RepsNet: Combining Vision with Language for Automated Medical Reports	Paper attempts to address two applications: (a) classification of answers for given questions in VQA-Rad dataset and (b) text generation task in IU dataset.	This paper proposes an approach for generating clinical reports using an image/text encoder-decoder model. Notably, it comprises a bi-linear attention network for image/text fusion, and a self-supervised contrastive alignment with NL descriptions. Results are provided on medical visual question and radiology report generation.	This paper presents an encoder-decoder method that combines two modalities (medical image and text) for medical visual question answering. The method consists of the contrastive image-text encoder and conditional language decoder. Experiments are performed on two public VQA datasets(Med-Rad and IU-Xray).
422	Residual Wavelon Convolutional Networks for Characterization of Disease Response on MRI	The main contribution of the paper is a deep learning framework using wavelets as activation functions and short-cuts within wavelon network blocks for residual learning. The authors applied the framework to three data sets, two for prediction tasks in rectal cancer, and one for a prediction task in Crohn's disease.	This paper proposes a RWCN method, and it is an efficient utilization of wavelet functions as activation unit for convolution response.	The author develope a new architecture form networks, layers and activation perspective using wavelet theory. They evaluate their outperform in different cohorts and topics. They deliver a variation of different network comparison in each topic.
423	Rethinking Breast Lesion Segmentation in Ultrasound: A New Video Dataset and A Baseline Network	A new benchmark dataset for automatic breast lesion segmentation in ultrasound video is presented. Dynamic parallel spatial-temporal transformer (DPSTT), implemented on the basis of temporally, and spatially decoupled Tansformer blocks, is proposed. Dynamic memory selection scheme is presented to dynamically update memory frames of the DPSTT. The dataset and network are assessed through a comprehensive ablation study and comparison with other SoTA models.	The authors publish the first annotated breast lesion segmentation dataset using ultrasound video. The paper presents a dynamic parallel temporal and spatial-decoupled transformer. The neural network efficiently reduces the amount of computation and enhances performance. The extensive comparative and ablation studies, it is shown that the accuracy of the proposed network outperforms existing methods.	The paper introduces an ultrasound video dataset with pixel-wise annotations for breast lesion segmentation. It additionally proposes a video segmentation method based on general segmentation architectures, i.e., STM. The results of the model on the dataset look good.
424	Rethinking Surgical Captioning: End-to-End Window-Based MLP Transformer Using Patches	The authors proposed a window-based MLP transformer (with patch-based shifted window) to achieve surgical captioning tasks on video data. Two surgical datasets are adopted for benchmarking purpose, where comparable results are obtained with much less computation burden.	This paper proposes an architecture for Surgical Captioning without the need of an intermediate feature extraction or detection step. The authors evaluated the use of Swin transformers with MLP and designed an Encoder-Decoder caption architecture. They evaluate their method on two datasets including Qualitative results.	This paper designs an end-to-end detector and feature extractor-free captioning model by utilizing the patch-based shifted window technique from the recently twin-transformer. Compared to the conventional swintransformer, it replaces the multi-head attention with window-based multi-head multi-layer perceptron. It releases the limitation of human annotation of bounding boxes and boost the real-time performance. The authors validate the model on the surgical video captioning task and compare with the baseline methods.
425	Rethinking Surgical Instrument Segmentation: A Background Image Can Be All You Need	"Use of simulated data to train a segmentation network. 
Without the high cost of data collection and annotation, the authors claim to have achieved decent surgical instrument segmentation performance."	The proposed work has the aim to reduce the data collection process specifically for the problem of segmentation of instruments in images acquired during surgical procedures. The main idea is to use a single background tissue image and a few instrument images and apply multiple augmentation and blending techniques to synthesize new data that could be used for training. The approach is based on a chained augmentation mixing approach used during training and tested using publicly available datasets.	"The paper presents a data augmentation strategy for surgical tool assessment in which a background video/image is used and a foreground surgical tool image is then superimposed on top of it, allowing for a gold standard multiple-instance foreground mask to be readily available and to control data distribution elements. The two images can also be augmented separately to increase variety. The method is then evaluated by training a U-Net on the EndoVis-2018 dataset once with the proposed synthetic data (using a massively reduced amount of data, i.e. 2-3 foreground stills per instrument) and one with the same background augmentations applied to the full data (i.e. augmentation without ""simulation"") and garners surprisingly good Dice given the very few annotations provided and with good generalisation to EndoVis-2017. A second experiment in which a previously unseen instrument is then added to the simulation database shows a further Dice improvement of ~1.6% generally."
426	Retrieval of surgical phase transitions using reinforcement learning	The paper proposes a new RL formulation for offline phase transition retrieval. Specifically, a network TRN is proposed which searches phase transitions using multi-agent RL. The proposed method is validated on Cholec80 and an in-house dataset.	The manuscript proposes an offline phase transition retrieval method using reinforcement learning. The method predicts phase transition timestamp instead of classifying all frames. The method is evaluated in two settings - first with a sparse number of frames resulting in subpar results than SOTA; the second where all frames are processed and claim to outperform SOTA which are TeCNO and Trans-SVNet. Evaluation is measured at frame level (accuracy, precision, recall, and F1-score) and at event level (event ratio).	The authors propose a novel method for offline surgical phase recognition using reinforcement learning. While most work views phase recognition as a frame-wise classification task, the authors rather define the task of finding the start and end point of each phase. This way, predicted phases are supposedly guaranteed to be contiguous. Two different initialization strategies are proposed which either use all (RMI) or only a subset of the video frames (FI). Methods are compared to SOTA online methods on 2 different datasets. The RMI-variant achieves superior performance on the cholec80 dataset.
427	Revealing Continuous Brain Dynamical Organization with Multimodal Graph Transformer	This paper proposed a novel spatio-temporal graph transformer model to explore the dependency of functional connectivity on anatomical structure.	The paper proposed a novel spatio-temporal graph Transformer model to integrate the structural and functional connectivity in both spatial and temporal domain, and exemplified its application in HCP data.	This work proposed a novel spatiotemporal graph Transformer model to learn the heterogeneous node and graph representation via contrastive learning based on multimodal brain data (i.e. fMRI, MRI, MEG and behavior performance). The experimental results reveal the significance of regional heterogeneity in modeling structure-function relationship of brain dynamical organization.
428	Rib Suppression in Digital Chest Tomosynthesis	This paper presents a rib suppression and lung enhancement network (TRIPLE-Net) for chest tomosynthesis. This is the first work on rib suppression using deep learning in tomosyntheses.	The paper presents a novel deep learning-based rib suppression approach in DCT by modeling the rib artifacts. The method is based on three subnetworks to model 2D and 3D rib components, and merging the results to make the final rib suppressed DCT prediction. The proposed TRIPLE-Net is validated against DCT dataset simulated from CT as well as clinical dataset.	The paper proposed TRIPLE-Net with three subnetworks (projection-net, volume-net, aggregation-net) that can model Rib in Digital Chest Tomosynthesis as a linear suppression. It can be trained in hard constraints from 2D and 3D domains. Therefore, such downstream tasks as pulmonary analysis will be beneficial. The improvement over RSGAN is to have a Filtered Back Projection that resembles the 2D images to 3D volume and captures more accurate rib modeling. A user study that involves two doctors is carried out, which shows that the proposed model gives a slightly better rib disentanglement.
429	Robust Segmentation of Brain MRI in the Wild with Hierarchical CNNs and no Retraining	"Novel robust automated segmentation framework on brain MRIs by adopting an hierarchy of conditional segmentation and denoising deep neural networks.
Thorough evaluation of the proposed model by comparing it against the SOTA and demonstrating its effectiveness in one of the volumetric studies related to ageing."	"The authors present SynthSeg+, a novel hierarchical architecture that enables
large-scale robust segmentation of brain MRI scans in the wild, without retraining.
According to the authors, the method shows considerably improved robustness relatively to SynthSeg, while outperforming cascaded CNNs and some state-of-the-art denoising networks. The authors demonstrate SynthSeg+ in a study of ageing using 10,000 highly heterogeneous clinical scans, where it accurately replicates atrophy patterns observed on research data of much higher quality."	"This paper proposes a SynthSeg+ method based on SynthSeg network to conduct medical image segmentation.
The proposed SynthSeg+ consists of two U-net components and one denoiser part in the manner of a hierarchical architecture."
430	RPLHR-CT Dataset and Transformer Baseline for Volumetric Super-Resolution from CT Scans	"The paper introduces a dataset for volumetric SR and concurrently proposes a transformer network for super resolution.
The data is evaluated for multiple network architectures, and an experiment for the domain gap and an ablation study for the proposed network is presented."	In this paper, the authors address the problem of super-resolution of CT images in the height dimension. The main contribution of the work is the following: a new dataset of 250 images of real-paired thin CTs and thick CTs, and a new transformer-based super-resolution model. Authors compare the model's performance with the state-of-the-art models and perform an ablation study of the main components of the model.	"1) The authors developed a public real-paired volume dataset, RPLHR-CT which contains real paired thin-CTs (slice thickness 1mm) and thick-CTs (slice thickness 5mm) of 250 patients. RPLHR-CT is the first benchmark for volumetric SR, which enables fair comparison between different methods.
2) This work explored the potential of transformer for volumetric SR and proposed a novel transformer volumetric super-resolution network to alleviate the inherent shortcomings of convolutional operations, i.e., the issue of long-range dependencies. Besides, the proposed TVSRN network achieves a better trade-off between image quality, the number of parameters, and running time.
3) The authors re-implement and benchmark state-of-the-art CNN-based volumetric SR algorithms developed for CT. This indicates that the work provides some benchmark comparison and reference for the community of volumetric CT image SR."
431	RT-DNAS: Real-time Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation	The paper proposed a differentiable neural architecture search (NAS) method for 3D Cardiac Cine MRI Segmentation. The experimental results found a suitable network architecture with good segmentation performance as well as satisfying the latency and throughput constraints. Experimental results on the extended 2017 MICCAI ACDC dataset showed that the proposed method RT-DNAS obtained better overall results.	"The paper presents a method for neural architecture search which considers latency (in this case, 50ms) and throughput (22 fps) constraints. 
Latency is incorporated in the loss function and the architectures which do not meet the throughput constraints are ignored and the search is conducted again. 
Genetic algorithm is used to create new network architectures."	The authors propose an extension of the Neural architecture search (NAS) to incorporate latency/throughput trade-off for cardiac cine-MRI application. They extend MS-NAS and use a genetic search algorithm to find the optimal paths with proposed trade-offs. Ablation experiments and comparisons with state-of-the-art architectures and other NAS methods demonstrate the benefits of their approach.
432	RTN: Reinforced Transformer Network for Coronary CT Angiography Vessel-level Image Quality Assessment	"The paper presents a method to assess image quality of 3D coronary computed-tomography angiography, i.e., with contrast enhancement, scans. Image quality assessment is approached as a binary classification problem per coronary branch.
The problem is addressed as multiple instance learning problem using artificial neural networks. As a minor contribution a reinforcement learning-based instance discarding module is introduced that selects the most relevant instances within the multiple instance learning framework for final classification."	This paper formulates CCTA vessel level image quality assessment (VIQA) as a multiple-instance learning (MIL) problem, and exploit Transformer-based MIL backbone (termed as T-MIL) to aggregate the multiple instances along the coronary centerline into the final quality.	In this paper, the authors present a novel Reinforced Transformer Network (RTN) model for the Vessel-level Image Quality Assessment task on Coronary CT Angiography images. This model contains two parts: The transformer-based multi-instance learning (T-MIL) backbone and the Progressive Reinforcement learning based Instance Discarding module (PRID). T-MIL takes the responsibility for feature extraction (from image cube instances), providing states for the latter PRID and final classification. PRID is to prevent the intervention of irrelevant instances. This model outperforms other existing approaches by a large margin on a private dataset.
433	S3R: Self-supervised Spectral Regression for Hyperspectral Histopathology Image Classification	This paper presents a self-supervised spectral regression (S3R) to address the problem of self-supervised pre-training for hyperspectral histopathology image classification. Specifically, S3R consists of two pretext tasks (BR and CR) to learn a general representation for down-stream tasks. Experimental results on PDAC and PLGC datasets evaluated the effectiveness of S3R.	The authors have conceptualized an efficient and effective self-supervised spectral regression method which proposes to understand the inherent structures of hyperspectral images and pathological characteristics of different morphologies. The paper is well-motivated, has novelty, and is clinically relevant.	This paper added prior knowledge that each band of the hyperspectral images (HSI) could be represented by a linear mixture of the remaining bands in self-supervised learning to learn the features efficiently and effectively. The proposed Coefficients Regression (S3R-CR) encourages the deep learning models to regress the linear coefficients among multiple bands, while the Band Regression (S3R-BR) converges the pixel-wise differences of the selected band by re-weighting the remaining bands. Masked image modeling was used during self-supervise learning. By exploring the low rankness in the spectral domain of an HSI, The proposed methods achieved better downstream classification accuracy compared with other contrastive learning approaches.
434	S5CL: Unifying Fully-Supervised, Self-Supervised, and Semi-Supervised Learning Through Hierarchical Contrastive Learning	This paper presents a new self-supervised framework, S5CL, by devising three contrastive losses defined for labeled, unlabeled, and pseudo-labeled images. Specifically, it devised supervised contrastive losses (SupConLoss) to unlabeled data and integrate it in training with lableled data. Experiments demonstrate the effectiveness of the proposed method and ablation study shows the effectiveness of each component.	To relieve the Pixel-wise annotation workload of histopathological data, this paper  proposes a novel framework, called S5CL, that unifies fully-supervised, self-supervised, and semi-supervised learning through hierarchical contrastive learning. With three contrastive losses defined for labeled, unlabeled, and pseudo-labeled images, S5CL can learn feature representations that reflect the hierarchy of distance relationships between images with respect to their class labels and consistency with different degrees of augmentations. Also, the resulting framework is easy to use and highly flexible.	This paper present a deep learning framework that is trained using a combination of supervised, semi-supervised and self-supervised losses. The proposed methodology borrows ideas from different SOTA approaches and combines them in a comprehensive way. Specifically, it utilizes two paths that correspond to labeled and unlabeled examples, for each of them appropriate losses are utilized (i.e. cross-entropy and supervised contrastive loss in different configurations). The authors show results on two medical tasks (multi-class H&E tile classification, multi-class single cell blood cytology images classification)
435	Sample hardness based gradient loss for long-tailed cervical cell detection	"To deal with existing problems in datasets with a long-tailed distribution, a novel concept of sample hardness is introduced in order to help improve the performance of gradient loss. The hardness is calibrated at sample level with the gradient.
Set in a cancer cells detection task, a novel gradient loss is presented where samples are re-weighted according to their hardness, achieving better gradient balance and much higher mAP than cross-entropy loss, surpassing other SOTA methods."	"In this work, the authors propose a method to take the ""hardness"" of each sample into account and rebalance the gradients of positive and negative samples. Specifically, Grad-Libra Loss is proposed to help put more emphasis on hard samples in both head and tail categories. Experiments show that 7.8% mAP improvement is achieved on TCT WSI image dataset using the proposed loss function."	"1.This paper provides a new loss re-weighting method for tackle long-tailed problem by utilizing gradient information of each sample.
2.This paper proposes to use gradient information to measure the hardness of each sample in long-tailed learning problem.
3.The method of this paper achieves better results than previous methods for tackling long-tailed problems."
436	SAPJNet: Sequence-Adaptive Prototype-Joint Network for Small Sample Multi-Sequence MRI Diagnosis	"this paper proposed to use Transformer and additive-angular-margin loss for small sample multi-sequence MR image classification. However, this paper has several major flaws and fails to illustrate their point:

The first component, Transformer model, is claimed to filter intra-sequence features and aggregate inter-sequence features, based on attention mechanism. But I didn't see any details about how to achieve these 2 goals in section 2.1. The overall writing quality is poor and difficult to follow.
Similarly, neither the section 2.2, prototype optimization strategy, illustrates how to approximate the intra-class prototype and alienate the inter-class prototype. For example, the query sample q^a and support sample s^b corresponding to which modalities, the loss_2 should be explicitly expressed like loss_1, and why you choose the additive-angular-margin loss instead of the ordinary cross-entropy loss for classification.
Fig 2 is very ambiguous and lacks sufficient explanation."	This paper proposes a new deep learning method for optimizing disease diagnoses that rely on small sample multi-sequence magnetic resonance imaging (MRI) data. Specifically, using a common neural network known as ResNet50 as the backbone, the study has developed a SAPJNet approach that: 1) behaves like a sequence-adaptive transformer to generate joint feature representations of disease prototypes, and 2) constrains the prototype distribution through a prototype optimization strategy. Experiments using MRI of heart and knee show that the SAPJNet is 6-10% more accurate than four other related neural networks.	The authors introduce a sequence adaptive transformer based architecture that generates joint representations according to disease prototype. The paper deals with how to generalize disease classification from MR images despite the small sample size and presence of multiple sequences.
437	SATr: Slice Attention with Transformer for Universal Lesion Detection	This paper presents an approach to integrate inter-slice information for universal lesion detection. Results show consistent improvements over various baseline approaches.	This paper propose a novel Slice Attention Transformer (SATr) block that could be easily integrated with various CNN models. Experiments show that the proposed method improves the detection performance on Universal Lesion Detection (ULD) task under the settings of both full or less training data.	This paper proposes a novel Slice Attention Transformer block (SATr) for universal lesion detection. The proposed SATr can extract features from both individual and multiple slices. It can also be integrated into multiple network structures. Experiments are conducted on DeepLesion. Promising results are achieved.
438	Scale-Equivariant Unrolled Neural Networks for Data-Efficient Accelerated MRI Reconstruction	This paper proposed scale-equivariant unrolled neural networks by modeling the proximal operators of the networks with scale-equivariant CNNs to improve the data-efficiency and robustness to variants for reconstructing MR images from undersampled k-space data.	"(1)	This paper proposed a scale-equivariant unrolled network for MRI reconstruction.
(2)	The experiments demonstrate that the proposed approach outperforms state-of-the-art unrolled neural networks"	"The paper introduces the use of scale-equivariant (scale and translation) networks for learned unrolled reconstruction methods, where the proximal operator is replaced by a neural network.
The geometric constraint on the network offers a better performance without the need for data augmentation."
439	Screening of Dementia on OCTA Images via Multi-projection Consistency and Complementarity	In order to predict dementia from OCTA images, authors proposed CsCp module to abstract the consistent and complement representations from multiple projections of OCTA. The proposed CVF is connected after that for the feature fusion. The experiments conducted on a private dataset show its superior performance over SOTA multi-view fusion frameworks.	This paper proposes a multi-projection consensus and complementarity learning network (MUCO-Net) for dementia screening on Optical Coherence Tomography Angiography images. The proposed method performs very well on their private dataset and open OCTA-500 Dataset.	This paper proposes MUCO-Net to explore OCTA-based dementia diagnosis. MUCO-Net includes a consistency and complementarity attention module and a cross-view fusion module for understanding projective relationships and combining features. The method achieves the best results on two datasets.
440	Scribble2D5: Weakly-Supervised Volumetric Image Segmentation via Scribble Annotations	"The paper presents scribble2D5, a weekly supervised deep learning approach to segment volumetric medical images  based on scribbles. The paper proposes an augmentation of a 2.5 attention UNet with a label propagation module to improve boundary predictions. Additionally, they extend an active boundary loss formulation to act in 3D.
The method is evaluated on three datasets and results show that the proposed method outperforms the state of the art on two of the datasets."	This paper presented Scribble2D5, a method for 3D anisotropic image segmentation using scribble annotations (a type of weak supervision). A label propagation module and an active boundary loss were proposed to improve performance in terms of Dice score and overall boundary smoothness. Extensive experiments were carried out on multiple datasets to validate the effectiveness of Scribble2D5.	Image annotations sometimes are not easy to obtain in practice because annotating at the image pixel-/voxel-level is time-consuming and needs medical expertise to provide high-quality annotations. The proposed method tries to address these challenges by presenting a scribble-based volumetric image segmentation, Scribble2D5, which tackles 3D anisotropic image segmentation and improves boundary prediction.
441	Scribble-Supervised Medical Image Segmentation via Dual-Branch Network and Dynamically Mixed Pseudo Labels Supervision	In this paper, the authors present a technique for scribble-based medical image segmentation. Their approach features a dual branch network that implements a perturbation-consistency strategy, encouraging the network to produce sensible segmentations despite having only scribbles as supervisory signal. Experiments and ablation studies suggest that the proposed technique is robust and accurate w.r.t several baselines.	This paper proposes a simple yet efficient dual-branch network with one encoder and two slightly different decoders for image segmentation, which combines the scribble supervision and auxiliary pseudo labels supervision and performs better than current scribble-supervised segmentation methods.	
442	SD-LayerNet: Semi-supervised retinal layer segmentation in OCT using disentangled representation with anatomical priors	This work introduced a novel SD-LayerNet as a semi-supervised paradigm into the retinal layer segmentation task that makes use of the information present in large-scale unlabeled datasets as well as anatomical priors.	The paper proposes a novel medel SD-LayerNet to do semi-supervised retinal layer segmentation in OCT. SD-LayerNet makes use of the information in the large unlabeled datasets as well as anatomical priors. The model use both 1D surface and 2D layer information to train. And this network can also work on nested anatomy and where the thickness of a tissue is measured.	This paper focuses on the retinal layer segmentation task under the semi-supervised setting. The authors propose Spatial Decomposition Layer Segmentation Network (SD-LayerNet) with two novel contributions: one is a fully differentiable topological engine which facilitates the disentangled representation learning, another is a set of tailored anatomical priors encoded as self-supervised tasks for unlabeled data. The experiments show that the method is able to achieve state-of-the-arts results under the low-data regime.
443	SeATrans: Learning Segmentation-Assisted diagnosis model via Transformer	"This paper presents a transformer-based architecture called SeATrans by utilizing the segmentation information to boost the diagnosis task.
The key techniques include: asymmetric multi-scale interaction and SeA-block for the segmentation-diagnosis interaction.
The experimental results improve a large margin compared with other SOTA methods."	"The author proposes a new transformer model for medical image diagnosis, which is named SeATrans. 
SeATrans is a transformer model equipped with multi-scale feature integration architecture that achieves promising results on three different tasks."	The authors proposed a general framework for segmentation-assisted disease diagnosis. Their method consists of two jointly trained networks, one UNet to extract multi-scale segmentation-related features and one ResNet50 that performs the classification without the use of segmentation masks. They have proposed to combine the coarse and fine segmentation features of UNet to the first layers of the Resnet50 and use a transformer-based encoder-decoder block to learn the combined space. They validate their method on three public datasets from three different domains, outperforming the baselines.
444	Segmentation of Whole-brain Tractography: A Deep Learning Algorithm Based on 3D Raw Curve Points	The author proposed a novel 3D deep model to classify brain white fiber tracts. Two channel-spatial attention modules are proposed and added to the backbone network architecture (PointNet) and leverage the model performance in the detection of 10 major fiber bundles.	This work proposed a network and a new data preprocess pipeline to category the white matter tensor into 11 groups including a non-major group. The model included a T-Net and two spatial attention layers. The proposed method was validated using a manually label dataset of 25 subjects.	"This paper proposed point cloud based 1d-CNN deep architecture to conduct whole-brain tractography segmentation. 3D raw curve points are used to represent the curves of fibers. The whole model is trained based on a classification task: the fiber are classified into 10 major fiber bundles and the ""other fibers"" types. The proposed method get a 98.80% average accuracy."
445	Self-Ensembling Vision Transformer (SEViT) for Robust Medical Image Classification	This paper works on improving the robustness of a ViT to adversarial attacks. The authors propose a self-ensembling technique to learn multiple classifiers based on the intermediate feature representations. Experiments are conducted on the Chest X-ray dataset.	The authors propose a self-ensembling transformer for adversarial robust medical image classification. The proposed SEViT is validated on two public datasets.	This paper targets a good topic on the robustness of transformer-based models. By studying adversarial attacks on the transformer model, the paper evaluates the effect when the perturbation exists in the Transformer model. In general, this paper is well written and has a potential impact on natural vision problems but limited innovation and interest in the medical imaging community.
446	Self-learning and One-shot Learning based Single-slice Annotation for 3D Medical Image Segmentation	The paper proposes a new method for 3D image segmentation that requires one slice annotations, addressing the problem of training data availability.	"The authors propose to learn image features that allow both (1) a ""representative"" slice to extracted from a 3D volume and (2) propagate manual annotations from it to the rest of the volume. First, to find the single slice to label, the method clusters the slices (K-means clustering), and finds the most representative slice from each cluster as that with the maximum summed cosine similarity between its learned features and the other slices in the cluster. Second, to propagate labels from slice to slice, the method weights the contribution of each pixel in the already labeled slice by the similarity of its features to the pixel in the unlabeled slice. The features are used for both steps, and are learned by the ability to reconstruct one slice from another when the weighting is again based on similarity in the feature space."	The authors present an approach to automatically select the best 2D slice in a 3D image that needs to be manually annotated. This annotation is propagated to other slices. This yields very good results with few effort.
447	SelfMix: A Self-adaptive Data Augmentation Method for Lesion Segmentation	SelfMix tried to solve the challenges that the generated tumor images are facing the problem of distortion, by adaptively adjusting the fusing weights of each lesion voxels based on the geometry and size information from the tumor itself	"The authors proposed 'SelfMix' for image segmentation which extends existing 'CutMix' and 'CarveMix'. It is tumor-aware and considers background information. 
It allows more realistic images for training the segmentation model and improves the  results overs baselines."	An effective lesion generation method is urgently needed to boost the performance of lesion segmentation. This paper proposes a novel data augmentation framework through better utilizing the lesion and non-tumor region information.
448	Self-Rating Curriculum Learning for Localization and Segmentation of Tuberculosis on Chest Radiograph	This paper presents a self-rating curriculum learning (SRCL) method for localization and segmentation of Tuberculosis on chest X-ray images. Experiments were conducted to compare the performance of the proposed method with that of the teacher model, Resnet50-FPN with Mask R-CNN, and the experimental results show the proposed method outperforms the teacher model.	Proposed an automatic method to rank image difficulty in order to perform curriculum learning by gradually adding more difficult images into the training set;	The study proposes a model training approach called self-rating curriculum learning. The idea of curriculum learning is starting the training process with relatively easier to predict dataset and gradually increase the difficulty level of the data. According to authors, one challenge for this approach is building difficulty measurer, which includes human expertise prior knowledge and effort. The study proposes a self-rating approach for difficulty measurer part, which does not require human participation. A teacher model is trained to classify the data into categories. The data is then gradually used to train to localize and segment the TB affected areas on CXRs. The authors also curated a large number of TB patient data from multi-center hospitals to develop and test the model. It is not clear that authors will share the dataset.
449	Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT)	This paper introduced knowledge distillation into masked autoencoders (MAE), wherein the teacher network takes all patches of a 3D volume, and the student network takes the visible patches only. Apart from the reconstruction loss in the original MAE, the authors proposed to distill [CLS] token and patch token from teacher to student networks, ensuring both global (volume-level) and local (voxel-level) constraints, respectively. The Vision Transformer (ViT) was pre-trained on 3,643 CT scans from a variety of body regions. The efficacy of the pre-trained ViT was evaluated on two datasets, but the description and results of the MRI upper abdominal organs segmentation were unclear in the paper. The results on the BTCV dataset showed the proposed pre-training approach outperformed existing self-supervised methods developed for CNNs and Transformers.	This paper presents a new self-supervised learning method, SMIT, for 3D multi-organ segmentation. Specifically, they use ViT, masked image modeling (MIM), to learn dense patch feature and use MT self-distillation to train the model. Extensive experiments demonstrate the effectiveness of the proposed method.	This paper proposed a self-supervised learning method for 3D multi-organ segmentation. They presented a self-distilled masked image transformer to pre-train the segmentation network and employed the well-trained model to initialize the model for better segmentation performance. The method has been validated on two public datasets with nice experiment results.
450	Self-supervised 3D Patient Modeling with Multi-modal Attentive Fusion	"This paper presents a method for 3D patient body modeling. To this end, the authors propose a framework to localize 2D keypoints with two branches for RGB and depth images and to estimate 3D mesh from the 2D keypoints. The proposed system using RGBD data shows a mean per joint position error (MPJPE) of 115 (mm) for 3D mesh regression, which is 22 mm lower than RDF [1].
[1] Yang, F., Li, R., Georgakis, G., Karanam, S., Chen, T., Ling, H., Wu, Z.: Robust multi-modal 3d patient body modeling. In: International Conference on Medical Image Computing and Computer-Assisted Intervention (2020)"	The manuscript presents an automatic approach to estimating the 3D mesh of a patient from a given RGB and depth image by proposing attentive fusion to fuse the RGB and depth image heatmaps to calculate 2D keypoints and heatmaps. The estimated 2D heatmaps and 2D keypoints are further passed to a regressor to estimate the SMPL parameter of the body mesh.	This paper describes a CNN-based approach for 3D patient modelling from RGB-D acquisitions under challenging conditions, i.e. different clinical scenarios. The main contribution is a more efficient supervision of the CNN, achieved by splitting the 3D model generation in two steps, which can be supervised individually: First, joint keypoints are detected from RGB, D or RGB-D inputs using an existing 2D keypoint detector and a fusion module, and the authors show how this can be trained using unsupervised pretraining and a relatively small number of labelled training data. For 3D mesh regressing, they also use an existing architecture, and describe an approach for generating synthetic 2D joint and mesh parameter pairs for training the mesh regressor in a self-supervised fashion. They evaluate their approach by comparing against other 2D joint and 3D mesh regression methods, showing good generalizability of their method.
451	Self-Supervised Depth Estimation in Laparoscopic Image using 3D Geometric Consistency	This paper, proposes a  self-supervised laparoscopic image depth estimation approach that in addition to left-right consistency, also invokes the inherent geometric structural consistency of real-world objects, as well as optimizing  mutual information between stereo pairs. The authors demonstrate their approach using public and locally- acquired datasets that show the ability of this approach to generalize across different instruments and imaging environments.	"The authors propose to use stereo images to train a depth from mono method. They propose to generate depth images from monocular depth estimation from each eye and use a consistency loss to ensure these depth maps are consistent. 
The method is validated on a well known benchmark dataset and compared with some previously published mainstream computer vision methods."	This work proposed a framework for laparoscopic image depth estimation. The estimator was trained self-supervised with stereo images, with 3D ICP loss and blinding mask, and achieved good performance on two datasets.
452	Self-Supervised Learning of Morphological Representation for 3D EM Segments with Cluster-Instance Correlations	Submission 2634 proposes a novel method to learn a representation of the morphology of 3D objects segmented from EM volumes. The method is self-supervised, validation is performed on a large manually annotated dataset of neurite fragments. Comparison to state-of-the-art shows the advantages of the method.	This paper proposes a new self-supervision method for point cloud representation with the application for neuron subcompartment classification. The proposed method combines existing self-supervised methods for images, BYOL and SwAV, with minor modification. On its own dataset, the proposed method outperforms baseline methods.	The authors present a self-supervised approach for learning 3D morphology representations from ultra-scale EM segments. The proposed method leverage contrastive learning at both instance level and cluster level to learn the representation. Experiments on the over-segmented results FAFB-FFN1 outperforms other contrastive learning methods.
453	Self-Supervised Pre-Training for Nuclei Segmentation	The paper addressess the problem of nuclei segmentation in whole slide images (WSI), and how vision transformers (VT) can be used for this. VT are data-hungry and therefore usually used pre-trained on ImageNet, but this is not so useful for nuclei segmentation. The paper presents a pre-training strategy, which makes VT preform better on WSI.	The author utilized the self-supervised learning for unlabelled data to tackle the need of large quantity of dataset in transformer pre-training for medical application. The paper proposed a unique framework to pre-train by combining triplet loss, scale loss with a learnable background foreground criterion.	This paper introduces a new self-supervised learning method to pre-train Vision Transformers for nuclei segmentation. The proposed method drives the network to predict the patch features from the surrounding neighboring patches, thereby encouraging the network to learn meaningful nuclei features. This method is motivated by an observation that it is more difficult to predict non-background patches than the background ones. After fine-tuning the pretrained weights on the nuclei segmentation network, in practice it is shown that the proposed method achieves better performance than previous works.
454	Semi-supervised histological image segmentation via hierarchical consistency enforcement	The authors propose a novel semi-supervised segmentation method applied to cells and glands in regions of histopathology images. The method follows a teacher-student model where the teacher is regularised with stochastically altered intermediate features.The results on two datasets of nuclei and glands segmentation show competitive, and in some cases better, results than state of the art SSL methods.	The paper describes a framework to utilize both labeled and unlabeled data for nuclear and gland segmentation in a hierarchical fashion. The method uses a teacher-student network setup where labeled data is fed to a student network for supervised optimization, while training with unlabeled data is based on consistency between multiple outputs from student network and a single output from the teacher network. Specifically, latent space perturbations are applied at multiple layers of the student decoder with prediction certainty maximized with self-supervised mechanisms and hierarchical losses using the Teacher model outputs. Results on existing public benchmark datasets show competitive results, including ablations on the proposed losses.	In this paper, the authors propose a semi-supervised histological image segmentation method based on the Mean-Teacher model with a hierarchical feature consistency loss. In experiments, the proposed method outperforms previous methods, including a SOTA method using transformation consistency.
455	Semi-supervised Learning for Nerve Segmentation in Corneal Confocal Microscope Photography	"The manuscript presents a semi-supervised learning framework for corneal nerve fibers segmentation in confocal images. 
The method is well described and characterized by many steps. Some of these steps are innovative and the overall method is a novelty. Results are well evaluated and show an improvement with respect to other methods for corneal nerve segmentation."	The authors proposed a semi-supervised segmentation framework that could work with only a few labeled data samples. They used masked image modeling (MIM) to pretrain a U-Net with unlabeled data and then fine-tune the model with labeled data and combined unlabeled data with pseudo-labels and actual labeled data to retrain the model. The performance is good and convincing.	The submission propose a semi-supvervised learninig framework for nerve segmentation in CCM, which contains three main components: pretraining on large unlabeled datasets and refining on small labelled datasets, generating pseudo labels, and retraining with the full datasets. The stage of pretraining utilize a masked image modeling based GAN structure, including coarse repring network, refine reparing network, and disciminator, among which the encoder of refine reparing network is used in the whole semi-supervised framework.
456	Semi-supervised learning with data harmonisation for biomarker discovery from resting state fMRI	"This paper proposes a deep-learning framework that includes data harmonisation and semi-supervised representation learning for disease classification and biomarker discovery by using data from multiple sites.
Their reported performance on two datasets is impressive compared to the existing work in the literature."	"combined harmonization and classification framework
demonstrates the ability to determine generalizable biomarkers"	This paper presents a semi-supervised learning (SSL) method to harmonize data across imaging sites while simultaneously learning a classification task. The proposed variational autoencoder (VAE) model has a data harmonization encoder and decoder, with the latent representation used to learn the target classification task. The model is trained in semi-supervised way, where unlabelled data from multiple other sites are used to learn the data harmonization encoding/decoding, while labelled data is additionally used to learn the classification portion of the model. A two-step harmonization approach was also proposed, where the ComBat method was used for initial harmonization, followed by the proposed method. The method was tested against supervised learning on single sites and SSL without harmonization using the public ABIDE dataset.
457	Semi-Supervised Medical Image Classification with Temporal Knowledge-Aware Regularization	This work proposes a new framework TEAR for semi-supervised medical image classification, which contains an AdaPL module for relaxing hard pseudo labels to soft-form ones and an IPH module for aligning feature prototypes across different training iterations.	This paper presents a semi-supervised image classification method with adaptive pseudo labelling and iterative prototype consistency. The adaptive pseudo labelling uses a loss estimating function to soften and calibrate hard pseudo labels while the iterative prototype consistency aligns the cluttered class centroids across model training iterations to reduce dependency of pseudo labels. The author conducts experiment on three datasets and the proposed method outperforms existing state-of-the-arts algorithms. Also, the author provides detailed ablation results to verify the effectiveness of their method.	"This paper proposes a TEmporal knowledge-Aware Regularization (TEAR) for semi-supervised
medical image classification. The upper bound of the loss of unlabeled samples was theoretically proved and it was used to relax pseudo labels (soft pseudo labels). In addition, the iterative prototype harmonizing (IPH) is proposed to maintain the harmonization of clustered prototypes across different iterations. In the experiments, the proposed method outperformed the state-of-the-art methods and sufficient ablation studies were conducted."
458	Semi-Supervised Medical Image Segmentation Using Cross-Model Pseudo-Supervision with Shape Awareness and Local Context Constraints	This study proposed a semi-supervised segmentation framework consisting of two Unet networks that generate pseudo-labels for each other. The study also proposed a loss function, local context loss, as an extension of the dice loss. The framework was evaluated using two public datasets and showed superior results compared to other approaches with semi-supervision (n=7,14) while underperformed the baseline method with full supervision.	This paper introduces a semi-supervised segmentation approach. It extends a prior art of cross-modal supervision by incorporating two things. First is the share awareness by co-teaching a shape agnostic network and a shape aware network. The second is to adopt local context constraints using patch level dice loss. The approach is applied on two public datasets in a semi-supervised setting, and demonstrates superiority over other methods	This manuscript is about incorporating shape priors in the context of segmentation with neural networks. For this purpose two networks are used. One network is shape agnostic. The second network is shape aware and receives as input the original image as well as the output of the first agnostic network. The second network also encodes local information since it considers different parts of a shape. The method is validated with two datasets.
459	Semi-Supervised PR Virtual Staining for Breast Histopathological Images	the authors designed a Pos/neg classification module  for consistency. Also they achieved the transformation of H&E staining to PR staining for breast cancer for the first time.	The paper describes a method of virtual staining that transfers between H&E stain and progesteron stain in breast cancer histopathological slides. The training is based on consecutive slides with different staining. Te stain transfer of un-paired patches is achieved based on the cycle-consistency framework.	The authors propose a smart system for IHC staining out of a H&E staining.
460	Semi-Supervised Spatial Temporal Attention Network for Video Polyp Segmentation	The authors propose possibly the first method for semi-supervised video-based polyp segmentation. To accomplish this, they annotate 60 videos of a video polyp detection dataset. Their technique uses two transformers to exploit both spatial and temporal information effectively. The proposed approach beats state of the art techniques.	A novel approach is proposed for polyp segmentation in clinical videos. This method consists of two main modules that shape a semi-supervised polyp segmentation architecture.	This paper proposed a semi-supervised polyp video segmentation by introducing Temporal Local Context Attention (TLCA) module and Proximity Frame Time-Space Attention (PFTSA) module to improve the video polyp segmentation.
461	Sensor Geometry Generalization to Untrained Conditions in Quantitative Ultrasound Imaging	"This paper describes a framework to generate attenuation coefficient (AC) images from ultrasound (US) that is able to generalize to different probe geometries, in the context of quantitative US. The main contribution of the proposed method is a Deformable Sensor Adaptation (DSA) module, which takes the radiofrequency signal and the B-mode image as input, and learns to adjust the sensory data to a common sensory representation. The DSA module is trained leveraging on a meta-learning scheme, which improves generalization to unseen probe conditions. 
Both numerical and in-vivo validation using probe configurations not seen at training time is performed. Comparison with other domain randomization approaches is present."	"They propose a deformable sensor generalizable network to calibrate probe conditions.
-They assessed the proposed method through numerical simulation and in-vivo studies."	The authors present a deep learning approach for AC reconstruction which is robust to the changes of the probe.
462	SETMIL: Spatial Encoding Transformer-based Multiple Instance Learning for Pathological Image Analysis	This paper presents a novel spatial encoding multiple instances learning method for pathological image analysis. It releases an attention-based pyramid multi-scale fusion module, which is a novelty for aggregating the local information of the patches. In addition, the joint relative and absolute position encoding module simulates the diagnosis process of pathologists. Presented the two modules, the transformer-based model gain improved performance in pathological image analysis.	"This paper proposes SET-MIL, a transformer-based framework for WSI representation learning which incorporates spatial information (neighbouring instances and globally correlated
instances) to obtain representations that capture more semantic information.
Based on the experiments, the proposed method outperforms recent MIL-based methods for WSI representation learning task."	The presented paper introduces a MIL approach for WSI level feature embedding and classifier with position preserving embedding followed by Transformer-based Pyramid Multi-Scale Fusion. Results were verified in two datasets in the paper and TCGA experiments in the supplementary materials.
463	SGT: Scene Graph-Guided Transformer for Surgical Report Generation	The paper proposes to leverage scene graph and Transformer to generate surgical report, where DPP is used to obtain the prototype for encoding global relation, and a homogeneous graph is constructed to encode local relation. Extensive experiments on EndoVis18 is performed to validate the effectiveness of method.	This work proposes a Transformer-based architecture guided by scene graphs to approach the surgical report generation task. This paper uses scene graphs representing visual objects and relationships encoded using a Transformer encoder. In the attention layer, the key and value are expanded with a sample memory obtained using a k-Determinant Point Process [12, 15]. This strategy allows the use of global and local attention. Finally, it uses a meshed decoder [5] to generate the report from the resulting encoder rendering. This paper presents results in one benchmark dataset: Endovis2018.	"This paper introduces a novel surgical report generation model vis scene graph-guided transformer (SGT).

The scene graph could extract the relation graph between tissues and instruments, which could accurately guide the report generation process.
A novel relation memory augmented attention is introduced to better interact between input videos and generated reports.
Graph neural network is adopted to better model the relations between tissues and instruments."
464	Shape-Aware Weakly/Semi-Supervised Optic Disc and Cup Segmentation with Regional/Marginal Consistency	"This paper discusses the segmentation of glaucoma with an hybrid supervision setting, mixing weak labels and no labels.
The idea is to regularize the training with regularization that taps into anatomical priors about the problem, such as the shape and diameter relationship of the two circles to be segmented."	The paper proposes a semi-supervised framework for optic disc and cup segmentation via a dual-task level of geometric consistency between pixel-wise segmentation mask with distance map.	The authors proposed a weakly/semisupervised framework with the benefits of geometric associations and specific domain knowledge between pixel-wise segmentation probability map (PM ), geometry-aware modified signed distance function representations (mSDF), and local boundary region of interest characteristics (B-ROI ). Experiments on six large-scale datasets demonstrated that their method outperform state-of-the-art semi-supervised approaches for segmentation of the optic disc and optic cup, and estimation of vCDR for glaucoma assessment in color fundus images, respectively.
465	Shape-based features of white matter fiber-tracts associated with outcome in Major Depression Disorder	The authors present an association of biomarkers created from shape of white matter fiber tracts with outcome in major depression in a longitudinal study of 63 individuals. The authors compute the shape metrics of the fibers from an MRI taken at start of the study and try to predict the outcome after 6 months, using their biomarkers and other relevant covariates.	The paper is about major depressive disorder and white matter imaging. The methods describe a technique to predict clinical improvement at six months.	The article describes a two levels shape analysis (global and local) of fiber bundles based on the large diffeomorphic deformation metric to discriminate treatment resistant depression.
466	ShapePU: A New PU Learning Framework Regularized by Global Consistency for Scribble Supervised Cardiac Segmentation	The authors propose a weakly supervised segmentation approach utilizing scribble-guided annotation, a positive-unlabeled learning framework and shape consistency regularization. The proportion of each segmentation class in the unlabeled pixels is estimated via EM. The approach is evaluated on two open data sets and reportedly outperforms other supervised as well as weakly supervised approaches.	"Authors propose a new scribbled method for cardiac segmentation with weak supervision based on the positive unlabeled framework and shape regularization, that penalizes inconsistent segmentation results.
Their method makes use of an Expectation-Maximization (EM) algorithm to estimate the proportion of each class in the unlabeled pixels."	In this work, authors have proposed a weakly supervised framework where they use scribbles to train the method for segmenting LV, RV and MYO on cardiac MR images. The method involves an EM algorithm for estimating the mixture proportion, PU learning to identify the classes of unlabelled pixels by maximising marginal probability and by leveraging the consistency of features across shapes by cutting out specific regions and finding cutout equivalence. They also perform comparative analysis with prior methods on two different datasets.
467	Show, Attend and Detect: Towards Fine-grained Assessment of Abdominal Aortic Calcification on Vertebral Fracture Assessment Scans	"This paper presents a framework for automated assessment of AAC (Abdominal Aortic Calcification). 
There are a few methods which predict an overall AAC-24 score, however they have some shortcomings.
To address them, an effective framework is proposed to generate fine-grained scores of images in a sequential manner.
It utilizes an attention based encoder-decoder network to mimic  the human-like AAC-24 scoring method.
According to the authors, this is the first time such a methodology is used to address the AAC-24 scoring problem."	The authors present a model for automatically assessing aortic calcification on DXA scans using an LSTM with attention. Their model has the benefit of providing individual scores for regions of the aorta, which is potentially useful for diagnosis as well as understanding model output. They compared against their implementation of a previous model and showed higher performance metrics.	In this paper, a framework for automated fine scoring of Abdominal Aortic Calcification using L1-L4 vertebral X-ray scans is described. The authors propose the use of a convolutional encoder to obtain a latent representation of the scans, and then train an attention mechanism to focus separately on the anterior and posterior segments of the abdominal aorta. The resulting output provides a fine-grained scoring, based on the AAC-24 scale, which is an improvement over previous efforts that only provided a global score for a given X-ray scan.
468	Siamese Encoder-based Spatial-Temporal Mixer for Growth Trend Prediction of Lung Nodules on CT Scans	"Main contributions are: 
(1) Authors derived the prediction of lung nodule evolution by organizing a new temporal CT dataset called NLSTt by combing automatic annotation and manual review.
(2) Authors proposed a spatial-temporal mixer (STM) to leverage both temporal and spatial information involved in the global and lesion features generated from 3D ROI pairs.
(3) Authors conducted extensive experiments on the NLSTt dataset to evaluate the performance of their proposed method and confirmed the effectiveness of their model on an in-house dataset from the perspective of clinical practice."	To advance the prediction of lung nodule evolution, the authors construct a new temporal CT dataset NLSTt, and propose a spatial-temporal mixer (STM) to extract the temporal and spatial information involved in the global and lesion features of CT images information.	This paper focuses on the prediction of lung nodule growth trend in CT scans.  Authors organized a new temporal CT dataset from NLST dataset and proposed a growth trend prediction framework including a Siamese encoder, a spatial-temporal mixer and a hierarchical loss. Authors validated the framework on the organized dataset as well as on an in-house dataset to demonstrate its feasibility.
469	Simultaneous Bone and Shadow Segmentation Network using Task Correspondence Consistency	This paper presents a incremental innovation for bone segmentation from US images. The main contribution is the cross task transfer block that improve the performance of the overall segmentation for both bone and shadow.	"Multi-task segmentation with the use of a new cross-task feature transfer block
Proposed a task correspondence consistency loss to improve multi-task learning
Validation on images of different anatomies and different ultrasound scanners."	Bone segmention from US images, taking into account the bone surface and shaow artiffact. The study is presente in the context of image-guided orthopaedic intervention, but it really is yet another segmentation paper.
470	Skin Lesion Recognition with Class-Hierarchy Regularized Hyperbolic Embeddings	"In this paper, a method for skin lesions embedding and classification based on hierarchical class relations encoding and hiperbolic embedding is presented.
The two main contribuions are:

They use hyperbolic geometry, instead of Euclidean, for the image embedding. 
. They incorporate to the loss a distance based on the hiearchical relations between classes."	This work proposes to use class hierarchy with deep learning algorithms for more accurate and reliable skin lesion recognition. A hyperbolic network is proposed to learn image embeddings and class prototypes. Validation was carried out on an in-house skin lesion database which consisted of ~230k dermoscopic images on 65 skin diseases.	This paper proposes a skin lesion classification approach that leverages a  hyperbolic embedding in a class hierarchy-aware setting. The authors' goal is to increase classification performance on the task by projecting the deep features to a hyperbolic geometric embedding and performing classification on it. Their method also models and enforces the problem's class hierarchy by incorporating a novel loss into the training process.
471	SLAM-TKA: Real-time Intra-operative Measurement of Tibial Resection Plane in Conventional Total Knee Arthroplasty	The authors propose a method to evaluate the 3D alignment of the tibia resection block during a total knee arthroplasty procedure based on a series of intraoperative fluoroscopy images and a preoperative CT scan of the tibia. The author(s) tested the proposed method in a simulation and clinical pilot study.	This paper presents a real-time algorithm for reliably and intraoperatively estimating the tibial resection plane for CON-TKAs. It solves a SLAM problem using a patient-specific pre-operative tibia CT scans, a trocar pin mesh model and two intra-operative X-ray images. Simulation experiments demonstrate the robustness and accuracy of their proposed algorithm.	This paper proposed a SLAM based approach to accurately estimate the proximal tibial resection plane intra-operatively, using 2 X-ray radiographs, 3D tibia mesh model, and trocar pin 3D mesh model. Simulation and in-vivo experiments demonstrated its good performance.
472	SMESwin Unet: Merging CNN and Transformer for Medical Image Segmentation	The authors proposed an image segmentation method that combines CNN with Transformer. As part of the network architecture, they introduced superpixel to reduce redundancy and noise in the images. It is fed into CNN to generate features of input images that are later combined with multi-scale features from Transformer. The proposed method is evaluated on two datasets, demonstrating superior performance in comparison to other related models.	his paper presents a new network architecture, SMESwin Unit, that merged CNN and transformer for medical image segmentation. It fuses multi-scale semantic features and attention maps, then introduces superpixels to avoid the interference of meaningless parts of the image, and finally uses external attention to consider the correlations among all data samples. The proposed network achieved better results than CNNs and other Transformer-based architectures on three medical image segmentation datasets.	Authors proposed one deep learning segmentation system based on hybrid swin-transformer and Channel-wise Cross fusion Transformer (CCT). They replaced one skip connection from CCT with one CNN branch processing super-pixeled raw images and name it MCCT. External attention mechanism was deployed to further refine the features. The system was tested in GlaS, MoNuSeg, and WBC for gland, nuclei, and cell segmentation, respectively and achieved promising performance.
473	Sparse Interpretation of Graph Convolutional Networks for Multi-Modal Diagnosis of Alzheimer's Disease	This paper presents a (GCN) Graph Neural Network-based approach for classification and detection of Alzheimer's disease from multi-modalities of brain images. The authors propose the sparsity to capture subgraph representations attending on most important features for better discrimination between AD and healthy groups. Ablations and experiments in the paper show that the SGCN method provides better classification than related work when using multi-model data.	"In this paper, a sparse interpretable GCN framework (SGCN) for the iden-
tification and classification of Alzheimer's disease (AD) is proposed using brain imag-
ing data with multiple modalities."	This paper proposed a sparse interpretable GCN framework (SGCN) for the identification and classification of Alzheimer's disease (AD) using brain imaging data with multiple modalities.
474	Spatial-hierarchical Graph Neural Network with Dynamic Structure Learning for Histological Image Classification	This work proposes a new Graph Neural Network (GNN) method for the classification of histology images. The two contributions of the proposed method include firstly the dynamic graph structure that is learnt as part of the learning stage. Secondly, the employed vision transformer mechanism improves the feature extraction using the deploying the multi-level structure of the graph.	The paper presents a spatial-hierarchical GNN framework including a dynamic structure learning module to explore the spatial topology and hierarchical dependency of the multi-level biological entities in order to improve histological image classification. The proposed framework was evaluated on two datasets and results demonstrate that it outperformed the state-of-the-art methods on both datasets.	In the paper a method for the classification of histopathological images is presented. The method is based on a Graph Neural Network (GNN) approach, introducing a dynamic learning. Moreover, an approach visual transformer-based is used for the final classification.
475	Spatiotemporal Attention for Early Prediction of Hepatocellular Carcinoma based on Longitudinal Ultrasound Images	This paper focuses on early prediction of hapatocellular carcinoma (HCC) based on longitudinal ultrasound images. The authors propose a spatiotemporal attention network that adopts a convolutional-neural-network-transformer framework. Their method achieves state-of-the-art performance compared with other popular sequence models.	The paper presents a CNN-transformer network for hepatocellular carcinoma (HCC) diagnosis from longitudinal ultrasound. The authors incorporate an ROI attention block into the CNN to perform feature extraction. They also use an age-based positional encoding to process longitudinal imaging of arbitrary time intervals.	This paper presents a new early HCC prediction method using a spatiotemporal attention network (STA-HCC) based on longitudinal US images. The topic is especially important in the case of 1) defining regions of interest (ROIs) in longitudinal US images and 2) sequential images and irregular temporal components. The proposal uses non- longitudinal US images to predict HCC. The motivation of the paper is clearly defined, and a brief state-of-the-art presented. Paper contributions: 1) ROI attention block, 2) age-based position embedding in transformers.
476	Spatio-temporal motion correction and iterative reconstruction of in-utero fetal fMRI	The authors attempt to address the motion1. challenges in fetal MRI by looking at the spatio-temporal dimensions of the 4D fMRI data set as a whole rather than as a set of 3D volumes over time.	As a general preprocessing step of fetal fMRI analysis, this manuscript proposes a four dimensional (4D) iterative reconstruction method to correct the motion scattered fMRI slices, while existing methods processing 3D images at each time frame individually.	The authors propose a spatial-temporal iterative reconstruction method for motion correction of in-utero fetal fMRI. Experimental results on a cohort of real clinical fetal fMRI data indicate improvement of reconstruction quality compared to the conventional interpolation approaches.
477	Stabilize, Decompose, and Denoise: Self-Supervised Fluoroscopy Denoising	The paper proposed a self supervised method for fluoroscopy denoising. In their method they have first stabilize the the frames to compensate the non stationary background effect induced by the motion of the x-ray detector, than decompose the background and foreground using RPCA(a variant of principle component analysis) and then denoised the background and foreground separately.	"They proposed a pipeline to stabilize and denoise fluoroscopy video where severe noise and motion exist. First find global motion between adjacent frame, decompose foreground and background using proposed mask-based RPCA, denoise them and composed.
They showed the better denoising performance compared to other approaches in numerical measure and expert evaluations."	Proposed a three stage framework for denoising including stabilizing using optical flow, decomposing by proposing masked Robust Principle Component Analysis (RPCA), and denoising by using a simple self-supervised network.
478	Stay focused - Enhancing model interpretability through guided feature training	"The authors propose a mask input-based training scenario that separates the training target from the background for the design of explanatory AI models. As a target task for explainable AI, a multi-class classification problem was targeted, and an instance segmentation model was utilized for mask generation. SmoothGrad [10] was applied to visualize the feature output of the model.
The authors propose the eCDF-Area method to evaluate the explanatory power of a model, and at the same time show that it is possible to train with mask-based synthesized images to minimize the burden of labeling in guided feature training."	This work proposes a data augmentation technique, named Guided Feature Training (GFT) for improving the interpretability of a deep learning model for the task of surgical instrument detection. The augmentation technique proposes to blur the background (everything that is not a surgical instrument) to guide the feature training towards the instruments and disregard other less useful information for the task (e.g. the background). The proposed augmentation requires a binary segmentation model (or binary segmentation annotations) that segment surgical instruments.	Improving the interpretability/generaisability of NN's using data augmentation and guided feature training for a surgical application, utilising numerical evaluaton of a model with a proposed area metric called eCDF.
479	Stepwise Feature Fusion: Local Guides Global	This paper proposes a transformer based segmentation architecture SSFormer. The main novelty of SSFormer is the local emphasis operator, which forces the attention to put more weights on nearby patches. SSFormer achieves good empirical performance on the polyp segmentation task.	In order to segment polyp more accurately, this work designs a new framework, SSFormer, which exploits pyramid transformer architecture as encoder, and proposes a multi-stage aggregate decoder (PLD) to progressively fuse information at different stages. It shows a better performance on different benchmarks.	The paper provide a pyramid transformer based model for 2D medical image segmentation, with a novel progressive locality decoder from multi-stage feature aggregation, in order to improve the generalizability/robustness and better capture local features in challenge segmentation task (polyp segmentation). Comprehensive experiments with promising performance are reported.
480	Stereo Depth Estimation via Self-Supervised Contrastive Representation Learning	This paper addresses the problem of stereo depth estimation. Authors introduce a self-supervised contrastive representation learning method for two-stage stereo depth estimation.	This paper proposes the first contrastive representation learning (CRL) method for stereo depth estimation based on a momentum pseudo-supervsied contrastive loss, which achieves state-of-the-art performance.	This paper proposes an approach for stereo depth estimation. This paper proposes a two-phase training procedure including contrastive representation for feature learning and self-supervised disparity learning.
481	Stroke lesion segmentation from low-quality and few-shot MRIs via similarity-weighted self-ensembling framework	This work approach the problem of Ischemic stroke lesion segmentation when the training dataset is small and the MRI images have low resolution. To accomplish this task, the authors propose a framework that simultaneously train a neural network to segment ischemic stroke lesion and brain tumor, such that the update from the ischemic stroke lesion is stronger than the update provided by the larger dataset on brain tumors. According to the authors, the key elements of their approach are 1) a module that identifies the lesions and iteratively refine the prediction (IDN), and 2) another module that transfers optimization direction from brain tumor problem to facilitate the learning to segment the stroke lesion (SDU). The authors compares the proposed method with three other methods proposed in the literature for few-shot learning in terms of Dice, Accuracy and Hausdorff distance, surpassing with a large margin in all metrics.	The authors propose a novel approach to automatically segment stroke lesions on low-quality and few-shots MRI. The method exploits attention mechanisms to first identify lesions from a global perspective and then progressively refine their segmentation. A new strategy is also proposed to overcome the few-shots challenge.	The paper presents a framework for stroke lesion segmentation from low-quality and few-shot MRI. The authors present the Identify-to-Discern Network, which combines a pyramidal structure with attention layers and a multiscale loss. They also propose a Soft Distribution-aware Updating strategy (SDU) as a more effective alternative to pretraining on a related task. These techniques achieve good performance when co-training on glioma segmentation.
482	Structure-consistent Restoration Network for Cataract Fundus Image Enhancement	In this paper, the authors proposed a restoration network (SCR-Net) for cataract fundus images enhancement. They designed a synthesis model of cataract images to generate synthesized training data (SCS), a restoration model to get cataract fundus images from synthesized data, and a module for HFC alignment. These three parts were integrated into the backbone of SCR-Net. Their approach was evaluated on two public datasets and two private datasets respectively and test results showed good performance.	This paper aims at enhancing the quality of fundus images to improve the certainty of fundus examination, proposes a structure-consistent restoration network (SCR-Net) to enhance cataract fundus images in the absence of supervised data. The authors generate synthesized cataract set (SAS) by synthesizing cataract fundus images sharing identical structures according to the imaging principle. To boost the training stage and structure preservation in SCR-Net, the high-frequency components (HFCs) are extracted from network to constrain structure consistency. Following comparison experiments and ablation studies prove that the proposed algorithm has achieved state-of-the-art.	The authors proposed a SCR-Net, which utlizes the high frequency structure consistency of fundus image, to enhance degraded fundus image. Moreover, a synthesis model for generating cataract images is proposed following the principle of fundus image.
483	Super-Focus: Domain Adaptation for Embryo Imaging via Self-Supervised Focal Plane Regression	This manuscripts presents a method for standardization and super-resolution (in the slice direction) of the human embryonic data. The authors present a method for simulating realistic-looking focal planes, that can be used both for generating missing planes as well as for upsampling the data via super-resolution. The methodology is simple but efficient and the validation is convincing.	"Authors are suggesting a generative model approach for generating the missing focal planes of different domains in human embryo microscopy. 3 different generators receive two consecutive planes and generate the third one (one for each case, up, down and middle). An autoencoder extracts the features and reconstructs the input. A discriminator helps with adversarial loss and finally latent space feature representations from the generated image and its ground-truth are aligned with a self supervised loss. 
Results are reported i) qualitatively ii) on embryo grading iii) on single cell segmentation"	The authors propose a method for predicting missing slices in embryo imaging data sets. The model is trained in a self-supervised manner and evaluated on a large data set including some tests with four human raters. Multiple generator models allow predicting missing slices either below, above or between two existing other slices. While the methods don't seem novel per se, the application to this problem are reasonable and the results indicate benefits of using this additional super-resolution approach.
484	SUPER-IVIM-DC: Intra-voxel incoherent motion based Fetal lung maturity assessment from limited DWI data using supervised learning coupled with data-consistency	"The authors propose a deep learning based method for the estimation of IVIM parameters. The proposed approach extends the state if the art by basically combining two previous approaches, where one works with a supervised loss measuring the difference between the ground truth IVIM parameters of a forward model and the parameters predicted by the DNN on the basis of the signal simulated using said model, and the other one works with an unsupervised loss measuring the difference between the measured/simulated signal and the signal generated by the DNN.
The authors perform experiments that are supposed to show that their extended approach yields more robust and accurate results as compared to a state of the art model."	Intravoxel incoherent motion imaging is an emerging MRI modality for the characterization of tissue microvascular perfusion and diffusion. Its clinical value is undoubtedly the ability to describe tissue viability and vascularity without the need for contrast agents, however, such measurements are often compromised by low SNR. The authors propose a DNN coupled with data-consistency term that may provide more reliable parameter estimates in low SNR settings. They test their hypothesis by undersampling a volunteer dataset. Furthermore, they evaluate the method in a challenging fetal MRI setting to characterize lung maturation. Compared to DNN based parameter estimation methods from the literature, the authors propose a supervised loss function coupled with a data-consistency term, which they hope to achieve more robust estimates in case of new data and in case of low SNR (fewer b-values). Their method yields lower standard error for the IVIM parameter estimates compared to the IVIM	This paper introduced SUPER-IVIM-DC, a DNN approach for the estimation of the IVIM model parameters from DWI data acquired with limited number of b-values. Their numerical simulations and healthy volunteer study show that SUPER-IVIM-DC estimates of the IVIM model parameters from limited DWI data had lower normalized root meansquared error compared to previous DNN-based approaches.
485	Supervised Contrastive Learning to Classify Paranasal Anomalies in the Maxillary Sinus	The paper proposes to augment a cross-entropy based classification task with an adapted contrastive SimCLR loss which uses samples from the same class as positive pairs.	The authors in this work propose to combine the supervised contrastive loss with a cross-entropy loss for classifying paranasal anomalies in the maxillary sinus.	"The authors propose a self-supervised SimCLR method to maxillary sinus classification in MRI images.
They also conduct a population study - experiments on large number of patients with wide distribution statistics - a clinically important but rather rare contribution in MICCAI."
486	Supervised Deep Learning for Head Motion Correction in PET	"In this paper, the authors proposed a new deep learning-based method to correct the head motion and diminish the artifacts and quantification errors in PET imaging. This is supposed to be a good start on algorithm-based motion correction in PET imaging.
However, the algorithms can't be perfect. The experimental results also confirmed this. I was wondering if the inaccurate motion correction is acceptable in clinical use? The results showed that the predicted correction sometimes even caused higher errors."	This work attempts to do a very challenging task of learning 3D rigid head motion from highly noisy data. A motion tracking system (Vicra) is used as the learning target. To achieve this, the authors designed a neural network based model which uses encoders on two input images at different time points, and a FWT unit that operates on the difference of these two images.	The paper introduces a deep learning approach to real-time motion tracking based on PET data. The motion tracking results are validated in a single-subject and multi subject experiment and against an external tracking device, the Polaris Vicra camera. This aproach to motion measurements is very interesting since it is a big problem in PET acquisitions due to their much longer acquisition times than e.g. CT or MRI.
487	Suppressing Poisoning Attacks on Federated Learning for Medical Imaging	"In this paper the authors propose a new method for federated learning that aims to address ""poisoning attacks"", ie. considers that some of the nodes contributing to the federated learning network are malicious. The proposed method is based on computing distances between the parameters that are communicated by each node and then weights them according to a copula-based outlier detection method. Empirical results illustrate the usefulness of the proposed method in two datasets."	"The paper propose a general aggregation rule of federated learning.

The proposed method is technically sound and simple.

The experimental results show the effectiveness of DOS against several types of attacks."	This paper proposes a Federated Learning framework with Distance-based Outlier Suppression (DOS) based on Euclidean and Cosine distances and a softmax operation with temperature for tackling client poisoning attacks. The proposed method is evaluated on two medical imaging datasets on classification tasks and achieve improved performance over previous methods.
489	Surgical Scene Segmentation Using Semantic Image Synthesis with a Virtual Surgery Environment	The paper performs extensive sets of experiments for surgical scene segmentation with real and synthetic images. Synthetics images are generated from an advanced surgery scene simulator. A large-scale segmentation dataset is also released.	"This paper propose a surgical image sythesis pipeline, which contains a complex virtual surgery environment, class-balanced frame sampling, domain randomization and semantic image sythesis.

The authors contribute a large-scale surgical image segmentation dataset with both real and sythetic images, which can be used for visual object
recognition and image-to-image translation research for gastrectomy with the dVSS.

The effects of synthetic data between tasks, models, and data are analyzed with extensive experiments."	The authors propose a synthetic data generation framework for generating synthetic data for minimally invasive surgical scene segmentation. The scene is rendered in the Unity engine as segmentation mask from which photorealistic images are generated using two different semantic image synthesis GAN-based methods. All related datasets will be published. A comparison of state-of-the-art segmentation models is performed.
490	Surgical Skill Assessment via Video Semantic Aggregation	The paper describes a method for analysis of videos to assess surgical skill. The network architecture includes a semantic grouping module that uses clustering of local semantic features.	This paper proposes a new framework called ViSA to predict the skill of surgical videos by discovering and aggregating different semantic parts. The framework has been compared to previous work and gets competitive performance on two datasets: JIGSAWS and HeiChole.	"The authors propose a novel framework called ViSA which predicts addresses the problem of automated skill assessment in surgical videos. The authors state that the state-of-the-art models often do not capture semantic information as they often employ CNNs for short-term feature extraction and temporal aggregation
networks (e.g., LSTMs) for long-term relationship modeling. They claim that global pooling over the spatial dimension on CNN features ignores semantic variance of different features. They propose to instead discover and aggregate different semantic parts of the surgical setting across spatiotemporal dimensions."
491	Surgical-VQA: Visual Question Answering in Surgical Scenes using Transformer	This paper introduces a VisualBERT and ResMLP based model for Surgical-VQA. It is evaluated on answer classification and sentence generation tasks on three datasets and achieve improved results over previous methods and the baseline method. Visualizations on the generated words/sentences are presented. Ablative studies are presented.	This work proposes to use VisualBERT[15] together with ResMLP[24] to approach the task of surgical VQA. This paper presents results in three datasets: Med-VQA, Endovis18-VQA, and Cholec80-VQA. Furthermore, it reports an ablation study on the proposed architecture.	The authors propose to use a deep learning method to answer the potential questions from student conditioned on the surgery video. It utilizes the Bert-based model to take visual tokens and text tokens in the feature extraction process, and apply conventional transformer-based decoder to predict the output answer. On this paper the RESMLP is proposed to enhance the representational ability of the transformer encoder. It also proposed an extension version of dataset based the EndoVis and Cholec80, including the questions and the answers. Finally, it has compared to the state-of-the-art model in Cholech 80 dataset.
492	Survival Prediction of Brain Cancer with Incomplete Radiology, Pathology, Genomic, and Demographic Data	This work introduces a two-stage deep learning approach that integrates multiple data modalities in the presence of missing data. In addition, the authors performed a detailed ablation and comparison study to justify the importance of each module, and the improvements over baselines, respectively.	The manuscript introduces an approach to predict patient survival based on multi-modality data which includes MRI scans from 4 sequences, histology images, genomics data, as well as demographic data. Three different multi-modality data fusion methods are compared, in which modality dropout was introduced to simulate the scenarios when certain data modalities were missing. Also assessed were whether reconstructing the missing modality could improve the prediction or not. Experiments were carried out on a combined public dataset. An ablation study was conducted to evaluate the effect of all the features introduced to the model.	This paper tackles the problem of effectively utilizing multi-modality data in the presence of missing modalities. In particular, the authors ask the question of how to effectively predict survival in glioma patients when some modalities might be missing for patients. This is a common setting in real life. To solve this problem, this work proposes to aggregate individual modality feature embeddings using the mean vector which can be decoded to obtain individual modalities. The resulting mean vectors is used for predicting survival.
493	SVoRT: Iterative Transformer for Slice-to-Volume Registration in Fetal Brain MRI	The authors proposed a novel slice to volume registration method using transformers in the context of fetal brain MRI reconstruction from multiple-stacks. The proposed framework not only provides the slide to volume estimation but also an estimation of the 3D volume as to assist the motion estimation process. Results are performed on synthetic data and compared to two other slice-to -volume approaches. Qualitative results on two real acquisitions are also presented.	This paper proposes a Slice-to-Volume Registration Transformer (SVoRT) to map multiple stacks of fetal MR slices into a canonical 3D space and to further initialize slice to volume registration and 3D reconstruction. 1) construct a Transformer-based network that models multiple stacks of slices acquired in one scan as a sequence of images and predicts rigid transformations of all the slices simultaneously by sharing information across the slices. 2) The model also estimates the underlying 3D volume to provide context for localizing slices in 3D space. 3) In the proposed model, slice transformations are updated in an iterative manner to progressively improve accuracy.	The authors propose a novel method for fetal brain slice-to-volume registration where they use a synthetic dataset to train a neural network based on the new transformers architecture along with an inverse problem formulation to reconstruct the final volume. They also applied their method to real clinical dataset and the result were visually more accurate. Comparisons were performed with respect to two baselines.
494	Swin Deformable Attention U-Net Transformer (SDAUT) for Explainable Fast MRI	This paper proposed a SDAUT network that combines Swin Transformer and deformable attention for fast MRI which also provides explainability	The authors solve the problem of accelerated MRI reconstruction from an undersampled k-space. They propose a UNet based on Shifted Windows (Swin) Transformer and deformable attention derived from deformable convolution networks.	"The authors integrate Swin deformable transformer [22] with U-Net to propose SDAUT, which is applied to undersampled MRI reconstruction.
The authors attempt to provide explainability of the proposed methods on its superiority to the comparison algorithms by showing the deformation fields and attention score in the inference stage.
The proposed SDAUT outperforms nPIDD-GAN and SwinMR with lower computational cost. SDAUT betas DAGAN in SSIM, PSNR and FFID but fails MACs."
495	Swin-VoxelMorph: A Symmetric Unsupervised Learning Model for Deformable Medical Image Registration Using Swin Transformer	"In this paper, the authors propose to a framework to do image registration usin swin transformer.
The architecture is the swin unet: a unet-like architecture with convolution blocks replaced by swin transformer blocks.
The output of the network are the geometric transformation from each input image to the other one.
The (symmetric) loss minimize: image dissimilarity and inverse consistency between the transformation and penalize irregular transforms and negative Jacobians.
The method is compared to state of the art methods on brain MRI images and evaluated using Dice on cerebrale structure and percentage of negative Jacobian."	The authors present a deformable image registration network based on the Swin Transformer - Swin-VoxelMorph. They use the ADNI and PPMI datasets to evaluate the model. They achieve an average Dice Similarity Coefficient (DSC) of 0.775.	This paper presents a method for deformable medical image registration using Swin Transformer.  The technical novelty of the method is to explicitly exploit Swin Transformer for deformable medical image registration, and utilize orientation and inverse consistency constraint to guarantee the topology-preservation and inverse consistency of the predicted transformations.
496	Tagged-MRI Sequence to Audio Synthesis via Self Residual Attention Guided Heterogeneous Translator	This paper propsoed a novel deep-learning based method to synthesize spectrograms (audio) from tagged-MRI sequences (imaging).	"To our knowledge, this is the first attempt at translating tagged-MRI sequences to audio waveforms.
They proposed a novel self residual attention guided heterogeneous translator to achieve efficient tagged-MRI-to-spectrogram synthesis.
The utterance and subject factors disentanglement and adversarial training are further explored to improve synthesis performance."	The authors propose an encoder-decoder (translator) model which is trained in GAN-fashion on pairs of input data to synthesize acoustic mel spectrograms from an MRI sequences of oropharyngeal muscles movement (which corresponds to tongue movement). To only exploit the information that lies in the muscle movement, an additional encoder-decoder FCNN network (residual attention) is trained alongside to filter out static regions in the input frames. The latent space of the encoder-decoder-model is disentangled into utterance-specific and subject-specific latent features, where the utterance-specific part is learned by enforcing prior knowledge via KL-divergence on utterance-matched sample pairs. All modifications seem to improve the performance of the model.
497	Task-oriented Self-supervised Learning for Anomaly Detection in Electroencephalography	his paper proposed a task-oriented self-supervised learning approach to train a feature extractor based on normal EEG data and key properties of the abnormal EEGs. Two-branch of CNN with larger kernels is designed for effective extraction of both small-scale and large-scale features.  The method is tested on two public and one internal EEG datasets with reasonable good performance.	In this paper, the authors demonstrate the use of converting domain knowledge into SSL transformation rules to augment the data, so that the anomaly detection result is improved. The authors demonstrate the effectiveness through two simple transformations.	A simulated based anomaly detection method for EEG Data.
498	Task-relevant Feature Replenishment for Cross-centre Polyp Segmentation	"A method to segment Colonscopy polyp images is presented. In particular, the paper focuses on the domain shift problem when data belongs to different centres. The paper proposes a domain invariant feature decomposition  (DIFD) module that aims to reduce style variations, then a task-relevant feature replenishment module tries to disentangle informative context from the residual domain specific features of DIFD, and finally, an adversarial learning strategy is applied to bridge the domain gap by aligning features in output space. 
The architecture is an encoder-decoder framework. The DIFD modules are placed after each encoding block. It decomposes the features into domain-invariant portion and side-out domain-specific portion. The domain-specific ones serve as input for TRFR module, which uses them to produce task-relevant features. Both domain-invariant features and task-relevant features are combined to predict four segmentation maps through a decoder network. Finally, features in the"	This paper propose an UDA method that effectively combines multiple techniques, including style transfer, adversarial learning and self-attention, for polyp segmentation. Extensive experiments demonstrate the superiority of the method over prior works.	The authors proposed  a Task-relevant Feature Re-plenishment based Network (TRFR-Net) to tackle existing problems in UDA, for eliminating domain shifts in multi-centre colonoscopy images while retaining sufficient discrimination capability.
499	TBraTS: Trusted Brain Tumor Segmentation	This paper brings a new method to be able to provide uncertainty in addition to the segmentation. They use Dirichlet distribution in a very nice way for this aim. Furthermore, the robustness of the network is improved.	This paper proposed an end-to-end trusted model for brain tumor segmentation by quantifying the voxel-wise uncertainty  and introduced the confidence level for the image segmentation in disease diagnosis. A series experiments were conducted and  the results verity the reliability of the model.	This paper proposes a trusted brain tumor segmentation relied on the evidential deep learning method. The proposed method estimates uncertainty without excessive computational burden and modification of the backbone networks. Experiments show improved performance.
500	Test Time Transform Prediction for Open Set Histopathological Image Recognition	The focus of this paper is to develop a method that can identify clinically relevant patches that are present in the train set (closed set) while ignoring the irrelevant ones, not present in the train set (open set). To this end, a model is trained with two tasks, one to predict the class and the other to predict the colour transform applied to the input image. During inference, the input patch without any transform is processed through the model. The confidence score for predicting the transform is used to distinguish between open and closed sets since it tends to be lower for the open set. The proposed model is evaluated on two colorectal datasets and is shown to perform better as compared to other techniques.	In this study, the authors proposed a new approach for Open Set histopathological image recognition based on training a model to accurately identify image categories and simultaneously predict which decoupled color-appearance data augmentation has been applied.	"The paper presents a methodology to detect Out-of-Distribution data in addition to classifying ""known"" regions of histopathology images"
501	Test-time Adaptation with Calibration of Medical Image Classification Nets for Label Distribution Shift	"This paper proposes a new method, named Test-time Adaptation with Calibration (TTADC), to handle arbitrary unknown test label distribution shifts, which deal with the practical issue of test class proportion being different from that of the training set.
Specifically, TTADC first trains K representative one-dominating-class classifiers during training, followed by adaptive Test-time aggregation of that K classifiers exploiting augmentation consistency.
Experiments on real-world medical diagnosis tasks demonstrate the effectiveness of the proposed TTADC."	"This paper presents the first method to tackle label shift for medical image classification, which effectively adapt the model learned from a single training label distribution to arbitrary unknown test label distribution. Note that the label distribution means the proportion of each class. The contributions can be summarized into aspects:
C1: This paper innovates distribution calibration to learn multiple representative classifiers, which are capable of handling different one-dominating-class distributions.
C2: When given a test image, the diverse classifiers are dynamically aggregated via the consistency-driven test-time adaptation, to deal with the unknown test label distribution.
C3: The authors validate our method on two medical image classification tasks including liver fibrosis staging and COVID-19 severity prediction."	The authors propose a framework to apply test time adaptation to solve label distribution shift in the context of CNN for medical images.  The method is composed by two phases: 1) training different models that are able to handle different labels distributions 2) aggregating these classifiers during test time in order to solve the labels shift problem
502	Test-Time Adaptation with Shape Moments for Image Segmentation	The authors propose a method to adapt a segmentation DNN using just the test data during inference. The adaptation is using a single subject. A UNet based DNN is first trained on the source domain using standard cross entropy loss. During test time, only the network's batchnorm parameters are adapted on the target subject using a combination of shannon entropy and shape descriptor losses (Shannon entropy for high confidence predictions, KL div between class ratios, Soft penalties on centroid and distance-to-centroid descriptors). The method is applied to two different scenarios:MRI to CT adaptation for cardiac segmentation (MMWHS data 20each), and cross-site adaptation for MRI prostate segmentation(NCI-ISBI Challenge T2-weighted MRI 30 each). The metrics used in results are 3D DSC and ASD. The method is compared against TTA, DA and SFDA methods. The proposed methd performs better than other methods for the DSC metric in both the cardiac segmentation and prostate segmentation scenarios.	The authors present a single subject test-time domain adaptation approach for image segmentation. The method is based on the entropy minimization of the target image's softmax prediction, introduced by Wang et al. and further extended by the authors to consider three different shape moments (class-ratios, class-centroids and class-centroid-distances) into the adaptation process. Related work implementations and results with ablations are presented on an MRI-CT multi organ cardiac and a cross-site prostate segmentation dataset. Overall, the authors could show significant performance increases by incorporating the class-ratio and class-centroid moments regarding the Dice score on both datasets and regarding the average surface distance on the MRI-CT task.	This paper proposed a simple formulation for source-free and single-subject test-time adaptation of segmentation networks, and demonstrated its performance in MRI-to-CT adaptation and cross-site adaptation.
503	Test-time image-to-image translation ensembling improves out-of-distribution generalization in histopathology	This paper proposed a new test-time data augmentation based on multi-domain image-to-image translation,  which is achieved based on a StarGanV2.  The proposed network achieves better performances on 3 public datasets compared with other SOTA methods.	The focus of this study is to improve the model generalization. To this end, test time image augmentation is performed based on multi-domain image translation. During test time, the proposed pipeline transforms an input image into a number of invariants with a multiple domain-specific styles. All these invariants are then passed through a classifier to obtain their respective class predictions. The final prediction to the input image is decided based on the ensembling strategy.	The authors propose a test-time augmentation (TTA) strategy based on StarGAN-V2 to specifically improve the domain generalization ability for histology images. This method is intended to overcome the stain variations across different data centers, which is a very common challenge in histology analysis. Three kinds of ensembling methods have been proposed to enhance the TTA.
504	TGANet: Text-guided attention for improved polyp segmentation	The authors focus on polyp segmentation and propose TGANet to use auxiliary classification task to improve the final performance. TGANet predicts the number and size of polyps and embeds them as the weight in channel attention. Experiments show that the proposed method can improve the final performance on multiple datasets.	The main contributions of the work include - 1) text guided attention, 2) feature enhancement module, 3) multi-scale feature aggregation, which improve the polyp segmentation performance. The proposed TGANet surpassed the recent related works on four public benchmark datasets.	The authors propose an auxiliary classification framework to weight the text-based embedding that allows network to learn additional feature representations. Also, they propose some attention modules to futher improve the performance.
505	The (de)biasing effect of GAN-based augmentation methods on skin lesion images	"This paper discusses (de)biasing effect of using GAN-based data augmentation. and 
introduce the dataset with manual annotations of biasing artifacts in six thou-
sands synthetic and real skin lesion images, which can serve as a benchmark for
further studies."	The paper investigates the tendency for conditional and unconditional GANs to exacerbate biases in their training databases, specifically looking at artifacts (e.g. dermatological markings, frames, etc...) and natural features (e.g. hair). The authors have found that for their GANs, strong correlations, spurious or otherwise, tend to be amplified and rare events suppressed. Interestingly, the authors suggest that unconditional GANs (trained separately on the two data classes) are less biased than conditional GANs (one GAN to generate both classes).	In this paper, the authors analyse the impact of data augmentation and bias inheritance on melanoma classification from skin lesion images. They experiment different settings such as manual annotation GAN augmentation, and artifacts such as hair, gel, ruler, frame, ... Results give specific insights on the bias generated with each method.
506	The Dice loss in the context of missing or empty labels: introducing Ph and 	The paper analyses the commonly used Dice loss in the context of missing or empty labels. It provides a formulation for the loss in terms of reduction dimensions 'phi' and smoothing term 'epsilon', and demonstrates how their choice influences segmentation results.	This paper investigates the underlying mechanism of Dice loss by checking its derivative during model training. Compared to some existing works that study the Dice loss, this paper provides more details about the derivative as well as the reasoning about the choice of $\Phi$ and $\epsilon$. Based on some theoretical analysis, this paper proposes heuristic combinations of $\Phi$ and $\epsilon$ that help train the segmentation network under missing or empty labels.	The authors study the Dice loss in the frequent context of missing or empty labels. They provide a useful formulation of the loss and clearly present the different possible subsets used for the reduction dimensions (image, batch, class), i.e. dimensions on which to aggregate the intersections and unions. They show the importance of these dimensions and of the smoothing term when dealing with missing or empty labels and propose well motivated heuristics for setting these parameters. Segmentation experiments on two public datasets (BRATS, ACDC) are performed to illustrate the effect of the heuristics, with quantitative and qualitative results.
507	The Intrinsic Manifolds of Radiological Images and their Role in Deep Learning	This paper analyses intrinsic dataset manifolds empirically, and shows that medical imaging datasets have a lower number of intrinsic dimensions than natural images, but still medical image recognition tasks are not easy. The authors indicate that their analysis highlights the importance of developing tailored medical image recognition approaches, and not just purely relying on the advances in the natural image recognition.	This paper computes the intrinsic dimension of the dataset using the method in [18] for natural images and medical images. The experimental results show that the medical images normally have smaller intrinsic dimension as well as worse test accuracy than natural images. The results empirically show that there is difference between natural images and medical images, and thus indicate more careful thoughts are needed to transfer from natural images to medical images.	
508	The Semi-constrained Network-Based Statistic (scNBS): integrating local and global information for brain network inference	The manuscript presents an extension to the Network Based Statistic (NBS) and constrained NBS (cNBS), by using a data driven policy to refine the large-scale constraints used in cNBS. The method, called semi-constrained NBS (scNBS), is based on four steps: network partition, marginal ranking, cut-off selection, and network-level inference. On semi-synthetic data, the Authors compare scNBS with multiple alternative solutions, like cNBS and NBS, claiming increased specificity, power and consistency.	This paper proposed a connectome-based inference that integrates both local and global information, called semi-constrained network-based statistic (scNBS). In experiments, the proposed method was applied to synthetic and true brain imaging data. The results showed that the proposed method increased statistical power and validity in synthetic data, and showed consistency for repeated measurements in resting state brain imaging data.	In this paper the authors propose a novel method, called Semi-constrained Network-Based Statistic or scNBS, that uses a data-driven selection procedure to pool individual edges bounded by predefined large-scale networks to compare functional connectivity matrices and tries to overcome the main issues raised by conventional edge-wise approaches.
509	Thoracic Lymph Node Segmentation in CT imaging via Lymph Node Station Stratification and Size Encoding	This paper proposes a new approach based on LN-station-specific and size-aware LN segmentation framework.  As a result, high performance LN segmentation could be achieved with good generalizability.	"This paper describes a novel way to segment thoracic lymph nodes (LN).  By first combining LN-station to form 3 ""super-stations"", then differentiating between large and small LNs, and finally going through a post-fusion module to generate the final prediction.  This is an interesting framework made to guide the learning, and it succeeded in improving the performance comparing to other methods."	To overcome the difficulties of segmenting visible lymph node (LN) from CT images, a novel LN-station-specific and size-aware LN segmentation framework is proposed, which can explicit utilize the LN-station priors and learn the LN size variance. Two-stage learning process is proposed, thoracic LN-stations are segment and then grouped into 3 super lymph node stations firstly. A multi-encoder deep network is designed to learn LN-station-specific LN features; secondly, to learn LN's size variance, two decoding branches are proposed to concentrate on learning the small and large LNs, respectively. Validated on the public NIH dataset and further tested on the external esophageal dataset, the proposed framework demonstrates high LN segmentation performance while preserving good generalizability.
510	TINC: Temporally Informed Non-Contrastive Learning for Disease Progression Modeling in Retinal OCT Volumes	The authors presents a modification of the recent VICReg self-supervised method for longitudinal imaging data. The modification is (1) using pairs of images that are randomly sampled from different time point of a patient, and (2) changing the first loss, which corresponds to the invariance of related presentations, to depend on the time between the two images, such that for smaller time difference will lead to stronger enforcement of similarity between the two representations.	This is an interesting paper. The authors propose a  modified loss function which they call TINC (Temporally Informed Non-Contrastive Loss) to be used with VICReg to predict whether an eye is going to convert to wet-AMD within 6 months time-frame.	This paper introduces a new loss function (TINC) to exploit existing temporal information in longitudinal context of OCT data. The proposed model outperforms the compared methods in terms of AUROC and PRAUC.
511	TMSS: An End-to-End Transformer-based Multimodal Network for Segmentation and Survival Prediction	The paper proposes a transformer network for head & neck tumor segmentation and outcome prediction challenge using PET-CT and EHR data.	An End-to-End Transformer-based Multimodal Network for Segmentation and Survival Prediction of Head and Neck Cancer. The problem is of clinical importance.	The paper proposes the use of a multimodal transformer network to combine the tasks segmentation and survival prediction in order to achieve an improved performance for the survival prediction and a competitive performance on the segmentation task. The model is evaluated on the HECKTOR dataset and achieves superior performance in comparison to state of the art algorithms.
512	Toward Clinically Assisted Colorectal Polyp Recognition via Structured Cross-modal Representation Consistency	The manuscript represents an approach for authomatic colorectal polyp classification via structured cross-modal representation consistency on WL and NBI images.	The manuscript presents an algorithm based on Structured Cross-modal Representation Consistency for polyp detection in colonoscopy images.	This manuscript proposed a novel method to directly achieve accurate white-light colonoscopy image classification by conducting structured cross-modal representation consistency.
513	Towards Confident Detection of Prostate Cancer using High Resolution Micro-ultrasound	This study proposes a learning model for PCa detection using micro-ultrasound that can provide an estimate of its predictive confidence and is robust to weak labels and OOD data. The proposed model uses a co-teaching paradigm to handle noise in labels, together with an evidential deep learning method for uncertainty estimation.	The authors presented the development of a deep learning model with a focus on micro-ultrasound-guided prostate cancer biopsy. This framework was tested leveraging a dataset of micro-ultrasound from 194 patients. The results from approaches assessed (evidential deep learning (EDL) and EDL + co-teaching) show promise in aiding the detection of prostate cancer.	The authors present a framework for training a classification model to detect prostate cancer from micro-ultrasound images which accounts for limitations in the quality of ground truth-specifically weak and out of distribution labels. Furthermore, the inference component of the framework provides uncertainty estimates for predictions with adjustable levels of confidence.
514	Towards Holistic Surgical Scene Understanding	"The authors present a novel dataset and method for benchmarking in the domain of surgical data science. The dataset, called ""Phase, Step, Instrument, and Atomic Visual Action (PSI-AVA)"", contains eight instances of radical prostatectomy surgeries (performed with the Da Vinci SI3000 Surgical System). The annotations in the dataset go beyond currently available datasets, comprising hierarchical annotations from atomic actions and surgical tool bounding boxes, to surgical phase detection. The proposed method (TAPIR) creates a strong baseline performance on this method and is shown to be able to make use of hierarchical annotations on PSI-AVA data."	"The paper introduces a new data-set (PSI-AVA) with annotations for phase and step recognition,instrument detection, and the novel task of atomic action recognition in surgical. The dataset is novel and unique and can serve as a new benchmark for multiple tasks in surgical video understanding.
The paper also proposes TAPIR, a transformer-based method that leverages the
multi-level annotations of PSI-AVA dataset. The authors show superior performance of their method compared to other baselines."	This paper introduces and validates the PSI-AVA dataset with annotations for phase and step recognition, instrument detection, and the novel task of atomic action recognition in surgical scenes. Besides, this paper proposes TAPIR, a transformer-based method that leverages the multi-level annotations of PSI-AVA dataset and establish a stepping stone for future work in our holistic benchmark.
515	Towards performant and reliable undersampled MR reconstruction via diffusion model sampling	In this paper, the authors proposed a novel diffusion model-based MR reconstruction method (DiffuseRecon), which is robust to the sampling pattern and acceleration factors. The proposed DiffuseRecon achieves SoTA performances in two large public datasets: fastMRI and SKM-TEA.	"This paper proposes a novel MR reconstruction framework based on the diffusion model.
Experiments show that the model can outperform other baselines consistently."	"The paper talks about how to achieve a robust and reliable model to reconstruct MRI images from undersampled acquisitions. The DiffuseRecon model consists of two components is proposed: 1) a k-space guidance module incorporates observation into the denoising process and allows for stochastic sampling from the marginal distribution of E[q(y_full
x_obs)]; 2) a coarse-to-fine sampling module accelerates the selection of reconstructed images and gives an approximation of the noise on reconstructed samples. The goal is to generate all candidate reconstruction samples of MR images and accelerate the reconstruction process."
516	Towards Unsupervised Ultrasound Video Clinical Quality Assessment with Multi-Modality Data	The authors developed a 3D encoder and decoder pair bi-directional model that identifies ultrasound images of the fetal head that are suitable for making measurement. The model does this by learning a spatio-temporal representation between the video space and the feature space.	In this paper, the authors describe an objective task-based approach to the quality assessment of clinical ultrasound video, which relies on learning a latent spatio-temporal representation from two modalities (ultrasound video and optical flow). A third modality is also included, i.e. gaze, which helps the model focus on regions of interest in high-quality videos. The proposed model aims at automatically assessing the diagnostic quality of fetal ultrasound exams. Videos containing the transventricular plane (TVP) were considered as the high-quality references for data-driven/unsupervised learning. The method uses the feature reconstruction error to discriminate between low and high-quality videos.	The authors presents an unsupervised approach for the quality assessment of ultrasound fetal head images.
517	Tracking by weakly-supervised learning and graph optimization for whole-embryo C. elegans lineages	In this paper, the authors propose an incremental extension of Linajea [14], a state-of-the-art tracker of cells in embryonic image data, to improve its tracking performance by employing a ResNet18-based cell state classifier [21] and to facilitate its hyper-parameter fine-tuning via structured SVM [8]. The proposed method has been quantitatively evaluated using three different sets of C.elegans embryo recordings and achieved insignificant improvements in the DET and TRA scores (third and fourth decimal digits as reported in Tables 1 and 2) when compared to Linajea.	This manuscripts presents a method for improved lineage tracing from whole-embryo C. elegans data. The authors build two additional modules: a cell-state detector and a weight estimator, on top of the earlier-developed algorithm. This results in improved performance, in particular to detection of cell divisions. The proposed method is leading the scoreboard of the dedicated challenge in this particular data category.	The authors present an extension to the previously published tool linajea to perform lineage reconstruction in whole embryo recordings of C. elegans. The extensions include cell state/polar body classification that are incorporated to the learning-based approach. Moreover, an automatic hyperparameter identification module using a structured SVM approach is used. The extensions are validated on three different data sets and show (slightly) superior results to previous methods.
518	TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis Framework Using Spectral Embedding and Vision Transformers	The key contribution is to construct a representation of whole-brain tractograms with consistent structure enabling applications of machine learning algorithms that take tractograms as input.	The paper approaches the problem of parcellation-free WBT analysis by the proposed TractoFormer. The proposed method first map the tractography information at the level of individual fiber streamlines to 2D representation then leverages ViT to performance classification.	This paper proposed a TractoEmbedding method to encode 3D fiber spatial relationships by 2D image. This representation method can represent fibers of different regions by different channels and by performing random downsampling, multiple TractoEmbedding images can be generated. Based on the generated 2D TractoEmbedding image,  a ViT-based TractoFormer was proposed to conduct HC/SCZ classification.
519	TransEM: Residual Swin-Transformer based regularized PET image reconstruction	The main contribution of this work is the introduction of swin transformer into PET reconstruction. The image reconstruction is done in the ML-EM iterative style, following exactly the framework in [11],  with the key update equation 9 being the same as the equation 6 in [11]. The reconstruction regularisation operates in the image domain, and is done by applying the swin transformer, a newly (relatively) developed model in the NLP-> computer vision field, which can efficiently capture long-range dependencies in an image. This is expected to improve the PET image reconstruction results in the proposed work.	The work proposes a novel TransEM method (an image reconstruction method based on MLEM and residual swin-transformer) for PET image reconstruction. Compared to the traditional convolutional neural networks-based methods, TransEM owns the strong ability in modeling long-range dependencies of the measurement data. It is able to reduce noise without compromising on image details. This is validated with simulated human brain data, and the robustness analysis is also well performed.	The paper describes an already presented approach combining an EM update and a neural network to solve the PET reconstruction inverse problem. The authors change the CNN network to a swin-transformer, which is the main contribution of the paper. The presented method is the best over other studied methods (some classical PET reconstruction algorithms and Deep learning based methods).
520	Transformer based feature fusion for left ventricle segmentation in 4D flow MRI	The paper describes a novel approach for segmenting the left ventricle from MRI 4D flow images. Using deep learning based on a combination of U-Net architecture with Transformer components and feature fusion layers, the algorithm tackles the challenges of poor anatomical appearance in 4D flow images.	This paper proposes a Transformer based segmentation model for 4D flow MRI. 4D flow MRI is a recent blood flow velocity diagnostic on which automatic assessment has not been fully investigated. The authors design two self- and cross-attention-based methods to fuse the information from different modalities in 4D flow, and perform evaluations on a large in-house dataset.	The authors propose a novel method to take the velocity and magnitude image into a unified segmentation framework to achieve the automatic segmentation of the LV directly from 4D Flow. The experiment demonstrates that their method outperforms the best previously published results for this task.
521	Transformer based multiple instance learning for weakly supervised histopathology image segmentation	This paper proposes a transformer-based multiple instance learning (MIL) for weakly supervised histopathology image segmentation. The motivation behind this paper is modeling dependencies of MIL instances via multi-head self-attention in the transformer. In addition, the authors propose deep supervision to overcome the limitation of annotations in weakly supervised scenarios and make the better utilization of hierarchical information from the Swin transformer. The experimental results demonstrate the method's superiority compared with other weakly supervised methods for the segmentation task.	This paper proposed a Transformer based method for semantic segmentation in histopathology image. Swin Transformer is introduced to this specific task to consider related information between instances in MIL. The method was evaluated on public colon cancer dataset in comparison with a number of MIL methods and reached SOTA results. Besides, the Ablation study explored the effect of backbones, stages, and deep supervision. The idea seems to be promising and valuable for research in this field, however, the paper needs to be further improved.	In this paper, a transformer-based MIL framework is proposed to overcome the limitation of segmentation performance caused by the lack of correlation between instances. In addition, deep supervision is introduced to strengthen the constraints. The experimental results show that the weakly supervised segmentation method proposed in this paper is effective.
522	Transformer Based Multi-task Deep Learning with Intravoxel Incoherent Motion Model Fitting for Microvascular Invasion Prediction of Hepatocellular Carcinoma	This paper focuses on prediction of MVI of HCC. The authors used a transformer approach in the network to obtain deep features of the images and, furthermore, they proposed a cross-attention block to improve the performance.	"In this work, the author proposed a multi-task learning method based on transformer to perform (1) MVI prediction and (2) IVIM parameter fitting at the same time, leveraging the fact that those 2 tasks are related to each other.
The method is compared to 2 other multi-task learning methods and single task methods for each of the 2 tasks."	This paper aimed to perform simultaneously IVIM parameter model fitting and MVI prediction using a multi-task learning method based on transformer. The originality of the work is to combine the advantages of convolution network and transformer to jointly achieve IVIM model parameter fitting and MVI prediction, which allowed the authors to obtain better results than those obtained when performing one single task (fitting or prediction).
523	Transformer Based Multi-View Network for Mammographic Image Classification	"This paper designed a multi-view network based entirely on transformer architecture. The used ""cross view attention block"" can work better in a pure transformer style.
This paper introduced a learnable ""classification token"" into the network. This token can gather all useful information to make better prediction.
This paper designed ""(Shifted) Window based Cross View Attention Block"". This structure can fuse cross view information anywhere in the network with low computational cost."	"This paper introduces several cross-view attention mechanisms to learn representations for multi-view images (i.e., mammographic images). 
This paper introduces:
(1) a ""cross-view attention"" to aggregate information over multiple views.
(2) a learnable ""classification token"" to make better predictions.
(3) a ""shifted window-based cross-view attention block"" for saving computational cost."	This paper proposes to use transformer architecture for multi-view mammographic classification, to more effectively use the cross view attention mechanism. A classification token is introduced, and experiments show that the proposed approach outperforms feature concatenation based approaches and CNN based cross view attention approaches, on malignancy classification task.
524	Transformer Lesion Tracker	A transformer based lesion tracker is proposed. In feature selection stage, a sparse selection strategy is chosen for cost reduction. Then a registration augmented cross attention transformer is used to predict the location, followed by a global regression module.	The authors present a novel approach using Transformers to propagate the center of a lesion from the baseline to the follow-up scan.	
525	Transforming the Interactive Segmentation for Medical Imaging	This paper describes a method to incorporate user interaction into the segmentation process. The method is validated using datasets containing lungs, colons, and pancreas. An ablation study is also provided.	Authors propose a framework based on transformers networks and user clicks to segment any structures and tries it on challenging ones, such as those from organ cancer. It refines automatic segmentations through the addition of click annotations, and it is denominated as Transformer-based architecture for Interactive Segmentation (TIS). They demonstrate their results on three different datasets	"This paper proposes TIS (transformers interactive segmentation), a new network architecture to allow for the refinement of segmentation inferences from a (multi-class) segmentation network (\Phi_ENC
\Theta_e) using clicks (i.e. xy positions and labels) encoded through a click encoding network (\Phi_REF
\Theta_r). In these experiments the segmenter is a U-Net but can in principle be any type of encoder decoder. The click encoder (the main contribution) is transformers based and takes as inputs both the click coordinates and the (vectorized) encoder output. This step is followed by  a ""label assignment"" mechanism whose purpose is to learn to balance the contribution of the clicks wrt similarity to ground truth labels."
526	TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation with Transformers	The paper has presented a transformer architecture to combine cross-view information in medical images that can help in segmentation. The TransFusion approach proposed by the authors is able to capture long range dependencies between different scales and views.	In this work, the authors have proposed TranFusion algorithm for the segmentation of Right Ventricles from cardiac-MRI. The proposed algorithm use to merge the divergent information from multiple views and scale. using attention mechanism.	This manuscript proposes TransFu-sion, a Transformer-based architecture to merge divergent multi-view imaging information using convolutional layers and powerful attention mechanisms for automated medical image segmentation.
527	TranSQ: Transformer-based Semantic Query for Medical Report Generation	"The authors propose a Transformer-based Semantic Query (TranSQ) model to generate medical reports. The approach considers report generation as a sentence set prediction and selection problem. So, it learns visual embeddings and semantic queries for the sentence candidate set. It is apparently the first work to consider medical report generation as a candidate set prediction and selection problem.
The authors conducted experiments to show that TranSQ achieves good performance against existing methods based on NLP metrics and clinical efficiency metrics.
They also provide a sentence-level interpretation of the report to illustrate the approach's explainability."	Proposes a system to generate reports from images by proceeding sentence by sentence.  A set of visual semantic queries are created.  Each query is then used to probe one specific aspect of the image, and the report is constructed from the collection of results	"This work proposes to treat the medical report generation task as a sentence candidate set prediction and selection problem, which is novel and interesting.
To solve this task, this work proposes a novel Transformer-based Semantic Query (TranSQ) model, which incorporates the well-known and powerful Vision Transformer (ViT) to significantly boost the performance.
The visualization shows that the proposed approach can achieve better interpretability than previous works."
528	Trichomonas Vaginalis Segmentation in Microscope Images	In this paper, the authors proposed a TVNet for Trichomonas Vaginalis segmentation in microscopy images. The proposed method is constructed by a high-resolution fusion (HRF) module and foreground-background attention (FBA) module. Extensive experiments on a private TVM13K dataset have shown the effectiveness of the proposed method by outperforming several image segmentation methods.	The authors present a new large-scale annotated dataset for the segmentation of Trichomonas vaginalis on microscopy images named TVMI3K, together with a novel deep neural network called TVNet used as baseline. TVNet is a Res2Net-like architecture with five levels of features, high-resolution fusion modules, a neighbor connection decoder and foreground-background attention modules. The proposed baseline performs favorably with respect to nine state-of-the-art image segmentation models.	The contribution of this paper is two-fold. First, a large dataset is created with annotations at different levels. Second, a new method is proposed for TVS.
529	UASSR:Unsupervised Arbitrary Scale Super-resolution Reconstruction of Single Anisotropic 3D images via Disentangled Representation Learning?	"The paper presents a method to increase the resolution of a 3D medical image (an anisotropic set of slices). The method relies on a generative adversarial network that learns how to augment resolution without requiring a huge number of samples as other machine learning approaches.
The method is compared with several other methods of the literature using well known metrics.
Quantitative results show that the presented method achieves higher scores on most of the comparisons. Qualitative results show visually pleasant results that are similar to the ground truth."	This paper addresses the problem of recovering high-resolution images from low-resolution images. Compared with other methods requiring the paired high and low-resolution images as input, this paper introduces an unsupervised arbitrary scale super-resolution reconstruction (UASSR) method to solve this problem and achieve good performance without pairing images between two resolutions.	This paper presented an unsupervised super-resolution methods via disentangled representation learning. The proposed method split images into content space and resolution specific space. The evaluation on MRI and CT images demonstrates the effectiveness of the proposed method.
530	ULTRA: Uncertainty-aware Label Distribution Learning for Breast Tumor Cellularity Assessment	This paper proposes a method of predicting Tumar Cellularity in breast cancer in a way to leverage label uncertainty in the deep learning process. The network optimizes the distance between a predicted distribution with target distribution (from GT labels)., as well as the MSE between a predicted mean with target TC mean.	"Authors propose an uncertainty-aware label distribution learning (ULTRA) framework for tumor cellularity (TC) estimation. In details, apart from directly regressing the TC score with MSE-Loss, authors model the uncertainty of TC score using normal distribution and train a multi-branch DNN to minimize the KL-divergence between the output and the normal distribution.
Authors validate the proposed method on the public TC estimation dataset BreastPathQ and achieve the SOTA."	The goal of the paper is to present a novel method for estimating tumor cellularity (TC) in breast cancer on histopathology images. TC assessment by experts suffers from variability and quantifying uncertainty is key for building better evaluation tools. For this matter, in this work, the regression problem on TC value is translated to TC distributions learning, multi-rater process is reproduced by a multi-branch fusion module (each branch is feed with an augmented version of input data). TC score is still included as an additional loss term. The public BreastPathQ dataset was used for evaluation the approaches and results are improved compared to SOTA.
531	Uncertainty Aware Sampling Framework of Weak-Label Learning for Histology Image Classification	The authors present a novel methodology for addressing one of the main challenges when analyzing WSIs in computer-aided diagnosis systems, which is focusing on the right patches to classify.	This paper tackles the weakly supervised histology image classification. Authors proposed a two-stage training framework to train a tile-level classifier with whole slide image labels. The main idea is to use an uncertainty-aware CNN (UACNN) trained with noisy labels to sample the most diagnostically relevant tiles for each WSI, and then to train another CNN based on the sampled tiles for better tile classification performance. The motivation is clear, and the technique is sound.	This paper presents an uncertainty-guided sampling approach for efficient training of  tissue classification in whole-slide imaging. The proposed method uses weak-labeling for tiles with low uncertainty to improve classification accuracy.
532	Uncertainty-aware Cascade Network for Ultrasound Image Segmentation with Ambiguous Boundary	"The uncertainty of each pixel from ultrasound images is leveraged to improve segmentation performance.
A new uncertainty-aware network with AFM, UAM, and RECM is proposed.
The experiment results are shown to be competitive compared to SOTA on three public US datasets."	For the task of ultrasound image segmentation, this paper proposed  an uncertainty-aware cascade framework. The confidence map-guided uncertainty map is adopt for feature fusion, feature attention and edge correction.	This paper proposes  an uncertainty-aware framework with multiple uncertainty-aware modules to improve the segmentation accuracy on ultrasound images.
533	Uncertainty-Guided Lung Nodule Segmentation with Feature-Aware Attention	The paper proposes to adapt a FCN architecture to the segmentation of lung nodules while taking into account uncertainty. The uncertainty stems from the fact that different radiologist contour the same region differently, due to the subjectivity of the manual segmentation process. The authors argue that these differences are not random, and model them in their proposed UGS-Net. This is an enhanced UNet augmented with a Uncertainty Aware Module and a Feature-Aware attention model. The content of the paper is technically sound and the results appear superior to other comparing methods.	This paper proposed a method for lung nodule segmentation on the LIDC-IDRI dataset.	In this manuscript, the author proposes an uncertainty-guided segmentation network to fully utilized all the annotations. A multi-confidence mask is proposed to obtain the uncertainty levels by including the intersection and union among all annotations. Then, the uncertainty-aware module and feature-aware attention module are applied to learn the uncertainty from the ambiguous regions, especially on the boundaries. The experiments on the LIDC dataset show state-of-the-art results, and the ablation study demonstrates each component's effectiveness.
534	Undersampled MRI Reconstruction with Side Information-Guided Normalisation	This paper investigates the use of MRI acquisition protocols, views, scanning parameters/manufacturers as embedding to improve image reconstruction quality in both knee and brain datasets.	This paper uses side information, which is normally accessible but overlooked, as the normalisation parameter to improve undersampled MRI reconstruction. The proposed SIGN encodes MRI acquisition information, attributes/imaging regions into a vector, which are mapped to a parameter space in the normalisation layers. The simple and effective design of SIGN improved performance considerably on two backbones: D5C5 and OUCR.	The authors propose a Side Information-Guided Normalisation (SIGN) module to encode the different acquisition parameters in a heterogenous dataset to generate the normalization parameters for the feature maps in the CNN reconstruction network. The SIGN module is tested in two popular CNN reconstruction networks and is demonstrated to be effective in improving the reconstruction performance.
535	UNeXt: MLP-based Rapid Medical Image Segmentation Network	This work proposes a UNet-like architecture that is very efficient in computational complexity (and inference time), without sacrificing performance on segmentation tasks. This is achieved by (1) reducing the number of convolution filters used, (2) presumbably by using a summing long skip connection (encoder to decoder) instead of concatenation, and (3) replacing the convolutions at the lowest two resolutions with depth-wise convolutions where mixing across channels is achieved by MLP. Horizontal and vertial shifting of the feature maps is also proposed in thse depth conv + MLP blocks.	The authors propose a method of modifying U-Net with state of the art MLP-Mixer and Token Mixup inspired techniques. The techniques allow the authors method to achieve state of the art results on 4 datasets while using only a small fraction of the parameters and runtime.	The authors propose to adopt MLP-based network and combine it with popular ConvNet to achieve faster medical image segmentation tasks with less computation burdens on mobile devices.
536	Uni4Eye: Unified 2D and 3D Self-supervised Pre-training via Masked Image Modeling Transformer for Ophthalmic Image Classification	This paper proposes a self-supervised architecture allowing to extract latent representations for both 2D and 3D heterogeneous ophthalmic imaging data. These latent features can then be fine-tuned on different classification tasks. A first step allows extracting a fixed number of patchs (2D or 3D) from the input images based on random masking of the images. These patchs are then fed to a pretrained visual transformer block. Two decoder blocks acting on all patches (non masked ones with visual attention, and masked ones) allows reconstructing the original images as well as the gradient images. Performance of this self-supervised latent space learning is evaluated on six classification tasks based on a dataset concatenating more than 95 000 samples aggregated from different public datasets.	Authors propose Uni4Eye, a self-supervised pre-training approach using Masked Image Modeling (MIM) and vision transformers to learn universal and relevant features of various 2D and 3D ophthalmic imaging modalities. The approach resides in proposing a Unified Patch Embedding module to handle both 2D and 3D data with MIM and multitask learning with the reconstruction of both the input images and its gradient map. Authors introduce and use mmOphth-v1, a large dataset of 2D and 3D ophthalmic image with numerous modalities, which will be made available publicly. The relevance of the proposed pertaining is showed on multiple downstream classification tasks (4 in 2D, 2 in 3D) in comparison to state of the art methods, as well as ablation studies.	The paper proposed a self-supervised method named Uni4Eye that was based on masked autoencoder with a Unified Patch Embedding (UPE) module to enable the model takes both 2D and 3D images as input, and two-branches decoder to enhance sharp edges in the reconstruction. The authors also collected the largest ophthalmic image dataset, and evaluated six downstream tasks to show the superiority of the method.
537	Unified Embeddings of Structural and Functional Connectome via a Function-Constrained Structural Graph Variational Auto-Encoder	This paper proposes a novel method, the Functionally Constrained Structural Graph Variational Autoencoder (FCS-GVAE), capable of combining information from the functional and structural connectomes in unsupervised learning. The method is evaluated on OASIS-3 Alzheimer's disease (AD) dataset. The results show that this method has a better performance than the baseline model.	The author proposed a function-constrained structural graph variational autoencoder model to learn the joint embedding of both structural and functional information. To further evaluate the proposed model, they used the joint embeddings to classify different populations.	This work proposes a function-constrained structural graph variational autoencoder (FCS-GVAE) capable of incorporating information from both functional and structural connectomes in an unsupervised fashion.
538	Unsupervised Contrastive Learning of Image Representations from Ultrasound Videos with Hard Negative Mining	This paper presents a contrastive learning based method for USG videos, mining both intra-video and cross-video negatives in a hardness-sensitive negative mining curriculum. The effectiveness of proposed strategy is evaluated on two downstream tasks: GB malignancy classification and COVID detection. And the paper construct a large-scale USG video dataset.	The paper includes two main contributions. One is a USG video dataset of 64 videos and 15800 frames; based on the dataset, an unsupervised representation learning method is proposed, with a simple but insightful hard example mining mechanism.	The authors propose representation learning from Ultrasound Videos with contrastive learning. They propose a hardness-sensitive negative mining curriculum from both intra-video and cross-video negatives. The authors also contribute USG image datasets related to GB malignancy.
539	Unsupervised Cross-Disease Domain Adaptation by Lesion Scale Matching	"(1)	Demonstrate the feasibility of cross-disease knowledge transfer, i.e., to transfer knowledge from thyroid lesions to breast lesions in an unsupervised cross-disease domain adaptation manner.
(2)	To address the lesion scale gap problem by proposing a lesion scale matching approach, i.e., search for bounding box size in latent space for rescaling, together with the Monte Carlo Expectation Maximization algorithm. 
(3)	Demonstrate the method with improved performance on one private thyroid US  dataset and one public breast US dataset."	This paper proposes an unsupervised approach to transfer knowledge across diseases i.e. from thyroid nodule to breast nodule classification in ultrasound imaging. It does not require labelled data in the target domain. To address the lesion scale gap across the two domains, they propose a lesion scale matching solution, which entails a framework of latent space search for bounding box size and a MC expectation maximization algorithm.	This paper propose a lesion scale matching approach to rescale the source domain image  and Monte Carlo Expectation Maximization algorithm is employed to match the lesion scale.  It shows noticeable improvement in average in 3 sets of ablation studies.
540	Unsupervised Cross-Domain Feature Extraction for Single Blood Cell Image Classification	The authors have proposed an approach of features extraction for white blood cell microscopy images such that the features may generalize well across samples collected from different sites. The paper defines the problem as a cross-domain learning task.	The paper presents a cross-domain methodology to extract features in an unsupervised manner from individual white blood cell image datasets.	This work proposed a representation learning method that can learn robust features which can work well on the unseen domains. The authors achieve this by manipulating the cell feature representation from the Mask R-CNN, using self-supervised learning and a domain adaptation approach.
541	Unsupervised Deep Non-Rigid Alignment by Low-Rank Loss and Multi-Input Attention	This paper presents a non-rigid registration network with a low-rank loss for noisy image registration. The experiments were conducted on synthetic and real images.	The paper propose three subnetworks for learning-based non-rigid alignments of photoacoustic hand imaging, that is, noise decomposition network with noise loss, non-rigid deformation network with low-rank loss, and sparse error complement network with multi-input attention module. Then the authors evaluate their method on both synthetic data and photoacoustic data, and compare with several other SOTA methods.	"They proposed a neural network for robust non-rigid image alignment.
This method is especially powerful when the noise and corruptions exist in the images.
It is based on the idea of low-rank and sparse decomposition, assuming that well-aligned images with corruptions and noise are removed should have a low rank, which is forced with a low-rank loss 
It achieves highest score among several rigid/non-rigid alignment algorithms."
542	Unsupervised Deformable Image Registration with Absent Correspondences in Pre-operative and Post-Recurrence Brain Tumor MRI Scans	The authors propose a deep learning-based deformable registration method for the pre-operative and post-recurrence brain MR registration. They use forward-backward consistency and inverse consistency to identify regions with absent correspondences and exclude them in the similarity measure. The proposed method is validated using the BraTS-Reg dataset.	The authors of the paper propose a novel method for deep learning based image registration of pre-operative and post-recurrence brain tumor MRI scans. The method automatically identifies regions where no correspondences can be established (e.g. due to tumor resection) and incorporates the resulting segmentations directly into the algorithm for masking the similarity measure and other parts of the loss function. Additionally, the method includes a constraint enforcing inverse consistency and is compared to several other algorithms showing superior registration results especially in near tumor regions.	This paper estimated the bidirectional deformation fields and located regions with absent correspondence, such as the tumor mask.
543	Unsupervised Domain Adaptation with Contrastive Learning for OCT Segmentation	"This paper presents a contrastive learning-based method to deal with unsupervised domain adaptation problem on the OCT segmentation task.
The key technology is the positive pair selection strategy. The authors not only utilize the augmentation samples but also the rounded slices in the 3D volumn.
The results on their own collected dataset show its effectiveness on various ablation studies."	The authors propose semi-supervised contrastive learning approach for domain adaptation, including augmentation strategy for pair generation, and projection head for embedding generation from convolutional features. The model validated on Spectralis and Cirrus datasets emerged from clinical trials.	The authors propose an unsupervised domain adaptation method for the segmentation of 3D OCT images. They train a U-Net segmentation model with full supervision on the source domain, and explore the effect of an adapted contrastive loss function, a new augmentation strategy, and a new projection head channel-wise aggregation. They state that they outperform  other contrastive frameworks on the target domain, and achieve similar (or sometimes better) results as the supervised method on the source domain.
544	Unsupervised Domain Adaptive Fundus Image Segmentation with Category-level Regularization	"This work proposed a category-level regularization approach for both intra and inter-domain categorization in unsupervised domain adaptation for segmentation.
A prototype-guided discriminative loss was proposed to learn discriminative feature representations.
The proposed method yielded a decent performance which is comparable to a supervised method that is deemed upper-bound, especially for Drishti-GS."	This paper focused on the UDA for Fundus Image Segmentation. The model majorly consists of three sections: inter-domain category regularization, source domain category regularization, and target domain category regularization. Experimental results showed that the proposed model outperforms several baseline methods.	This paper proposes an unsupervised domain adaptation framework based on category-level regularization to accurately segment the optic disc and cup from fundus images.
545	Unsupervised Lesion-Aware Transfer Learning for Diabetic Retinopathy Grading in Ultra-Wide-Field Fundus Photography	The paper presents an unsupervised method for DR grading in ultra-widefield retinal images by utilizing additional narrow-field fundus photography. The paper consider an auxiliary task of lesion detection in narrow-field images because the DR grading is closely related to lesion	Ultra-Wide-Field Fundus Photography is an emerging novel imaging technique that can provide a broader field of view . This is useful for diabetic retinopathy disease screening and grading. However, due to the unavailability of a large public UWF dataset, it is hard to train an automated system with a UWF dataset. Here the author proposes a transfer learning-based method where originally, the well-labeled publicly available color fundus photography images were used to train the system. Subsequently, an unsupervised transfer learning based strategy was taken to assist the DR grading of  UWF images with the help of well-labeled color fundus photography image dataset.	This paper proposes an unsupervised framework (ULTRA) for the classification of diabetic retinopathy (DR) in ultra-widefield (UWF) images, by transfer learning from labeled (and more common) colour fundus photograph (CFP) images (including pixel annotations for CFP images). The CFP data is used to train an adversarial lesion generation model (segmentation model) for the UWF images, the feature maps of which are then combined by a lesion external attention module. Classification performance of ULTRA is claimed to be superior to supervised training with CFP labels, and a few other methods.
546	Unsupervised Nuclei Segmentation using Spatial Organization Priors	The authors propose a novel unsupervised nuclei segmentation method for IHC images. It utilizes the consistency of nuclei distribution between HE and IHC images and imposes the spatial organization prior via generative adversarial learning. Experiments on three datasets demonstrate its effectiveness	This paper propose an unsupervised segmentation method for nuclei segmentation. The proposed approach train a Unet based segmentor in an adversarial training setting. The segmentor is trained to generate nuclei segmentation masks. The predicted masks and the real masks from some other nuclei dataset are used to train the discriminator. To avoid false negative segmentation, a reconstruction network is trained to reconstruct the input image based on the predicted segmentation mask. The proposed method is verified on three public datasets. The results seems promising. This paper conveys novel contribution and is well written. The reviewer has a little concern that how practical such system can be. Segmentation networks are usually used to extract the shape information of the nuclei. This requires the segmentation network to be accurate enough to capture the variance in the nuclei shapes. It is unclear if this segmentation method can achieve that level of accuracy.	"This paper presents a novel unsupervised method for nuclei segmentation incorporating priors from public H&E datasets for use in IHC-stained images.
The method exploits available information at the segmentation level by encoding and identifying the histological tissue characteristics that are independent of the staining."
547	Unsupervised Representation Learning of Cingulate Cortical Folding Patterns	Technically, the major contribution of this work is the introduction of topology-based augmentations in the SimCLR setting and adding a decoder to SimCLR and analyzing SimCLR and b-VAE reconstructions to recover folding patterns.	The author used unsupervised learning to learn latent representation and apply them in discovering folding patterns.	The paper develops an unsupervised learning framework based on b-VAE and SimCLR models, and affinity propagation clustering algorithm, to explore the folding patterns of cingulate cortex. The method is performed on HCP database with 550 subjects. The experiment results are interesting. Overall, the proposed method is reasonable, but the descriptions are not very clear.
548	Usable Region Estimate for Assessing Practical Usability of Medical Image Segmentation Models	The authors note that there is often a discordance between accuracy and usability in machine learning models. They propose two metrics to address this issue. First, Correctness-Confidence Rank Correlation measures the association between prediction correctness and confidence. Second, Usable Region Estimation measures the proportion of the population for which the model is clinically usable.	The paper propose a concrete and unified measure, called Usable Region Estimate (URE), to quantify both the correctness and reliability of the model, which is more clinically-usable and helpful for comparing and selecting models.	"The paper proposes two new indeces : CCRC that measures the correlation between correctness scores and confidence estimates and URE that
quantifies prediction correctness and reliability of confidence estimates. The authors tested the two indeces on 6 different clinical applications"
549	USG-Net: Deep Learning-based Ultrasound Scanning-Guide for an Orthopedic Sonographer	"This work proposes USG-Net, a method for identifying RCT in US images. A generator portion of the method generates a 3D portion prior to the classification module which helps guide the direction of the probe motion.
In contrast to previous work, the proposed method does not rely on inertial measurement unit signals. While the authors don't specifically say this (which I think they should - if I'm correct) this could mean a simpler setup, or in other words use of existing clinical pipelines without additional equipment (i.e. added cost/complexity)"	"A deep learning-based scanning-guide algorithm is proposed to guide to the exact target diseased region without external motion-tracking sensors.
A new scanningguide task that aims to search target disease regions using a corresponding network.
They develop an automatic dataset construction method to train the deep learning-based scanningguide network."	In this paper, the authors extract feasible 2D US images from clinical 3D US volumes and use these to create a deep-learning approach for simultaneously detecting rotator cuff tears (RCT) in 2D US images and providing feedback to sonographers on US probe movements if RCT is not detected in the plane.
550	Using Guided Self-Attention with Local Information for Polyp Segmentation	This paper proposes PPFormer for accurate polyp segmentation. It combines transformer and CNN to improve polyp segmentation accuracy.	The paper propose a novel transformer block, called L2G PPFormer block, to better model boundary information in Polyp segmentation. Experiments demonstrate that the proposed method advance the SOTA results.	"The authors present a set of attention techniques to perform polyp segmentation on colonoscopic images.
The main specific contributions are:

PPFormer, a neural network combining transformers and CNN's for global and local feature extraction respectively.
PP-Guided self-attention, a technique used to guide the model to focus on regions that are difficult to classify.
L2G (local to global), a mechanism designed to capture first local then global information in each transformer block.
State-of-the-art results on multiple representative datasets.

Note: ""PP"" refers to a dot product performed in the L2G blocks, P*P, where P is the flattened feature map from a level with smaller resolution."
551	USPoint: Self-Supervised Interest Point Detection and Description for Ultrasound-Probe Motion Estimation during Fine-Adjustment Standard Fetal Plane Finding	This manuscript presents an end-to-end learning method to obtain the relative 3D pose between source and target ultrasound images. The proposed method first extracts interest points with descriptions from two images, finds the best matches with a graph neural network, and applies singular value decomposition to get the final relative 3D pose between the coordinate system where the IMU sensor is installed during data collection. The paper conducted experiments to demonstrate that their method has better feature matching performance than a hand-craft and a learning-based feature matching method. They also compared this proposed method with a regression-based pose estimation method for motion estimation and showed better performance.	In this work, the authors propose a method where they can estimate the relative probe motion from a pair of images, using self-supervised keypoint detection and attentional graph NN to match those keypoints between the source and target image pair. They apply this to fetal Ultrasound (US) images with the intention of being able to guide non-expert users to successfully acquire the desired US view-plane. Once probe motion is reliably estimated, relative to an ideally established probe position for that view-plane, instruction can potentially be given to remedy that deviation from the ideal position. In terms of results, they demonstrate that both their features, and the method, is superior to other methods they compare with.	A feature-based network is for motion estimation of US images is proposed.
552	Vector Quantisation for Robust Segmentation	The paper provides a novel method to make a standard U-Net segmentation model more robust by incorporating a discrete bottleneck using Vector Quantization. The paper claims to perform well within a certain degree of perturbation and domain shift under a certain set of assumptions and also provides a simple theoretical justification for it.	This paper proposes a quantisation block that learns a discrete representation in the embedding space in the bottleneck of UNet architecture to improve the robustness under domain shift and noise perturbations in segmentation models.	This manuscript describes an application of quantized low-dimensional space in medical image segmentation to achieve more robust segmentations.
553	Video-based Surgical Skills Assessment using Long term Tool Tracking	The paper proposed a method to assess the surgeon's skills in minimally invasive surgery. The proposed method is video-based and has two main steps. The first one is creating motion trajectories of the surgical instruments by tracking the their motion in the video. The second step is using these trajectories to classify the skill into two classes; good and poor performance. The proposed method was tested on real surgery videos from the Cholec80 data set.	This paper provides some incremental contributions on algorithms for video-based tracking of surgical procedures.	The manuscript proposes an automated way of assessing a surgeon's skills based on the tool tracking method employed on the video feed. The idea is to track the instruments over a longer time span and use the trajectories to predict skill levels. The proposed tracking model uses a transformer architecture and is evaluated on the Cholec80 dataset with skill ratings provided on Calot Triangle Dissection. The manuscript further compares the transformer method with traditional ML methods like a random forest with the goal of reducing the number of identity switches. The manuscript provides results on both tracking and skills assessment where it outperforms a state-of-the-art tracking method.
554	Vision-Language Contrastive Learning Approach to Robust Automatic Placenta Analysis Using Photographic Images	The author improved current ConVIRT with NegLogCosh (Negative Logarithmic Hyperbolic Cosine ) and sub-feature comparison to address the feature suppression problem. Experiments verified the generalizability and robustness of their method on their placenta dataset.	The main contributions are two-fold: 1. introduces a vision-language contrastive (VLC) framework for pretraining for placenta analysis. 2. introduces a new loss function for training the VLC model and the proposed loss function seems to give better results.	The authors present a vision-language contrastive learning approach to classify placenta images. The method pretrain a generic image encoder using pathology reports and images. The contrastive-learning loss uses a negative logarithmic hyperbolic cosine similarity to avoid shortcut solutions in the model. The pre-training dataset consisted of 10K images and the fine tuning dataset of 2.8K images. The results show that the model outperforms the visual only baseline using resnet and the multimodal conVIRT models.
555	Visual deep learning-based explanation for neuritic plaques segmentation in Alzheimer's Disease using weakly annotated whole slide histopathological images	The authors propose a deep-learning based method for semantic segmentation of taupathies for AD patients. They present a baseline to generate a significant advantage for morphological analysis.	The authors of this paper describe neuritic plaque segmentation using 8 brain whole slide images. The authors try different patch size, different scanners, different stain normalization, and different models (UNet and attention UNet) to segment plaques and improve human annotations.	In this paper, a baseline for semantic segmentation of neuritic plaques in human WSI is proposed. Also, the release of a new expert annotated database as well as the code will be useful for the scientific community to accelerate the development of new pipelines for human WSI processing in AD.
556	Visual explanations for the detection of diabetic retinopathy from retinal fundus images	This submission attempts to maintain highly accurate and improved visual explanations simultaneously for the detection of diabetic retinopathy by combining a plain and an adversarially robust model. The combined model shows better prediction accuracy than the robust model, while with improved visual explanations compared with plain models using experimental results.	"The authors propose an ensemble model (consisting of a baseline model and an adversarially robust model) to mitigate the trade-off between classification performance and quality of visual explanations.
Experiments were performed in three Diabetic Retinopathy (DR) datasets, one of which had DR lesion annotations at pixel level.
They compare the interpretability results obtained between a visual counterfactual explanation and two common saliency map techniques (Guided-Backprop and Integrated Gradients)."	This paper suggest two contributions: the proposal to ensemble a tranditionally-learnt and an adversarially-learnt model together in order to improve interpretability, and an adversarial approach to generating saliency maps.
557	vMFNet: Compositionality Meets Domain-generalised Segmentation	In this paper, the authors developed a 2D semi-supervised vMF-kernel based model for domain generalization segmentation.  The authors also propose to leverage the unlabeled data using a reconstruction module.  The experiments on 2 datasets show ed the superiority of the vMFNet compared to SOTA methods.	The paper present a method for semi-supervised and test-time domain generalization based on the composition of von-Mises-Fisher (vMF) kernels. The proposed method models the distribution of features as a mixture of vMF components. This mixture (clustering) prior is used to regularize training with a loss minimizing the negative log likelihood. This loss is combined with an unsupervised reconstruction loss and a supervised segmentation to learn a representation for segmentation which is more robust to domain shifts. The proposed method is tested on two datasets for cardiac segmentation (M&M) and spinal grey matter segmentation (SCGM), and shows improved performance compared to different baselines.	"A novel architecture and loss function is proposed for domain generalization in medical image segmentation. The novelties are inspired by recent progress in compositional CNNs.
Experiments on multi-center cardiac and spine MRI datasets reveal improved robustness to domain shifts, as compared to several recent domain generalization methods.
The performance is shown to improve further upon training some blocks of the pipeline at test time, using an unsupervised loss that was also used during the initial training."
558	Vol2Flow: Segment 3D Volumes using a Sequence of Registration Flows	This paper presented a self-supervised algorithm for 3D image registration to find 2D displacement fields between all adjacent slices within a whole volume together. The output of Vol2Flow is employed to segment each arbitrary anatomical structure in a 3D medical image by gradually propagating the 2D segmentation mask provided by a user between other slices.	The paper presents an image segmentation method via slice-to-volume label propagation using image registration. It is overall an interesting and novel approach and it has shown to outperform a few other methods in the literature (e.g. fully supervised, other registration methods, etc.).	The paper proposes a method trained to create a 3D segmentation given a single slice manual 2D segmentation. The 2D segmentation is propagated sequentially to neighboring 2D slices using the inter-slice 2D displacement field (flow).  The Flow between all pair of 2D slices is generated by the network, which was trained (self supervised) to align neighboring slides of the train images.
559	Warm Start Active Learning with Proxy Labels & Selection via Semi-Supervised Fine-Tuning	The manuscript deals with the problem of a cold start in active learning. The problem addressed here is which sample we shall start labeling given a set of unlabeled data.	This work applied self-supervised training for cold-start and semi-supervised training for active learning. The pseudo-labels in self-supervised task are collected by thresholding and the task is to perform binary segmentation. The pseudo-labels in the semi-supervised task are collected from the trained network. During the process, images need to be ranked based on network's uncertainty using MC. The proposed method outperformed the baselines on two datasets.	The paper presents a method to label 3D medical image volumes without any labelled data to begin with. A proxy segmentation task on pseudo-labelled data provide uncertainty measure to rank unlabelled data for initial annotation. Following this, a two stage combination of supervised segmentation model and a semi-supervised fine-tuning model take over selection of unlabelled data to be annotated next.
560	WavTrans: Synergizing Wavelet and Cross-Attention Transformer for Multi-Contrast MRI Super-resolution	This paper proposed a joint wavelet and residual cross-attention transformer network for multi-contrast SR reconstruction which tried to restore high-frequency information in the target image with the help of high-resolution reference image. This method is evaluated on two datasets derived from the in-house datasets brain and public dataset fastMRI knee. Comparisons with several previous methods also prove the effectiveness of proposed method.	The paper presents a novely way of synergizing wavelet with swin transformer to obtain super-resolution images from multi-contrast MRI. The ideas proposed are interesting and the obtained results have been compared to various recent methods with an improvement over all of them.	Autorhs propose a novel WavTrans to synergize wavelet transforms with a new cross-attention transformer to tackle the challenges in super-resolution. The proposed method outperforms state-of-the-art methods by a considerable margin with UFs of both 2-fold and 4-fold.
561	Weakly Supervised MR-TRUS Image Synthesis for Brachytherapy of Prostate Cancer	The authors propose a novel weakly supervised learning strategy to train DCLGAN, thus achieving the transition from input MRI images to output TRUS images. Prostate Contour Segmentation and MRI Pattern Exaction are proposed to realize the weakly supervised learning for DCLGAN.	"To cope with low soft tissue contrast and tumor visualization in the prostate area of TRUS imaging, this paper proposes a method that synthesizes TRUS images from unpaired MR images.
Anatomical structural constraints with weakly supervised modules are considered to emphasize the structural content of the synthesized TRUS image."	The paper employs DCLGAN to generate TRUS-styled MR images using weakly supervised learning. This can be applied to LDR prostate brachytherapy planning and treatment. The results show both image quality enhancement and precise segmentation.
562	Weakly Supervised Online Action Detection for Infant General Movements	"This paper presents a method to classify and localize the fidgety movements of infants in videos. To this end, the authors propose a framework consisting of a local feature extraction module from human pose keypoints and two branches of clip-level pseudo labels generation and online action modeling. The proposed system shows an accuracy of 93.8 % in the collected dataset, which is 5.4 % higher than MS-G3D [1].
Liu, Z., Zhang, H., Chen, Z., Wang, Z., Ouyang, W.: Disentangling and unifying graph convolutions for skeleton-based action recognition. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 143-152 (2020)"	"The authors propose an FM online action detector for automated GMA analysis for early medical intervention for cerebral palsy in infants. The proposed MIL loss-based action detector is divided into two branches to enable online learning of the vertex fusion features of the extracted key points. The authors appropriately borrowed the ideas of weakly supervised learning and online action detection to train successful FM detectors.
The authors have built their large-scale datasets for FM detection, but they will not be released to the public."	In paper, the authors have proposed a weakly supervised online action detection framework for infant movements. The proposed framework had been evaluated on 757 videos and can achieve promising results with only clip-level supervision. In addition, the proposed framework is of great importance of clinical use. Only the first 20% duration of the video is needed to get classification results as good as fully observed, suggesting a significant cut of diagnosis time.
563	Weakly Supervised Segmentation by Tensor Graph Learning for Whole Slide Images	"The authors are addressing the well-known challenge of annotating medical data, in this case, the annotation of large-scale Whole Slide Images (WSI) for semantic segmentation. For this, the authors combine the idea of superpixels with sparse point annotations and graph networks. They propose a new architecture with three paths including different approaches (Handcrafted features + graph network, learned features + DL-Classification, learned features + Graph Network).
The overall network architecture is evaluated using two public datasets. They conduct a comparison with other fully-supervised and semi-supervised methods and include an ablation study to the data."	This work propose to 1) use superpixel classification to split patch into super pixels 2) extract features per super pixel, 3) define graphs based on which, multiple losses are defined in addition to segmentation cross entropy loss. One of the additional losses if node classification.	Proposed a weakly supervised network based on tensor graphs for segmentation of whole slide images.
564	Weakly Supervised Volumetric Image Segmentation with Deformed Templates	The authors propose a weakly supervised segmentation method which uses user inputs, a deformable template governed by an active surface model (ASM) through a 3D neural network to segment structures in multiple imaging modalities. The user obtains an initial estimate of the segmentation by initialising the ASM via clicks, and obtains refined predictions by supplying more click. The neural network is used to create complete these updated shapes in response of the clicks. The method is interesting. Experiments highlight advantages.	The paper proposed a novel approach for weakly-supervised volumetric image segmentation, which requires only a few 3D points as training input. The main supervisions are obtained by comparing the segmentation results with a deformable template, and comparing a reconstructed image with the original image.	A method of training networks to segment volumetric images with using only minimal annotations - a sparse set of points.
565	Weakly-supervised Biomechanically-constrained CT/MRI Registration of the Spine	This paper introduces a weakly supervised anatomy aware method for registration of CT & MRI images of the spine.	"The paper proposed a weakly-supervised deep learning framework that preserves the rigidity and the volume of each vertebra while maximizing the accuracy
of the registration. Authors introduced anatomy-aware losses depended
only on the CT vertebra segmentation for training the network.Results show that
adding the anatomy-aware losses increases the plausibility of the inferred transformation while keeping the accuracy untouched."	The paper presents a deep learning-driven deformable registration method using vertebra contour-based DVF rigidity loss, to preserve the local rigidity of the DVF while allowing global deformation.
566	Weakly-supervised High-fidelity Ultrasound Video Synthesis with Feature Decoupling	This paper proposes a framework to generate videos from static content Ultrasound images. This work is based on self- and supervised- learning approaches.  at the first key point detector network is trained in a weakly supervised manner and then a dense motion network is used to learn occlusion and heatmap, finally, an encoder with two outputs (content and texture) is designed to generate a final prediction. A quantitative and qualitative result was demonstrated and compared to other works.	In this paper, the authors proposed a weakly-supervised learning-based framework to synthesize high-fidelity ultrasound videos, by animating the static source images based on the motion of the driving videos.	In this paper, a conditional ultrasound video generation model is proposed. In training phase, the key point and motion module takes source and driving image as input and predict occlusion map, and optical flow. Then the optical flow and occlusion map are used for frame generation, supervised by GAN and reconstruction loss.
567	Weighted Concordance Index Loss-based Multimodal Survival Modeling for Radiation Encephalopathy Assessment in Nasopharyngeal Carcinoma Radiotherapy	"(1)To assess the rationality of nasopharyngeal carcinoma radiotherapy regimen, the author proposed a deep multimodal survival network (MSN) equipped with two feature extractors to learn discriminative features from image and non-image data;
(2)A new WCI loss function is proposed for MSN training, which has temperature hyperparameters that can effectively utilize the REP samples of each batch to help the model converge."	This paper proposes a new multi modality model for predicting radiotherapy-induced radiation encephalopathy (REP). The author proposes a multimodal survival network and a new weighted CI loss function to improve the accuracy of the prediction.	This paper describes a model to predict the risk at 36 months for developing radiation encephalopathy (REP) in patients diagnosed with nasopharyngeal carcinoma (NPC) and treated with radiotherapy. The model was trained using image data (CT and RT) fed to a multimodal survival network and non-image diagnostic data fed to a multilayer perceptron model. The outputs from the two networks were weighted and summed to provide a final risk value. The data used to train, test, and validate the model was used from the time of treatment for a pool of n=4,816 patients. The model was implemented and tested using multiple different loss functions, including their own novel weighted concordance index loss function. The author's novel WCI loss function resulted in the trained model that had the highest measured CI and AUC values compared to the same model trained with 5 other loss functions.
568	What can we learn about a generated image corrupting its latent representation?	This paper presents a noise injection technique that allows generating multiple outputs, thus quantifying the differences between these outputs and providing a confidence score that can be used to determine the uncertain parts of the generated image, the quality of the generated sample, and to some extent their impact on a downstream task.	"Proposing noise injection technique for testing latent representation;
Proposing two metrics to calculate uncertainty for synthesized images;
Validating the hypothesis that robust latent representation leads to better quality of generated image.
Small noise injections during the training phase lead to more robust representation and slightly higher image quality."	the authors investigated the hypothesis that we the image quality can be predicted based on its latent representation in the GANs bottleneck.The authors presented a method using latent representation corruption with noise as such that multiple outputs can be generated to obtain uncertainty. The results demonstrated in this paper show that the method has the ability to predict uncertain parts of synthesized images, and identify samples that may not be reliable for downstream tasks.
569	What Makes for Automatic Reconstruction of Pulmonary Segments	This paper describes the definitions of the anatomy of pulmonary segments and the definition of dice score in segmentation metric. This paper also provides a convolutional deep network called ImPulse for the segmentation task	"The authors present a method for the automatic reconstruction of lung segments using deep learning. 
First the authors formulate the problem in a concise manner. Second they propose a deep-learning method for lung segment reconstruction that is not based on pixel-wise assessment. Instead, they authors probe different locations of the lung segment border and report a class for such continuous locations.
The authors show the performance of the method in a database of 800 CT scans from multiple medical centres with a data split 7:1:2. The proposed implicit method achieves better performance than end-to-end networks. 
Further experiments show the performance of the method when detecting bronchi and arteries."	The authors propose an implicit-function-based model for the pulmonary segment reconstruction, that makes the pulmonary anatomical lobe segmentation further. The anatomy of pulmonary segments are defined. Then, the implicit pulmonary segmentation (ImPulSe) is proposed. In the experiments, the ImPulSe achieves better performance and uses less training time, comparing to the fully-convolutional methods like UNet.
570	White Matter Tracts are Point Clouds: Neuropsychological Score Prediction and Critical Region Localization via Geometric Deep Learning	The authors present a new approach for predicting neuropsychological assessments scores from brain MRI data using a point representation of individual white matter fiber tracts. The approach uses a point-based siamese network adapted from PointNet. Their approach further enables the identification of areas in the input point cloud that are critical for the prediction. They evaluate their approach against classic along-tract analysis as well as a simple analysis of the tract specific mean values of the used feature maps. Their results are in line with previous research and they claim better performance.	This work proposes a novel framework for predicting neuropsychological scores, which represent fiber bundles as point clouds, and then preserve point information about diffusion measurements and enable efficient processing using point-based deep neural networks.	This work presents a deep network for neuropsychological score prediction based on point cloud representation of white matter tract features. The proposed network is trained by using a Paired-Siamese cost in addition to the MSE loss. The results of prediction compare favorably to traditional measures and a 1D network defined on tractometry. Based on this network, a critical region localization algorithm is proposed to detect the informative anatomical regions relevant to language processing.
571	Whole Slide Cervical Cancer Screening Using Graph Attention Network and Supervised Contrastive Learning	The authors propose a cervical cancer screening method based on whole slide images. Specifically, they use graph attention network to aggregate the features from representative patches and use supervised contrastive learning to enhance the separability of graph representations.	The authors worked on Graph Attention Network and Supervised Contrastive Learning algorithms for the whole slide cervical cancer screening.	This paper proposes to utilize the relationships between suspicious patches in whole slide images for classification. Graph attention network describes and extracts connections among suspicious patches. A loss function is designed to enlarge latent distances for positive WSIs and reduce latent distances for negative WSIs.
572	Why patient data cannot be easily forgotten?	The paper discusses the problem of machine unlearning of patient-wise data from ML models. A targeted forgetting approach is presented and evaluated on cardiac MRI data (and compared to a computer vision application).	"This paper addresses the problem of forgetting patient data in a DL model when for example patient consent is withdrawn. The problem is phrased as patient-wise forgetting, i.e. one patient (all images of the patient) is selected to be forgotten. They formulate two hypothesis: the patient's data is similar to other data (common cluster hypothesis) and the patient's data is different to other data (rare case, edge case). They show that the common cluster hypothesis holds often for computer vision data, while the edge case is more common in medical image data. They propose a new approach for forgetting edge-case patient data.
The hypothesis and method is evaluated on CIFAR-10 and the ACDC dataset."	In this paper the authors propose an framework that can be used to forget a patient's imaging data from AI models. The proposed approach divides patient data in two categories: edge cases and common cases. The authors claim that the proposed framework outperforms related work when edge cases need to be removed/forgotten.
573	XMorpher: Full Transformer for Deformable Medical Image Registration via Cross Attention	This paper proposed a full transformer architecture to extend the cross-attention transformer to establish the attention mechanism between images for the multi-level semantic correspondence.	The authors introduced a parallel transformer backbone, XMorpher, for image registration task. Different to current CNN-based registration network which moving-fixed image feature fusion first or fusion last, the proposed method utilized a cross-attention block to fuse the moving-fixed feature in multi-level progressively.	The paper proposed a transformer architecture called XMorpher for DMIR. XMorpher includes dual parallel network to extract image features of the fixed and the moving image. Then, at each level the Cross Attention Transformer (CAT) blocks compute the mutual relevance between extracted features and match the corresponding regions to obtain the fine DVF. Results show some improvement compared to other methods.
574	Y-Net: A Spatiospectral Dual-Encoder Network for Medical Image Segmentation	"-- The paper proposes a novel framework for combining spectral and spatial features for OCT layer and fluid segmentation.
-- The method is evaluated on public dataset with performance gain of 1.9% over other methods."	"The paper proposes an end-to-end conditional OCT layer segmentation network, which actually is an '""U-net"" like model  with an additional Fast Fourier Block branches. Furthermore, the segmentation experimental result does reach the state-of-the-art performance. "	The authors proposed an architecture for  retinal OCT segmentation, which was consists of a spatial encoder, a spectral encoder and a spatial decoder.   The proposed method was evaluated on a public dataset, experimental results showed that proposed model outperforms existing models in fluid segmentation retinal layer segmentation.
